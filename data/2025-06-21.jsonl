{"id": "2506.15174", "pdf": "https://arxiv.org/pdf/2506.15174", "abs": "https://arxiv.org/abs/2506.15174", "authors": ["Hossein Albakri", "Kazem Cheshmi"], "title": "A Novel Compiler Transformation for Fast Sparse Matrix Multiplication in GPUs", "categories": ["cs.PL"], "comment": null, "summary": "Sparse data structures are commonly used in neural networks to reduce the\nmemory footprint. These data structures are compact but cause irregularities\nsuch as random memory accesses, which prevent efficient use of the memory\nhierarchy. GPUs are a common platform for machine learning practitioners, but\nrunning compact data structures on these devices often leads to slow-downs due\nto inefficient use of computing and memory resources. This paper proposes a new\ncompiler transformation, enumerate-and-sparse-coarsen, that accelerates sparse\nmatrix-matrix multiplication (SPMM) on GPU devices. The transformation\nincreases data reuse in registers and caches while creating more balanced\nworkloads for GPU computing resources. The transformation is tested on sparse\nneural networks in convolutional and transformer models. On an A100 GPU and\nacross a columns of matrix B (bCols) in $ A \\times B = C$ from range of 32 to\n128, the transformation yields a geometric mean speedup of 1.84$\\times$ to\n2.27$\\times$ compared to cuBLAS and cuSPARSE baselines, respectively."}
{"id": "2506.15424", "pdf": "https://arxiv.org/pdf/2506.15424", "abs": "https://arxiv.org/abs/2506.15424", "authors": ["Michael Mendler", "Marc Pouzet"], "title": "PSM: Policy Synchronised Deterministic Memory", "categories": ["cs.PL"], "comment": "This report summarises work on coding the theory of\n  policy-synchronised memory (see https://rdcu.be/erBwl) in Haskell. This was\n  developed for a graduate level course on Functional Reactive Programming\n  taught at Bamberg University by the first author during 2020-2023. An early\n  version of the PSM library had been presented at the SYNCHRON Workshop\n  (Aussois, France), November 2019", "summary": "Concurrency and determinacy do not go well with each other when resources\nmust be shared. Haskell provides parallel programming abstractions such as IVar\nand LVar in the Par monad and concurrent abstractions such as MVar and TVar in\nthe in IO and STM monads, respectively. The former are determinate but have no\ndestructive updates and the latter have destructive updates but do not\nguarantee determinacy. Programming patterns that are both concurrent and\ndeterminate, such as those provided by Kahn or Berry require memory\nabstractions at a higher level than is currently available. In this paper we\ndescribe a new type context PSM for policy synchronised memory in Haskell. Like\nSTM and IO, the computations in PSM can access persistent state and, as a\nside-effect, update the memory in imperative style. Like the Par and IO monads,\nPSM supports concurrent threads and shared state. However, in contrast to IO,\nour PSM contexts are race-free since concurrent accesses are policy coordinated\nwhich guarantees determinacy.Well-typed transactions in the PSM context can\naccommodate abstract data structures that are imperative, concurrently\nshareable and still behave deterministically, by construction."}
{"id": "2506.15135", "pdf": "https://arxiv.org/pdf/2506.15135", "abs": "https://arxiv.org/abs/2506.15135", "authors": ["Zhengqun Koo"], "title": "Towards Bug-Free Distributed Go Programs", "categories": ["cs.SE", "cs.LO", "cs.PL", "F.3.1; F.1.2"], "comment": "Version 1. B.Comp. Dissertation", "summary": "Programmers of distributed systems need to reason about concurrency to avoid\nraces. However, reasoning about concurrency is difficult, and unexpected races\nshow up as bugs. Data race detection in shared memory systems is well-studied\n(dynamic data race detection [13], behavioral types [15], dynamic race\ndetection [31]). Similar to how a data race consists of reads and writes not\nrelated by happens-before at a shared memory location, a communication race\nconsists of receives and sends not related by happens-before on a shared\nchannel. Communication races are problematic: a receiver expects a specific\nmessage from a specific sender, but with a communication race, the receiver can\nreceive a message meant for another receiver, or not receive anything at all.\nIn this work, we describe a verification framework that can prove the absence\nof communication races for distributed programs that use a subset of the Go\nprogramming language, where synchronization is mainly achieved via message\npassing. We statically reason about how a distributed program executes, using a\nhappens-before order, extended to buffered and unbuffered channels."}
