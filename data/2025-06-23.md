<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [A System Level Compiler for Massively-Parallel, Spatial, Dataflow Architectures](https://arxiv.org/abs/2506.15875)
*Dirk Van Essendelft,Patrick Wingo,Terry Jordan,Ryan Smith,Wissam Saidi*

Main category: cs.PL

TL;DR: MACH是一种新型编译器，专为大规模并行、空间数据流架构设计，同时支持传统统一内存设备。它通过虚拟机和领域特定语言简化了空间架构的编译复杂性。


<details>
  <summary>Details</summary>
Motivation: 解决空间架构编译的复杂性，提供跨架构的灵活性和兼容性。

Method: 采用虚拟机概念、领域特定语言和编译器，将高级语言转换为机器特定代码。

Result: 成功展示了从NumPy密集张量到Wafer Scale Engine的代码转换。

Conclusion: MACH为空间架构编译提供了高效灵活的解决方案，并展示了实际应用潜力。

Abstract: We have developed a novel compiler called the Multiple-Architecture Compiler
for Advanced Computing Hardware (MACH) designed specifically for
massively-parallel, spatial, dataflow architectures like the Wafer Scale
Engine. Additionally, MACH can execute code on traditional unified-memory
devices. MACH addresses the complexities in compiling for spatial architectures
through a conceptual Virtual Machine, a flexible domain-specific language, and
a compiler that can lower high-level languages to machine-specific code in
compliance with the Virtual Machine concept. While MACH is designed to be
operable on several architectures and provide the flexibility for several
standard and user-defined data mappings, we introduce the concept with dense
tensor examples from NumPy and show lowering to the Wafer Scale Engine by
targeting Cerebras' hardware specific languages.

</details>


### [2] [WAMI: Compilation to WebAssembly through MLIR without Losing Abstraction](https://arxiv.org/abs/2506.16048)
*Byeongjee Kang,Harsh Desai,Limin Jia,Brandon Lucia*

Main category: cs.PL

TL;DR: 本文提出了一种基于MLIR的新型WebAssembly（Wasm）编译流水线，通过设计Wasm方言直接生成高级Wasm代码，避免了抽象丢失，并在性能上接近或优于基于LLVM的编译器。


<details>
  <summary>Details</summary>
Motivation: 现有的Wasm编译方法要么缺乏可重用设计，要么因降低高级构造为低级表示（如LLVM IR）而丢失抽象，阻碍了高级特性的采用。

Method: 利用MLIR的多层次抽象能力，设计Wasm方言以直接生成高级Wasm代码，并通过案例研究展示了其可扩展性。

Result: 在PolyBench基准测试中，新流水线生成的代码性能最多比基于LLVM的编译器慢7.7%，在某些环境下更快。

Conclusion: 该方法提供了一种模块化和可扩展的方式，支持高级Wasm特性，同时保持了性能竞争力。

Abstract: WebAssembly (Wasm) is a portable bytecode format that serves as a compilation
target for high-level languages, enabling their secure and efficient execution
across diverse platforms, including web browsers and embedded systems. To
improve support for high-level languages without incurring significant code
size or performance overheads, Wasm continuously evolves by integrating
high-level features such as Garbage Collection and Stack Switching. However,
existing compilation approaches either lack reusable design -- requiring
redundant implementation efforts for each language -- or lose abstraction by
lowering high-level constructs into low-level shared representations like LLVM
IR, which hinder the adoption of high-level features. MLIR compiler
infrastructure provides the compilation pipeline with multiple levels of
abstraction, preserving high-level abstractions throughout the compilation
pipeline, yet the current MLIR pipeline relies on the LLVM backend for Wasm
code generation, thereby inheriting LLVM's limitations.
  This paper presents a novel compilation pipeline for Wasm, featuring Wasm
dialects explicitly designed to represent high-level Wasm constructs within
MLIR. Our approach enables direct generation of high-level Wasm code from
corresponding high-level MLIR dialects without losing abstraction, providing a
modular and extensible way to incorporate high-level Wasm features. We
illustrate this extensibility through a case study that leverages Stack
Switching, a recently introduced high-level feature of Wasm. Performance
evaluations on PolyBench benchmarks show that our pipeline, benefiting from
optimizations within the MLIR and Wasm ecosystems, produces code with at most
7.7\% slower, and faster in some execution environments, compared to LLVM-based
compilers.

</details>


### [3] [Low Overhead Allocation Sampling in a Garbage Collected Virtual Machine](https://arxiv.org/abs/2506.16883)
*Christoph Jung,C. F. Bolz-Tereick*

Main category: cs.PL

TL;DR: 提出了一种采样分配分析器，集成到PyPy的垃圾回收器中，显著降低了分析开销。


<details>
  <summary>Details</summary>
Motivation: 动态类型语言中分配分析比时间分析更有效，但全部分配分析效率低。

Method: 在PyPy的垃圾回收器中集成采样分配分析器，可调节采样周期。

Result: 采样周期为4MB时，最大时间开销为25%。

Conclusion: 该方法在低开销下实现了高效的分配分析。

Abstract: Compared to the more commonly used time-based profiling, allocation profiling
provides an alternate view of the execution of allocation heavy dynamically
typed languages. However, profiling every single allocation in a program is
very inefficient. We present a sampling allocation profiler that is deeply
integrated into the garbage collector of PyPy, a Python virtual machine. This
integration ensures tunable low overhead for the allocation profiler, which we
measure and quantify. Enabling allocation sampling profiling with a sampling
period of 4 MB leads to a maximum time overhead of 25% in our benchmarks, over
un-profiled regular execution.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Floating-Point Neural Networks Are Provably Robust Universal Approximators](https://arxiv.org/abs/2506.16065)
*Geonho Hwang,Wonyeol Lee,Yeachan Park,Sejun Park,Feras Saad*

Main category: cs.LG

TL;DR: 本文提出了第一个适用于浮点神经网络的区间通用逼近定理（IUA），证明了其在浮点计算环境下仍能完美逼近目标函数的直接图像映射。


<details>
  <summary>Details</summary>
Motivation: 经典通用逼近定理假设神经网络在无限精度的实数上计算，而实际软件实现使用有限精度的浮点数。本文旨在探讨浮点神经网络是否仍满足IUA定理。

Method: 通过理论分析，证明了浮点神经网络在浮点计算环境下仍能完美逼近目标函数的直接图像映射。

Result: 浮点神经网络在浮点环境下仍具有强大的表达能力，且与实数环境下的IUA定理存在本质差异。此外，还得出了一些意外推论。

Conclusion: 浮点神经网络在浮点计算环境下仍满足IUA定理，且其表达能力不受限制，同时揭示了浮点计算模型的独特性质。

Abstract: The classical universal approximation (UA) theorem for neural networks
establishes mild conditions under which a feedforward neural network can
approximate a continuous function $f$ with arbitrary accuracy. A recent result
shows that neural networks also enjoy a more general interval universal
approximation (IUA) theorem, in the sense that the abstract interpretation
semantics of the network using the interval domain can approximate the direct
image map of $f$ (i.e., the result of applying $f$ to a set of inputs) with
arbitrary accuracy. These theorems, however, rest on the unrealistic assumption
that the neural network computes over infinitely precise real numbers, whereas
their software implementations in practice compute over finite-precision
floating-point numbers. An open question is whether the IUA theorem still holds
in the floating-point setting.
  This paper introduces the first IUA theorem for floating-point neural
networks that proves their remarkable ability to perfectly capture the direct
image map of any rounded target function $f$, showing no limits exist on their
expressiveness. Our IUA theorem in the floating-point setting exhibits material
differences from the real-valued setting, which reflects the fundamental
distinctions between these two computational models. This theorem also implies
surprising corollaries, which include (i) the existence of provably robust
floating-point neural networks; and (ii) the computational completeness of the
class of straight-line programs that use only floating-point additions and
multiplications for the class of all floating-point programs that halt.

</details>
