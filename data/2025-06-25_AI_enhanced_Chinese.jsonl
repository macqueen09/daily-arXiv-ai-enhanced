{"id": "2506.18923", "pdf": "https://arxiv.org/pdf/2506.18923", "abs": "https://arxiv.org/abs/2506.18923", "authors": ["Yifan Zong", "Yuntian Deng", "Pengyu Nie"], "title": "Mix-of-Language-Experts Architecture for Multilingual Programming", "categories": ["cs.PL", "cs.CL", "cs.SE"], "comment": "Accepted at LLM4Code @ ICSE 2025", "summary": "Large language models (LLMs) have demonstrated impressive capabilities in\naiding developers with tasks like code comprehension, generation, and\ntranslation. Supporting multilingual programming -- i.e., coding tasks across\nmultiple programming languages -- typically requires either (1) finetuning a\nsingle LLM across all programming languages, which is cost-efficient but\nsacrifices language-specific specialization and performance, or (2) finetuning\nseparate LLMs for each programming language, which allows for specialization\nbut is computationally expensive and storage-intensive due to the duplication\nof parameters. This paper introduces MoLE (Mix-of-Language-Experts), a novel\narchitecture that balances efficiency and specialization for multilingual\nprogramming. MoLE is composed of a base model, a shared LoRA (low-rank\nadaptation) module, and a collection of language-specific LoRA modules. These\nmodules are jointly optimized during the finetuning process, enabling effective\nknowledge sharing and specialization across programming languages. During\ninference, MoLE automatically routes to the language-specific LoRA module\ncorresponding to the programming language of the code token being generated.\nOur experiments demonstrate that MoLE achieves greater parameter efficiency\ncompared to training separate language-specific LoRAs, while outperforming a\nsingle shared LLM finetuned for all programming languages in terms of accuracy.", "AI": {"tldr": "MoLE\u67b6\u6784\u901a\u8fc7\u7ed3\u5408\u5171\u4eab\u548c\u8bed\u8a00\u7279\u5b9a\u7684LoRA\u6a21\u5757\uff0c\u5e73\u8861\u4e86\u591a\u8bed\u8a00\u7f16\u7a0b\u7684\u6548\u7387\u4e0e\u4e13\u4e1a\u6027\u3002", "motivation": "\u89e3\u51b3\u591a\u8bed\u8a00\u7f16\u7a0b\u4e2d\u5355\u4e00\u6a21\u578b\u6548\u7387\u4f4e\u6216\u4e13\u7528\u6a21\u578b\u8d44\u6e90\u6d88\u8017\u5927\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u57fa\u7840\u6a21\u578b\u3001\u5171\u4eabLoRA\u6a21\u5757\u548c\u8bed\u8a00\u7279\u5b9aLoRA\u6a21\u5757\uff0c\u8054\u5408\u4f18\u5316\u5e76\u52a8\u6001\u8def\u7531\u3002", "result": "MoLE\u5728\u53c2\u6570\u6548\u7387\u4e0a\u4f18\u4e8e\u4e13\u7528\u6a21\u578b\uff0c\u5728\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u5171\u4eab\u6a21\u578b\u3002", "conclusion": "MoLE\u5728\u591a\u8bed\u8a00\u7f16\u7a0b\u4e2d\u5b9e\u73b0\u4e86\u6548\u7387\u4e0e\u6027\u80fd\u7684\u5e73\u8861\u3002"}}
{"id": "2506.19457", "pdf": "https://arxiv.org/pdf/2506.19457", "abs": "https://arxiv.org/abs/2506.19457", "authors": ["Tom T. P. Franken", "Thomas Neele", "Jan Friso Groote"], "title": "The Autonomous Data Language -- Concepts, Design and Formal Verification", "categories": ["cs.PL", "cs.DC", "D.3.1; F.3.1; F.3.2"], "comment": "48 pages, preprint submitted to Elsevier", "summary": "Nowadays, the main advances in computational power are due to parallelism.\nHowever, most parallel languages have been designed with a focus on processors\nand threads. This makes dealing with data and memory in programs hard, which\ndistances the implementation from its original algorithm. We propose a new\nparadigm for parallel programming, the data-autonomous paradigm, where\ncomputation is performed by autonomous data elements. Programs in this paradigm\nare focused on making the data collaborate in a highly parallel fashion. We\nfurthermore present AuDaLa, the first data autonomous programming language, and\nprovide a full formalisation that includes a type system and operational\nsemantics. Programming in AuDaLa is very natural, as illustrated by examples,\nalbeit in a style very different from sequential and contemporary parallel\nprogramming. Additionally, it lends itself for the formal verification of\nparallel programs, which we demonstrate.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5e76\u884c\u7f16\u7a0b\u8303\u5f0f\u2014\u2014\u6570\u636e\u81ea\u6cbb\u8303\u5f0f\uff0c\u5176\u4e2d\u8ba1\u7b97\u7531\u81ea\u6cbb\u6570\u636e\u5143\u7d20\u6267\u884c\uff0c\u5e76\u4ecb\u7ecd\u4e86\u9996\u4e2a\u6570\u636e\u81ea\u6cbb\u7f16\u7a0b\u8bed\u8a00AuDaLa\u53ca\u5176\u5f62\u5f0f\u5316\u5b9a\u4e49\u3002", "motivation": "\u5f53\u524d\u5e76\u884c\u8bed\u8a00\u4e3b\u8981\u5173\u6ce8\u5904\u7406\u5668\u548c\u7ebf\u7a0b\uff0c\u5bfc\u81f4\u6570\u636e\u5904\u7406\u590d\u6742\uff0c\u4e0e\u539f\u59cb\u7b97\u6cd5\u8131\u8282\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u81ea\u7136\u7684\u6570\u636e\u534f\u4f5c\u65b9\u5f0f\u3002", "method": "\u63d0\u51fa\u6570\u636e\u81ea\u6cbb\u8303\u5f0f\uff0c\u5f00\u53d1AuDaLa\u8bed\u8a00\uff0c\u5305\u62ec\u7c7b\u578b\u7cfb\u7edf\u548c\u64cd\u4f5c\u8bed\u4e49\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u5c55\u793a\u5176\u7f16\u7a0b\u98ce\u683c\u3002", "result": "AuDaLa\u7f16\u7a0b\u66f4\u81ea\u7136\uff0c\u652f\u6301\u5e76\u884c\u7a0b\u5e8f\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002", "conclusion": "\u6570\u636e\u81ea\u6cbb\u8303\u5f0f\u4e3a\u5e76\u884c\u7f16\u7a0b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0cAuDaLa\u8bed\u8a00\u5c55\u793a\u4e86\u5176\u6f5c\u529b\u3002"}}
