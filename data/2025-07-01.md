<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 3]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Verifying Properties of Index Arrays in a Purely-Functional Data-Parallel Language](https://arxiv.org/abs/2506.23058)
*Nikolaj Hey Hinnerskov,Robert Schenck,Cosmin E. Oancea*

Main category: cs.PL

TL;DR: 提出一种新方法，通过索引函数表示数组，自动验证纯数据并行程序的属性，并利用代数不等式求解器进行推理。


<details>
  <summary>Details</summary>
Motivation: 解决纯数据并行程序中非线性索引属性的自动验证问题，扩展编译器优化能力。

Method: 将数组表示为索引函数，通过代数不等式求解器验证属性，适用于Futhark语言。

Result: 在7个应用中平均验证时间为1秒，动态验证消除可显著提升GPU程序性能。

Conclusion: 该方法实用且高效，能扩展编译器优化范围，适用于实际应用。

Abstract: This paper presents a novel approach to automatically verify properties of
pure data-parallel programs with non-linear indexing -- expressed as pre- and
post-conditions on functions. Programs consist of nests of second-order array
combinators (e.g., map, scan, and scatter) and loops. The key idea is to
represent arrays as index functions: programs are index function
transformations over which properties are propagated and inferred. Our
framework proves properties on index functions by distilling them into
algebraic (in)equalities and discharging them to a Fourier-Motzkin-based
solver. The framework is practical and accessible: properties are not
restricted to a decidable logic, but instead are carefully selected to express
practically useful guarantees that can be automatically reasoned about and
inferred. These guarantees extend beyond program correctness and can be
exploited by the entire compiler pipeline for optimization. We implement our
system in the pure data-parallel language Futhark and demonstrate its
practicality on seven applications, reporting an average verification time of 1
second. Two case studies show how eliminating dynamic verification in GPU
programs results in significant speedups.

</details>


### [2] [A Denotational Semantics for Quantum Loops](https://arxiv.org/abs/2506.23320)
*Nicola Assolini,Alessandra Di Pierro*

Main category: cs.PL

TL;DR: 本文提出了一种用于高级量子编程结构的指称语义，重点研究量子控制分支和迭代的概念意义。


<details>
  <summary>Details</summary>
Motivation: 量子计算机编程需要在不同抽象层次上实现量子算法，本文旨在为量子控制流提供数学定义。

Method: 引入了一个指称域，用于定义量子控制流（包括循环）的数学意义，反映量子程序的相干演化。

Result: 提出了一种能够描述量子控制流和循环的语义框架。

Conclusion: 该指称语义为量子编程提供了理论基础，支持量子控制流和循环的数学建模。

Abstract: Programming a quantum computer, i.e., implementing quantum algorithms on a
quantum processor-based copmputer architecture, is a task that can be addressed
(just as for classical computers) at different levels of abstraction. This
paper proposes a denotational semantics for high-level quantum programming
constructs, focusing on the conceptual meaning of quantum-controlled branching
and iteration. We introduce a denotational domain where a mathematical meaning
of a quantum control flow with loops can be defined, which reflects the
coherent evolution of the quantum system implementing the program.

</details>


### [3] [Compiling a Q# Subset to QASM 3.0 in TypeScript via a JSON Based IR](https://arxiv.org/abs/2506.23407)
*Marcus Edwards*

Main category: cs.PL

TL;DR: 实现了从Q#到QASM 3.0的编译工具链，包括完整的词法分析和语法分析器，支持部分Q#功能。


<details>
  <summary>Details</summary>
Motivation: 为在Web环境中实现Q#功能，开发了一个基于TypeScript的编译工具链。

Method: 实现了词法分析器、语法分析器和编译器，支持部分Q#功能，并与现有工具进行比较。

Result: 工具链成功处理多种Q#程序，验证了其功能。

Conclusion: 该工具链为Web环境提供了Q#编译功能，区别于微软的官方实现。

Abstract: We implement a compile toolchain from Q# to QASM 3.0 including a
full-featured lexer and parser implementation, as well as a compiler that
supports a subset of Q# features. The lexer, parser and compiler are shown to
work with various input Q# programs and the implementation is compared against
existing Q# compile tools. Unlike the Microsoft implementation of the official
Q# compile toolchain, our implementation is written in TypeScript in order to
port functionality to web environments.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation](https://arxiv.org/abs/2506.22776)
*Sen Fang,Weiyuan Ding,Antonio Mastropaolo,Bowen Xu*

Main category: cs.SE

TL;DR: 量化技术能压缩大型语言模型（LLM），减少内存需求并加速推理，但其对鲁棒性的影响尚未充分研究。本文首次系统研究了量化对LLM在代码生成任务中鲁棒性的影响，发现量化后的模型往往比全精度模型更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 量化技术被广泛用于压缩LLM，但其对模型鲁棒性的影响尚未被充分探索。本文旨在填补这一空白，研究量化如何影响LLM在代码生成任务中的鲁棒性。

Method: 通过实验评估四种主流LLM家族（LLaMA、DeepSeek、CodeGen和StarCoder），参数规模从350M到33B，从对抗攻击和噪声扰动两个角度量化鲁棒性。

Result: 量化后的LLM在对抗攻击和噪声扰动实验中表现优于全精度模型，51.59%的对抗实验和噪声扰动实验显示量化模型更具鲁棒性。

Conclusion: 量化不仅能降低计算需求，还能增强LLM在代码生成任务中的鲁棒性，为开发更高效和可靠的LLM部署策略提供了新思路。

Abstract: Quantization has emerged as a mainstream method for compressing Large
Language Models (LLMs), reducing memory requirements and accelerating inference
without architectural modifications. While existing research primarily focuses
on evaluating the effectiveness of quantized LLMs compared to their original
counterparts, the impact on robustness remains largely unexplored.In this
paper, we present the first systematic investigation of how quantization
affects the robustness of LLMs in code generation tasks. Through extensive
experiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and
StarCoder) with parameter scales ranging from 350M to 33B, we evaluate
robustness from dual perspectives: adversarial attacks on input prompts and
noise perturbations on model architecture. Our findings challenge conventional
wisdom by demonstrating that quantized LLMs often exhibit superior robustness
compared to their full-precision counterparts, with 51.59% versus 42.86% of our
adversarial experiments showing better resilience in quantized LLMs. Similarly,
our noise perturbation experiments also confirm that LLMs after quantitation
generally withstand higher levels of weight disturbances. These results suggest
that quantization not only reduces computational requirements but can actually
enhance LLMs' reliability in code generation tasks, providing valuable insights
for developing more robust and efficient LLM deployment strategies.

</details>


### [5] [On the Feasibility of Deduplicating Compiler Bugs with Bisection](https://arxiv.org/abs/2506.23281)
*Xintong Zhou,Zhenyang Xu,Chengnian Sun*

Main category: cs.SE

TL;DR: 本文提出了一种基于二分法的编译器Bug去重方法BugLens，显著优于现有基于程序分析的方法。


<details>
  <summary>Details</summary>
Motivation: 随机测试中重复的测试程序暴露相同编译器Bug，现有去重方法计算开销大且泛化能力有限。

Method: 利用二分法定位导致Bug的提交，并结合触发Bug的优化技术，提出BugLens方法。

Result: 在四个真实数据集上，BugLens比Tamer和D3分别节省26.98%和9.64%的人力。

Conclusion: 二分法因其简单性和泛化能力，为编译器Bug去重提供了实用解决方案。

Abstract: Random testing has proven to be an effective technique for compiler
validation. However, the debugging of bugs identified through random testing
presents a significant challenge due to the frequent occurrence of duplicate
test programs that expose identical compiler bugs. The process to identify
duplicates is a practical research problem known as bug deduplication. Prior
methodologies for compiler bug deduplication primarily rely on program analysis
to extract bug-related features for duplicate identification, which can result
in substantial computational overhead and limited generalizability. This paper
investigates the feasibility of employing bisection, a standard debugging
procedure largely overlooked in prior research on compiler bug deduplication,
for this purpose. Our study demonstrates that the utilization of bisection to
locate failure-inducing commits provides a valuable criterion for
deduplication, albeit one that requires supplementary techniques for more
accurate identification. Building on these results, we introduce BugLens, a
novel deduplication method that primarily uses bisection, enhanced by the
identification of bug-triggering optimizations to minimize false negatives.
Empirical evaluations conducted on four real-world datasets demonstrate that
BugLens significantly outperforms the state-of-the-art analysis-based
methodologies Tamer and D3 by saving an average of 26.98% and 9.64% human
effort to identify the same number of distinct bugs. Given the inherent
simplicity and generalizability of bisection, it presents a highly practical
solution for compiler bug deduplication in real-world applications.

</details>


### [6] [What Challenges Do Developers Face When Using Verification-Aware Programming Languages?](https://arxiv.org/abs/2506.23696)
*Francisco Oliveira,Alexandra Mendes,Carolina Carreira*

Main category: cs.SE

TL;DR: 研究探讨了验证感知（VA）语言采用率低的原因，通过分析开发者讨论和调查，发现学习曲线陡峭和可用性问题，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 尽管验证感知（VA）语言提供更强的正确性保证，但其采用率仍然有限，研究旨在探索阻碍其采用的原因。

Method: 通过主题建模技术分析开发者论坛讨论，并辅以开发者调查，了解VA语言的实际挑战。

Result: 研究发现主要障碍包括学习曲线陡峭和可用性问题，建议简化工具界面、提供更好的教育材料和改进开发环境集成。

Conclusion: 研究为提升VA语言可用性和验证工具的可访问性提供了可行的建议。

Abstract: Software reliability is critical in ensuring that the digital systems we
depend on function correctly. In software development, increasing software
reliability often involves testing. However, for complex and critical systems,
developers can use Design by Contract (DbC) methods to define precise
specifications that software components must satisfy. Verification-Aware (VA)
programming languages support DbC and formal verification at compile-time or
run-time, offering stronger correctness guarantees than traditional testing.
However, despite the strong guarantees provided by VA languages, their adoption
remains limited. In this study, we investigate the barriers to adopting VA
languages by analyzing developer discussions on public forums using topic
modeling techniques. We complement this analysis with a developer survey to
better understand the practical challenges associated with VA languages. Our
findings reveal key obstacles to adoption, including steep learning curves and
usability issues. Based on these insights, we identify actionable
recommendations to improve the usability and accessibility of VA languages. Our
findings suggest that simplifying tool interfaces, providing better educational
materials, and improving integration with everyday development environments
could improve the usability and adoption of these languages. Our work provides
actionable insights for improving the usability of VA languages and making
verification tools more accessible.

</details>
