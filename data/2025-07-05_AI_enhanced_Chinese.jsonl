{"id": "2507.02226", "pdf": "https://arxiv.org/pdf/2507.02226", "abs": "https://arxiv.org/abs/2507.02226", "authors": ["Mohammad Akyash", "Kimia Azar", "Hadi Kamali"], "title": "DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs", "categories": ["cs.PL", "cs.AR", "cs.LG"], "comment": "Accepted to the International Conference on Computer-Aided Design\n  (ICCAD 2025)", "summary": "As one of their many applications, large language models (LLMs) have recently\nshown promise in automating register transfer level (RTL) code generation.\nHowever, conventional LLM decoding strategies, originally designed for natural\nlanguage, often fail to meet the structural and semantic demands of RTL,\nleading to hallucinated, repetitive, or invalid code outputs. In this paper, we\nfirst investigate the root causes of these decoding failures through an\nempirical analysis of token-level entropy during RTL generation. Our findings\nreveal that LLMs exhibit low confidence in regions of structural ambiguity or\nsemantic complexity, showing that standard decoding strategies fail to\ndifferentiate between regions requiring determinism (syntax-critical regions)\nand those that benefit from creative exploratory variability (design-critical\nregions). Then, to overcome this, we introduce DecoRTL, a novel run-time\ndecoding strategy, that is both syntax-aware and contrastive for RTL code\ngeneration. DecoRTL integrates two complementary components: (i)\nself-consistency sampling, which generates multiple candidates and re-ranks\nthem based on token-level agreement to promote correctness while maintaining\ndiversity; and (ii) syntax-aware temperature adaptation, which classifies\ntokens by their syntactical and functional roles and adjusts the sampling\ntemperature accordingly, enforcing low temperature for syntax-critical tokens\nand higher temperature for exploratory ones. Our approach operates entirely at\ninference time without requiring any additional model fine-tuning. Through\nevaluations on multiple open-source LLMs using the VerilogEval benchmark, we\ndemonstrate significant improvements in syntactic validity, functional\ncorrectness, and output diversity, while the execution overhead (performance\noverhead) is imperceptible.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faDecoRTL\uff0c\u4e00\u79cd\u9488\u5bf9RTL\u4ee3\u7801\u751f\u6210\u7684\u8fd0\u884c\u65f6\u89e3\u7801\u7b56\u7565\uff0c\u901a\u8fc7\u81ea\u4e00\u81f4\u6027\u91c7\u6837\u548c\u8bed\u6cd5\u611f\u77e5\u6e29\u5ea6\u9002\u5e94\uff0c\u663e\u8457\u63d0\u5347\u4ee3\u7801\u7684\u8bed\u6cd5\u6709\u6548\u6027\u3001\u529f\u80fd\u6b63\u786e\u6027\u548c\u591a\u6837\u6027\u3002", "motivation": "\u4f20\u7edfLLM\u89e3\u7801\u7b56\u7565\u5728RTL\u4ee3\u7801\u751f\u6210\u4e2d\u5e38\u4ea7\u751f\u65e0\u6548\u6216\u91cd\u590d\u4ee3\u7801\uff0c\u65e0\u6cd5\u6ee1\u8db3\u7ed3\u6784\u548c\u8bed\u4e49\u9700\u6c42\u3002", "method": "DecoRTL\u7ed3\u5408\u81ea\u4e00\u81f4\u6027\u91c7\u6837\u548c\u8bed\u6cd5\u611f\u77e5\u6e29\u5ea6\u9002\u5e94\uff0c\u52a8\u6001\u8c03\u6574\u89e3\u7801\u7b56\u7565\u3002", "result": "\u5728VerilogEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDecoRTL\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u7684\u8bed\u6cd5\u6709\u6548\u6027\u3001\u529f\u80fd\u6b63\u786e\u6027\u548c\u591a\u6837\u6027\uff0c\u4e14\u6027\u80fd\u5f00\u9500\u53ef\u5ffd\u7565\u3002", "conclusion": "DecoRTL\u662f\u4e00\u79cd\u65e0\u9700\u989d\u5916\u5fae\u8c03\u7684\u9ad8\u6548\u89e3\u7801\u7b56\u7565\uff0c\u9002\u7528\u4e8eRTL\u4ee3\u7801\u751f\u6210\u3002"}}
{"id": "2507.02107", "pdf": "https://arxiv.org/pdf/2507.02107", "abs": "https://arxiv.org/abs/2507.02107", "authors": ["Ben Limpanukorn", "Yanjun Wang", "Zach Patterson", "Pranav Garg", "Murali Krishna Ramanathan", "Xiaofei Ma", "Anoop Deoras", "Miryung Kim"], "title": "Structural Code Search using Natural Language Queries", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "Searching code is a common task that developers perform to understand APIs,\nlearn common code patterns, and navigate code. Currently, developers most\ncommonly search using keywords and regular expressions that are easy to use and\nwidely available. Beyond keywords and regular expressions, structural code\nsearch tools allow developers to search for code based on its syntactic\nstructure. This has numerous applications ranging from bug finding to\nsystematically refactoring code. However, these structural code search tools\noperate on queries expressed in domain-specific languages (DSL) that can be\ndifficult to learn and write. We propose to allow developers to use natural\nlanguage to search for code structurally. Expressing queries in natural\nlanguage provides an intuitive way to search for code and lowers the barrier to\nentry.\n  In this work, we develop a novel general approach that combines the reasoning\ncapabilities of an LLM to interpret natural language search queries with the\npower of structural search tools to efficiently and accurately retrieve\nrelevant code. We then instantiate this approach for two structural code search\nDSLs: Semgrep and GQL. In our evaluation, we construct a new benchmark for\nstructural code search consisting of 400 queries over 10 Java projects. We show\nthat our approach for structural code search based on translating NL queries to\nDSL queries using an LLM is effective and robust, achieving a high precision\nand recall ranging from 55% - 70%. Further, our approach significantly\noutperforms baselines based on semantic code search and LLM retrievals by up to\n57% and 14% on F1 scores.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u81ea\u7136\u8bed\u8a00\u8fdb\u884c\u7ed3\u6784\u5316\u4ee3\u7801\u641c\u7d22\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408LLM\u548c\u7ed3\u6784\u5316\u641c\u7d22\u5de5\u5177\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u641c\u7d22\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u5f00\u53d1\u8005\u901a\u5e38\u4f7f\u7528\u5173\u952e\u8bcd\u548c\u6b63\u5219\u8868\u8fbe\u5f0f\u641c\u7d22\u4ee3\u7801\uff0c\u4f46\u7ed3\u6784\u5316\u641c\u7d22\u5de5\u5177\u9700\u8981\u5b66\u4e60DSL\uff0c\u95e8\u69db\u8f83\u9ad8\u3002\u81ea\u7136\u8bed\u8a00\u641c\u7d22\u53ef\u4ee5\u964d\u4f4e\u4f7f\u7528\u95e8\u69db\u3002", "method": "\u7ed3\u5408LLM\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u548c\u7ed3\u6784\u5316\u641c\u7d22\u5de5\u5177\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7ffb\u8bd1\u4e3aDSL\u67e5\u8be2\uff0c\u5e76\u5728Semgrep\u548cGQL\u4e0a\u5b9e\u73b0\u3002", "result": "\u5728400\u4e2a\u67e5\u8be2\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u65b9\u6cd5\u8868\u73b0\u51fa\u8272\uff0c\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u572855%-70%\u4e4b\u95f4\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u7684\u7ed3\u6784\u5316\u4ee3\u7801\u641c\u7d22\u662f\u4e00\u79cd\u6709\u6548\u4e14\u76f4\u89c2\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5f00\u53d1\u8005\u7684\u641c\u7d22\u4f53\u9a8c\u3002"}}
