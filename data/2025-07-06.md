<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [DecoRTL: A Run-time Decoding Framework for RTL Code Generation with LLMs](https://arxiv.org/abs/2507.02226)
*Mohammad Akyash,Kimia Azar,Hadi Kamali*

Main category: cs.PL

TL;DR: 论文提出了一种新的解码策略DecoRTL，用于改进LLM在RTL代码生成中的表现，解决了传统解码策略在结构和语义上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统LLM解码策略在RTL代码生成中常产生无效或重复代码，无法区分语法关键区域和设计关键区域的需求。

Method: DecoRTL结合了自一致性采样和语法感知温度调整，无需额外微调，在推理时优化生成结果。

Result: 在VerilogEval基准测试中，DecoRTL显著提升了语法有效性、功能正确性和输出多样性，且性能开销几乎为零。

Conclusion: DecoRTL是一种高效且无需额外训练的解决方案，显著提升了LLM在RTL代码生成中的表现。

Abstract: As one of their many applications, large language models (LLMs) have recently
shown promise in automating register transfer level (RTL) code generation.
However, conventional LLM decoding strategies, originally designed for natural
language, often fail to meet the structural and semantic demands of RTL,
leading to hallucinated, repetitive, or invalid code outputs. In this paper, we
first investigate the root causes of these decoding failures through an
empirical analysis of token-level entropy during RTL generation. Our findings
reveal that LLMs exhibit low confidence in regions of structural ambiguity or
semantic complexity, showing that standard decoding strategies fail to
differentiate between regions requiring determinism (syntax-critical regions)
and those that benefit from creative exploratory variability (design-critical
regions). Then, to overcome this, we introduce DecoRTL, a novel run-time
decoding strategy, that is both syntax-aware and contrastive for RTL code
generation. DecoRTL integrates two complementary components: (i)
self-consistency sampling, which generates multiple candidates and re-ranks
them based on token-level agreement to promote correctness while maintaining
diversity; and (ii) syntax-aware temperature adaptation, which classifies
tokens by their syntactical and functional roles and adjusts the sampling
temperature accordingly, enforcing low temperature for syntax-critical tokens
and higher temperature for exploratory ones. Our approach operates entirely at
inference time without requiring any additional model fine-tuning. Through
evaluations on multiple open-source LLMs using the VerilogEval benchmark, we
demonstrate significant improvements in syntactic validity, functional
correctness, and output diversity, while the execution overhead (performance
overhead) is imperceptible.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Structural Code Search using Natural Language Queries](https://arxiv.org/abs/2507.02107)
*Ben Limpanukorn,Yanjun Wang,Zach Patterson,Pranav Garg,Murali Krishna Ramanathan,Xiaofei Ma,Anoop Deoras,Miryung Kim*

Main category: cs.SE

TL;DR: 提出了一种结合LLM和结构代码搜索工具的方法，允许开发者用自然语言进行代码搜索，显著提高了搜索效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 开发者常用关键词和正则表达式搜索代码，但结构代码搜索工具需要复杂的DSL查询，学习门槛高。自然语言查询可以降低使用门槛。

Method: 结合LLM解释自然语言查询的能力和结构搜索工具的高效性，为Semgrep和GQL两种DSL实现该方法。

Result: 在400个查询的基准测试中，方法表现出色，精确率和召回率在55%-70%之间，显著优于基线方法。

Conclusion: 自然语言查询结合LLM和结构搜索工具是一种有效且易用的代码搜索方法。

Abstract: Searching code is a common task that developers perform to understand APIs,
learn common code patterns, and navigate code. Currently, developers most
commonly search using keywords and regular expressions that are easy to use and
widely available. Beyond keywords and regular expressions, structural code
search tools allow developers to search for code based on its syntactic
structure. This has numerous applications ranging from bug finding to
systematically refactoring code. However, these structural code search tools
operate on queries expressed in domain-specific languages (DSL) that can be
difficult to learn and write. We propose to allow developers to use natural
language to search for code structurally. Expressing queries in natural
language provides an intuitive way to search for code and lowers the barrier to
entry.
  In this work, we develop a novel general approach that combines the reasoning
capabilities of an LLM to interpret natural language search queries with the
power of structural search tools to efficiently and accurately retrieve
relevant code. We then instantiate this approach for two structural code search
DSLs: Semgrep and GQL. In our evaluation, we construct a new benchmark for
structural code search consisting of 400 queries over 10 Java projects. We show
that our approach for structural code search based on translating NL queries to
DSL queries using an LLM is effective and robust, achieving a high precision
and recall ranging from 55% - 70%. Further, our approach significantly
outperforms baselines based on semantic code search and LLM retrievals by up to
57% and 14% on F1 scores.

</details>
