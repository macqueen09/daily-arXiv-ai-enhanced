{"id": "2507.03629", "pdf": "https://arxiv.org/pdf/2507.03629", "abs": "https://arxiv.org/abs/2507.03629", "authors": ["SÃ©rgio Queiroz de Medeiros", "Fabio Mascarenhas"], "title": "Towards Automatic Error Recovery in Parsing Expression", "categories": ["cs.PL", "cs.FL", "F.4.3; D.3.1; D.3.4"], "comment": "arXiv admin note: substantial text overlap with arXiv:1905.02145", "summary": "Error recovery is an essential feature for a parser that should be plugged in\nIntegrated Development Environments (IDEs), which must build Abstract Syntax\nTrees (ASTs) even for syntactically invalid programs in order to offer features\nsuch as automated refactoring and code completion.\n  Parsing Expressions Grammars (PEGs) are a formalism that naturally describes\nrecursive top-down parsers using a restricted form of backtracking. Labeled\nfailures are a conservative extension of PEGs that adds an error reporting\nmechanism for PEG parsers, and these labels can also be associated with\nrecovery expressions to also be an error recovery mechanism. These expressions\ncan use the full expressivity of PEGs to recover from syntactic errors.\n  Manually annotating a large grammar with labels and recovery expressions can\nbe difficult. In this work, we present an algorithm that automatically\nannotates a PEG with labels, and builds their corresponding recovery\nexpressions. We evaluate this algorithm by adding error recovery to the parser\nof the Titan programming language. The results shown that with a small amount\nof manual intervention our algorithm can be used to produce error recovering\nparsers for PEGs where most of the alternatives are disjoint."}
{"id": "2507.03867", "pdf": "https://arxiv.org/pdf/2507.03867", "abs": "https://arxiv.org/abs/2507.03867", "authors": ["Yu Xiang Zhu", "Amos Robinson", "Sophia Roshal", "Timothy Mou", "Julian Mackay", "Jonathan Aldrich", "Alex Potanin"], "title": "Semantically Separating Nominal Wyvern for Usability and Decidability", "categories": ["cs.PL"], "comment": null, "summary": "The Dependent Object Types (DOT) calculus incorporates concepts from\nfunctional languages (e.g. modules) with traditional object-oriented features\n(e.g. objects, subtyping) to achieve greater expressivity (e.g. F-bounded\npolymorphism). However, this merger of paradigms comes at the cost of subtype\ndecidability. Recent work on bringing decidability to DOT has either sacrificed\nexpressiveness or ease of use. The unrestricted construction of recursive types\nand type bounds has made subtype decidability a much harder problem than in\ntraditional object-oriented programming.\n  Recognizing this, our paper introduces Nominal Wyvern, a DOT-like dependent\ntype system that takes an alternative approach: instead of having a uniform\nstructural syntax like DOT, Nominal Wyvern is designed around a \"semantic\nseparation\" between the nominal declaration of recursive types on the one hand,\nand the structural refinement of those types when they are used on the other.\nThis design naturally guides the user to avoid writing undecidably recursive\nstructural types.\n  From a technical standpoint, this separation also makes guaranteeing\ndecidability possible by allowing for an intuitive adaptation of material/shape\nseparation, a technique for achieving subtype decidability by separating types\nresponsible for subtyping constraints from types that represent concrete data.\nThe result is a type system with syntax and structure familiar to OOP users\nthat achieves decidability without compromising the expressiveness of F-bounded\npolymorphism and module systems as they are used in practice."}
{"id": "2507.04298", "pdf": "https://arxiv.org/pdf/2507.04298", "abs": "https://arxiv.org/abs/2507.04298", "authors": ["Youngju Song", "Minki Cho"], "title": "CCR 2.0: High-level Reasoning for Conditional Refinements", "categories": ["cs.PL"], "comment": null, "summary": "In recent years, great progress has been made in the field of formal\nverification for low-level systems. Many of them are based on one of two\npopular approaches: refinement or separation logic. These two approaches are\nvery different in nature and offer complementary benefits in terms of\ncompositionality. Recently, to fuse these benefits in a unified mechanism, a\nnew approach called Conditional Contextual Refinement (CCR 1.0 for short) was\nproposed. In this paper, we advance the model of CCR 1.0 and provide novel and\nintuitive reasoning principles, resulting in: CCR 2.0. Specifically, CCR 2.0\n(i) comes with a better compositionality theorem, having the practical benefit\nof facilitating more proof reuse, and (ii) provides a proof technique that\nhides model-level (i.e., resources of the separation logic) details from the\nuser. Achieving this goal was challenging due to non-trivial counterexamples\nwhich necessitated us to devise novel notions. Our results are formalized in\nCoq."}
{"id": "2507.04316", "pdf": "https://arxiv.org/pdf/2507.04316", "abs": "https://arxiv.org/abs/2507.04316", "authors": ["Jay Lee"], "title": "Retargeting an Abstract Interpreter for a New Language by Partial Evaluation", "categories": ["cs.PL"], "comment": "Presented at the Student Research Competition (SRC) at PLDI 2025\n  (https://pldi25.sigplan.org/details/pldi-2025-src/1/)", "summary": "It is well-known that abstract interpreters can be systematically derived\nfrom their concrete counterparts using a \"recipe,\" but developing sound static\nanalyzers remains a time-consuming task. Reducing the effort required and\nmechanizing the process of developing analyzers continues to be a significant\nchallenge. Is it possible to automatically retarget an existing abstract\ninterpreter for a new language?\n  We propose a novel technique to automatically derive abstract interpreters\nfor various languages from an existing abstract interpreter. By leveraging\npartial evaluation, we specialize an abstract interpreter for a source\nlanguage. The specialization is performed using the semantics of target\nlanguages written in the source language. Our approach eliminates the need to\ndevelop analyzers for new targets from scratch. We show that our method can\neffectively retarget an abstract interpreter for one language into a correct\nanalyzer for another language."}
{"id": "2507.05234", "pdf": "https://arxiv.org/pdf/2507.05234", "abs": "https://arxiv.org/abs/2507.05234", "authors": ["Jay Lee", "Joongwon Ahn", "Kwangkeun Yi"], "title": "React-tRace: A Semantics for Understanding React Hooks", "categories": ["cs.PL", "cs.SE"], "comment": "Conditionally accepted to OOPSLA 2025", "summary": "React has become the most widely used web front-end framework, enabling the\ncreation of user interfaces in a declarative and compositional manner. Hooks\nare a set of APIs that manage side effects in functional components in React.\nHowever, their semantics are often seen as opaque to developers, leading to UI\nbugs. In this paper, we formalize the semantics of the essence of React Hooks\nwe name React-tRace, providing a framework that clarifies their behavior. We\ndemonstrate that our model captures the behavior of React, by theoretically\nshowing that it embodies essential properties of Hooks and empirically\ncomparing our React-tRace-definitional interpreter against a test suite.\nFurthermore, we showcase a practical visualization tool based on the\nformalization to demonstrate how developers can better understand the semantics\nof Hooks."}
{"id": "2507.03659", "pdf": "https://arxiv.org/pdf/2507.03659", "abs": "https://arxiv.org/abs/2507.03659", "authors": ["Valentina Wu", "Alexandra Mendes", "Alexandre Abreu"], "title": "Specification-Guided Repair of Arithmetic Errors in Dafny Programs using LLMs", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "Formal verification offers strong assurances of software correctness.\nHowever, debugging and repairing the underlying faults can be complex and\ntime-consuming when verification fails. Automated Program Repair (APR) aims to\nease this by automatically identifying and fixing faults. Traditional APR\ntechniques often depend on test suites for validation, but these may fail to\ncapture all scenarios. In contrast, formal specifications provide stronger\ncorrectness criteria for effective repairs.\n  We present an innovative APR tool for Dafny, a verification-aware programming\nlanguage that uses formal specifications - including pre-conditions,\npost-conditions, and invariants - as oracles for fault localization and repair.\nAssuming the correctness of the specifications and focusing on arithmetic bugs,\nwe localize faults through a series of steps, which include using Hoare Logic\nto determine the state of each statement within the program and\nstate-of-the-art Large Language Models (LLMs) to synthesize candidate fixes.\nThe chosen models were GPT-4o mini, Llama 3, Mistral 7B, and Llemma 7B.\n  We evaluate our approach using DafnyBench, a benchmark of real-world Dafny\nprograms. Our tool achieves 89.6% accuracy in fault localization, with GPT-4o\nmini yielding the highest repair success rate (74.18%). These results highlight\nthe potential of combining formal reasoning with LLM-driven program synthesis\nfor automated program repair."}
{"id": "2507.03773", "pdf": "https://arxiv.org/pdf/2507.03773", "abs": "https://arxiv.org/abs/2507.03773", "authors": ["Yibo He", "Cunjian Huang", "Xianmiao Qu", "Hongdeng Chen", "Wei Yang", "Tao Xie"], "title": "RVISmith: Fuzzing Compilers for RVV Intrinsics", "categories": ["cs.CR", "cs.DC", "cs.PL", "cs.SE"], "comment": "To appear in ACM CCS 2025", "summary": "Modern processors are equipped with single instruction multiple data (SIMD)\ninstructions for fine-grained data parallelism. Compiler auto-vectorization\ntechniques that target SIMD instructions face performance limitations due to\ninsufficient information available at compile time, requiring programmers to\nmanually manipulate SIMD instructions. SIMD intrinsics, a type of built-in\nfunction provided by modern compilers, enable programmers to manipulate SIMD\ninstructions within high-level programming languages. Bugs in compilers for\nSIMD intrinsics can introduce potential threats to software security, producing\nunintended calculation results, data loss, program crashes, etc.\n  To detect bugs in compilers for SIMD intrinsics, we propose RVISmith, a\nrandomized fuzzer that generates well-defined C programs that include various\ninvocation sequences of RVV (RISC-V Vector Extension) intrinsics. We design\nRVISmith to achieve the following objectives: (i) achieving high intrinsic\ncoverage, (ii) improving sequence variety, and (iii) without known undefined\nbehaviors. We implement RVISmith based on the ratified RVV intrinsic\nspecification and evaluate our approach with three modern compilers: GCC, LLVM,\nand XuanTie. Experimental results show that RVISmith achieves 11.5 times higher\nintrinsic coverage than the state-of-the-art fuzzer for RVV intrinsics. By\ndifferential testing that compares results across different compilers,\noptimizations, and equivalent programs, we detect and report 13 previously\nunknown bugs of the three compilers under test to date. Of these bugs, 10 are\nconfirmed and another 3 are fixed by the compiler developers."}
{"id": "2507.04736", "pdf": "https://arxiv.org/pdf/2507.04736", "abs": "https://arxiv.org/abs/2507.04736", "authors": ["Zhirong Chen", "Kaiyan Chang", "Zhuolin Li", "Xinyang He", "Chujie Chen", "Cangyuan Li", "Mengdi Wang", "Haobo Xu", "Yinhe Han", "Ying Wang"], "title": "ChipSeek-R1: Generating Human-Surpassing RTL with LLM via Hierarchical Reward-Driven Reinforcement Learning", "categories": ["cs.AI", "cs.AR", "cs.PL"], "comment": null, "summary": "Large Language Models (LLMs) show significant potential for automating\nRegister-Transfer Level (RTL) code generation. However, current approaches face\na critical challenge: they can not simultaneously optimize for functional\ncorrectness and hardware quality (Power, Performance, Area - PPA). Methods\nbased on supervised fine-tuning often generate functionally correct but\nPPA-suboptimal code, lacking mechanisms to learn optimization principles. In\ncontrast, post-processing techniques that attempt to improve PPA metrics after\ngeneration are often inefficient because they operate externally without\nupdating the LLM's parameters, thus failing to enhance the model's intrinsic\ndesign capabilities.\n  To bridge this gap, we introduce ChipSeek-R1, a hierarchical reward-driven\nreinforcement learning framework to train LLMs to generate RTL code that\nachieves both functional correctness and optimized PPA metrics. ChipSeek-R1\nemploys a hierarchical reward system, which incorporates direct feedback on\nsyntax, functional correctness (from simulators) and PPA metrics (from\nsynthesis tools) during reinforcement learning. This enables the model to learn\ncomplex hardware design trade-offs via trial-and-error, generating RTL code\nthat is both functionally correct and PPA-optimized. Evaluating ChipSeek-R1 on\nstandard benchmarks (VerilogEval, RTLLM), we achieve state-of-the-art results\nin functional correctness. Notably, on the RTLLM benchmark, ChipSeek-R1\ngenerated 27 RTL designs surpassing the PPA metrics of the original\nhuman-written code. Our findings demonstrate the effectiveness of integrating\ntoolchain feedback into LLM training and highlight the potential for\nreinforcement learning to enable automated generation of human-surpassing RTL\ncode. We open-source our code in anonymous github."}
