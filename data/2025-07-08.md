<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 5]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Towards Automatic Error Recovery in Parsing Expression](https://arxiv.org/abs/2507.03629)
*Sérgio Queiroz de Medeiros,Fabio Mascarenhas*

Main category: cs.PL

TL;DR: 论文提出了一种自动为PEG语法添加标签和恢复表达式的算法，用于错误恢复，并在Titan编程语言的解析器中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 在IDE中，即使程序语法错误，解析器也需要构建AST以支持自动重构和代码补全。PEGs及其扩展（带标签的失败）提供了错误报告和恢复机制，但手动标注大型语法困难。

Method: 提出一种算法，自动为PEG语法添加标签并构建对应的恢复表达式。

Result: 在Titan语言的解析器中验证，结果表明算法只需少量手动干预即可为大多数不重叠的PEG生成错误恢复解析器。

Conclusion: 自动标注算法能有效简化PEG语法错误恢复的实现，适用于大多数不重叠的PEG场景。

Abstract: Error recovery is an essential feature for a parser that should be plugged in
Integrated Development Environments (IDEs), which must build Abstract Syntax
Trees (ASTs) even for syntactically invalid programs in order to offer features
such as automated refactoring and code completion.
  Parsing Expressions Grammars (PEGs) are a formalism that naturally describes
recursive top-down parsers using a restricted form of backtracking. Labeled
failures are a conservative extension of PEGs that adds an error reporting
mechanism for PEG parsers, and these labels can also be associated with
recovery expressions to also be an error recovery mechanism. These expressions
can use the full expressivity of PEGs to recover from syntactic errors.
  Manually annotating a large grammar with labels and recovery expressions can
be difficult. In this work, we present an algorithm that automatically
annotates a PEG with labels, and builds their corresponding recovery
expressions. We evaluate this algorithm by adding error recovery to the parser
of the Titan programming language. The results shown that with a small amount
of manual intervention our algorithm can be used to produce error recovering
parsers for PEGs where most of the alternatives are disjoint.

</details>


### [2] [Semantically Separating Nominal Wyvern for Usability and Decidability](https://arxiv.org/abs/2507.03867)
*Yu Xiang Zhu,Amos Robinson,Sophia Roshal,Timothy Mou,Julian Mackay,Jonathan Aldrich,Alex Potanin*

Main category: cs.PL

TL;DR: Nominal Wyvern是一种DOT类依赖类型系统，通过名义声明和结构精化的分离，解决了DOT中子类型可判定性问题，同时保持了F-界多态和模块系统的表达能力。


<details>
  <summary>Details</summary>
Motivation: DOT演算结合了函数式和面向对象特性，但牺牲了子类型的可判定性。现有方法要么限制表达能力，要么牺牲易用性。本文旨在解决这一问题。

Method: 引入Nominal Wyvern，采用名义声明和结构精化的分离设计，避免不可判定的递归结构类型，并借鉴材料/形状分离技术。

Result: 实现了子类型可判定性，同时保留了F-界多态和模块系统的表达能力。

Conclusion: Nominal Wyvern提供了一种既直观又强大的类型系统设计，解决了DOT的可判定性问题。

Abstract: The Dependent Object Types (DOT) calculus incorporates concepts from
functional languages (e.g. modules) with traditional object-oriented features
(e.g. objects, subtyping) to achieve greater expressivity (e.g. F-bounded
polymorphism). However, this merger of paradigms comes at the cost of subtype
decidability. Recent work on bringing decidability to DOT has either sacrificed
expressiveness or ease of use. The unrestricted construction of recursive types
and type bounds has made subtype decidability a much harder problem than in
traditional object-oriented programming.
  Recognizing this, our paper introduces Nominal Wyvern, a DOT-like dependent
type system that takes an alternative approach: instead of having a uniform
structural syntax like DOT, Nominal Wyvern is designed around a "semantic
separation" between the nominal declaration of recursive types on the one hand,
and the structural refinement of those types when they are used on the other.
This design naturally guides the user to avoid writing undecidably recursive
structural types.
  From a technical standpoint, this separation also makes guaranteeing
decidability possible by allowing for an intuitive adaptation of material/shape
separation, a technique for achieving subtype decidability by separating types
responsible for subtyping constraints from types that represent concrete data.
The result is a type system with syntax and structure familiar to OOP users
that achieves decidability without compromising the expressiveness of F-bounded
polymorphism and module systems as they are used in practice.

</details>


### [3] [CCR 2.0: High-level Reasoning for Conditional Refinements](https://arxiv.org/abs/2507.04298)
*Youngju Song,Minki Cho*

Main category: cs.PL

TL;DR: 论文提出了一种改进的CCR 2.0模型，结合了细化和分离逻辑的优点，提供了更好的组合性定理和隐藏模型细节的证明技术。


<details>
  <summary>Details</summary>
Motivation: 结合细化和分离逻辑的互补优势，提出统一的验证机制。

Method: 改进CCR 1.0模型，引入新的推理原则，形成CCR 2.0，并在Coq中形式化验证。

Result: CCR 2.0具有更好的组合性定理，促进证明重用，并隐藏模型细节。

Conclusion: CCR 2.0成功融合了两种方法的优点，为低层系统验证提供了更高效的工具。

Abstract: In recent years, great progress has been made in the field of formal
verification for low-level systems. Many of them are based on one of two
popular approaches: refinement or separation logic. These two approaches are
very different in nature and offer complementary benefits in terms of
compositionality. Recently, to fuse these benefits in a unified mechanism, a
new approach called Conditional Contextual Refinement (CCR 1.0 for short) was
proposed. In this paper, we advance the model of CCR 1.0 and provide novel and
intuitive reasoning principles, resulting in: CCR 2.0. Specifically, CCR 2.0
(i) comes with a better compositionality theorem, having the practical benefit
of facilitating more proof reuse, and (ii) provides a proof technique that
hides model-level (i.e., resources of the separation logic) details from the
user. Achieving this goal was challenging due to non-trivial counterexamples
which necessitated us to devise novel notions. Our results are formalized in
Coq.

</details>


### [4] [Retargeting an Abstract Interpreter for a New Language by Partial Evaluation](https://arxiv.org/abs/2507.04316)
*Jay Lee*

Main category: cs.PL

TL;DR: 提出了一种通过部分评估自动为不同语言生成抽象解释器的新技术，避免从头开发分析器。


<details>
  <summary>Details</summary>
Motivation: 减少开发静态分析器的时间和精力，解决自动重定向现有抽象解释器到新语言的挑战。

Method: 利用部分评估技术，基于源语言的语义，将抽象解释器特化为目标语言的分析器。

Result: 成功将一种语言的抽象解释器重定向为另一种语言的正确分析器。

Conclusion: 该方法有效减少了开发新分析器的工作量，实现了抽象解释器的自动重定向。

Abstract: It is well-known that abstract interpreters can be systematically derived
from their concrete counterparts using a "recipe," but developing sound static
analyzers remains a time-consuming task. Reducing the effort required and
mechanizing the process of developing analyzers continues to be a significant
challenge. Is it possible to automatically retarget an existing abstract
interpreter for a new language?
  We propose a novel technique to automatically derive abstract interpreters
for various languages from an existing abstract interpreter. By leveraging
partial evaluation, we specialize an abstract interpreter for a source
language. The specialization is performed using the semantics of target
languages written in the source language. Our approach eliminates the need to
develop analyzers for new targets from scratch. We show that our method can
effectively retarget an abstract interpreter for one language into a correct
analyzer for another language.

</details>


### [5] [React-tRace: A Semantics for Understanding React Hooks](https://arxiv.org/abs/2507.05234)
*Jay Lee,Joongwon Ahn,Kwangkeun Yi*

Main category: cs.PL

TL;DR: 本文提出React-tRace框架，形式化React Hooks的语义，帮助开发者理解其行为，减少UI错误。


<details>
  <summary>Details</summary>
Motivation: React Hooks的语义对开发者不透明，容易导致UI错误，需要形式化其行为。

Method: 提出React-tRace框架，通过定义解释器和测试套件验证其准确性，并开发可视化工具。

Result: 理论证明React-tRace体现Hooks的核心特性，并通过测试验证其准确性。

Conclusion: React-tRace为开发者提供了理解Hooks语义的工具，减少错误。

Abstract: React has become the most widely used web front-end framework, enabling the
creation of user interfaces in a declarative and compositional manner. Hooks
are a set of APIs that manage side effects in functional components in React.
However, their semantics are often seen as opaque to developers, leading to UI
bugs. In this paper, we formalize the semantics of the essence of React Hooks
we name React-tRace, providing a framework that clarifies their behavior. We
demonstrate that our model captures the behavior of React, by theoretically
showing that it embodies essential properties of Hooks and empirically
comparing our React-tRace-definitional interpreter against a test suite.
Furthermore, we showcase a practical visualization tool based on the
formalization to demonstrate how developers can better understand the semantics
of Hooks.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [6] [RVISmith: Fuzzing Compilers for RVV Intrinsics](https://arxiv.org/abs/2507.03773)
*Yibo He,Cunjian Huang,Xianmiao Qu,Hongdeng Chen,Wei Yang,Tao Xie*

Main category: cs.CR

TL;DR: RVISmith是一种随机模糊测试工具，用于检测编译器中的SIMD内部函数错误，通过生成多样化的RVV内部函数调用序列，显著提高了覆盖率并发现了多个未知错误。


<details>
  <summary>Details</summary>
Motivation: 现代编译器对SIMD内部函数的支持可能存在错误，导致安全威胁和程序异常，需要一种高效的方法来检测这些错误。

Method: RVISmith通过生成定义良好的C程序，包含多样化的RVV内部函数调用序列，并结合差分测试比较不同编译器的结果。

Result: 实验显示RVISmith的覆盖率比现有工具高11.5倍，并检测到13个未知错误，其中10个已确认，3个已修复。

Conclusion: RVISmith是一种有效的工具，能够显著提升编译器对SIMD内部函数的错误检测能力。

Abstract: Modern processors are equipped with single instruction multiple data (SIMD)
instructions for fine-grained data parallelism. Compiler auto-vectorization
techniques that target SIMD instructions face performance limitations due to
insufficient information available at compile time, requiring programmers to
manually manipulate SIMD instructions. SIMD intrinsics, a type of built-in
function provided by modern compilers, enable programmers to manipulate SIMD
instructions within high-level programming languages. Bugs in compilers for
SIMD intrinsics can introduce potential threats to software security, producing
unintended calculation results, data loss, program crashes, etc.
  To detect bugs in compilers for SIMD intrinsics, we propose RVISmith, a
randomized fuzzer that generates well-defined C programs that include various
invocation sequences of RVV (RISC-V Vector Extension) intrinsics. We design
RVISmith to achieve the following objectives: (i) achieving high intrinsic
coverage, (ii) improving sequence variety, and (iii) without known undefined
behaviors. We implement RVISmith based on the ratified RVV intrinsic
specification and evaluate our approach with three modern compilers: GCC, LLVM,
and XuanTie. Experimental results show that RVISmith achieves 11.5 times higher
intrinsic coverage than the state-of-the-art fuzzer for RVV intrinsics. By
differential testing that compares results across different compilers,
optimizations, and equivalent programs, we detect and report 13 previously
unknown bugs of the three compilers under test to date. Of these bugs, 10 are
confirmed and another 3 are fixed by the compiler developers.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [ChipSeek-R1: Generating Human-Surpassing RTL with LLM via Hierarchical Reward-Driven Reinforcement Learning](https://arxiv.org/abs/2507.04736)
*Zhirong Chen,Kaiyan Chang,Zhuolin Li,Xinyang He,Chujie Chen,Cangyuan Li,Mengdi Wang,Haobo Xu,Yinhe Han,Ying Wang*

Main category: cs.AI

TL;DR: ChipSeek-R1是一个基于分层奖励的强化学习框架，用于训练LLM生成功能正确且PPA优化的RTL代码。


<details>
  <summary>Details</summary>
Motivation: 当前方法无法同时优化功能正确性和硬件质量（PPA），需要一种新方法提升LLM的设计能力。

Method: 采用分层奖励驱动的强化学习框架，结合语法、功能正确性和PPA指标的反馈。

Result: 在标准基准测试中表现优异，生成27个RTL设计超越人工代码的PPA指标。

Conclusion: 强化学习结合工具链反馈可自动化生成超越人工的RTL代码。

Abstract: Large Language Models (LLMs) show significant potential for automating
Register-Transfer Level (RTL) code generation. However, current approaches face
a critical challenge: they can not simultaneously optimize for functional
correctness and hardware quality (Power, Performance, Area - PPA). Methods
based on supervised fine-tuning often generate functionally correct but
PPA-suboptimal code, lacking mechanisms to learn optimization principles. In
contrast, post-processing techniques that attempt to improve PPA metrics after
generation are often inefficient because they operate externally without
updating the LLM's parameters, thus failing to enhance the model's intrinsic
design capabilities.
  To bridge this gap, we introduce ChipSeek-R1, a hierarchical reward-driven
reinforcement learning framework to train LLMs to generate RTL code that
achieves both functional correctness and optimized PPA metrics. ChipSeek-R1
employs a hierarchical reward system, which incorporates direct feedback on
syntax, functional correctness (from simulators) and PPA metrics (from
synthesis tools) during reinforcement learning. This enables the model to learn
complex hardware design trade-offs via trial-and-error, generating RTL code
that is both functionally correct and PPA-optimized. Evaluating ChipSeek-R1 on
standard benchmarks (VerilogEval, RTLLM), we achieve state-of-the-art results
in functional correctness. Notably, on the RTLLM benchmark, ChipSeek-R1
generated 27 RTL designs surpassing the PPA metrics of the original
human-written code. Our findings demonstrate the effectiveness of integrating
toolchain feedback into LLM training and highlight the potential for
reinforcement learning to enable automated generation of human-surpassing RTL
code. We open-source our code in anonymous github.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [8] [Specification-Guided Repair of Arithmetic Errors in Dafny Programs using LLMs](https://arxiv.org/abs/2507.03659)
*Valentina Wu,Alexandra Mendes,Alexandre Abreu*

Main category: cs.SE

TL;DR: 论文提出了一种结合形式化规范和大型语言模型（LLM）的自动程序修复工具，用于Dafny语言，实现了高精度的故障定位和修复。


<details>
  <summary>Details</summary>
Motivation: 传统自动程序修复（APR）依赖测试套件，但无法覆盖所有场景。形式化规范提供了更强的正确性标准，结合LLM可以更高效地定位和修复故障。

Method: 使用Hoare逻辑分析程序状态，结合LLM（如GPT-4o mini）生成候选修复方案，专注于算术错误。

Result: 在DafnyBench基准测试中，故障定位准确率为89.6%，GPT-4o mini修复成功率达74.18%。

Conclusion: 形式化推理与LLM驱动的程序合成结合，在自动程序修复中具有显著潜力。

Abstract: Formal verification offers strong assurances of software correctness.
However, debugging and repairing the underlying faults can be complex and
time-consuming when verification fails. Automated Program Repair (APR) aims to
ease this by automatically identifying and fixing faults. Traditional APR
techniques often depend on test suites for validation, but these may fail to
capture all scenarios. In contrast, formal specifications provide stronger
correctness criteria for effective repairs.
  We present an innovative APR tool for Dafny, a verification-aware programming
language that uses formal specifications - including pre-conditions,
post-conditions, and invariants - as oracles for fault localization and repair.
Assuming the correctness of the specifications and focusing on arithmetic bugs,
we localize faults through a series of steps, which include using Hoare Logic
to determine the state of each statement within the program and
state-of-the-art Large Language Models (LLMs) to synthesize candidate fixes.
The chosen models were GPT-4o mini, Llama 3, Mistral 7B, and Llemma 7B.
  We evaluate our approach using DafnyBench, a benchmark of real-world Dafny
programs. Our tool achieves 89.6% accuracy in fault localization, with GPT-4o
mini yielding the highest repair success rate (74.18%). These results highlight
the potential of combining formal reasoning with LLM-driven program synthesis
for automated program repair.

</details>
