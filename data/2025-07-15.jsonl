{"id": "2507.09539", "pdf": "https://arxiv.org/pdf/2507.09539", "abs": "https://arxiv.org/abs/2507.09539", "authors": ["Anna Bolotina", "Christoph M. Kirsch", "Stefanie Muroya Lei", "Matthias Pleschinger"], "title": "Bounded Model Checking of RISC-V Machine Code with Context-Free-Language Ordered Binary Decision Diagrams", "categories": ["cs.PL"], "comment": null, "summary": "Symbolic execution is a powerful technique for analyzing the behavior of\nsoftware yet scalability remains a challenge due to state explosion in control\nand data flow. Existing tools typically aim at managing control flow\ninternally, often at the expense of completeness, while offloading reasoning\nover data flow to SMT solvers. Moreover, reasoning typically happens on source\ncode or intermediate representation level to leverage structural information,\nmaking machine code generation part of the trust base. We are interested in\nchanging the equation in two non-trivial ways: pushing reasoning down to\nmachine code level, and then offloading reasoning entirely into SMT solvers and\nother, possibly more efficient solver technology. In more abstract terms, we\nare asking if bit-precise reasoning technology can be made scalable on\nsoftware, and not just hardware. For this purpose, we developed two tools\ncalled rotor and bitme for model generation and bounded model checking,\nrespectively. We chose RISC-V restricted to integer arithmetic as modeling\ntarget for rotor since RISC-V integer semantics is essentially equivalent to\nestablished SMT semantics over bitvectors and arrays of bitvectors. While\nstate-of-the-art SMT solvers struggle in our experiments, we have evidence that\nthere is potential for improvement. To show the potential, we have slightly\ngeneralized and then implemented in bitme two types of binary decision diagrams\n(BDDs): algebraic decision diagrams (ADDs) and context-free-language ordered\nbinary decision diagrams (CFLOBDDs). Bitme uses BDDs to propagate program input\nthrough models, essentially generalizing constant propagation to domain\npropagation. SMT solvers only get involved when model input cannot be\npropagated, significanly speeding up SMT solving. We then study the impact on\nstate explosion of CFLOBDDs, which are potentially more scalable than ADDs."}
{"id": "2507.09883", "pdf": "https://arxiv.org/pdf/2507.09883", "abs": "https://arxiv.org/abs/2507.09883", "authors": ["Swarn Priya", "Frédéric Besson", "Connor Sughrue", "Tim Steenvoorden", "Jamie Fulford", "Freek Verbeek", "Binoy Ravindran"], "title": "BeePL: Correct-by-compilation kernel extensions", "categories": ["cs.PL"], "comment": "45 pages, 18 figures", "summary": "eBPF is a technology that allows developers to safely extend kernel\nfunctionality without modifying kernel source code or developing loadable\nkernel modules. Since the kernel governs critical system operations and\nenforces isolation boundaries between user space and privileged data, any\nmechanism that modifies its behavior must meet the highest standards of safety\nand correctness. To this end, the eBPF toolchain includes a verifier, which\nstatically checks safety properties such as memory access validity, bounded\nloops, and type correctness before loading the program into the kernel.\nHowever, the existing verifier is both overly conservative in some\ncases-rejecting valid programs-and unsound in others, permitting unsafe\nbehavior that violates the intended semantics of the kernel interface.\n  To address these challenges, we introduce BeePL, a domain-specific language\nfor eBPF with a formally verified type system. The BeePL type system, along\nwith the language design, statically enforces key safety properties such as\ntype-correct memory access, safe pointer usage, absence of unbounded loops, and\nstructured control flow. These guarantees are backed by formal type soundness\nproofs, ensuring that well-typed programs satisfy the safety invariants\nrequired by the eBPF execution environment. BeePL also proves that well-typed\nsource programs meet critical eBPF-specific properties related to memory\nsafety, termination, and control flow, enabling high-level reasoning prior to\ncompilation. For properties not fully enforceable statically-such as dynamic\nbounds and undefined behavior-BeePL inserts semantics-preserving runtime checks\nduring compilation. We develop a verified compilation strategy that extends\nCompCert to generate BPF bytecode from BeePL programs, establishing a\nprincipled foundation for an end-to-end verifiable toolchain for safe kernel\nextensions."}
{"id": "2507.10301", "pdf": "https://arxiv.org/pdf/2507.10301", "abs": "https://arxiv.org/abs/2507.10301", "authors": ["Wenhao Tang", "Sam Lindley"], "title": "Rows and Capabilities as Modal Effects", "categories": ["cs.PL"], "comment": null, "summary": "Effect handlers allow programmers to model and compose computational effects\nmodularly. Effect systems statically guarantee that all effects are handled.\nSeveral recent practical effect systems are based on either row polymorphism or\ncapabilities. However, there remains a gap in understanding the precise\nrelationship between effect systems with such disparate foundations. The main\ndifficulty is that in both row-based and capability-based systems, effect\ntracking is typically entangled with other features such as functions.\n  We propose a uniform framework for encoding, analysing, and comparing effect\nsystems. Our framework exploits and generalises modal effect types, a recent\nnovel effect system which decouples effect tracking from functions via\nmodalities. Modalities offer fine-grained control over when and how effects are\ntracked, enabling us to express different strategies for effect tracking. We\ngive encodings as macro translations from existing row-based and\ncapability-based effect systems into our framework and show that these\nencodings preserve types and semantics. Our encodings reveal the essence of\neffect tracking mechanisms in different effect systems, enable a direct\nanalysis on their differences, and provide valuable insights on language\ndesign."}
{"id": "2507.10482", "pdf": "https://arxiv.org/pdf/2507.10482", "abs": "https://arxiv.org/abs/2507.10482", "authors": ["Simon Guilloud", "Viktor Kunčak"], "title": "Orthologic Type Systems", "categories": ["cs.PL", "cs.LO"], "comment": null, "summary": "We propose to use orthologic as the basis for designing type systems\nsupporting intersection, union, and negation types in the presence of subtyping\nassumptions. We show how to extend orthologic to support monotonic and\nantimonotonic functions, supporting the use of type constructors in such type\nsystems. We present a proof system for orthologic with function symbols,\nshowing that it admits partial cut elimination. Using these insights, we\npresent an $\\mathcal O(n^2(1+m))$ algorithm for deciding the subtyping relation\nunder $m$ assumptions. We also show $O(n^2)$ polynomial-time normalization\nalgorithm, allowing simplification of types to their minimal canonical form."}
{"id": "2507.08992", "pdf": "https://arxiv.org/pdf/2507.08992", "abs": "https://arxiv.org/abs/2507.08992", "authors": ["Abdelhalim Dahou", "Ansgar Scherp", "Sebastian Kurten", "Brigitte Mathiak", "Madhu Chauhan"], "title": "Semantic Source Code Segmentation using Small and Large Language Models", "categories": ["cs.SE", "cs.CL", "cs.PL"], "comment": "18 pages, 4 figures", "summary": "Source code segmentation, dividing code into functionally coherent segments,\nis crucial for knowledge retrieval and maintenance in software development.\nWhile enabling efficient navigation and comprehension of large codebases,\nmanual and syntactic analysis approaches have become impractical as\nrepositories grow, especially for low-resource languages like R and their\nresearch domains (e.g., social sciences, psychology).This paper introduces an\nautomated, domain-specific approach for research R code segmentation using\nLarge and Small Language Models (LLMs/SLMs). It presents two novel approaches\nand a human-annotated dataset, StatCodeSeg. We explore two distinct approaches:\nline-by-line analysis with context and range-based segment determination. We\nexperiment with LLMs and fine-tuned SLMs. To support the generalizability of\nour approaches, we also include experiments on Python code from the computer\nscience domain.Our results show that context-based line-by-line analysis is\nsuperior over range-based segmentation.Using smaller language models like\nCodeBERT and an encoder-only version of CodeT5+ are better than their LLM\ncounterparts. Most notably, these two best-performing models did not see R code\nduring pre-training versus the LLMs but were only fine-tuned on 4,130 lines of\nmanually annotated code."}
{"id": "2507.10099", "pdf": "https://arxiv.org/pdf/2507.10099", "abs": "https://arxiv.org/abs/2507.10099", "authors": ["Jay Lee", "Gyuhyeok Oh", "Joongwon Ahn", "Xiaokang Qiu"], "title": "ReDemon UI: Reactive Synthesis by Demonstration for Web UI", "categories": ["cs.HC", "cs.PL"], "comment": "Submitted to UIST 2025 Posters", "summary": "ReDemon UI synthesizes React applications from user demonstrations, enabling\ndesigners and non-expert programmers to create UIs that integrate with standard\nUI prototyping workflows. Users provide a static mockup sketch with event\nhandler holes and demonstrate desired runtime behaviors by interacting with the\nrendered mockup and editing the sketch. ReDemon UI identifies reactive data and\nsynthesizes a React program with correct state update logic. We utilize\nenumerative synthesis for simple UIs and LLMs for more complex UIs."}
{"id": "2507.10324", "pdf": "https://arxiv.org/pdf/2507.10324", "abs": "https://arxiv.org/abs/2507.10324", "authors": ["Amit K. Chopra", "Samuel H. Christie V", "Munindar P. Singh"], "title": "Toolsuite for Implementing Multiagent Systems Based on Communication Protocols", "categories": ["cs.MA", "cs.AI", "cs.PL", "cs.SE", "I.2.11; I.2.4; I.2.5"], "comment": null, "summary": "Interaction-Oriented Programming (IOP) is an approach to building a\nmultiagent system by modeling the interactions between its roles via a flexible\ninteraction protocol and implementing agents to realize the interactions of the\nroles they play in the protocol.\n  In recent years, we have developed an extensive suite of software that\nenables multiagent system developers to apply IOP. These include tools for\nefficiently verifying protocols for properties such as liveness and safety and\nmiddleware that simplifies the implementation of agents. This paper presents\nsome of that software suite."}
