<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Bounded Model Checking of RISC-V Machine Code with Context-Free-Language Ordered Binary Decision Diagrams](https://arxiv.org/abs/2507.09539)
*Anna Bolotina,Christoph M. Kirsch,Stefanie Muroya Lei,Matthias Pleschinger*

Main category: cs.PL

TL;DR: 该论文探讨了符号执行在软件分析中的可扩展性问题，提出将推理下推到机器码级别并完全依赖SMT求解器，开发了工具rotor和bitme以验证其潜力。


<details>
  <summary>Details</summary>
Motivation: 符号执行在软件分析中面临状态爆炸的挑战，现有工具通常在控制流和数据流之间权衡，且依赖源代码或中间表示。论文旨在探索在机器码级别进行位精确推理的可行性。

Method: 开发了rotor用于模型生成，bitme用于有界模型检查，并利用RISC-V整数语义作为建模目标。bitme采用BDDs（ADDs和CFLOBDDs）传播程序输入，减少对SMT求解器的依赖。

Result: 实验表明，现有SMT求解器在机器码级别的推理中表现不佳，但通过BDDs（尤其是CFLOBDDs）可显著提升效率，减少状态爆炸问题。

Conclusion: 论文展示了在机器码级别进行位精确推理的潜力，并通过BDDs优化了符号执行的效率，为未来研究提供了方向。

Abstract: Symbolic execution is a powerful technique for analyzing the behavior of
software yet scalability remains a challenge due to state explosion in control
and data flow. Existing tools typically aim at managing control flow
internally, often at the expense of completeness, while offloading reasoning
over data flow to SMT solvers. Moreover, reasoning typically happens on source
code or intermediate representation level to leverage structural information,
making machine code generation part of the trust base. We are interested in
changing the equation in two non-trivial ways: pushing reasoning down to
machine code level, and then offloading reasoning entirely into SMT solvers and
other, possibly more efficient solver technology. In more abstract terms, we
are asking if bit-precise reasoning technology can be made scalable on
software, and not just hardware. For this purpose, we developed two tools
called rotor and bitme for model generation and bounded model checking,
respectively. We chose RISC-V restricted to integer arithmetic as modeling
target for rotor since RISC-V integer semantics is essentially equivalent to
established SMT semantics over bitvectors and arrays of bitvectors. While
state-of-the-art SMT solvers struggle in our experiments, we have evidence that
there is potential for improvement. To show the potential, we have slightly
generalized and then implemented in bitme two types of binary decision diagrams
(BDDs): algebraic decision diagrams (ADDs) and context-free-language ordered
binary decision diagrams (CFLOBDDs). Bitme uses BDDs to propagate program input
through models, essentially generalizing constant propagation to domain
propagation. SMT solvers only get involved when model input cannot be
propagated, significanly speeding up SMT solving. We then study the impact on
state explosion of CFLOBDDs, which are potentially more scalable than ADDs.

</details>


### [2] [BeePL: Correct-by-compilation kernel extensions](https://arxiv.org/abs/2507.09883)
*Swarn Priya,Frédéric Besson,Connor Sughrue,Tim Steenvoorden,Jamie Fulford,Freek Verbeek,Binoy Ravindran*

Main category: cs.PL

TL;DR: BeePL是一种针对eBPF的领域特定语言，通过形式化验证的类型系统确保程序安全，解决了现有eBPF验证器的不足。


<details>
  <summary>Details</summary>
Motivation: eBPF验证器在某些情况下过于保守或不够安全，无法完全保证程序的安全性和正确性。

Method: 引入BeePL语言，设计形式化验证的类型系统，静态检查关键安全属性，并在编译时插入运行时检查。

Result: BeePL确保程序满足内存安全、终止性和控制流等关键属性，并通过形式化证明支持其安全性。

Conclusion: BeePL为eBPF提供了一个端到端可验证的工具链，显著提升了内核扩展的安全性和可靠性。

Abstract: eBPF is a technology that allows developers to safely extend kernel
functionality without modifying kernel source code or developing loadable
kernel modules. Since the kernel governs critical system operations and
enforces isolation boundaries between user space and privileged data, any
mechanism that modifies its behavior must meet the highest standards of safety
and correctness. To this end, the eBPF toolchain includes a verifier, which
statically checks safety properties such as memory access validity, bounded
loops, and type correctness before loading the program into the kernel.
However, the existing verifier is both overly conservative in some
cases-rejecting valid programs-and unsound in others, permitting unsafe
behavior that violates the intended semantics of the kernel interface.
  To address these challenges, we introduce BeePL, a domain-specific language
for eBPF with a formally verified type system. The BeePL type system, along
with the language design, statically enforces key safety properties such as
type-correct memory access, safe pointer usage, absence of unbounded loops, and
structured control flow. These guarantees are backed by formal type soundness
proofs, ensuring that well-typed programs satisfy the safety invariants
required by the eBPF execution environment. BeePL also proves that well-typed
source programs meet critical eBPF-specific properties related to memory
safety, termination, and control flow, enabling high-level reasoning prior to
compilation. For properties not fully enforceable statically-such as dynamic
bounds and undefined behavior-BeePL inserts semantics-preserving runtime checks
during compilation. We develop a verified compilation strategy that extends
CompCert to generate BPF bytecode from BeePL programs, establishing a
principled foundation for an end-to-end verifiable toolchain for safe kernel
extensions.

</details>


### [3] [Rows and Capabilities as Modal Effects](https://arxiv.org/abs/2507.10301)
*Wenhao Tang,Sam Lindley*

Main category: cs.PL

TL;DR: 提出一个统一的框架，用于编码、分析和比较基于行多态和能力的效果系统，揭示效果跟踪机制的本质。


<details>
  <summary>Details</summary>
Motivation: 理解基于行多态和能力的效果系统之间的精确关系，解决效果跟踪与其他特性（如函数）纠缠的问题。

Method: 利用模态效果类型，提出一个统一的框架，支持从现有系统到框架的宏翻译，保留类型和语义。

Result: 编码揭示了不同效果系统中效果跟踪机制的本质，支持直接分析差异，并为语言设计提供见解。

Conclusion: 该框架为效果系统的比较和分析提供了新方法，有助于未来语言设计。

Abstract: Effect handlers allow programmers to model and compose computational effects
modularly. Effect systems statically guarantee that all effects are handled.
Several recent practical effect systems are based on either row polymorphism or
capabilities. However, there remains a gap in understanding the precise
relationship between effect systems with such disparate foundations. The main
difficulty is that in both row-based and capability-based systems, effect
tracking is typically entangled with other features such as functions.
  We propose a uniform framework for encoding, analysing, and comparing effect
systems. Our framework exploits and generalises modal effect types, a recent
novel effect system which decouples effect tracking from functions via
modalities. Modalities offer fine-grained control over when and how effects are
tracked, enabling us to express different strategies for effect tracking. We
give encodings as macro translations from existing row-based and
capability-based effect systems into our framework and show that these
encodings preserve types and semantics. Our encodings reveal the essence of
effect tracking mechanisms in different effect systems, enable a direct
analysis on their differences, and provide valuable insights on language
design.

</details>


### [4] [Orthologic Type Systems](https://arxiv.org/abs/2507.10482)
*Simon Guilloud,Viktor Kunčak*

Main category: cs.PL

TL;DR: 论文提出基于正交逻辑设计支持交、并、补类型及子类型假设的类型系统，扩展了正交逻辑以支持单调和反单调函数，并提出了部分切割消除的证明系统。最终给出了O(n²(1+m))的子类型判定算法和O(n²)的多项式时间规范化算法。


<details>
  <summary>Details</summary>
Motivation: 设计支持复杂类型操作（如交、并、补）的类型系统，同时处理子类型假设，以提升类型系统的表达能力。

Method: 扩展正交逻辑以支持单调和反单调函数，构建包含函数符号的证明系统，并证明其部分切割消除性质。

Result: 提出了O(n²(1+m))的子类型判定算法和O(n²)的规范化算法，简化类型至最小规范形式。

Conclusion: 通过正交逻辑的扩展和算法实现，成功支持了复杂类型操作和子类型假设的高效处理。

Abstract: We propose to use orthologic as the basis for designing type systems
supporting intersection, union, and negation types in the presence of subtyping
assumptions. We show how to extend orthologic to support monotonic and
antimonotonic functions, supporting the use of type constructors in such type
systems. We present a proof system for orthologic with function symbols,
showing that it admits partial cut elimination. Using these insights, we
present an $\mathcal O(n^2(1+m))$ algorithm for deciding the subtyping relation
under $m$ assumptions. We also show $O(n^2)$ polynomial-time normalization
algorithm, allowing simplification of types to their minimal canonical form.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [5] [ReDemon UI: Reactive Synthesis by Demonstration for Web UI](https://arxiv.org/abs/2507.10099)
*Jay Lee,Gyuhyeok Oh,Joongwon Ahn,Xiaokang Qiu*

Main category: cs.HC

TL;DR: ReDemon UI通过用户演示生成React应用，帮助设计师和非专业程序员创建符合标准UI原型工作流程的界面。


<details>
  <summary>Details</summary>
Motivation: 让设计师和非专业程序员能够轻松创建动态UI，无需深入编程知识。

Method: 用户提供静态草图并演示行为，系统识别响应式数据，结合枚举合成和LLM生成React程序。

Result: 成功合成了具有正确状态更新逻辑的React应用。

Conclusion: ReDemon UI为非专业开发者提供了一种高效创建动态UI的方法。

Abstract: ReDemon UI synthesizes React applications from user demonstrations, enabling
designers and non-expert programmers to create UIs that integrate with standard
UI prototyping workflows. Users provide a static mockup sketch with event
handler holes and demonstrate desired runtime behaviors by interacting with the
rendered mockup and editing the sketch. ReDemon UI identifies reactive data and
synthesizes a React program with correct state update logic. We utilize
enumerative synthesis for simple UIs and LLMs for more complex UIs.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [6] [Toolsuite for Implementing Multiagent Systems Based on Communication Protocols](https://arxiv.org/abs/2507.10324)
*Amit K. Chopra,Samuel H. Christie V,Munindar P. Singh*

Main category: cs.MA

TL;DR: 本文介绍了交互导向编程（IOP）及其相关工具，用于多智能体系统的开发和验证。


<details>
  <summary>Details</summary>
Motivation: 通过灵活的交互协议建模角色间的交互，简化多智能体系统的开发。

Method: 开发了一套软件工具，包括协议验证和中间件实现。

Result: 提供了高效验证协议属性的工具和简化代理实现的中间件。

Conclusion: IOP及其工具套件为多智能体系统的开发提供了实用支持。

Abstract: Interaction-Oriented Programming (IOP) is an approach to building a
multiagent system by modeling the interactions between its roles via a flexible
interaction protocol and implementing agents to realize the interactions of the
roles they play in the protocol.
  In recent years, we have developed an extensive suite of software that
enables multiagent system developers to apply IOP. These include tools for
efficiently verifying protocols for properties such as liveness and safety and
middleware that simplifies the implementation of agents. This paper presents
some of that software suite.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Semantic Source Code Segmentation using Small and Large Language Models](https://arxiv.org/abs/2507.08992)
*Abdelhalim Dahou,Ansgar Scherp,Sebastian Kurten,Brigitte Mathiak,Madhu Chauhan*

Main category: cs.SE

TL;DR: 论文提出了一种自动化方法，利用大语言模型（LLMs）和小语言模型（SLMs）对研究领域的R代码进行分割，并比较了两种方法的效果。


<details>
  <summary>Details</summary>
Motivation: 随着代码库规模的增长，手动和基于语法分析的方法变得不切实际，尤其是在低资源语言（如R）及其研究领域（如社会科学、心理学）中。

Method: 提出了两种新颖的方法：基于上下文的逐行分析和基于范围的片段确定，并实验了LLMs和微调的SLMs。

Result: 结果显示，基于上下文的逐行分析优于基于范围的分割，且小语言模型（如CodeBERT和CodeT5+）表现优于大语言模型。

Conclusion: 即使未在预训练中接触R代码，仅通过微调少量手动标注代码，小语言模型也能表现出色。

Abstract: Source code segmentation, dividing code into functionally coherent segments,
is crucial for knowledge retrieval and maintenance in software development.
While enabling efficient navigation and comprehension of large codebases,
manual and syntactic analysis approaches have become impractical as
repositories grow, especially for low-resource languages like R and their
research domains (e.g., social sciences, psychology).This paper introduces an
automated, domain-specific approach for research R code segmentation using
Large and Small Language Models (LLMs/SLMs). It presents two novel approaches
and a human-annotated dataset, StatCodeSeg. We explore two distinct approaches:
line-by-line analysis with context and range-based segment determination. We
experiment with LLMs and fine-tuned SLMs. To support the generalizability of
our approaches, we also include experiments on Python code from the computer
science domain.Our results show that context-based line-by-line analysis is
superior over range-based segmentation.Using smaller language models like
CodeBERT and an encoder-only version of CodeT5+ are better than their LLM
counterparts. Most notably, these two best-performing models did not see R code
during pre-training versus the LLMs but were only fine-tuned on 4,130 lines of
manually annotated code.

</details>
