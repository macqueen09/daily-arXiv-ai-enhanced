{"id": "2507.16051", "pdf": "https://arxiv.org/pdf/2507.16051", "abs": "https://arxiv.org/abs/2507.16051", "authors": ["Juan Altmayer Pizzorno", "Emery D. Berger"], "title": "RightTyper: Effective and Efficient Type Annotation for Python", "categories": ["cs.PL", "cs.SE"], "comment": null, "summary": "Python type annotations bring the benefits of static type checking to the\nlanguage. However, manually writing annotations can be time-consuming and\ntedious. The result is that most real-world Python code remains largely\nuntyped. Past approaches to annotating types in Python code fall short in a\nnumber of ways. Static approaches struggle with dynamic features and infer\noverly broad types. AI-based methods are inherently unsound and can miss rare\nor user-defined types. Dynamic methods can impose extreme runtime overheads,\ndegrading performance by up to 270x, abort execution as they exhaust resources,\nand even infer incorrect types that lead to runtime errors. Crucially, all\nprior work assumes implicitly that the code to be annotated is already correct.\nThis assumption is generally unwarranted, especially for large codebases that\nhave been untyped.\n  This paper presents RightTyper, a novel approach for Python that overcomes\nthese disadvantages. RightTyper not only generates precise type annotations\nbased on actual program behavior, improving recall in type checking relative to\nprior approaches. It also turns type checking into anomaly detection, allowing\nthe type checker to identify corner cases that the programmer can audit for\nunintended behavior. RightTyper is also fast and space-efficient, imposing just\n30% performance overhead on average. RightTyper achieves these characteristics\nby a principled yet pervasive use of sampling--guided by self-profiling--along\nwith statistical filtering and careful resolution and aggregation of type\ninformation."}
{"id": "2507.16086", "pdf": "https://arxiv.org/pdf/2507.16086", "abs": "https://arxiv.org/abs/2507.16086", "authors": ["Andrew Marmaduke", "Apoorv Ingle", "J. Garrett Morris"], "title": "Understanding Haskell-style Overloading via Open Data and Open Functions", "categories": ["cs.PL"], "comment": null, "summary": "We present a new, uniform semantics for Haskell-style overloading. We realize\nour approach in a new core language, System F$_\\mathrm{D}$, whose metatheory we\nmechanize in the Lean4 interactive theorem prover. System F$_\\mathrm{D}$ is\ndistinguished by its open data types and open functions, each given by a\ncollection of instances rather than by a single definition. We show that System\nF$_\\mathrm{D}$ can encode advanced features of Haskell's of type class systems,\nmore expressively than current semantics of these features, and without\nassuming additional type equality axioms."}
{"id": "2507.16089", "pdf": "https://arxiv.org/pdf/2507.16089", "abs": "https://arxiv.org/abs/2507.16089", "authors": ["Michael J. Sullivan", "Zhibo Chen", "Elvis Pranskevichus", "Robert J. Simmons", "Victor Petrovykh", "Aljaž Mur Eržen", "Yury Selivanov"], "title": "Querying Graph-Relational Data", "categories": ["cs.PL", "cs.DB"], "comment": null, "summary": "For applications that store structured data in relational databases, there is\nan impedance mismatch between the flat representations encouraged by relational\ndata models and the deeply nested information that applications expect to\nreceive. In this work, we present the graph-relational database model, which\nprovides a flexible, compositional, and strongly-typed solution to this\n\"object-relational mismatch.\" We formally define the graph-relational database\nmodel and present a static and dynamic semantics for queries. In addition, we\ndiscuss the realization of the graph-relational database model in EdgeQL, a\ngeneral-purpose SQL-style query language, and the Gel system, which compiles\nEdgeQL schemas and queries into PostgreSQL queries. Gel facilitates the kind of\nobject-shaped data manipulation that is frequently provided inefficiently by\nobject-relational mapping (ORM) technologies, while achieving most of the\nefficiency that comes from require writing complex PostgreSQL queries directly."}
{"id": "2507.16660", "pdf": "https://arxiv.org/pdf/2507.16660", "abs": "https://arxiv.org/abs/2507.16660", "authors": ["Xuran Cai"], "title": "Enhancing Compiler Optimization Efficiency through Grammatical Decompositions of Control-Flow Graphs", "categories": ["cs.PL"], "comment": null, "summary": "This thesis addresses the complexities of compiler optimizations, such as\nregister allocation and Lifetime-optimal Speculative Partial Redundancy\nElimination (LOSPRE), which are often handled using tree decomposition\nalgorithms. However, these methods frequently overlook important sparsity\naspects of Control Flow Graphs (CFGs) and result in high computational costs.\nWe introduce the SPL (Series-Parallel-Loop) decomposition, a novel framework\nthat offers optimal solutions to these challenges. A key contribution is the\nformulation of a general solution for Partial Constraint Satisfaction Problems\n(PCSPs) within graph structures, applied to three optimization problems. First,\nSPL decomposition enhances register allocation by accurately modeling variable\ninterference graphs, leading to efficient register assignments and improved\nperformance across benchmarks. Second, it optimizes LOSPRE by effectively\nidentifying and eliminating redundancies in program execution. Finally, the\nthesis focuses on optimizing the placement of bank selection instructions to\nenhance data retrieval efficiency and reduce latency. Extensive experimentation\ndemonstrates significant performance improvements over existing methods,\nestablishing SPL decomposition as a powerful tool for complex compiler\noptimizations, including register allocation, LOSPRE, and bank selection."}
