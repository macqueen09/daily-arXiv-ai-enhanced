{"id": "2507.18509", "pdf": "https://arxiv.org/pdf/2507.18509", "abs": "https://arxiv.org/abs/2507.18509", "authors": ["Henning Urbat"], "title": "Higher-Order Behavioural Conformances via Fibrations", "categories": ["cs.PL"], "comment": null, "summary": "Coinduction is a widely used technique for establishing behavioural\nequivalence of programs in higher-order languages. In recent years, the rise of\nlanguages with quantitative (e.g.~probabilistic) features has led to extensions\nof coinductive methods to more refined types of behavioural conformances, most\nnotably notions of behavioural distance. To guarantee soundness of coinductive\nreasoning, one needs to show that the behavioural conformance at hand forms a\nprogram congruence, i.e. it is suitably compatible with the operations of the\nlanguage. This is usually achieved by a complex proof technique known as\n\\emph{Howe's method}, which needs to be carefully adapted to both the specific\nlanguage and the targeted notion of behavioural conformance. We develop a\nuniform categorical approach to Howe's method that features two orthogonal\ndimensions of abstraction: (1) the underlying higher-order language is modelled\nby an \\emph{abstract higher-order specification} (AHOS), a novel and very\ngeneral categorical account of operational semantics, and (2) notions of\nbehavioural conformance (such as relations or metrics) are modelled via\nfibrations over the base category of an AHOS. Our main result is a fundamental\ncongruence theorem at this level of generality: Under natural conditions on the\ncategorical ingredients and the operational rules of a language modelled by an\nAHOS, the greatest behavioural (bi)conformance on its operational model forms a\ncongruence. We illustrate our theory by deriving congruence of bisimilarity and\nbehavioural pseudometrics for probabilistic higher-order languages.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u8303\u7574\u5316\u65b9\u6cd5\uff0c\u6269\u5c55\u4e86Howe\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc1\u660e\u9ad8\u9636\u8bed\u8a00\u4e2d\u884c\u4e3a\u4e00\u81f4\u6027\u7684\u7a0b\u5e8f\u540c\u4f59\u6027\u3002", "motivation": "\u968f\u7740\u5177\u6709\u5b9a\u91cf\u7279\u5f81\uff08\u5982\u6982\u7387\uff09\u7684\u8bed\u8a00\u5174\u8d77\uff0c\u9700\u8981\u6269\u5c55\u5171\u5f52\u7eb3\u65b9\u6cd5\u4ee5\u652f\u6301\u66f4\u7cbe\u7ec6\u7684\u884c\u4e3a\u4e00\u81f4\u6027\u6982\u5ff5\uff0c\u5982\u884c\u4e3a\u8ddd\u79bb\u3002", "method": "\u91c7\u7528\u62bd\u8c61\u7684\u8303\u7574\u5316\u6846\u67b6\uff08AHOS\uff09\u548c\u7ea4\u7ef4\u5316\u6a21\u578b\uff0c\u7edf\u4e00\u5904\u7406\u884c\u4e3a\u4e00\u81f4\u6027\uff0c\u5e76\u8bc1\u660e\u5176\u540c\u4f59\u6027\u3002", "result": "\u5728AHOS\u6846\u67b6\u4e0b\uff0c\u8bc1\u660e\u4e86\u6700\u5927\u884c\u4e3a\uff08\u53cc\uff09\u4e00\u81f4\u6027\u5f62\u6210\u540c\u4f59\u6027\uff0c\u9002\u7528\u4e8e\u6982\u7387\u9ad8\u9636\u8bed\u8a00\u3002", "conclusion": "\u8be5\u7406\u8bba\u4e3a\u884c\u4e3a\u4e00\u81f4\u6027\u7684\u540c\u4f59\u6027\u8bc1\u660e\u63d0\u4f9b\u4e86\u901a\u7528\u65b9\u6cd5\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u6982\u7387\u9ad8\u9636\u8bed\u8a00\u7684\u6848\u4f8b\u5206\u6790\u3002"}}
{"id": "2507.18268", "pdf": "https://arxiv.org/pdf/2507.18268", "abs": "https://arxiv.org/abs/2507.18268", "authors": ["Giulio Malenza", "Giovanni Stabile", "Filippo Spiga", "Robert Birke", "Marco Aldinucci"], "title": "Building an Accelerated OpenFOAM Proof-of-Concept Application using Modern C++", "categories": ["cs.MS", "cs.PF", "cs.PL"], "comment": null, "summary": "The modern trend in High-Performance Computing (HPC) involves the use of\naccelerators such as Graphics Processing Units (GPUs) alongside Central\nProcessing Units (CPUs) to speed up numerical operations in various\napplications. Leading manufacturers such as NVIDIA, Intel, and AMD are\nconstantly advancing these architectures, augmenting them with features such as\nmixed precision, enhanced memory hierarchies, and specialised accelerator\nsilicon blocks (e.g., Tensor Cores on GPU or AMX/SME engines on CPU) to enhance\ncompute performance. At the same time, significant efforts in software\ndevelopment are aimed at optimizing the use of these innovations, seeking to\nimprove usability and accessibility. This work contributes to the\nstate-of-the-art of OpenFOAM development by presenting a working\nProof-Of-Concept application built using modern ISO C++ parallel constructs.\nThis approach, combined with an appropriate compiler runtime stack, like the\none provided by the NVIDIA HPC SDK, makes it possible to accelerate\nwell-defined kernels, allowing multi-core execution and GPU offloading using a\nsingle codebase. The study demonstrates that it is possible to increase the\nperformance of the OpenFOAM laplacianFoam application by offloading the\ncomputations on NVIDIA GPUs using the C++ parallel construct.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u73b0\u4ee3ISO C++\u5e76\u884c\u7ed3\u6784\u52a0\u901fOpenFOAM\u5e94\u7528\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7GPU\u5378\u8f7d\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u9ad8\u6027\u80fd\u8ba1\u7b97\u8d8b\u52bf\u4e2d\uff0c\u52a0\u901f\u5668\uff08\u5982GPU\uff09\u4e0eCPU\u7ed3\u5408\u4f7f\u7528\u4ee5\u63d0\u5347\u8ba1\u7b97\u6027\u80fd\uff0c\u4f46\u9700\u8981\u4f18\u5316\u8f6f\u4ef6\u4ee5\u5145\u5206\u5229\u7528\u786c\u4ef6\u521b\u65b0\u3002", "method": "\u91c7\u7528\u73b0\u4ee3ISO C++\u5e76\u884c\u7ed3\u6784\uff0c\u7ed3\u5408NVIDIA HPC SDK\u7f16\u8bd1\u5668\u8fd0\u884c\u65f6\u6808\uff0c\u5b9e\u73b0\u591a\u6838\u6267\u884c\u548cGPU\u5378\u8f7d\u7684\u5355\u4ee3\u7801\u5e93\u3002", "result": "\u901a\u8fc7GPU\u5378\u8f7d\uff0c\u6210\u529f\u63d0\u5347\u4e86OpenFOAM\u4e2dlaplacianFoam\u5e94\u7528\u7684\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5229\u7528C++\u5e76\u884c\u7ed3\u6784\u53ef\u4ee5\u9ad8\u6548\u5b9e\u73b0GPU\u52a0\u901f\uff0c\u4e3aOpenFOAM\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.18454", "pdf": "https://arxiv.org/pdf/2507.18454", "abs": "https://arxiv.org/abs/2507.18454", "authors": ["Juntao Zhao", "Jiuru Li", "Chuan Wu"], "title": "Sandwich: Separating Prefill-Decode Compilation for Efficient CPU LLM Serving", "categories": ["cs.AR", "cs.AI", "cs.DC", "cs.PL"], "comment": null, "summary": "Utilizing CPUs to serve large language models (LLMs) is a resource-friendly\nalternative to GPU serving. Existing CPU-based solutions ignore workload\ndifferences between the prefill and the decode phases of LLM inference,\napplying a static per-NUMA (Non-Uniform Memory Access) node model partition and\nutilizing vendor libraries for operator-level execution, which is suboptimal.\nWe propose Sandwich, a hardware-centric CPU-based LLM serving engine that uses\ndifferent execution plans for the prefill and decode phases and optimizes them\nseparately.\n  We evaluate Sandwich across diverse baselines and datasets on five CPU\nplatforms, including x86 with AVX-2 and AVX-512, as well as ARM with NEON.\nSandwich achieves an average 2.01x throughput improvement and 90% satisfactory\ntime-to-first-token (TTFT) and time-per-output-token (TPOT) latencies with up\nto 3.40x lower requirements in single sequence serving, and significant\nimprovement in Goodput in continuous-batching serving. The GEMM kernels\ngenerated by Sandwich outperform representative vendor kernels and other\ndynamic shape solutions, achieving performance comparable to static compilers\nwith three orders of magnitude less kernel tuning costs.", "AI": {"tldr": "Sandwich\u662f\u4e00\u79cd\u57fa\u4e8eCPU\u7684LLM\u670d\u52a1\u5f15\u64ce\uff0c\u901a\u8fc7\u4e3a\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u8bbe\u8ba1\u4e0d\u540c\u7684\u6267\u884c\u8ba1\u5212\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eCPU\u7684\u89e3\u51b3\u65b9\u6848\u5ffd\u7565\u4e86LLM\u63a8\u7406\u4e2d\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u7684\u5de5\u4f5c\u8d1f\u8f7d\u5dee\u5f02\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u3002", "method": "\u63d0\u51faSandwich\u5f15\u64ce\uff0c\u9488\u5bf9\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u5206\u522b\u4f18\u5316\u6267\u884c\u8ba1\u5212\uff0c\u5e76\u5728\u591a\u79cdCPU\u5e73\u53f0\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "Sandwich\u5728\u541e\u5410\u91cf\u3001\u5ef6\u8fdf\u548c\u8d44\u6e90\u9700\u6c42\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\uff0c\u751f\u6210\u7684GEMM\u5185\u6838\u6027\u80fd\u63a5\u8fd1\u9759\u6001\u7f16\u8bd1\u5668\u3002", "conclusion": "Sandwich\u4e3aCPU\u4e0a\u7684LLM\u670d\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u8d44\u6e90\u53cb\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
