<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Development and Evaluation of Adaptive LearningSupport System Based on Ontology of MultipleProgramming Languages](https://arxiv.org/abs/2507.19728)
*Lalita Na Nongkhai,Jingyun Wang,Takahiko Mendori*

Main category: cs.PL

TL;DR: 论文介绍了一种基于本体的自适应学习支持系统ADVENTURE，用于个性化编程练习，通过Elo评分系统动态调整难度，实验结果显示自适应模式优于随机模式。


<details>
  <summary>Details</summary>
Motivation: 为编程学习者提供个性化的练习内容，提升学习效果。

Method: 利用本体CONTINUOUS和Elo评分系统，动态调整练习难度并提供提示。

Result: 自适应模式在正确提交和通过概念数量上显著优于随机模式。

Conclusion: ADVENTURE系统能有效支持编程学习者的练习。

Abstract: This paper introduces an ontology-based approach within an adaptive learning
support system for computer programming. This system (named ADVENTURE) is
designed to deliver personalized programming exercises that are tailored to
individual learners' skill levels. ADVENTURE utilizes an ontology, named
CONTINUOUS, which encompasses common concepts across multiple programming
languages. The system leverages this ontology not only to visualize programming
concepts but also to provide hints during practice programming exercises and
recommend subsequent programming concepts. The adaptive mechanism is driven by
the Elo Rating System, applied in an educational context to dynamically
estimate the most appropriate exercise difficulty for each learner. An
experimental study compared two instructional modes, adaptive and random, based
on six features derived from 1,186 code submissions across all the experimental
groups. The results indicate significant differences in four of six analyzed
features between these two modes. Notably, the adaptive mode demonstrates a
significant difference over the random mode in two features, the submission of
correct answers and the number of pass concepts. Therefore, these results
underscore that this adaptive learning support system may support learners in
practicing programming exercises.

</details>


### [2] [The Power of Negation in Higher-Order Datalog](https://arxiv.org/abs/2507.20251)
*Angelos Charalambidis,Babis Kostopoulos,Christos Nomikos,Panos Rondogiannis*

Main category: cs.PL

TL;DR: 研究了高阶Datalog$^\neg$在良基语义和稳定模型语义下的表达能力，揭示了与复杂性类的紧密联系。


<details>
  <summary>Details</summary>
Motivation: 探索高阶逻辑程序设计的表达能力及其与计算复杂性类的关系。

Method: 通过良基语义和稳定模型语义分析高阶Datalog$^\neg$的表达能力，使用谓词变量和部分应用关系等方法。

Result: 在良基语义下，$(k+1)$-Order Datalog$^\neg$捕获k-EXP；在稳定模型语义下，捕获co-(k-NEXP)和k-NEXP。

Conclusion: 研究揭示了高阶逻辑程序设计中阶数与非确定性之间的权衡关系。

Abstract: We investigate the expressive power of Higher-Order Datalog$^\neg$ under both
the well-founded and the stable model semantics, establishing tight connections
with complexity classes. We prove that under the well-founded semantics, for
all $k\geq 1$, $(k+1)$-Order Datalog$^\neg$ captures k-EXP, a result that holds
without explicit ordering of the input database. The proof of this fact can be
performed either by using the powerful existential predicate variables of the
language or by using partially applied relations and relation enumeration.
Furthermore, we demonstrate that this expressive power is retained within a
stratified fragment of the language. Under the stable model semantics, we show
that $(k+1)$-Order Datalog$^\neg$ captures co-(k-NEXP) using cautious reasoning
and k-NEXP using brave reasoning, again with analogous results for the
stratified fragment augmented with choice rules. Our results establish a
hierarchy of expressive power, highlighting an interesting trade-off between
order and non-determinism in the context of higher-order logic programming:
increasing the order of programs under the well-founded semantics can surpass
the expressive power of lower-order programs under the stable model semantics.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [LLM-Based Repair of Static Nullability Errors](https://arxiv.org/abs/2507.20674)
*Nima Karimipour,Michael Pradel,Martin Kellogg,Manu Sridharan*

Main category: cs.SE

TL;DR: NullRepair是一个结合LLM和静态分析的系统，用于自动修复Java代码中的空指针异常错误，解决了现有工具无法完全解决的问题。


<details>
  <summary>Details</summary>
Motivation: 现代Java项目广泛使用静态分析工具处理空指针异常，但现有工具在大型代码库中仍存在难以解决的残余错误，手动修复耗时且易出错。

Method: NullRepair通过静态分析识别符号的安全使用区域，结合LLM生成修复补丁，采用迭代交互和项目全局上下文优化决策。

Result: 在12个真实Java项目中，NullRepair平均修复了72%的残余错误，且保持了程序语义，10/12项目的所有单元测试通过。

Conclusion: NullRepair展示了LLM在结构化工作流中的潜力，能够高效且准确地修复空指针异常错误。

Abstract: Modern Java projects increasingly adopt static analysis tools that prevent
null-pointer exceptions by treating nullness as a type property. However,
integrating such tools into large, existing codebases remains a significant
challenge. While annotation inference can eliminate many errors automatically,
a subset of residual errors -- typically a mix of real bugs and false positives
-- often persist and can only be resolved via code changes. Manually addressing
these errors is tedious and error-prone. Large language models (LLMs) offer a
promising path toward automating these repairs, but naively-prompted LLMs often
generate incorrect, contextually-inappropriate edits. Resolving a nullability
error demands a deep understanding of how a symbol is used across the codebase,
often spanning methods, classes, and packages. We present NullRepair, a system
that integrates LLMs into a structured workflow for resolving the errors from a
nullability checker. NullRepair's decision process follows a flowchart derived
from manual analysis of 200 real-world errors. It leverages static analysis to
identify safe and unsafe usage regions of symbols, using error-free usage
examples to contextualize model prompts. Patches are generated through an
iterative interaction with the LLM that incorporates project-wide context and
decision logic. Our evaluation on 12 real-world Java projects shows that
NullRepair resolves an average of 72% of the errors that remain after applying
a state-of-the-art annotation inference technique. Unlike a naively-prompted
LLM, NullRepair also largely preserves program semantics, with all unit tests
passing in 10/12 projects after applying every edit proposed by NullRepair, and
98% or more tests passing in the remaining two projects.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [4] [Program Analysis for High-Value Smart Contract Vulnerabilities: Techniques and Insights](https://arxiv.org/abs/2507.20672)
*Yannis Smaragdakis,Neville Grech,Sifis Lagouvardos,Konstantinos Triantafyllou,Ilias Tsatiris,Yannis Bollanos,Tony Rocco Valentine*

Main category: cs.CR

TL;DR: 论文展示了自动化技术在发现高价值智能合约漏洞中的成功应用，通过高完整性静态分析和领域知识实现了显著成果。


<details>
  <summary>Details</summary>
Motivation: 反驳区块链安全社区认为自动化技术只能检测低价值漏洞的普遍观点，证明自动化技术在高价值漏洞发现中的潜力。

Method: 采用高完整性静态分析结合领域知识（专家提供或通过统计推断获取），并提出从大量合约中自动推断领域知识的新技术。

Result: 成功发现多个高价值漏洞，获得10个漏洞赏金（总计超过300万美元），并在预部署或审计代码中检测到数百个漏洞。

Conclusion: 高价值漏洞检测工具需要高误报率和低警告率，与传统学术研究中的低误报率要求形成对比。

Abstract: A widespread belief in the blockchain security community is that automated
techniques are only good for detecting shallow bugs, typically of small value.
In this paper, we present the techniques and insights that have led us to
repeatable success in automatically discovering high-value smart contract
vulnerabilities. Our vulnerability disclosures have yielded 10 bug bounties,
for a total of over $3M, over high-profile deployed code, as well as hundreds
of bugs detected in pre-deployment or under-audit code.
  We argue that the elements of this surprising success are a) a very
high-completeness static analysis approach that manages to maintain acceptable
precision; b) domain knowledge, provided by experts or captured via statistical
inference. We present novel techniques for automatically inferring domain
knowledge from statistical analysis of a large corpus of deployed contracts, as
well as discuss insights on the ideal precision and warning rate of a promising
vulnerability detector. In contrast to academic literature in program analysis,
which routinely expects false-positive rates below 50% for publishable results,
we posit that a useful analysis for high-value real-world vulnerabilities will
likely flag very few programs (under 1%) and will do so with a high
false-positive rate (e.g., 95%, meaning that only one-of-twenty human
inspections will yield an exploitable vulnerability).

</details>
