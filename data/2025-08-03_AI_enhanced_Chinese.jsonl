{"id": "2507.23151", "pdf": "https://arxiv.org/pdf/2507.23151", "abs": "https://arxiv.org/abs/2507.23151", "authors": ["Louis Rustenholz", "Pedro Lopez-Garcia", "Manuel V. Hermenegildo"], "title": "Abstractions of Sequences, Functions and Operators", "categories": ["cs.PL", "cs.LO"], "comment": "Under consideration for publication in STTT", "summary": "We present theoretical and practical results on the order theory of lattices\nof functions, focusing on Galois connections that abstract (sets of) functions\n- a topic known as higher-order abstract interpretation.\n  We are motivated by the challenge of inferring closed-form bounds on\nfunctions which are defined recursively, i.e. as the fixed point of an operator\nor, equivalently, as the solution to a functional equation. This has multiple\napplications in program analysis (e.g. cost analysis, loop acceleration,\ndeclarative language analysis) and in hybrid systems governed by differential\nequations.\n  Our main contribution is a new family of constraint-based abstract domains\nfor abstracting numerical functions, B-bound domains, which abstract a function\nf by a conjunction of bounds from a preselected set of boundary functions. They\nallow inferring highly non-linear numerical invariants, which classical\nnumerical abstract domains struggle with. We uncover a convexity property in\nthe constraint space that simplifies, and, in some cases, fully automates,\ntransfer function design.\n  We also introduce domain abstraction, a functor that lifts arbitrary mappings\nin value space to Galois connections in function space. This supports\nabstraction from symbolic to numerical functions (i.e. size abstraction), and\nenables dimensionality reduction of equations.\n  We base our constructions of transfer functions on a simple operator\nlanguage, starting with sequences, and extending to more general functions,\nincluding multivariate, piecewise, and non-discrete domains.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u51fd\u6570\u683c\u5e8f\u7406\u8bba\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ea6\u675f\u62bd\u8c61\u57dfB-bound domains\uff0c\u7528\u4e8e\u63a8\u65ad\u9012\u5f52\u5b9a\u4e49\u7684\u51fd\u6570\u7684\u95ed\u5f0f\u8fb9\u754c\uff0c\u5e76\u5f15\u5165\u4e86\u57df\u62bd\u8c61\u6280\u672f\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u9012\u5f52\u5b9a\u4e49\u51fd\u6570\u7684\u95ed\u5f0f\u8fb9\u754c\u63a8\u65ad\u95ee\u9898\uff0c\u5e94\u7528\u4e8e\u7a0b\u5e8f\u5206\u6790\u548c\u6df7\u5408\u7cfb\u7edf\u7b49\u9886\u57df\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u63d0\u51faB-bound domains\u62bd\u8c61\u57df\uff0c\u5229\u7528\u51f8\u6027\u7b80\u5316\u4f20\u9012\u51fd\u6570\u8bbe\u8ba1\uff0c\u5e76\u5f15\u5165\u57df\u62bd\u8c61\u6280\u672f\u3002", "result": "\u7ed3\u679c\u8868\u660eB-bound domains\u80fd\u63a8\u65ad\u9ad8\u5ea6\u975e\u7ebf\u6027\u6570\u503c\u4e0d\u53d8\u91cf\uff0c\u4f18\u4e8e\u7ecf\u5178\u6570\u503c\u62bd\u8c61\u57df\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8fd9\u4e9b\u65b9\u6cd5\u5728\u7a0b\u5e8f\u5206\u6790\u548c\u6df7\u5408\u7cfb\u7edf\u4e2d\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.23205", "pdf": "https://arxiv.org/pdf/2507.23205", "abs": "https://arxiv.org/abs/2507.23205", "authors": ["Hebi Li", "Forrest Sheng Bao", "Qi Xiao", "Jin Tian"], "title": "Kernel-FFI: Transparent Foreign Function Interfaces for Interactive Notebooks", "categories": ["cs.PL", "cs.SE"], "comment": null, "summary": "Foreign Function Interfaces (FFIs) are essential for enabling\ninteroperability between programming languages, yet existing FFI solutions are\nill-suited for the dynamic, interactive workflows prevalent in modern notebook\nenvironments such as Jupyter. Current approaches require extensive manual\nconfiguration, introduce significant boilerplate, and often lack support for\nrecursive calls and object-oriented programming (OOP) constructs-features\ncritical for productive, multi-language development.\n  We present Kernel-FFI, a transparent, language-agnostic framework that\nenables seamless cross-language function calls and object manipulation within\ninteractive notebooks. Kernel-FFI employs source-level transformation to\nautomatically rewrite cross-language invocations, eliminating the need for\nmanual bindings or boilerplate. Kernel-FFI provides robust support for OOP by\nenabling foreign object referencing and automatic resource management across\nlanguage boundaries. Furthermore, to address the blocking nature of Jupyter\nkernels and support recursive and asynchronous foreign calls, we introduce a\nnovel side-channel communication mechanism. Our tool will be open-sourced and\navailable at https://codepod.io/docs/kernel-ffi", "AI": {"tldr": "Kernel-FFI\u662f\u4e00\u4e2a\u900f\u660e\u3001\u8bed\u8a00\u65e0\u5173\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4ea4\u4e92\u5f0f\u7b14\u8bb0\u672c\u4e2d\u5b9e\u73b0\u65e0\u7f1d\u8de8\u8bed\u8a00\u51fd\u6570\u8c03\u7528\u548c\u5bf9\u8c61\u64cd\u4f5c\uff0c\u89e3\u51b3\u4e86\u73b0\u6709FFI\u89e3\u51b3\u65b9\u6848\u5728\u52a8\u6001\u5de5\u4f5c\u6d41\u4e2d\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709FFI\u89e3\u51b3\u65b9\u6848\u5728\u52a8\u6001\u4ea4\u4e92\u5f0f\u7b14\u8bb0\u672c\u73af\u5883\u4e2d\u5b58\u5728\u914d\u7f6e\u7e41\u7410\u3001\u7f3a\u4e4f\u9012\u5f52\u8c03\u7528\u548c\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u652f\u6301\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u591a\u8bed\u8a00\u5f00\u53d1\u7684\u6548\u7387\u3002", "method": "Kernel-FFI\u901a\u8fc7\u6e90\u4ee3\u7801\u7ea7\u8f6c\u6362\u81ea\u52a8\u91cd\u5199\u8de8\u8bed\u8a00\u8c03\u7528\uff0c\u65e0\u9700\u624b\u52a8\u7ed1\u5b9a\u6216\u5197\u4f59\u4ee3\u7801\uff0c\u5e76\u5f15\u5165\u4fa7\u901a\u9053\u901a\u4fe1\u673a\u5236\u652f\u6301\u9012\u5f52\u548c\u5f02\u6b65\u8c03\u7528\u3002", "result": "Kernel-FFI\u63d0\u4f9b\u4e86\u5bf9\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u7684\u5168\u9762\u652f\u6301\uff0c\u5305\u62ec\u8de8\u8bed\u8a00\u5bf9\u8c61\u5f15\u7528\u548c\u81ea\u52a8\u8d44\u6e90\u7ba1\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u8bed\u8a00\u5f00\u53d1\u7684\u4fbf\u6377\u6027\u3002", "conclusion": "Kernel-FFI\u4e3a\u4ea4\u4e92\u5f0f\u7b14\u8bb0\u672c\u73af\u5883\u4e2d\u7684\u8de8\u8bed\u8a00\u5f00\u53d1\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u900f\u660e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c06\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2507.23186", "pdf": "https://arxiv.org/pdf/2507.23186", "abs": "https://arxiv.org/abs/2507.23186", "authors": ["Peter Sharpe"], "title": "NaN-Propagation: A Novel Method for Sparsity Detection in Black-Box Computational Functions", "categories": ["cs.LG", "cs.PL"], "comment": null, "summary": "Sparsity detection in black-box functions enables significant computational\nspeedups in gradient-based optimization through Jacobian compression, but\nexisting finite-difference methods suffer from false negatives due to\ncoincidental zero gradients. These false negatives can silently corrupt\ngradient calculations, leading to difficult-to-diagnose errors. We introduce\nNaN-propagation, which exploits the universal contamination property of IEEE\n754 Not-a-Number floating-point values to trace input-output dependencies\nthrough floating-point numerical computations. By systematically contaminating\ninputs with NaN and observing which outputs become NaN, the method reconstructs\nconservative sparsity patterns that eliminate false negatives. We demonstrate\nthe approach on an aerospace wing weight model, achieving a 1.52x speedup while\ndetecting dozens of dependencies missed by conventional methods -- a\nsignificant improvement since gradient computation is the bottleneck in many\noptimization workflows. The technique leverages IEEE 754 compliance to work\nacross programming languages and math libraries without modifying existing\nblack-box codes. Advanced strategies including NaN payload encoding enable\nfaster-than-linear time complexity, improving upon existing black-box sparsity\ndetection methods. Practical algorithms are also proposed to mitigate\nchallenges from branching code execution common in engineering applications.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eNaN\u4f20\u64ad\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u9ed1\u76d2\u51fd\u6570\u4e2d\u7684\u7a00\u758f\u6027\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u6709\u9650\u5dee\u5206\u65b9\u6cd5\u4e2d\u7684\u5047\u9634\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68af\u5ea6\u8ba1\u7b97\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u6709\u9650\u5dee\u5206\u65b9\u6cd5\u5728\u68c0\u6d4b\u9ed1\u76d2\u51fd\u6570\u7a00\u758f\u6027\u65f6\u5b58\u5728\u5047\u9634\u6027\u95ee\u9898\uff0c\u5bfc\u81f4\u68af\u5ea6\u8ba1\u7b97\u9519\u8bef\u4e14\u96be\u4ee5\u8bca\u65ad\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u7528NaN\u6c61\u67d3\u8f93\u5165\u5e76\u89c2\u5bdf\u8f93\u51fa\u662f\u5426\u53d8\u4e3aNaN\uff0c\u91cd\u5efa\u4fdd\u5b88\u7684\u7a00\u758f\u6a21\u5f0f\uff0c\u6d88\u9664\u5047\u9634\u6027\u3002", "result": "\u5728\u822a\u7a7a\u822a\u5929\u673a\u7ffc\u91cd\u91cf\u6a21\u578b\u4e2d\uff0c\u5b9e\u73b0\u4e861.52\u500d\u7684\u52a0\u901f\uff0c\u5e76\u68c0\u6d4b\u5230\u4f20\u7edf\u65b9\u6cd5\u9057\u6f0f\u7684\u6570\u5341\u4e2a\u4f9d\u8d56\u5173\u7cfb\u3002", "conclusion": "NaN\u4f20\u64ad\u65b9\u6cd5\u5229\u7528IEEE 754\u6807\u51c6\uff0c\u65e0\u9700\u4fee\u6539\u73b0\u6709\u9ed1\u76d2\u4ee3\u7801\u5373\u53ef\u8de8\u8bed\u8a00\u548c\u6570\u5b66\u5e93\u5de5\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7a00\u758f\u6027\u68c0\u6d4b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2507.23292", "pdf": "https://arxiv.org/pdf/2507.23292", "abs": "https://arxiv.org/abs/2507.23292", "authors": ["RJ Skerry-Ryan", "Julian Salazar", "Soroosh Mariooryad", "David Kao", "Daisy Stanton", "Eric Battenberg", "Matt Shannon", "Ron J. Weiss", "Robin Scheibler", "Jonas Rothfuss", "Tom Bagby"], "title": "SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy", "categories": ["cs.LG", "cs.CL", "cs.PL", "cs.SE", "eess.AS"], "comment": null, "summary": "We introduce a neural network layer API and library for sequence modeling,\ndesigned for easy creation of sequence models that can be executed both\nlayer-by-layer (e.g., teacher-forced training) and step-by-step (e.g.,\nautoregressive sampling). To achieve this, layers define an explicit\nrepresentation of their state over time (e.g., a Transformer KV cache, a\nconvolution buffer, an RNN hidden state), and a step method that evolves that\nstate, tested to give identical results to a stateless layer-wise invocation.\nThis and other aspects of the SequenceLayers contract enables complex models to\nbe immediately streamable, mitigates a wide range of common bugs arising in\nboth streaming and parallel sequence processing, and can be implemented in any\ndeep learning library. A composable and declarative API, along with a\ncomprehensive suite of layers and combinators, streamlines the construction of\nproduction-scale models from simple streamable components while preserving\nstrong correctness guarantees. Our current implementations of SequenceLayers\n(JAX, TensorFlow 2) are available at https://github.com/google/sequence-layers.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7528\u4e8e\u5e8f\u5217\u5efa\u6a21\u7684\u795e\u7ecf\u7f51\u7edc\u5c42API\u548c\u5e93\uff0c\u652f\u6301\u9010\u5c42\u548c\u9010\u6b65\u6267\u884c\uff0c\u786e\u4fdd\u72b6\u6001\u4e00\u81f4\u6027\u3002", "motivation": "\u7b80\u5316\u5e8f\u5217\u6a21\u578b\u7684\u521b\u5efa\uff0c\u652f\u6301\u6d41\u5f0f\u5904\u7406\u548c\u5e76\u884c\u5e8f\u5217\u5904\u7406\uff0c\u51cf\u5c11\u5e38\u89c1\u9519\u8bef\u3002", "method": "\u5b9a\u4e49\u663e\u5f0f\u72b6\u6001\u8868\u793a\u548c\u9010\u6b65\u65b9\u6cd5\uff0c\u786e\u4fdd\u4e0e\u65e0\u72b6\u6001\u9010\u5c42\u8c03\u7528\u7ed3\u679c\u4e00\u81f4\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u7acb\u5373\u6d41\u5f0f\u5904\u7406\u7684\u590d\u6742\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u5c42\u548c\u7ec4\u5408\u5668\u3002", "conclusion": "SequenceLayers\u5e93\u5728JAX\u548cTensorFlow 2\u4e2d\u53ef\u7528\uff0c\u652f\u6301\u751f\u4ea7\u7ea7\u6a21\u578b\u7684\u6784\u5efa\u3002"}}
