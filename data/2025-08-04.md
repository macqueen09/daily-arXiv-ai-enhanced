<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 6]
- [cs.SE](#cs.SE) [Total: 3]
- [cs.LO](#cs.LO) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Modelling Program Spaces in Program Synthesis with Constraints](https://arxiv.org/abs/2508.00005)
*Tilman Hinnerichs,Bart Swinkels,Jaap de Jong,Reuben Gardos Reid,Tudor Magirescu,Neil Yorke-Smith,Sebastijan Dumancic*

Main category: cs.PL

TL;DR: 论文提出了一种利用语法约束来高效缩小程序空间的方法，并通过BART求解器验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 程序合成的核心挑战在于处理庞大的程序空间，现有方法未充分利用约束来剔除无用程序。

Method: 引入语法约束建模程序空间，开发BART求解器进行高效约束传播与求解。

Result: 约束可消除高达99%的程序空间，显著减少枚举时间。

Conclusion: 语法约束是优化程序合成的有效工具，BART验证了其潜力。

Abstract: A core challenge in program synthesis is taming the large space of possible
programs. Since program synthesis is essentially a combinatorial search, the
community has sought to leverage powerful combinatorial constraint solvers.
Here, constraints are used to express the program semantics, but not as a
potentially potent tool to remove unwanted programs. Recent inductive logic
programming approaches introduce constraints on the program's syntax to be
synthesized. These syntactic constraints allow for checking and propagating a
constraint without executing the program, and thus for arbitrary operators. In
this work, we leverage syntactic constraints to model program spaces, defining
not just solutions that are feasible, but also ones that are likely useful. To
demonstrate this idea, we introduce BART, a solver that efficiently propagates
and solves these constraints. We evaluate BART on program space enumeration
tasks, finding that the constraints eliminate up to 99 percent of the program
space, and that modeling program spaces significantly reduces enumeration time.

</details>


### [2] [From Provable Correctness to Probabilistic Generation: A Comparative Review of Program Synthesis Paradigms](https://arxiv.org/abs/2508.00013)
*Zurabi Kobaladze,Anna Arnania,Tamar Sanikidze*

Main category: cs.PL

TL;DR: 该论文综述了程序合成的五种主要范式，从逻辑基础方法到神经符号混合方法，分析了其原理、系统、应用及权衡。


<details>
  <summary>Details</summary>
Motivation: 探讨程序合成领域的演变，从传统逻辑方法到现代神经模型，以全面理解其进展与挑战。

Method: 比较五种关键方法：逻辑合成、归纳合成、草图/模式合成、大语言模型合成及神经符号混合方法。

Result: 展示了从形式验证工具到数据驱动模型的进展，强调了神经符号混合方法的潜力。

Conclusion: 程序合成正从符号方法转向神经符号混合方法，未来需关注可靠性与可扩展性。

Abstract: Program synthesis--the automated generation of executable code from
high-level specifications--has been a central goal of computer science for over
fifty years. This thesis provides a comparative literature review of the main
paradigms that have shaped the field, tracing its evolution from formal logic
based methods to recent advances using large scale neural models. We examine
five key approaches: logic based (deductive) synthesis, inductive (example
based) synthesis, sketch/schema based synthesis, large language model based
synthesis, and neuro-symbolic hybrids. For each, we analyze foundational
principles, notable systems, and practical applications, highlighting trade
offs between correctness guarantees, specification requirements, search
complexity, and expressive power. By reviewing developments from formally
verified synthesis tools such as KIDS and Coq to data driven models generating
probabilistic code from natural language like Codex, we present a comprehensive
narrative of progress and ongoing challenges. This work emphasizes the
transition from symbolic to hybrid neuro-symbolic methods and outlines future
directions for reliable and scalable program synthesis.

</details>


### [3] [Extended Abstract: Mutable Objects with Several Implementations](https://arxiv.org/abs/2508.00016)
*Matt Kaufmann,Yahya Sohail,Warren A. Hunt Jr*

Main category: cs.PL

TL;DR: ACL2的attach-stobj功能支持对抽象stobj的不同可执行操作，无需重新认证相关书籍或定理。


<details>
  <summary>Details</summary>
Motivation: 为了解决在ACL2中对抽象stobj进行操作时需重新认证书籍或定理的问题，提高灵活性和效率。

Method: 介绍了attach-stobj功能，包括其背景、用户级概述和实现细节。

Result: 实现了对抽象stobj的不同操作支持，避免了重新认证的需求。

Conclusion: attach-stobj功能为ACL2用户提供了更灵活的操作方式，简化了开发流程。

Abstract: This extended abstract outlines an ACL2 feature, attach-stobj, that first
appeared in ACL2 Version 8.6 (October, 2024). This feature supports different
executable operations for a given abstract stobj, without requiring
recertification of the book that introduces that stobj or theorems about it.
The paper provides background as well as a user-level overview and some
implementation notes.

</details>


### [4] [Automated Type Annotation in Python Using Large Language Models](https://arxiv.org/abs/2508.00422)
*Varun Bharti,Shashwat Jha,Dhruv Kumar,Pankaj Jalote*

Main category: cs.PL

TL;DR: 使用LLM生成Python类型注释，通过生成-检查-修复流程提高注释的一致性和准确性，无需额外训练即可与传统深度学习方法竞争。


<details>
  <summary>Details</summary>
Motivation: 手动生成Python类型注释易出错且耗时，传统自动化方法存在局限性，探索LLM在此任务中的潜力。

Method: 采用生成-检查-修复流程：LLM基于语法树生成注释，静态检查器验证并反馈错误进行迭代优化。

Result: GPT 4.1mini和O3Mini表现最佳，一致性达88.6%，准确率最高70.5%（精确匹配）和79.1%（基本类型匹配）。

Conclusion: LLM无需任务特定微调即可高效生成类型注释，适用于Python及其他可选类型语言。

Abstract: Type annotations in Python enhance maintainability and error detection.
However, generating these annotations manually is error prone and requires
extra effort. Traditional automation approaches like static analysis, machine
learning, and deep learning struggle with limited type vocabularies, behavioral
over approximation, and reliance on large labeled datasets. In this work, we
explore the use of LLMs for generating type annotations in Python. We develop a
generate check repair pipeline: the LLM proposes annotations guided by a
Concrete Syntax Tree representation, a static type checker (Mypy) verifies
them, and any errors are fed back for iterative refinement. We evaluate four
LLM variants: GPT 4oMini, GPT 4.1mini (general-purpose), and O3Mini, O4Mini
(reasoning optimized), on 6000 code snippets from the ManyTypes4Py benchmark.
We first measure the proportion of code snippets annotated by LLMs for which
MyPy reported no errors (i.e., consistent results): GPT 4oMini achieved
consistency on 65.9% of cases (34.1% inconsistent), while GPT 4.1mini, O3Mini,
and O4Mini each reached approximately 88.6% consistency (around 11.4%
failures). To measure annotation quality, we then compute exact-match and
base-type match accuracies over all 6000 snippets: GPT 4.1mini and O3Mini
perform the best, achieving up to 70.5% exact match and 79.1% base type
accuracy, requiring under one repair iteration on average. Our results
demonstrate that general-purpose and reasoning optimized LLMs, without any task
specific fine tuning or additional training can be effective in generating
consistent type annotations.They perform competitively with traditional deep
learning techniques which require large labeled dataset for training. While our
work focuses on Python, the pipeline can be extended to other optionally typed
imperative languages like Ruby

</details>


### [5] [Semantic Subtyping for Maps in Erlang](https://arxiv.org/abs/2508.00482)
*Erdem Yildirim,Albert Schimpf,Stefan Wehr,Annette Bieniusa*

Main category: cs.PL

TL;DR: 构建了一个包含类型变量、基本类型、集合类型和映射类型的集合论模型，定义了基于集合包含的语义子类型关系，重点研究了参数化映射类型的子类型关系。


<details>
  <summary>Details</summary>
Motivation: 为Erlang中的映射类型提供一个统一的集合论模型，并定义其语义子类型关系，特别是针对参数化映射类型。

Method: 构建了一个类型模型，包含类型变量、基本类型、集合类型和映射类型，并基于集合包含定义了子类型关系。

Result: 成功定义了参数化映射类型的子类型关系，扩展了语义子类型理论的应用范围。

Conclusion: 该模型为Erlang中的映射类型提供了理论基础，特别是在参数化映射类型的子类型关系方面具有创新性。

Abstract: In this paper we will construct a set-theoretic model of types featuring type
variables, base types, set-theoretic types and map types. Syntax of map types
spans all the map types available in Erlang. The model of types is used to
define a semantic subtyping relation based on set containment. The novelty of
this work is the definition of subtyping over parameteric map types.

</details>


### [6] [Towards a unified framework for programming paradigms: A systematic review of classification formalisms and methodological foundations](https://arxiv.org/abs/2508.00534)
*Mikel Vandeloise*

Main category: cs.PL

TL;DR: 本文通过系统文献综述，探讨了多范式编程语言的分类问题，提出了一种基于数学框架的重构方法，以解决现有分类法的局限性。


<details>
  <summary>Details</summary>
Motivation: 多范式语言的兴起挑战了传统分类方法，导致互操作性缺陷等实际问题，需要更强大的理论基础。

Method: 基于74项主要研究的综合分析，评估现有分类形式及其局限性，并探索基于类型理论、范畴论和统一编程理论的重构方法。

Result: 研究发现现有分类法缺乏概念粒度和统一形式基础，而重构方法通过正交原子原语和数学框架提供了解决方案。

Conclusion: 文献表明，研究趋势正从分类转向形式化重构框架，本文提出了统一这些框架的研究议程。

Abstract: The rise of multi-paradigm languages challenges traditional classification
methods, leading to practical software engineering issues like interoperability
defects. This systematic literature review (SLR) maps the formal foundations of
programming paradigms. Our objective is twofold: (1) to assess the state of the
art of classification formalisms and their limitations, and (2) to identify the
conceptual primitives and mathematical frameworks for a more powerful,
reconstructive approach.
  Based on a synthesis of 74 primary studies, we find that existing taxonomies
lack conceptual granularity, a unified formal basis, and struggle with hybrid
languages. In response, our analysis reveals a strong convergence toward a
compositional reconstruction of paradigms. This approach identifies a minimal
set of orthogonal, atomic primitives and leverages mathematical frameworks,
predominantly Type theory, Category theory and Unifying Theories of Programming
(UTP), to formally guarantee their compositional properties.
  We conclude that the literature reflects a significant intellectual shift
away from classification towards these promising formal, reconstructive
frameworks. This review provides a map of this evolution and proposes a
research agenda for their unification.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Functional vs. Object-Oriented: Comparing How Programming Paradigms Affect the Architectural Characteristics of Systems](https://arxiv.org/abs/2508.00244)
*Briza Mel Dias de Sousa,Renato Cordeiro Ferreira,Alfredo Goldman*

Main category: cs.SE

TL;DR: 比较面向对象编程（OOP）和函数式编程（FP）对软件系统架构特性的影响，通过Kotlin和Scala实现数字钱包系统，结合定性和定量分析。


<details>
  <summary>Details</summary>
Motivation: 探讨OOP和FP对软件架构的影响，为开发者和组织选择编程范式提供依据。

Method: 使用Kotlin（OOP）和Scala（FP）实现数字钱包系统，进行定性（自我民族志）和定量（开发者调查）分析。

Result: 定性分析揭示编写代码的视角，定量分析展示开发者对代码的反馈。

Conclusion: 研究结果有助于开发者和组织根据需求选择更适合的编程范式。

Abstract: After decades of dominance by object-oriented programming (OOP), functional
programming (FP) is gaining increasing attention in the software industry. This
study compares the impact of OOP and FP on the architectural characteristics of
software systems. For that, it examines the design and implementation of a
Digital Wallet system, developed in Kotlin (representing OOP) and Scala
(representing FP). The comparison is made through both qualitative and
quantitative analyses to explore how each paradigm influences the system's
architectural characteristics. The self-ethnographic qualitative analysis
provides a side-by-side comparison of both implementations, revealing the
perspective of those writing such code. The survey-based quantitative analysis
gathers feedback from developers with diverse backgrounds, showing their
impressions of those reading this code. Hopefully, these results may be useful
for developers or organizations seeking to make more informed decisions about
which paradigm is best suited for their next project.

</details>


### [8] [Desyan: A Platform for Seamless Value-Flow and Symbolic Analysis](https://arxiv.org/abs/2508.00508)
*Panagiotis Diamantakis,Thanassis Avgerinos,Yannis Smaragdakis*

Main category: cs.SE

TL;DR: Desyan平台无缝整合了值流分析和符号推理，通过扩展Datalog引擎并集成SMT求解器，实现了高效的程序分析。


<details>
  <summary>Details</summary>
Motivation: 解决值流分析和符号分析长期分离的问题，提供一个统一的平台以高效整合两种技术。

Method: 扩展Soufflé Datalog引擎，集成SMT求解器，支持自动处理程序分析中的常见模式。

Result: Desyan在值流分析中表现最佳，执行时间快20倍；在需要SMT的应用中利用领先求解器；轻量级符号推理速度提升2倍。

Conclusion: Desyan成功实现了不同推理技术的灵活融合，为程序分析提供了高效统一的解决方案。

Abstract: Over the past two decades, two different types of static analyses have
emerged as dominant paradigms both in academia and industry: value-flow
analysis (e.g., data-flow analysis or points-to analysis) and symbolic analysis
(e.g., symbolic execution). Despite their individual successes in numerous
application fields, the two approaches have remained largely separate; an
artifact of the simple reality that there is no broadly adopted unifying
platform for effortless and efficient integration of symbolic techniques with
high-performance data-flow reasoning.
  To bridge this gap, we introduce Desyan: a platform for writing program
analyses with seamless integration of value-flow and symbolic reasoning. Desyan
expands a production-ready Datalog fixpoint engine (Souffl\'e) with
full-fledged SMT solving invoking industry-leading SMT engines. Desyan provides
constructs for automatically (and efficiently!) handling typical patterns that
come up in program analysis. At the same time, the integration is agnostic with
respect to the solving technology, and supports Datalog-native symbolic
reasoning, via a bottom-up algebraic reasoning module.
  The result is an engine that allows blending different kinds of reasoning, as
needed for the underlying analysis. For value-flow analysis, the engine is the
best-in-class Datalog evaluator (often by a factor of over 20x in execution
time); for applications that require full SMT (e.g., a concolic execution
engine or other symbolic evaluator that needs to solve arbitrarily complex
conditions), the engine is leveraging the leading SMT solvers; for lightweight
symbolic evaluation (e.g., solving simple conditionals in the context of a
path-sensitive analysis), the engine can use Datalog-native symbolic reasoning,
achieving large speedups (often of over 2x) compared to eagerly appealing to an
SMT solver.

</details>


### [9] [From Code to Career: Assessing Competitive Programmers for Industry Placement](https://arxiv.org/abs/2508.00772)
*Md Imranur Rahman Akib,Fathima Binthe Muhammed,Umit Saha,Md Fazlul Karim Patwary,Mehrin Anannya,Md Alomgeer Hussein,Md Biplob Hosen*

Main category: cs.SE

TL;DR: 研究通过Codeforces用户的编程竞赛表现预测其就业潜力，使用随机森林分类器将用户分为四个就业能力等级，模型效果显著。


<details>
  <summary>Details</summary>
Motivation: 快速发展的科技行业需要评估程序员就业准备的工具，研究旨在分析编程竞赛表现与就业机会的关联。

Method: 通过Codeforces API收集用户数据，处理关键性能指标，使用随机森林分类器构建预测模型，并通过Flask部署实时预测系统。

Result: 模型能有效区分不同技能水平的用户，从需要提升到适合顶级科技公司职位。

Conclusion: 研究为机器学习在职业评估中的应用奠定了基础，可扩展至更广泛的技术领域就业预测。

Abstract: In today's fast-paced tech industry, there is a growing need for tools that
evaluate a programmer's job readiness based on their coding performance. This
study focuses on predicting the potential of Codeforces users to secure various
levels of software engineering jobs. The primary objective is to analyze how a
user's competitive programming activity correlates with their chances of
obtaining positions, ranging from entry-level roles to jobs at major tech
companies. We collect user data using the Codeforces API, process key
performance metrics, and build a prediction model using a Random Forest
classifier. The model categorizes users into four levels of employability,
ranging from those needing further development to those ready for top-tier tech
jobs. The system is implemented using Flask and deployed on Render for
real-time predictions. Our evaluation demonstrates that the approach
effectively distinguishes between different skill levels based on coding
proficiency and participation. This work lays a foundation for the use of
machine learning in career assessment and could be extended to predict job
readiness in broader technical fields.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [10] [Loop Invariant Generation: A Hybrid Framework of Reasoning optimised LLMs and SMT Solvers](https://arxiv.org/abs/2508.00419)
*Varun Bharti,Shashwat Jha,Dhruv Kumar,Pankaj Jalote*

Main category: cs.LO

TL;DR: 论文探讨了利用优化推理的大型语言模型（LLMs）结合Z3求解器自动合成循环不变式，在Code2Inv基准测试中实现100%覆盖率，优于之前的最佳结果。


<details>
  <summary>Details</summary>
Motivation: 循环不变式对程序验证至关重要，但自动合成具有挑战性。现有方法仅适用于部分标准基准测试，因此研究LLMs是否能提升合成效果。

Method: 结合OpenAI的O1、O1-mini和O3-mini模型与Z3求解器，通过生成-检查迭代优化不变式。

Result: 在133个任务中实现100%覆盖率，仅需1-2次模型提议和14-55秒时间，优于之前107/133的结果。

Conclusion: LLMs具有潜在逻辑推理能力，可推广到其他命令式语言。

Abstract: Loop invariants are essential for proving the correctness of programs with
loops. Developing loop invariants is challenging, and fully automatic synthesis
cannot be guaranteed for arbitrary programs. Some approaches have been proposed
to synthesize loop invariants using symbolic techniques and more recently using
neural approaches. These approaches are able to correctly synthesize loop
invariants only for subsets of standard benchmarks. In this work, we
investigate whether modern, reasoning-optimized large language models can do
better. We integrate OpenAI's O1, O1-mini, and O3-mini into a tightly coupled
generate-and-check pipeline with the Z3 SMT solver, using solver
counterexamples to iteratively guide invariant refinement. We use Code2Inv
benchmark, which provides C programs along with their formal preconditions and
postconditions. On this benchmark of 133 tasks, our framework achieves 100%
coverage (133 out of 133), outperforming the previous best of 107 out of 133,
while requiring only 1-2 model proposals per instance and 14-55 seconds of
wall-clock time. These results demonstrate that LLMs possess latent logical
reasoning capabilities which can help automate loop invariant synthesis. While
our experiments target C-specific programs, this approach should be
generalizable to other imperative languages.

</details>
