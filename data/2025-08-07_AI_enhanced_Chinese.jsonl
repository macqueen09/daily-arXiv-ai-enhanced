{"id": "2508.03830", "pdf": "https://arxiv.org/pdf/2508.03830", "abs": "https://arxiv.org/abs/2508.03830", "authors": ["Hanwen Guo", "Ben Greenman"], "title": "If-T: A Benchmark for Type Narrowing", "categories": ["cs.PL"], "comment": null, "summary": "**Context:** The design of static type systems that can validate\ndynamically-typed programs (**gradually**) is an ongoing challenge. A key\ndifficulty is that dynamic code rarely follows datatype-driven design. Programs\ninstead use runtime tests to narrow down the proper usage of incoming data.\nType systems for dynamic languages thus need a **type narrowing** mechanism\nthat refines the type environment along individual control paths based on\ndominating tests, a form of flow-sensitive typing. In order to express\nrefinements, the type system must have some notion of sets and subsets. Since\nset-theoretic types are computationally and ergonomically complex, the need for\ntype narrowing raises design questions about how to balance precision and\nperformance. **Inquiry:** To date, the design of type narrowing systems has\nbeen driven by intuition, past experience, and examples from users in various\nlanguage communities. There is no standard that captures desirable and\nundesirable behaviors. Prior formalizations of narrowing are also significantly\nmore complex than a standard type system, and it is unclear how the extra\ncomplexity pays off in terms of concrete examples. This paper addresses the\nproblems through If-T, a language-agnostic **design benchmark** for type\nnarrowing that characterizes the abilities of implementations using simple\nprograms that draw attention to fundamental questions. Unlike a traditional\nperformance-focused benchmark, If-T measures a narrowing system's ability to\nvalidate correct code and reject incorrect code. Unlike a test suite, systems\nare not required to fully conform to If-T. Deviations are acceptable provided\nthey are justified by well-reasoned design considerations, such as compile-time\nperformance. **Approach:** If-T is guided by the literature on type narrowing,\nthe documentation of gradual languages such as TypeScript, and experiments with\ntypechecker implementations. We have identified a set of core technical\ndimensions for type narrowing. For each dimension, the benchmark contains a set\nof topics and (at least) two characterizing programs per topic: one that should\ntypecheck and one that should not typecheck. **Knowledge:** If-T provides a\nbaseline to measure type narrowing systems. For researchers, it provides\ncriteria to categorize future designs via its collection of positive and\nnegative examples. For language designers, the benchmark demonstrates the\npayoff of typechecker complexity in terms of concrete examples. Designers can\nuse the examples to decide whether supporting a particular example is\nworthwhile. Both the benchmark and its implementations are freely available\nonline. **Grounding:** We have implemented the benchmark for five typecheckers:\nTypeScript, Flow, Typed Racket, mypy, and Pyright. The results highlight\nimportant differences, such as the ability to track logical implications among\nprogram variables and typechecking for user-defined narrowing predicates.\n**Importance:** Type narrowing is essential for gradual type systems, but the\ntradeoffs between systems with different complexity have been unclear. If-T\nclarifies these tradeoffs by illustrating the benefits and limitations of each\nlevel of complexity. With If-T as a way to assess implementations in a fair,\ncross-language manner, future type system designs can strive for a better\nbalance among precision, annotation burden, and performance.", "AI": {"tldr": "If-T\u662f\u4e00\u4e2a\u8bed\u8a00\u65e0\u5173\u7684\u8bbe\u8ba1\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u7c7b\u578b\u7f29\u7a84\u7cfb\u7edf\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u7b80\u5355\u7a0b\u5e8f\u63ed\u793a\u5176\u4f18\u7f3a\u70b9\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u548c\u8bed\u8a00\u8bbe\u8ba1\u8005\u5728\u7cbe\u5ea6\u3001\u6027\u80fd\u548c\u590d\u6742\u6027\u4e4b\u95f4\u627e\u5230\u5e73\u8861\u3002", "motivation": "\u52a8\u6001\u7c7b\u578b\u7a0b\u5e8f\u7684\u8bbe\u8ba1\u7f3a\u4e4f\u7edf\u4e00\u6807\u51c6\uff0c\u7c7b\u578b\u7f29\u7a84\u7cfb\u7edf\u7684\u590d\u6742\u6027\u4e0e\u5176\u5b9e\u9645\u6536\u76ca\u4e0d\u660e\u786e\uff0c\u9700\u8981\u4e00\u79cd\u57fa\u51c6\u6765\u8bc4\u4f30\u548c\u6bd4\u8f83\u4e0d\u540c\u5b9e\u73b0\u3002", "method": "\u57fa\u4e8e\u6587\u732e\u3001\u8bed\u8a00\u6587\u6863\u548c\u5b9e\u9a8c\uff0cIf-T\u5b9a\u4e49\u4e86\u6838\u5fc3\u6280\u672f\u7ef4\u5ea6\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u7ef4\u5ea6\u63d0\u4f9b\u6b63\u53cd\u4f8b\u7a0b\u5e8f\uff0c\u7528\u4e8e\u6d4b\u8bd5\u7c7b\u578b\u7f29\u7a84\u7cfb\u7edf\u7684\u80fd\u529b\u3002", "result": "If-T\u5df2\u5e94\u7528\u4e8e\u4e94\u79cd\u7c7b\u578b\u68c0\u67e5\u5668\uff08\u5982TypeScript\u3001Flow\u7b49\uff09\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u903b\u8f91\u63a8\u7406\u548c\u7528\u6237\u5b9a\u4e49\u7f29\u7a84\u8c13\u8bcd\u7b49\u65b9\u9762\u7684\u5dee\u5f02\u3002", "conclusion": "If-T\u4e3a\u7c7b\u578b\u7f29\u7a84\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8bc4\u4f30\u6807\u51c6\uff0c\u5e2e\u52a9\u672a\u6765\u8bbe\u8ba1\u5728\u7cbe\u5ea6\u3001\u6027\u80fd\u548c\u590d\u6742\u6027\u4e4b\u95f4\u53d6\u5f97\u66f4\u597d\u5e73\u8861\u3002"}}
{"id": "2508.03831", "pdf": "https://arxiv.org/pdf/2508.03831", "abs": "https://arxiv.org/abs/2508.03831", "authors": ["Chinmayi Prabhu Baramashetru", "Paola Giannini", "Silvia Lizeth Tapia Tarifa", "Olaf Owe"], "title": "A Type System for Data Privacy Compliance in Active Object Languages", "categories": ["cs.PL"], "comment": null, "summary": "Data protection laws such as GDPR aim to give users unprecedented control\nover their personal data. Compliance with these regulations requires\nsystematically considering information flow and interactions among entities\nhandling sensitive data. Privacy-by-design principles advocate embedding data\nprotection into system architectures as a default. However, translating these\nabstract principles into concrete, explicit methods remains a significant\nchallenge. This paper addresses this gap by proposing a language-based approach\nto privacy integration, combining static and runtime techniques. By employing\ntype checking and type inference in an active object language, the framework\nenables the tracking of authorised data flows and the automatic generation of\nconstraints checked at runtime based on user consent. This ensures that\npersonal data is processed in compliance with GDPR constraints. The key\ncontribution of this work is a type system that gather the compliance checks\nand the changes to users consent and integrates data privacy compliance\nverification into system execution. The paper demonstrates the feasibility of\nthis approach through a soundness proof and several examples, illustrating how\nthe proposed language addresses common GDPR requirements, such as user consent,\npurpose limitation, and data subject rights. This work advances the state of\nthe art in privacy-aware system design by offering a systematic and automated\nmethod for integrating GDPR compliance into programming languages. This\ncapability has implications for building trustworthy systems in domains such as\nhealthcare or finance, where data privacy is crucial.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bed\u8a00\u7684\u9690\u79c1\u96c6\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u9759\u6001\u548c\u8fd0\u884c\u65f6\u6280\u672f\uff0c\u901a\u8fc7\u7c7b\u578b\u68c0\u67e5\u548c\u63a8\u65ad\u786e\u4fddGDPR\u5408\u89c4\u6027\u3002", "motivation": "GDPR\u7b49\u6570\u636e\u4fdd\u62a4\u6cd5\u89c4\u8981\u6c42\u7cfb\u7edf\u8bbe\u8ba1\u5d4c\u5165\u9690\u79c1\u4fdd\u62a4\uff0c\u4f46\u5c06\u62bd\u8c61\u539f\u5219\u8f6c\u5316\u4e3a\u5177\u4f53\u65b9\u6cd5\u4ecd\u5177\u6311\u6218\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7c7b\u578b\u68c0\u67e5\u548c\u63a8\u65ad\u7684\u4e3b\u52a8\u5bf9\u8c61\u8bed\u8a00\u6846\u67b6\uff0c\u8ddf\u8e2a\u6388\u6743\u6570\u636e\u6d41\u5e76\u81ea\u52a8\u751f\u6210\u8fd0\u884c\u65f6\u7ea6\u675f\u3002", "result": "\u901a\u8fc7\u7c7b\u578b\u7cfb\u7edf\u6574\u5408\u5408\u89c4\u6027\u68c0\u67e5\u548c\u7528\u6237\u540c\u610f\u53d8\u66f4\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u5e76\u6ee1\u8db3GDPR\u5e38\u89c1\u8981\u6c42\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u9690\u79c1\u611f\u77e5\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u3001\u81ea\u52a8\u5316\u7684GDPR\u5408\u89c4\u96c6\u6210\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u533b\u7597\u548c\u91d1\u878d\u7b49\u9886\u57df\u3002"}}
{"id": "2508.03832", "pdf": "https://arxiv.org/pdf/2508.03832", "abs": "https://arxiv.org/abs/2508.03832", "authors": ["Andreas Pointner", "Josef Pichler", "Herbert Pr\u00e4hofer"], "title": "Generating Inputs for Grammar Mining using Dynamic Symbolic Execution", "categories": ["cs.PL"], "comment": null, "summary": "A vast number of software systems include components that parse and process\nstructured input. In addition to programming languages, which are analyzed by\ncompilers or interpreters, there are numerous components that process\nstandardized or proprietary data formats of varying complexity. Even if such\ncomponents were initially developed and tested based on a specification, such\nas a grammar, numerous modifications and adaptations over the course of\nsoftware evolution can make it impossible to precisely determine which inputs\nthey actually accept. In this situation, grammar mining can be used to\nreconstruct the specification in the form of a grammar. Established approaches\nalready produce useful results, provided that sufficient input data is\navailable to fully cover the input language. However, achieving this\ncompleteness is a major challenge. In practice, only input data recorded during\nthe operation of the software systems is available. If this data is used for\ngrammar mining, the resulting grammar reflects only the actual processed inputs\nbut not the complete grammar of the input language accepted by the software\ncomponent. As a result, edge cases or previously supported features that no\nlonger appear in the available input data are missing from the generated\ngrammar. This work addresses this challenge by introducing a novel approach for\nthe automatic generation of inputs for grammar mining. Although input\ngenerators have already been used for fuzz testing, it remains unclear whether\nthey are also suitable for grammar miners. Building on the grammar miner Mimid,\nthis work presents a fully automated approach to input generation. The approach\nleverages Dynamic Symbolic Execution (DSE) and extends it with two mechanisms\nto overcome the limitations of DSE regarding structured input parsers. First,\nthe search for new inputs is guided by an iterative expansion that starts with\na single-character input and gradually extends it. Second, input generation is\nstructured into a novel three-phase approach, which separates the generation of\ninputs for parser functions. The proposed method was evaluated against a\ndiverse set of eleven benchmark applications from the existing literature.\nResults demonstrate that the approach achieves precision and recall for\nextracted grammars close to those derived from state-of-the-art grammar miners\nsuch as Mimid. Notably, it successfully uncovers subtle features and edge cases\nin parsers that are typically missed by such grammar miners. The effectiveness\nof the method is supported by empirical evidence, showing that it can achieve\nhigh performance in various domains without requiring prior input samples. This\ncontribution is significant for researchers and practitioners in software\nengineering, offering an automated, scalable, and precise solution for grammar\nmining. By eliminating the need for manual input generation, the approach not\nonly reduces workload but also enhances the robustness and comprehensiveness of\nthe extracted grammars. Following this approach, software engineers can\nreconstruct specification from existing (legacy) parsers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u7b26\u53f7\u6267\u884c\uff08DSE\uff09\u7684\u81ea\u52a8\u5316\u8f93\u5165\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u8bed\u6cd5\u6316\u6398\u7684\u5b8c\u6574\u6027\u548c\u51c6\u786e\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u56e0\u8f93\u5165\u6570\u636e\u4e0d\u8db3\u800c\u9057\u6f0f\u8fb9\u7f18\u6848\u4f8b\u7684\u95ee\u9898\u3002", "motivation": "\u8f6f\u4ef6\u7ec4\u4ef6\u5728\u6f14\u5316\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u504f\u79bb\u539f\u59cb\u89c4\u8303\uff0c\u5bfc\u81f4\u8bed\u6cd5\u6316\u6398\u65e0\u6cd5\u8986\u76d6\u5b8c\u6574\u8f93\u5165\u8bed\u8a00\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u64cd\u4f5c\u6570\u636e\uff0c\u96be\u4ee5\u6355\u6349\u8fb9\u7f18\u6848\u4f8b\u6216\u4e0d\u518d\u4f7f\u7528\u7684\u529f\u80fd\u3002", "method": "\u7ed3\u5408\u52a8\u6001\u7b26\u53f7\u6267\u884c\uff08DSE\uff09\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u9636\u6bb5\u8f93\u5165\u751f\u6210\u65b9\u6cd5\uff0c\u9010\u6b65\u6269\u5c55\u8f93\u5165\u5e76\u5206\u79bb\u89e3\u6790\u51fd\u6570\u3002\u57fa\u4e8e\u8bed\u6cd5\u6316\u6398\u5de5\u5177Mimid\u5b9e\u73b0\u3002", "result": "\u572811\u4e2a\u57fa\u51c6\u5e94\u7528\u4e2d\u9a8c\u8bc1\uff0c\u65b0\u65b9\u6cd5\u63d0\u53d6\u7684\u8bed\u6cd5\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u63a5\u8fd1\u73b0\u6709\u5de5\u5177\uff0c\u4e14\u80fd\u53d1\u73b0\u4f20\u7edf\u5de5\u5177\u9057\u6f0f\u7684\u7ec6\u5fae\u7279\u5f81\u548c\u8fb9\u7f18\u6848\u4f8b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u8bed\u6cd5\u6316\u6398\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u3001\u53ef\u6269\u5c55\u4e14\u7cbe\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u8f93\u5165\u751f\u6210\u9700\u6c42\uff0c\u63d0\u5347\u8bed\u6cd5\u5b8c\u6574\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2508.04115", "pdf": "https://arxiv.org/pdf/2508.04115", "abs": "https://arxiv.org/abs/2508.04115", "authors": ["Roger C. Su", "Robert J. Colvin"], "title": "Weak Memory Model Formalisms: Introduction and Survey", "categories": ["cs.PL", "A.1; C.1.2; D.3.1; F.3.1; F.3.2"], "comment": null, "summary": "Memory consistency models define the order in which accesses to shared memory\nin a concurrent system may be observed to occur. Such models are a necessity\nsince program order is not a reliable indicator of execution order, due to\nmicroarchitectural features or compiler transformations. Concurrent\nprogramming, already a challenging task, is thus made even harder when weak\nmemory effects must be addressed. A rigorous specification of weak memory\nmodels is therefore essential to make this problem tractable for developers of\nsafety- and security-critical, low-level software.\n  In this paper we survey the field of formalisations of weak memory models,\nincluding their specification, their effects on execution, and tools and\ninference systems for reasoning about code. To assist the discussion we also\nprovide an introduction to two styles of formal representation found commonly\nin the literature (using a much simplified version of Intel's x86 as the\nexample): a step-by-step construction of traces of the system (operational\nsemantics); and with respect to relations between memory events (axiomatic\nsemantics). The survey covers some long-standing hardware features that lead to\nobservable weak behaviours, a description of historical developments in\npractice and in theory, an overview of computability and complexity results,\nand outlines current and future directions in the field.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5f31\u5185\u5b58\u6a21\u578b\u7684\u89c4\u8303\u5316\u7814\u7a76\uff0c\u5305\u62ec\u5176\u5b9a\u4e49\u3001\u6267\u884c\u5f71\u54cd\u53ca\u63a8\u7406\u5de5\u5177\uff0c\u5e76\u4ecb\u7ecd\u4e86\u4e24\u79cd\u5e38\u89c1\u7684\u5f62\u5f0f\u5316\u8868\u793a\u65b9\u6cd5\u3002", "motivation": "\u5e76\u53d1\u7f16\u7a0b\u4e2d\u5f31\u5185\u5b58\u6548\u5e94\u589e\u52a0\u4e86\u5f00\u53d1\u590d\u6742\u6027\uff0c\u9700\u8981\u4e25\u683c\u7684\u89c4\u8303\u6765\u652f\u6301\u5b89\u5168\u548c\u5173\u952e\u8f6f\u4ef6\u5f00\u53d1\u3002", "method": "\u901a\u8fc7\u64cd\u4f5c\u8bed\u4e49\u548c\u516c\u7406\u8bed\u4e49\u4e24\u79cd\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u7ed3\u5408\u7b80\u5316\u7248Intel x86\u793a\u4f8b\uff0c\u5206\u6790\u5f31\u5185\u5b58\u6a21\u578b\u3002", "result": "\u7efc\u8ff0\u4e86\u786c\u4ef6\u7279\u6027\u3001\u5386\u53f2\u53d1\u5c55\u3001\u7406\u8bba\u6210\u679c\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u5f31\u5185\u5b58\u6a21\u578b\u7684\u89c4\u8303\u5316\u7814\u7a76\u5bf9\u5f00\u53d1\u5b89\u5168\u548c\u5173\u952e\u8f6f\u4ef6\u81f3\u5173\u91cd\u8981\uff0c\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2508.03978", "pdf": "https://arxiv.org/pdf/2508.03978", "abs": "https://arxiv.org/abs/2508.03978", "authors": ["Amir Shaikhha", "Youning Xia", "Meisam Tarabkhah", "Jazal Saleem", "Anna Herlihy"], "title": "Raqlet: Cross-Paradigm Compilation for Recursive Queries", "categories": ["cs.DB", "cs.PL"], "comment": null, "summary": "We introduce Raqlet, a source-to-source compilation framework that addresses\nthe fragmentation of recursive querying engines spanning relational (recursive\nSQL), graph (Cypher, GQL), and deductive (Datalog) systems. Recent standards\nsuch as SQL:2023's SQL/PGQ and the GQL standard provide a common foundation for\nquerying graph data within relational and graph databases; however, real-world\nsupport remains inconsistent across systems. Raqlet bridges this gap by\ntranslating recursive queries across paradigms through leveraging intermediate\nrepresentations (IRs) grounded in well-defined semantics; it translates Cypher\nor SQL/PGQ to PGIR (inspired by Cypher), then into DLIR (inspired by Datalog),\nand finally to SQIR (inspired by recursive SQL). Raqlet provides a shared\nsemantic basis that can serve as a golden reference implementation for language\nstandards, while supporting static analysis and transformations (e.g.,\nmagic-set transformation) for performance tuning. Our vision is to make Raqlet\na robust platform that enables rapid cross-paradigm prototyping, portable\nrecursive queries, and formal reasoning about recursion even when targeting\ndiverse query execution engines.", "AI": {"tldr": "Raqlet\u662f\u4e00\u4e2a\u6e90\u5230\u6e90\u7684\u7f16\u8bd1\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u9012\u5f52\u67e5\u8be2\u5f15\u64ce\u5728\u5173\u7cfb\u578b\u3001\u56fe\u578b\u548c\u6f14\u7ece\u578b\u7cfb\u7edf\u4e2d\u7684\u788e\u7247\u5316\u95ee\u9898\u3002", "motivation": "\u7531\u4e8e\u4e0d\u540c\u7cfb\u7edf\u5bf9\u9012\u5f52\u67e5\u8be2\u7684\u652f\u6301\u4e0d\u4e00\u81f4\uff0cRaqlet\u65e8\u5728\u901a\u8fc7\u7edf\u4e00\u7684\u4e2d\u95f4\u8868\u793a\uff08IRs\uff09\u5b9e\u73b0\u8de8\u8303\u5f0f\u7684\u9012\u5f52\u67e5\u8be2\u7ffb\u8bd1\u3002", "method": "Raqlet\u901a\u8fc7\u5c06Cypher\u6216SQL/PGQ\u8f6c\u6362\u4e3aPGIR\uff0c\u518d\u8f6c\u4e3aDLIR\uff0c\u6700\u540e\u8f6c\u4e3aSQIR\uff0c\u5b9e\u73b0\u67e5\u8be2\u7684\u8de8\u8303\u5f0f\u7ffb\u8bd1\u3002", "result": "Raqlet\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5171\u4eab\u7684\u8bed\u4e49\u57fa\u7840\uff0c\u53ef\u4f5c\u4e3a\u8bed\u8a00\u6807\u51c6\u7684\u53c2\u8003\u5b9e\u73b0\uff0c\u5e76\u652f\u6301\u9759\u6001\u5206\u6790\u548c\u6027\u80fd\u4f18\u5316\u3002", "conclusion": "Raqlet\u7684\u76ee\u6807\u662f\u6210\u4e3a\u4e00\u4e2a\u652f\u6301\u8de8\u8303\u5f0f\u539f\u578b\u8bbe\u8ba1\u3001\u4fbf\u643a\u5f0f\u9012\u5f52\u67e5\u8be2\u548c\u5f62\u5f0f\u5316\u63a8\u7406\u7684\u5065\u58ee\u5e73\u53f0\u3002"}}
