{"id": "2508.11665", "pdf": "https://arxiv.org/pdf/2508.11665", "abs": "https://arxiv.org/abs/2508.11665", "authors": ["Xinkui Zhao", "Yifan Zhang", "Zhengyi Zhou", "Yueshen Xu"], "title": "StackPilot: Autonomous Function Agents for Scalable and Environment-Free Code Execution", "categories": ["cs.PL", "cs.MA"], "comment": null, "summary": "Recent advances in large language models (LLMs) have substantially enhanced\nautomated code generation across a wide range of programming languages.\nNonetheless, verifying the correctness and executability of LLM-generated code\nremains a significant challenge, as traditional methods rely on\nlanguage-specific compilers and environment-dependent runtimes. To overcome\nthese limitations, we introduce StackPilot, an LLM-native, multi-agent\nframework designed for language-agnostic code verification and execution, which\noperates independently of conventional toolchains. StackPilot offers three\nprincipal innovations: (1) a Function-as-Agents paradigm, in which each\nfunction is modeled as an autonomous agent capable of fine-grained reasoning\nand collaborative verification; (2) an LLM-as-Executor strategy, which enables\nscalable verification via stack-based scheduling; and (3) a novel snapshot\nmechanism that preserves complete execution contexts, facilitating\ndeterministic and lossless context switching during verification. Empirical\nevaluations demonstrate that StackPilot achieves framework reliability rates\nbetween 89% and 97%, substantially outperforming baseline approaches. These\nresults indicate that StackPilot can reliably verify and execute a\nsignificantly larger proportion of LLM-generated code across diverse\nprogramming tasks compared to existing methods."}
{"id": "2508.12054", "pdf": "https://arxiv.org/pdf/2508.12054", "abs": "https://arxiv.org/abs/2508.12054", "authors": ["Guilherme de Oliveira Silva", "Fernando Magno Quintão Pereira"], "title": "Certified Compilation based on Gödel Numbers", "categories": ["cs.PL", "11A51", "D.3.1"], "comment": "32 pages, 19 figures", "summary": "In his 1984 Turing Award lecture, Ken Thompson showed that a compiler could\nbe maliciously altered to insert backdoors into programs it compiles and\nperpetuate this behavior by modifying any compiler it subsequently builds.\nThompson's hack has been reproduced in real-world systems for demonstration\npurposes. Several countermeasures have been proposed to defend against\nThompson-style backdoors, including the well-known {\\it Diverse\nDouble-Compiling} (DDC) technique, as well as methods like translation\nvalidation and CompCert-style compilation. However, these approaches ultimately\ncircle back to the fundamental question: \"How can we trust the compiler used to\ncompile the tools we rely on?\" In this paper, we introduce a novel approach to\ngenerating certificates to guarantee that a binary image faithfully represents\nthe source code. These certificates ensure that the binary contains all and\nonly the statements from the source code, preserves their order, and maintains\nequivalent def-use dependencies. The certificate is represented as an integer\nderivable from both the source code and the binary using a concise set of\nderivation rules, each applied in constant time. To demonstrate the\npracticality of our method, we present Charon, a compiler designed to handle a\nsubset of C expressive enough to compile FaCT, the Flexible and Constant Time\ncryptographic programming language."}
{"id": "2508.12427", "pdf": "https://arxiv.org/pdf/2508.12427", "abs": "https://arxiv.org/abs/2508.12427", "authors": ["Paul Downen"], "title": "Controlling Copatterns: There and Back Again (Extended Version)", "categories": ["cs.PL", "D.3.3; F.3.2; F.3.3"], "comment": "To find the detailed step-by-step process, which serves as their\n  proof of correctness, see https://github.com/pdownen/derive-copat", "summary": "Copatterns give functional programs a flexible mechanism for responding to\ntheir context, and composition can greatly enhance their expressiveness.\nHowever, that same expressive power makes it harder to precisely specify the\nbehavior of programs. Using Danvy's functional and syntactic correspondence\nbetween different semantic artifacts, we derive a full suite of semantics for\ncopatterns, twice. First, a calculus of monolithic copatterns is taken on a\njourney from small-step operational semantics to abstract machine to\ncontinuation-passing style. Then within continuation-passing style, we refactor\nthe semantics to derive a more general calculus of compositional copatterns,\nand take the return journey back to derive the other semantic artifacts in\nreverse order."}
{"id": "2508.12475", "pdf": "https://arxiv.org/pdf/2508.12475", "abs": "https://arxiv.org/abs/2508.12475", "authors": ["Abhijit Paul"], "title": "Type-Driven Prompt Programming: From Typed Interfaces to a Calculus of Constraints", "categories": ["cs.PL", "cs.FL"], "comment": "Accepted as Extended Abstract in TyDe Workshop 2025,co-located with\n  ICFP", "summary": "Prompt programming treats large language model prompts as software components\nwith typed interfaces. Based on a literature survey of 15 recent works from\n2023 to 2025, we observe a consistent trend: type systems are central to\nemerging prompt programming frameworks. However, there are gaps in constraint\nexpressiveness and in supporting algorithms. To address these issues, we\nintroduce the notion of Lambda Prompt, a dependently typed calculus with\nprobabilistic refinements for syntactic and semantic constraints. While this is\nnot yet a full calculus, the formulation motivates a type-theoretic foundation\nfor prompt programming. Our catalog of 13 constraints highlights underexplored\nareas in constraint expressiveness (constraints 9 through 13). To address the\nalgorithmic gap, we propose a constraint-preserving optimization rule. Finally,\nwe outline research directions on developing a compiler for prompt programs."}
