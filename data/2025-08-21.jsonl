{"id": "2508.14394", "pdf": "https://arxiv.org/pdf/2508.14394", "abs": "https://arxiv.org/abs/2508.14394", "authors": ["Ryan Tjoa", "Poorva Garg", "Harrison Goldstein", "Todd Millstein", "Benjamin Pierce", "Guy Van den Broeck"], "title": "Tuning Random Generators: Property-Based Testing as Probabilistic Programming", "categories": ["cs.PL", "cs.SE", "D.3; D.2.5; G.3"], "comment": "Extended version of OOPSLA '25 paper", "summary": "Property-based testing validates software against an executable specification\nby evaluating it on randomly generated inputs. The standard way that PBT users\ngenerate test inputs is via generators that describe how to sample test inputs\nthrough random choices. To achieve a good distribution over test inputs, users\nmust tune their generators, i.e., decide on the weights of these individual\nrandom choices. Unfortunately, it is very difficult to understand how to choose\nindividual generator weights in order to achieve a desired distribution, so\ntoday this process is tedious and limits the distributions that can be\npractically achieved.\n  In this paper, we develop techniques for the automatic and offline tuning of\ngenerators. Given a generator with undetermined symbolic weights and an\nobjective function, our approach automatically learns values for these weights\nthat optimize for the objective. We describe useful objective functions that\nallow users to (1) target desired distributions and (2) improve the diversity\nand validity of their test cases. We have implemented our approach in a novel\ndiscrete probabilistic programming system, Loaded Dice, that supports\ndifferentiation and parameter learning, and use it as a language for\ngenerators. We empirically demonstrate that our approach is effective at\noptimizing generator distributions according to the specified objective\nfunctions. We also perform a thorough evaluation on PBT benchmarks,\ndemonstrating that, when automatically tuned for diversity and validity, the\ngenerators exhibit a 3.1-7.4x speedup in bug finding."}
{"id": "2508.14614", "pdf": "https://arxiv.org/pdf/2508.14614", "abs": "https://arxiv.org/abs/2508.14614", "authors": ["Ashish Mishra", "Suresh Jagannathan"], "title": "Close is Good Enough: Component-Based Synthesis Modulo Logical Similarity", "categories": ["cs.PL", "D.3.0; D.3.1"], "comment": null, "summary": "Component-based synthesis (CBS) aims to generate loop-free programs from a\nset of libraries whose methods are annotated with specifications and whose\noutput must satisfy a set of logical constraints, expressed as a query. The\neffectiveness of a CBS algorithm critically depends on the severity of the\nconstraints imposed by the query. The more exact these constraints are, the\nsparser the space of feasible solutions. This maxim also applies when we enrich\nthe expressiveness of the specifications affixed to library methods. In both\ncases, the search must now contend with constraints that may only hold over a\nsmall number of the possible execution paths that can be enumerated by a CBS\nprocedure.\n  In this paper, we address this challenge by equipping CBS search with the\nability to reason about logical similarities among the paths it explores. Our\nsetting considers library methods equipped with refinement-type specifications\nthat enrich ordinary base types with a set of rich logical qualifiers to\nconstrain the set of values accepted by that type. We perform a search over a\ntree automata variant called Qualified Tree Automata that intelligently records\ninformation about enumerated terms, leveraging subtyping constraints over the\nrefinement types associated with these terms to enable reasoning about\nsimilarity among candidate solutions as search proceeds, thereby avoiding\nexploration of semantically similar paths.\n  We present an implementation of this idea in a tool called \\name, and provide\na comprehensive evaluation that demonstrates \\name's ability to synthesize\nsolutions to complex CBS queries that go well-beyond the capabilities of the\nexisting state-of-the-art."}
{"id": "2508.14851", "pdf": "https://arxiv.org/pdf/2508.14851", "abs": "https://arxiv.org/abs/2508.14851", "authors": ["Rados≈Çaw Jan Rowicki", "Adrian Francalanza", "Alceste Scalas"], "title": "Correct Black-Box Monitors for Distributed Deadlock Detection: Formalisation and Implementation (Technical Report)", "categories": ["cs.LO", "cs.PL"], "comment": null, "summary": "Many software applications rely on concurrent and distributed (micro)services\nthat interact via message-passing and various forms of remote procedure calls\n(RPC). As these systems organically evolve and grow in scale and complexity,\nthe risk of introducing deadlocks increases and their impact may worsen: even\nif only a few services deadlock, many other services may block while awaiting\nresponses from the deadlocked ones. As a result, the \"core\" of the deadlock can\nbe obfuscated by its consequences on the rest of the system, and diagnosing and\nfixing the problem can be challenging.\n  In this work we tackle the challenge by proposing distributed black-box\nmonitors that are deployed alongside each service and detect deadlocks by only\nobserving the incoming and outgoing messages, and exchanging probes with other\nmonitors. We present a formal model that captures popular RPC-based application\nstyles (e.g., gen_servers in Erlang/OTP), and a distributed black-box\nmonitoring algorithm that we prove sound and complete (i.e., identifies\ndeadlocked services with neither false positives nor false negatives). We\nimplement our results in a tool called DDMon for the monitoring of Erlang/OTP\napplications, and we evaluate its performance.\n  This is the first work that formalises, proves the correctness, and\nimplements distributed black-box monitors for deadlock detection. Our results\nare mechanised in Coq. DDMon is the companion artifact of this paper."}
