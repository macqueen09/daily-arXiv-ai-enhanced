<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 5]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Correctness-Guaranteed Code Generation via Constrained Decoding](https://arxiv.org/abs/2508.15866)
*Lingxiao Li,Salar Rahili,Yiwei Zhao*

Main category: cs.PL

TL;DR: 通过约束解码算法和上下文敏感语法分析器，生成语义正确的程序，应用于游戏和机器人学需要一次正确的预测场景


<details>
  <summary>Details</summary>
Motivation: 确保代码生成模型生成的程序正确性，特别是在游戏和机器人等需要一次正确的运行时关键组件

Method: 使用约束解码算法，结合上下文敏感语法分析器，在每个步骤输出满足关键属性的正则表达式来指导下一个标记序列的生成，构建动态语法分析器树(ToP)来处理上下文信息

Result: 在sLua(强类型Lua变种)中验证了方法的有效性，能够生成符合任何指定脚本API的语义正确程序，并在游戏机制生成中验证了运行时正确性

Conclusion: 该方法能够为代码生成提供语义正确性保证，甚至扩展到运行时正确性，适用于需要高可靠性的预测场景

Abstract: Language Models (LMs) are increasingly being used for code generation, but
ensuring the correctness of generated programs remains a significant challenge.
Although imperfect code may be acceptable during software development with
human oversight, domains such as video games and robotics require one-shot
correctness for runtime-critical components. We present a constrained decoding
algorithm for generating semantically correct programs that incorporates a
context-sensitive parser, which, at each step, outputs a regular expression
that satisfies a critical non-extensible property to guide the generation of
the next token sequence that can continue to a correct program. To build such a
context-sensitive parser, we propose a framework of a dynamic tree of parsers
(ToP) during parsing, where each parser corresponds to a modular context-free
grammar enriched with contextual information such as variable scopes and type
constraints, with tree branches representing ambiguity in the future code
segment. We demonstrate our approach through sLua, a strongly typed variant of
Lua, showing that our method can generate semantically correct programs
conforming to any prescribed scripting API. We further show that, with careful
design, our semantic guarantees extend to runtime correctness, as validated in
the application of generating game mechanics for a roguelike video game.

</details>


### [2] [Automated Formal Verification of a Software Fault Isolation System](https://arxiv.org/abs/2508.15898)
*Matthew Sotoudeh,Zachary Yedidia*

Main category: cs.PL

TL;DR: 本文通过自动化形式验证方法，验证了轻量级故障隔离(LFI)系统的验证器，确保其接受的程序不会读写沙盒区域外的内存


<details>
  <summary>Details</summary>
Motivation: 软件故障隔离(SFI)验证器中的声音性漏洞会破坏SFI安全模型，允许沙盒代码读取受保护内存，因此需要确保验证器的正确性

Method: 采用自动化形式验证技术，对LFI系统的验证器进行形式化验证

Result: 成功验证了LFI验证器接受的程序永远不会读写指定沙盒区域外的内存

Conclusion: 通过形式化验证可以确保SFI验证器的正确性，从而增强软件故障隔离系统的安全性

Abstract: Software fault isolation (SFI) is a popular way to sandbox untrusted
software. A key component of SFI is the verifier that checks the untrusted code
is written in a subset of the machine language that guarantees it never reads
or writes outside of a region of memory dedicated to the sandbox. Soundness
bugs in the SFI verifier would break the SFI security model and allow the
supposedly sandboxed code to read protected memory. In this paper, we address
the concern of SFI verifier bugs by performing an automated formal verification
of a recent SFI system called Lightweight Fault Isolation (LFI). In particular,
we formally verify that programs accepted by the LFI verifier never read or
write to memory outside of a designated sandbox region.

</details>


### [3] [Synthesizing DSLs for Few-Shot Learning](https://arxiv.org/abs/2508.16063)
*Paul Krogmeier,P. Madhusudan*

Main category: cs.PL

TL;DR: 研究在符号领域少样本学习中合成领域特定语言(DSL)的问题，证明在特定条件下该问题是可判定的


<details>
  <summary>Details</summary>
Motivation: 解决符号领域少样本学习中需要为特定任务定制DSL的问题，通过从训练样本中学习语法规则来保证泛化能力

Method: 给定基础语言和少样本学习问题实例，通过语法合成方法寻找能保证训练样本解也能解决对应测试样本的语法

Result: 证明了对于可由树自动机评估语义的语言类，当表达式大小对应语法分析树深度时，该问题是可判定的

Conclusion: DSL合成问题在特定形式化条件下是可判定的，为符号少样本学习提供了理论基础

Abstract: We study the problem of synthesizing domain-specific languages (DSLs) for
few-shot learning in symbolic domains. Given a base language and instances of
few-shot learning problems, where each instance is split into training and
testing samples, the DSL synthesis problem asks for a grammar over the base
language that guarantees that small expressions solving training samples also
solve corresponding testing samples. We prove that the problem is decidable for
a class of languages whose semantics over fixed structures can be evaluated by
tree automata and when expression size corresponds to parse tree depth in the
grammar, and, furthermore, the grammars solving the problem correspond to a
regular set of trees. We also prove decidability results for variants of the
problem where DSLs are only required to express solutions for input learning
problems and where DSLs are defined using macro grammars.

</details>


### [4] [Leveraging Large Language Models to Detect Missed Peephole Optimizations](https://arxiv.org/abs/2508.16125)
*Zhenyang Xu,Hongxu Xu,Yongqiang Tian,Xintong Zhou,Chengnian Sun*

Main category: cs.PL

TL;DR: Lampo是一个结合大型语言模型和翻译验证工具的自动化框架，用于检测编译器中的窥孔优化机会，在LLVM生态系统中表现出色，能够发现比现有工具更多的优化机会。


<details>
  <summary>Details</summary>
Motivation: 窥孔优化对编译器性能至关重要，但由于指令集复杂多样，发现新的有效优化具有挑战性。现有方法要么扩展性差，要么只能捕获有限的优化子集。

Method: 提出Lampo框架，将LLMs的创造性代码优化能力与翻译验证工具的正确性验证相结合，通过反馈驱动的迭代过程来检测遗漏的窥孔优化。

Result: 在LLVM生态系统中，Lampo平均能检测出25个已知遗漏优化中的17个，而最先进的超级优化器Souper只检测出15个。在7个月开发中发现了26个遗漏优化，其中15个已确认，6个已修复。

Conclusion: Lampo在持续检测遗漏窥孔优化方面展现出强大潜力，证明了LLMs与形式化验证工具结合的有效性。

Abstract: By replacing small, suboptimal instruction sequences within programs with a
more efficient equivalent, peephole optimization can not only directly optimize
code size and performance, but also potentially enables further transformations
in the subsequent optimization pipeline. Although peephole optimization is a
critical class of compiler optimizations, discovering new and effective
peephole optimizations is challenging as the instruction sets can be extremely
complex and diverse. Previous methods either do not scale well or can only
capture a limited subset of peephole optimizations. In this work, we leverage
Large Language Models (LLMs) to detect missed peephole optimizations. We
propose Lampo, a novel automated framework that synergistically combines the
creative but unreliable code optimization ability of LLMs with rigorous
correctness verification performed by translation validation tools, integrated
in a feedback-driven iterative process. Through a comprehensive evaluation
within LLVM ecosystems, we show that Lampo can successfully detect up to 17 out
of 25 previously reported missed optimizations in LLVM on average, and that 22
out of 25 can potentially be found by Lampo with different LLMs. For
comparison, the state-of-the-art superoptimizer for LLVM, Souper, identified 15
of them. Moreover, within seven months of development and intermittent
experiments, Lampo found 26 missed peephole optimizations, 15 of which have
been confirmed and 6 already fixed. These results demonstrate Lampo's strong
potential in continuously detecting missed peephole optimizations.

</details>


### [5] [On the Duality of Task and Actor Programming Models](https://arxiv.org/abs/2508.16522)
*Rohan Yadav,Joseph Guman,Sean Treichler,Michael Garland,Alex Aiken,Fredrik Kjolstad,Michael Bauer*

Main category: cs.PL

TL;DR: 本文证明了任务模型和参与者模型在分布式异构计算中的对偶性，提出了让任务系统达到参与者系统性能水平的技术，在Realm和Legion运行时中实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 分布式异构计算中，任务模型开发效率高但性能较差，参与者模型性能好但开发效率低。需要找到既能保持任务模型开发效率又能达到参与者模型性能的方法。

Method: 通过理论分析证明任务模型和参与者模型的对偶性，开发降低任务系统开销的技术，并在Realm（显式并行任务运行时）和Legion（隐式并行任务运行时）中实现这些优化技术。

Result: Realm的开销降低了1.7-5.3倍，接近Charm++和MPI等优化参与者系统的开销水平；未修改的Legion应用获得了1.3-5.0倍的强扩展性提升。

Conclusion: 任务模型和参与者模型本质上是等价的，通过适当的技术优化，任务系统可以在保持开发效率的同时达到与参与者系统相当的性能水平。

Abstract: Programming models for distributed and heterogeneous machines are rapidly
growing in popularity to meet the demands of modern workloads. Task and actor
models are common choices that offer different trade-offs between development
productivity and achieved performance. Task-based models offer better
productivity and composition of software, whereas actor-based models routinely
deliver better peak performance due to lower overheads. While task-based and
actor-based models appear to be different superficially, we demonstrate these
programming models are duals of each other. Importantly, we show that this
duality extends beyond functionality to performance, and elucidate techniques
that let task-based systems deliver performance competitive with actor-based
systems without compromising productivity. We apply these techniques to both
Realm, an explicitly parallel task-based runtime, as well as Legion, an
implicitly parallel task-based runtime. We show these techniques reduce Realm's
overheads by between 1.7-5.3x, coming within a factor of two of the overheads
imposed by heavily optimized actor-based systems like Charm++ and MPI. We
further show that our techniques enable between 1.3-5.0x improved strong
scaling of unmodified Legion applications.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [ARSP: Automated Repair of Verilog Designs via Semantic Partitioning](https://arxiv.org/abs/2508.16517)
*Bingkun Yao,Ning Wang,Xiangfeng Liu,Yuxin Du,Yuchen Hu,Hong Gao,Zhe Jiang,Nan Guan*

Main category: cs.SE

TL;DR: ARSP是一个两阶段系统，通过语义引导的分段方法解决Verilog调试中长上下文导致的bug信号稀释问题，显著提升了调试准确率


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自动化调试方法在工业规模模块上表现不佳，主要原因是长上下文中bug相关信号被大量无关代码稀释，分散了模型的注意力

Method: 采用两阶段系统：1) 分区LLM将模块分割成语义紧密的片段；2) 修复LLM修补每个片段；编辑合并时不改变无关逻辑。使用合成数据框架生成片段级训练对来监督两个模型

Result: ARSP达到77.92% pass@1和83.88% pass@5，优于主流商业LLM和SOTA自动化Verilog调试工具。语义分区相比整模块调试提升pass@1 11.6%和pass@5 10.2%

Conclusion: 语义引导的分段方法有效缓解了bug信号稀释问题，片段级范围缩减在基于LLM的Verilog调试中具有显著效果

Abstract: Debugging functional Verilog bugs consumes a significant portion of front-end
design time. While Large Language Models (LLMs) have demonstrated great
potential in mitigating this effort, existing LLM-based automated debugging
methods underperform on industrial-scale modules. A major reason for this is
bug signal dilution in long contexts, where a few bug-relevant tokens are
overwhelmed by hundreds of unrelated lines, diffusing the model's attention. To
address this issue, we introduce ARSP, a two-stage system that mitigates
dilution via semantics-guided fragmentation. A Partition LLM splits a module
into semantically tight fragments; a Repair LLM patches each fragment; edits
are merged without altering unrelated logic. A synthetic data framework
generates fragment-level training pairs spanning bug types, design styles, and
scales to supervise both models. Experiments show that ARSP achieves 77.92%
pass@1 and 83.88% pass@5, outperforming mainstream commercial LLMs including
Claude-3.7 and SOTA automated Verilog debugging tools Strider and MEIC. Also,
semantic partitioning improves pass@1 by 11.6% and pass@5 by 10.2% over
whole-module debugging, validating the effectiveness of fragment-level scope
reduction in LLM-based Verilog debugging.

</details>
