<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [SafeTree: Expressive Tree Policies for Microservices](https://arxiv.org/abs/2508.16746)
*Karuna Grewal,P. Brighten Godfrey,Justin Hsu*

Main category: cs.PL

TL;DR: 基于可见堆栈自动机的微服务树策略动态执行机制，通过服务网格实现低延迟监控


<details>
  <summary>Details</summary>
Motivation: 当前微服务部署工具仅支持限制性的单跳策略，忽略了微服务调用树结构，导致策略过于免科

Method: 设计表达力丰富的服务树结构策略语言，基于可见堆栈自动机建立动态执行机制，在Istio服务网格上实现分布式监控器

Result: 监控器能够执行丰富的安全属性，仅添加毫秒级别的延迟开销

Conclusion: 该方法无需修改服务实现或访问代码，通过服务网格实现了对微服务树结构的细粒度控制

Abstract: A microservice-based application is composed of multiple self-contained
components called microservices, and controlling inter-service communication is
important for enforcing safety properties. Presently, inter-service
communication is configured using microservice deployment tools. However, such
tools only support a limited class of single-hop policies, which can be overly
permissive because they ignore the rich service tree structure of microservice
calls. Policies that can express the service tree structure can offer
development and security teams more fine-grained control over communication
patterns.
  To this end, we design an expressive policy language to specify service tree
structures, and we develop a visibly pushdown automata-based dynamic
enforcement mechanism to enforce service tree policies. Our technique is
non-invasive: it does not require any changes to service implementations, and
does not require access to microservice code. To realize our method, we build a
runtime monitor on top of a service mesh, an emerging network infrastructure
layer that can control inter-service communication during deployment. In
particular, we employ the programmable network traffic filtering capabilities
of Istio, a popular service mesh implementation, to implement an online and
distributed monitor. Our experiments show that our monitor can enforce rich
safety properties while adding minimal latency overhead on the order of
milliseconds.

</details>


### [2] [Syntactic Completions with Material Obligations](https://arxiv.org/abs/2508.16848)
*David Moon,Andrew Blinn,Thomas J. Porter,Cyrus Omar*

Main category: cs.PL

TL;DR: 本文提出了一种名为tylr的新型解析器和编辑器生成器，通过插入义务（obligations）来补全任意格式错误的代码，解决了现有语法错误恢复技术过于粗糙或产生过多补全选项的问题。


<details>
  <summary>Details</summary>
Motivation: 现有代码编辑器在存在语法错误时往往失效，传统的语法错误恢复技术要么过于粗糙（如删除大量代码），要么导致补全选项过多。需要一种更好的方法来处理不完整或错误的代码。

Method: 基于瓦片解析理论，扩展了运算符优先级解析：1）用语法行走替代传统标记优先级比较来生成义务；2）基于语法拉链的"塑形"系统通过义务最小化标准来消除歧义。tylr能够插入覆盖缺失操作数、运算符、混合关键词和类型转换的义务。

Result: 开发了一个能够可视化展示义务给用户的编辑器，作为文本编辑器和结构编辑器之间的新型混合体。通过人类受试者研究评估了这种方法的可用性和实用性。

Conclusion: tylr提供了一种新颖的错误纠正方法，研究发现了积极的使用效果，并为未来工作开辟了有趣的新方向。

Abstract: Code editors provide essential services that help developers understand,
navigate, and modify programs. However, these services often fail in the
presence of syntax errors. Existing syntax error recovery techniques, like
panic mode and multi-option repairs, are either too coarse, e.g. in deleting
large swathes of code, or lead to a proliferation of possible completions. This
paper introduces $\texttt{tylr}$, a parser and editor generator that completes
arbitrarily malformed code by inserting obligations, which generalize holes to
cover missing operands, operators, mixfix keywords, and sort transitions.
$\texttt{tylr}$ is backed by a novel theory of tile-based parsing, which
extends operator-precedence parsing in two ways. First, traditional token
precedence comparisons are replaced by a notion of grammar walks, which form
the basis for generating obligations. Second, a distinct "molding" system based
on grammar zippers expand grammar expressivity by allowing the system to
disambiguate between possible parses and completions based on an obligation
minimization criterion. In addition to serving as a novel approach to error
correction, $\texttt{tylr}$'s design enables the development of an editor that
visually materializes obligations to the human user, serving as a novel hybrid
between a text editor and a structure editor. We introduce $\texttt{tylr}$ by
example, then formalize its key ideas. Finally, we conduct a human subjects
study to evaluate the extent to which an editor like $\texttt{tylr}$ that
materializes syntactic obligations might be usable and useful, finding both
points of positivity and interesting new avenues for future work.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [3] [Borrowing Dirty Qubits in Quantum Programs](https://arxiv.org/abs/2508.17190)
*Bonan Su,Li Zhou,Yuan Feng,Mingsheng Ying*

Main category: quant-ph

TL;DR: 本文正式定义了量子编程语言中脏量子位借用语义，提出了脏量子位安全反计算的概念，并提供了验证算法和实验结果


<details>
  <summary>Details</summary>
Motivation: 量子计算中清洁量子位资源稀缺，通过借用空闲的脏量子位进行重用可以缓解资源需求，但需要确保其初始状态不影响电路功能且使用后能完全恢复原始状态

Method: 形式化定义脏量子位借用语义，引入脏量子位安全反计算概念，开发高效验证算法来验证量子电路中脏量子位的安全反计算

Result: 提出了形式化语义框架和验证算法，实验结果表明该方法是有效的

Conclusion: 脏量子位借用机制可以显著减少清洁量子位需求，通过形式化语义和验证算法确保了重用的安全性和正确性

Abstract: Dirty qubits are ancillary qubits that can be borrowed from idle parts of a
computation, enabling qubit reuse and reducing the demand for fresh, clean
qubits-a resource that is typically scarce in practice. For such reuse to be
valid, the initial states of the dirty qubits must not affect the functionality
of the quantum circuits in which they are employed. Moreover, their original
states, including any entanglement they possess, must be fully restored after
use-a requirement commonly known as safe uncomputation. In this paper, we
formally define the semantics of dirty-qubit borrowing as a feature in quantum
programming languages, and introduce a notion of safe uncomputation for dirty
qubits in quantum programs. We also present an efficient algorithm, along with
experimental results, for verifying safe uncomputation of dirty qubits in
certain quantum circuits.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [4] [Compositional Verification in Concurrent Separation Logic with Permissions Regions](https://arxiv.org/abs/2508.18115)
*Quang Loc Le*

Main category: cs.LO

TL;DR: 提出了一个基于CSL-Perm的组合式并发程序验证系统，通过新的逻辑原则和蕴含过程实现自动化推理，解决了原有逻辑缺乏自动化和组合性的问题


<details>
  <summary>Details</summary>
Motivation: 并发分离逻辑CSL-Perm虽然为细粒度程序验证提供了坚实基础，但缺乏自动化和组合性支持，限制了其实际应用

Method: 引入了新颖的逻辑原则和蕴含过程，能够推断框架规则中的剩余堆，支持带显式算术约束的内存堆分离性推理

Result: 开发了原型工具CoSl，在10个具有挑战性的并发程序上测试，包括超越现有技术水平的情况，验证了方法的优势

Conclusion: 该系统成功解决了CSL-Perm的组合性和自动化问题，为并发程序验证提供了有效的解决方案

Abstract: Concurrent separation logic with fractional permissions (CSLPerm) provides a
promising reasoning system to verify most complex sequential and concurrent
fine-grained programs. The logic with strong and weak separating conjunctions
offers a solid foundation for producing concise and precise proofs. However, it
lacks automation and compositionality support. This paper addresses this
limitation by introducing a compositional verification system for concurrent
programs that manipulate regions of shared memory. The centre of our system is
novel logical principles and an entailment procedure that can infer the
residual heaps in the frame rule for a fragment of CSL-Perm with explicit
arithmetical constraints for memory heaps' disjointness. This procedure enables
the compositional reasoning for concurrent threads and function calls. We have
implemented the proposal in a prototype tool called CoSl, tested it with 10
challenging concurrent programs, including those beyond the state-of-the-art,
and confirmed the advantage of our approach.

</details>


### [5] [To bind or not to bind? Discovering Stable Relationships in Object-centric Processes (Extended Version)](https://arxiv.org/abs/2508.18231)
*Anjo Seidel,Sarah Winkler,Alessandro Gianola,Marco Montali,Mathias Weske*

Main category: cs.LO

TL;DR: 本文提出了一种将对象中心Petri网(OCPN)映射到具有标识符的对象中心Petri网(OPID)的方法，通过显式捕获稳定的多对一关系来实现对象的正确同步。


<details>
  <summary>Details</summary>
Motivation: 现有的OCPN虽然能表示对象在流程中的流动和共现，但无法充分表示对象间的关系，导致无法正确同步相关对象和识别违规执行。OPID虽然能表示对象身份和关系，但其发现方法尚未被研究。

Method: 通过识别对象中心事件日志中隐含的稳定多对一关系假设，将OCPN与显式稳定多对一关系结合，建立从OCPN到OPID的严格映射，显式捕获预期关系和对象同步。

Result: 证明了原始OCPN与生成的OPID在满足预期关系的执行中是一致的，并提供了从OCPN到OPID映射的实现。

Conclusion: 该方法成功填补了OCPN与形式化OPID之间的差距，通过显式数据模型实现了对象关系的正确表示和同步，为对象中心流程挖掘提供了更精确的建模能力。

Abstract: Object-centric process mining investigates the intertwined behavior of
multiple objects in business processes. From object-centric event logs,
object-centric Petri nets (OCPN) can be discovered to replay the behavior of
processes accessing different object types. Although they indicate how objects
flow through the process and co-occur in events, OCPNs remain underspecified
about the relationships of objects. Hence, they are not able to represent
synchronization, i.e. executing objects only according to their intended
relationships, and fail to identify violating executions. Existing formal
modeling approaches, such as object-centric Petri nets with identifiers (OPID),
represent object identities and relationships to synchronize them correctly.
However, OPID discovery has not yet been studied. This paper uses explicit data
models to bridge the gap between OCPNs and formal OPIDs. We identify the
implicit assumptions of stable many-to-one relationships in object-centric
event logs, which implies synchronization of related objects. To formally
underpin this observation, we combine OCPNs with explicit stable many-to-one
relationships in a rigorous mapping from OCPNs to OPIDs explicitly capturing
the intended stable relationships and the synchronization of related objects.
We prove that the original OCPNs and the resulting OPIDs coincide for those
executions that satisfy the intended relationships. Moreover, we provide an
implementation of the mapping from OCPN to OPID under stable relationships.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [6] [MetaGen: A DSL, Database, and Benchmark for VLM-Assisted Metamaterial Generation](https://arxiv.org/abs/2508.17568)
*Liane Makatura,Benjamin Jones,Siyuan Bian,Wojciech Matusik*

Main category: cs.CV

TL;DR: 该论文提出了MetaDSL领域特定语言、MetaDB数据库和MetaBench基准测试套件三个核心组件，用于解决超材料设计中的几何复杂性和结构-性能映射难题。


<details>
  <summary>Details</summary>
Motivation: 超材料设计面临几何结构复杂和结构-性能映射非线性的挑战，需要开发系统性的工具来支持设计过程。

Method: 开发了MetaDSL语言描述超材料设计，构建了包含15万+参数化程序的MetaDB数据库，并创建了MetaBench基准测试套件来评估视觉-语言模型的能力。

Result: 通过微调先进的视觉-语言模型建立了基线性能，并在CAD式交互界面中部署了全模型，展示了在结构重建、逆向设计和性能预测方面的能力。

Conclusion: 该框架为实现结构-表示-性能关系的集成设计和理解提供了重要基础，是超材料设计领域的重要进展。

Abstract: Metamaterials are micro-architected structures whose geometry imparts highly
tunable-often counter-intuitive-bulk properties. Yet their design is difficult
because of geometric complexity and a non-trivial mapping from architecture to
behaviour. We address these challenges with three complementary contributions.
(i) MetaDSL: a compact, semantically rich domain-specific language that
captures diverse metamaterial designs in a form that is both human-readable and
machine-parsable. (ii) MetaDB: a curated repository of more than 150,000
parameterized MetaDSL programs together with their
derivatives-three-dimensional geometry, multi-view renderings, and simulated
elastic properties. (iii) MetaBench: benchmark suites that test three core
capabilities of vision-language metamaterial assistants-structure
reconstruction, property-driven inverse design, and performance prediction. We
establish baselines by fine-tuning state-of-the-art vision-language models and
deploy an omni-model within an interactive, CAD-like interface. Case studies
show that our framework provides a strong first step toward integrated design
and understanding of structure-representation-property relationships.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Who Wins the Race? (R Vs Python) - An Exploratory Study on Energy Consumption of Machine Learning Algorithms](https://arxiv.org/abs/2508.17344)
*Rajrupa Chattaraj,Sridhar Chimalakonda,Vibhu Saujanya Sharma,Vikrant Kaulgud*

Main category: cs.SE

TL;DR: 比较Python和R两种流行编程语言在机器学习任务中的能耗差异，发现两者在95%的情况下存在显著差异，语言选择对能耗效率影响可达99%以上


<details>
  <summary>Details</summary>
Motivation: 机器学习应用广泛但能耗巨大，现有研究多关注性能精度而忽视环境影响，特别是缺乏不同编程语言在ML任务中的能耗比较

Method: 通过实证研究测量比较Python和R在5个回归和5个分类任务中的能耗和运行时性能

Result: 95%的案例显示两种语言能耗存在统计显著差异，语言选择对训练能耗影响达99.16%，推理能耗影响达99.8%

Conclusion: 编程语言选择对机器学习任务的能耗有重大影响，需要重视语言选择的环境成本

Abstract: The utilization of Machine Learning (ML) in contemporary software systems is
extensive and continually expanding. However, its usage is energy-intensive,
contributing to increased carbon emissions and demanding significant resources.
While numerous studies examine the performance and accuracy of ML, only a
limited few focus on its environmental aspects, particularly energy
consumption. In addition, despite emerging efforts to compare energy
consumption across various programming languages for specific algorithms and
tasks, there remains a gap specifically in comparing these languages for
ML-based tasks. This paper aims to raise awareness of the energy costs
associated with employing different programming languages for ML model training
and inference. Through this empirical study, we measure and compare the energy
consumption along with run-time performance of five regression and five
classification tasks implemented in Python and R, the two most popular
programming languages in this context. Our study results reveal a statistically
significant difference in costs between the two languages in 95% of the cases
examined. Furthermore, our analysis demonstrates that the choice of programming
language can influence energy efficiency significantly, up to 99.16% during
model training and up to 99.8% during inferences, for a given ML task.

</details>
