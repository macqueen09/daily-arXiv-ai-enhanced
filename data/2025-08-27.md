<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [A Case Study on the Effectiveness of LLMs in Verification with Proof Assistants](https://arxiv.org/abs/2508.18587)
*Barış Bayazıt,Yao Li,Xujie Si*

Main category: cs.PL

TL;DR: 评估大型语言模型在证明助手验证任务中的有效性，通过定量和定性分析发现LLMs在小型证明上表现良好，但受外部依赖和项目差异影响较大


<details>
  <summary>Details</summary>
Motivation: 大型语言模型有潜力通过自动化证明来辅助证明助手进行验证，但其在此任务中的实际效果尚不明确，需要进行系统评估

Method: 基于两个成熟的Rocq项目（hs-to-coq工具和Verdi）进行案例研究，采用定量和定性分析方法评估LLMs生成证明的有效性

Result: 研究发现：(1)外部依赖和同源文件上下文显著帮助证明生成；(2)LLMs在小型证明上表现优异，也能生成大型证明；(3)在不同验证项目上表现不同；(4)能生成简洁智能的证明，应用经典技术到新定义，但也会犯奇怪错误

Conclusion: LLMs在证明生成方面具有潜力，特别是在小型证明和特定上下文条件下表现良好，但仍存在局限性，需要进一步研究其在不同验证项目中的适用性和错误模式

Abstract: Large language models (LLMs) can potentially help with verification using
proof assistants by automating proofs. However, it is unclear how effective
LLMs are in this task. In this paper, we perform a case study based on two
mature Rocq projects: the hs-to-coq tool and Verdi. We evaluate the
effectiveness of LLMs in generating proofs by both quantitative and qualitative
analysis. Our study finds that: (1) external dependencies and context in the
same source file can significantly help proof generation; (2) LLMs perform
great on small proofs but can also generate large proofs; (3) LLMs perform
differently on different verification projects; and (4) LLMs can generate
concise and smart proofs, apply classical techniques to new definitions, but
can also make odd mistakes.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [2] [An LLM-powered Natural-to-Robotic Language Translation Framework with Correctness Guarantees](https://arxiv.org/abs/2508.19074)
*ZhenDong Chen,ZhanShang Nie,ShiXing Wan,JunYi Li,YongTian Cheng,Shuai Zhao*

Main category: cs.RO

TL;DR: 提出NRTrans框架，通过Robot Skill Language (RSL) 和编译器验证机制，为LLM生成的机器人控制程序提供正确性保证和反馈优化


<details>
  <summary>Details</summary>
Motivation: 现有方法直接让LLM从自然语言生成可执行程序，但由于LLM的不一致性和任务复杂性，经常产生大量编程错误，特别是在轻量级LLM上效果不佳

Method: 提出Robot Skill Language (RSL) 抽象控制程序细节，构建RSL编译器和调试器验证程序正确性，并通过错误反馈机制让LLM迭代优化输出

Result: NRTrans在多种LLM和任务上优于现有方法，显著提高了轻量级LLM的成功率

Conclusion: 该框架为LLM生成的机器人控制程序提供了正确性保证，显著提升了LLM驱动的机器人应用效果

Abstract: The Large Language Models (LLM) are increasingly being deployed in robotics
to generate robot control programs for specific user tasks, enabling embodied
intelligence. Existing methods primarily focus on LLM training and prompt
design that utilize LLMs to generate executable programs directly from user
tasks in natural language. However, due to the inconsistency of the LLMs and
the high complexity of the tasks, such best-effort approaches often lead to
tremendous programming errors in the generated code, which significantly
undermines the effectiveness especially when the light-weight LLMs are applied.
This paper introduces a natural-robotic language translation framework that (i)
provides correctness verification for generated control programs and (ii)
enhances the performance of LLMs in program generation via feedback-based
fine-tuning for the programs. To achieve this, a Robot Skill Language (RSL) is
proposed to abstract away from the intricate details of the control programs,
bridging the natural language tasks with the underlying robot skills. Then, the
RSL compiler and debugger are constructed to verify RSL programs generated by
the LLM and provide error feedback to the LLM for refining the outputs until
being verified by the compiler. This provides correctness guarantees for the
LLM-generated programs before being offloaded to the robots for execution,
significantly enhancing the effectiveness of LLM-powered robotic applications.
Experiments demonstrate NRTrans outperforms the existing method under a range
of LLMs and tasks, and achieves a high success rate for light-weight LLMs.

</details>
