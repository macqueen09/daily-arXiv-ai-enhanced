{"id": "2509.07003", "pdf": "https://arxiv.org/pdf/2509.07003", "abs": "https://arxiv.org/abs/2509.07003", "authors": ["Youjie Li", "Cheng Wan", "Zhiqi Lin", "Hongyu Zhu", "Jiacheng Yang", "Ziang Song", "Xinyi Di", "Jiawei Wu", "Huiyao Shu", "Wenlei Bao", "Yanghua Peng", "Haibin Lin", "Li-Wen Chang"], "title": "veScale: Consistent and Efficient Tensor Programming with Eager-Mode SPMD", "categories": ["cs.PL", "cs.DC", "cs.LG"], "comment": "21 pages, 16 figures, 5 tables", "summary": "Large Language Models (LLMs) have scaled rapidly in size and complexity,\nrequiring increasingly intricate parallelism for distributed training, such as\n3D parallelism. This sophistication motivates a shift toward simpler, more\ndebuggable programming paradigm like Single Program Multiple Data (SPMD).\nHowever, SPMD in eager execution introduces two key challenges: ensuring\nconsistency with single-device execution and achieving high performance at\nscale. In this paper, we introduce veScale, an eager-mode training system that\nfully embraces SPMD paradigm to democratize distributed tensor programming.\nveScale addresses the prevalent issue of inconsistent results in systems like\nPyTorch by introducing a novel algorithm of distributed Random Number\nGeneration (RNG) compatible with arbitrary sharded operators. veScale also\nsignificantly boosts training performance by reducing PyTorch primitive's\noverhead and improving communication efficiency. Evaluations show that veScale\ndelivers up to 2.2x speedup over the state-of-the-art training systems, like\nTorchTitan, and cuts code complexity by 78.4%, while preserving\nsingle-device-equivalent results.", "AI": {"tldr": "veScale\u662f\u4e00\u4e2a\u57fa\u4e8eSPMD\u8303\u5f0f\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u7cfb\u7edf\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5206\u5e03\u5f0f\u968f\u673a\u6570\u751f\u6210\u7b97\u6cd5\u89e3\u51b3\u4e86\u7ed3\u679c\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u5e76\u5728\u6027\u80fd\u548c\u4ee3\u7801\u590d\u6742\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u89c4\u6a21\u548c\u590d\u6742\u5ea6\u7684\u5feb\u901f\u589e\u957f\uff0c\u5206\u5e03\u5f0f\u8bad\u7ec3\u9700\u8981\u66f4\u590d\u6742\u7684\u5e76\u884c\u7b56\u7565\uff08\u59823D\u5e76\u884c\uff09\uff0c\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u5bfb\u6c42\u66f4\u7b80\u5355\u3001\u66f4\u6613\u8c03\u8bd5\u7684\u7f16\u7a0b\u8303\u5f0f\uff0c\u5982SPMD\u3002\u4f46SPMD\u5728\u5373\u65f6\u6267\u884c\u6a21\u5f0f\u4e0b\u5b58\u5728\u7ed3\u679c\u4e00\u81f4\u6027\u548c\u6027\u80fd\u6269\u5c55\u4e24\u5927\u6311\u6218", "method": "veScale\u91c7\u7528\u5b8c\u5168SPMD\u8303\u5f0f\uff0c\u5f15\u5165\u521b\u65b0\u7684\u5206\u5e03\u5f0f\u968f\u673a\u6570\u751f\u6210\u7b97\u6cd5\uff08\u517c\u5bb9\u4efb\u610f\u5206\u7247\u64cd\u4f5c\u7b26\uff09\uff0c\u901a\u8fc7\u51cf\u5c11PyTorch\u539f\u8bed\u5f00\u9500\u548c\u63d0\u5347\u901a\u4fe1\u6548\u7387\u6765\u4f18\u5316\u6027\u80fd", "result": "\u8bc4\u4f30\u663e\u793aveScale\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u8bad\u7ec3\u7cfb\u7edf\uff08\u5982TorchTitan\uff09\u5b9e\u73b0\u4e86\u6700\u9ad82.2\u500d\u7684\u52a0\u901f\uff0c\u4ee3\u7801\u590d\u6742\u5ea6\u964d\u4f4e78.4%\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u5355\u8bbe\u5907\u7b49\u6548\u7684\u7ed3\u679c", "conclusion": "veScale\u6210\u529f\u5b9e\u73b0\u4e86SPMD\u8303\u5f0f\u7684\u6c11\u4e3b\u5316\u5206\u5e03\u5f0f\u5f20\u91cf\u7f16\u7a0b\uff0c\u5728\u4fdd\u8bc1\u7ed3\u679c\u4e00\u81f4\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u8bad\u7ec3\u6027\u80fd\u548c\u5f00\u53d1\u6548\u7387"}}
{"id": "2509.07551", "pdf": "https://arxiv.org/pdf/2509.07551", "abs": "https://arxiv.org/abs/2509.07551", "authors": ["Sean Bocirnea", "William J. Bowman"], "title": "Fast and Extensible Hybrid Embeddings with Micros", "categories": ["cs.PL"], "comment": "13 pages", "summary": "Macro embedding is a popular approach to defining extensible shallow\nembeddings of object languages in Scheme like host languages. While macro\nembedding has even been shown to enable implementing extensible typed languages\nin systems like Racket, it comes at a cost: compile-time performance. In this\npaper, we revisit micros - syntax to intermediate representation (IR)\ntransformers, rather than source syntax to source syntax transformers (macros).\nMicro embedding enables stopping at an IR, producing a deep embedding and\nenabling high performance compile-time functions over an efficient IR, before\nshallowly embedding the IR back into source syntax. Combining micros with\nseveral design patterns to enable the IR and functions over it to be\nextensible, we achieve extensible hybrid embedding of statically typed\nlanguages with significantly improved compile-time compared to macro-embedding\napproaches. We describe our design patterns and propose new abstractions\npackaging these patterns.", "AI": {"tldr": "\u5c0f\u578b\u5d4c\u5165\u6280\u672f\uff08micros\uff09\u901a\u8fc7\u8bed\u6cd5\u5230\u4e2d\u95f4\u8868\u793a\u7684\u8f6c\u6362\uff0c\u63d0\u9ad8\u4e86\u7f16\u8bd1\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u9759\u6001\u7c7b\u578b\u8bed\u8a00\u5d4c\u5165", "motivation": "\u89e3\u51b3\u5b8f\u5d4c\u5165\u6280\u672f\u5728\u7f16\u8bd1\u65f6\u6027\u80fd\u4e0a\u7684\u4e0d\u8db3\uff0c\u867d\u7136\u5b8f\u5d4c\u5165\u80fd\u591f\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u7c7b\u578b\u8bed\u8a00\uff0c\u4f46\u7f16\u8bd1\u901f\u5ea6\u8f83\u6162", "method": "\u91c7\u7528micros\u6280\u672f\uff08\u8bed\u6cd5\u5230IR\u8f6c\u6362\u5668\uff09\uff0c\u5148\u751f\u6210\u6df1\u5ea6\u5d4c\u5165\u7684\u4e2d\u95f4\u8868\u793a\uff0c\u7136\u540e\u518d\u6d45\u5d4c\u5165\u56de\u6e90\u4ee3\u7801\u8bed\u6cd5\uff0c\u7ed3\u5408\u591a\u79cd\u8bbe\u8ba1\u6a21\u5f0f\u4f7fIR\u53ca\u5176\u51fd\u6570\u53ef\u6269\u5c55", "result": "\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u6df7\u5408\u5d4c\u5165\u9759\u6001\u7c7b\u578b\u8bed\u8a00\uff0c\u7f16\u8bd1\u65f6\u6027\u80fd\u663e\u8457\u63d0\u9ad8\uff0c\u8f83\u5b8f\u5d4c\u5165\u65b9\u6cd5\u6709\u663e\u8457\u6539\u5584", "conclusion": "Micro\u5d4c\u5165\u6280\u672f\u901a\u8fc7\u4f18\u5316\u7f16\u8bd1\u8fc7\u7a0b\uff0c\u5728\u4fdd\u6301\u8bed\u8a00\u6269\u5c55\u6027\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u4e86\u7f16\u8bd1\u6548\u7387\uff0c\u4e3a\u5d4c\u5165\u5f0f\u8bed\u8a00\u5f00\u53d1\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.07609", "pdf": "https://arxiv.org/pdf/2509.07609", "abs": "https://arxiv.org/abs/2509.07609", "authors": ["Yichen Xu", "Oliver Bra\u010devac", "Cao Nguyen Pham", "Martin Odersky"], "title": "What's in the Box: Ergonomic and Expressive Capture Tracking over Generic Data Structures (Extended Version)", "categories": ["cs.PL"], "comment": null, "summary": "Capturing types in Scala unify static effect and resource tracking with\nobject capabilities, enabling lightweight effect polymorphism with minimal\nnotational overhead. However, their expressiveness has been insufficient for\ntracking capabilities embedded in generic data structures, preventing them from\nscaling to the standard collections library -- an essential prerequisite for\nbroader adoption. This limitation stems from the inability to name capabilities\nwithin the system's notion of box types.\n  This paper develops System Capless, a new foundation for capturing types that\nprovides the theoretical basis for reach capabilities (rcaps), a novel\nmechanism for naming \"what's in the box.\" The calculus refines the universal\ncapability notion into a new scheme with existential and universal capture set\nquantification. Intuitively, rcaps witness existentially quantified capture\nsets inside the boxes of generic types in a way that does not require exposing\nexistential capture types in the surface language. We have fully mechanized the\nformal metatheory of System Capless in Lean, including proofs of type soundness\nand scope safety. System Capless supports the same lightweight notation of\ncapturing types plus rcaps, as certified by a type-preserving translation, and\nalso enables fully optional explicit capture-set quantification to increase\nexpressiveness.\n  Finally, we present a full reimplementation of capture checking in Scala 3\nbased on System Capless and migrate the entire Scala collections library and an\nasynchronous programming library to evaluate its practicality and ergonomics.\nOur results demonstrate that reach capabilities enable the adoption of capture\nchecking in production code with minimal changes and minimal-to-zero notational\noverhead in a vast majority of cases.", "AI": {"tldr": "System Capless\u4e3aScala\u6355\u83b7\u7c7b\u578b\u63d0\u4f9b\u4e86\u65b0\u7406\u8bba\u57fa\u7840\uff0c\u901a\u8fc7reach capabilities\u673a\u5236\u89e3\u51b3\u6cdb\u578b\u6570\u636e\u7ed3\u6784\u4e2d\u80fd\u529b\u547d\u540d\u95ee\u9898\uff0c\u652f\u6301\u6807\u51c6\u96c6\u5408\u5e93\u7684\u6355\u83b7\u68c0\u67e5", "motivation": "\u73b0\u6709Scala\u6355\u83b7\u7c7b\u578b\u7cfb\u7edf\u65e0\u6cd5\u6709\u6548\u8ddf\u8e2a\u5d4c\u5165\u5728\u6cdb\u578b\u6570\u636e\u7ed3\u6784\u4e2d\u7684\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5176\u5728\u6807\u51c6\u96c6\u5408\u5e93\u4e2d\u7684\u5e94\u7528\uff0c\u963b\u788d\u4e86\u66f4\u5e7f\u6cdb\u7684\u91c7\u7528", "method": "\u5f00\u53d1System Capless\u6f14\u7b97\uff0c\u5f15\u5165reach capabilities\u673a\u5236\uff0c\u5c06\u901a\u7528\u80fd\u529b\u6982\u5ff5\u7ec6\u5316\u4e3a\u5b58\u5728\u548c\u901a\u7528\u6355\u83b7\u96c6\u91cf\u5316\u65b9\u6848\uff0c\u5e76\u5728Lean\u4e2d\u5f62\u5f0f\u5316\u9a8c\u8bc1", "result": "\u57fa\u4e8eSystem Capless\u5728Scala 3\u4e2d\u5b8c\u5168\u91cd\u65b0\u5b9e\u73b0\u6355\u83b7\u68c0\u67e5\uff0c\u6210\u529f\u8fc1\u79fb\u6574\u4e2aScala\u96c6\u5408\u5e93\u548c\u5f02\u6b65\u7f16\u7a0b\u5e93\uff0c\u8bc1\u660e\u5728\u5b9e\u9645\u4ee3\u7801\u4e2d\u91c7\u7528\u7684\u6700\u5c0f\u6539\u52a8\u548c\u96f6\u6807\u6ce8\u5f00\u9500", "conclusion": "reach capabilities\u4f7f\u5f97\u6355\u83b7\u68c0\u67e5\u80fd\u591f\u5728\u751f\u4ea7\u4ee3\u7801\u4e2d\u4ee5\u6700\u5c0f\u6539\u52a8\u548c\u51e0\u4e4e\u96f6\u6807\u6ce8\u5f00\u9500\u7684\u65b9\u5f0f\u88ab\u91c7\u7528\uff0c\u89e3\u51b3\u4e86\u6cdb\u578b\u6570\u636e\u7ed3\u6784\u4e2d\u80fd\u529b\u8ddf\u8e2a\u7684\u5173\u952e\u9650\u5236"}}
{"id": "2509.07763", "pdf": "https://arxiv.org/pdf/2509.07763", "abs": "https://arxiv.org/abs/2509.07763", "authors": ["Mikel Robredo", "Matteo Esposito", "Fabio Palomba", "Rafael Pe\u00f1aloza", "Valentina Lenarduzzi"], "title": "What Were You Thinking? An LLM-Driven Large-Scale Study of Refactoring Motivations in Open-Source Projects", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Context. Code refactoring improves software quality without changing external\nbehavior. Despite its advantages, its benefits are hindered by the considerable\ncost of time, resources, and continuous effort it demands. Aim. Understanding\nwhy developers refactor, and which metrics capture these motivations, may\nsupport wider and more effective use of refactoring in practice. Method. We\nperformed a large-scale empirical study to analyze developers refactoring\nactivity, leveraging Large Language Models (LLMs) to identify underlying\nmotivations from version control data, comparing our findings with previous\nmotivations reported in the literature. Results. LLMs matched human judgment in\n80% of cases, but aligned with literature-based motivations in only 47%. They\nenriched 22% of motivations with more detailed rationale, often highlighting\nreadability, clarity, and structural improvements. Most motivations were\npragmatic, focused on simplification and maintainability. While metrics related\nto developer experience and code readability ranked highest, their correlation\nwith motivation categories was weak. Conclusions. We conclude that LLMs\neffectively capture surface-level motivations but struggle with architectural\nreasoning. Their value lies in providing localized explanations, which, when\ncombined with software metrics, can form hybrid approaches. Such integration\noffers a promising path toward prioritizing refactoring more systematically and\nbalancing short-term improvements with long-term architectural goals.", "AI": {"tldr": "LLMs\u80fd\u6709\u6548\u8bc6\u522b80%\u7684\u4ee3\u7801\u91cd\u6784\u52a8\u673a\uff0c\u4f46\u4e0e\u4f20\u7edf\u6587\u732e\u52a8\u673a\u4ec547%\u4e00\u81f4\uff0c\u4e3b\u8981\u5173\u6ce8\u53ef\u8bfb\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u7b49\u5b9e\u7528\u76ee\u6807\u3002", "motivation": "\u7406\u89e3\u5f00\u53d1\u8005\u91cd\u6784\u4ee3\u7801\u7684\u52a8\u673a\u4ee5\u53ca\u54ea\u4e9b\u6307\u6807\u80fd\u6355\u6349\u8fd9\u4e9b\u52a8\u673a\uff0c\u4ee5\u652f\u6301\u66f4\u5e7f\u6cdb\u548c\u6709\u6548\u7684\u91cd\u6784\u5b9e\u8df5\u3002", "method": "\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u7248\u672c\u63a7\u5236\u6570\u636e\u4e2d\u8bc6\u522b\u91cd\u6784\u52a8\u673a\uff0c\u5e76\u4e0e\u6587\u732e\u4e2d\u62a5\u544a\u7684\u52a8\u673a\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "LLMs\u572880%\u7684\u60c5\u51b5\u4e0b\u4e0e\u4eba\u7c7b\u5224\u65ad\u4e00\u81f4\uff0c\u4f46\u4e0e\u6587\u732e\u52a8\u673a\u4ec547%\u4e00\u81f4\uff1b\u4e30\u5bcc\u4e8622%\u7684\u52a8\u673a\u7ec6\u8282\uff1b\u4e3b\u8981\u52a8\u673a\u662f\u7b80\u5316\u4ee3\u7801\u548c\u63d0\u9ad8\u53ef\u7ef4\u62a4\u6027\uff1b\u5f00\u53d1\u8005\u7ecf\u9a8c\u548c\u4ee3\u7801\u53ef\u8bfb\u6027\u6307\u6807\u76f8\u5173\u6027\u8f83\u5f31\u3002", "conclusion": "LLMs\u80fd\u6709\u6548\u6355\u6349\u8868\u9762\u5c42\u52a8\u673a\u4f46\u96be\u4ee5\u5904\u7406\u67b6\u6784\u63a8\u7406\uff0c\u5176\u4ef7\u503c\u5728\u4e8e\u63d0\u4f9b\u5c40\u90e8\u89e3\u91ca\uff0c\u4e0e\u8f6f\u4ef6\u6307\u6807\u7ed3\u5408\u53ef\u5f62\u6210\u6df7\u5408\u65b9\u6cd5\uff0c\u7cfb\u7edf\u5316\u91cd\u6784\u4f18\u5148\u7ea7\u5e76\u5e73\u8861\u77ed\u671f\u6539\u8fdb\u4e0e\u957f\u671f\u67b6\u6784\u76ee\u6807\u3002"}}
