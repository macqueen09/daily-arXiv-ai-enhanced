<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 4]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [DeliverC: Teaching Pointers through GenAI-Powered Game-Based Learning](https://arxiv.org/abs/2509.14496)
*Wyatt Petula,Anushcka Joshi,Peggy Tu,Amrutha Somasundar,Suman Saha*

Main category: cs.PL

TL;DR: DeliverC是一个集成GPT-4-mini的GenAI增强游戏，为C语言指针学习提供实时个性化提示和挑战生成。研究表明它能提升学生信心和反思能力，但AI反馈质量仍需改进。


<details>
  <summary>Details</summary>
Motivation: 传统游戏化编程教育缺乏对复杂主题（如C指针）的实时自适应支持，需要开发能够提供个性化学习体验的工具。

Method: 开发DeliverC游戏，集成GPT-4-mini提供个性化提示和动态生成指针相关挑战。通过25名本科生的试点研究，收集游戏数据和15项问卷调查，评估动机、自我效能、元认知和反馈质量等构念。

Result: 大多数学生使用后感到更自信和善于反思，错误率随脚手架式关卡进展而下降。但参与度随任务难度增加而降低，部分学生反馈AI生成的提示不够清晰。

Conclusion: DeliverC能够增强系统编程的参与度和理解，但需要改进AI生成反馈的质量。研究展示了GenAI与游戏化学习结合在传统挑战性编程领域支持个性化交互实践的潜力。

Abstract: While game-based learning is widely used in programming education, few tools
offer adaptive, real-time support for complex topics, such as C pointers. We
present DeliverC, a GenAI-enhanced game that integrates GPT-4-mini to provide
personalized hints and generate pointer-related challenges on the fly. In a
pilot study involving 25 undergraduate students, we investigated the impact of
the system on learning through gameplay data and a 15-item survey that covered
constructs such as motivation, self-efficacy, metacognition, and feedback
quality. Results show that most students felt more confident and reflective
after using the tool, and error rates decreased as students progressed through
scaffolded levels. However, participation decreased with task difficulty, and
some students reported receiving unclear or vague feedback. These findings
suggest that DeliverC can enhance engagement and understanding in systems
programming, although refinement in AI-generated feedback is still needed. Our
study highlights the potential of combining GenAI with game-based learning to
support personalized and interactive practice in traditionally challenging
programming domains.

</details>


### [2] [Refinement-Types Driven Development: A study](https://arxiv.org/abs/2509.15005)
*Facundo Domínguez,Arnaud Spiwack*

Main category: cs.PL

TL;DR: 推广SMT求解器在日常编程中的应用，通过精细类型与编译器整合提升程序组合能力


<details>
  <summary>Details</summary>
Motivation: 质疑SMT求解器仅适用于形式验证的传统观点，认为其在普通编程任务中也有广阔应用潜力

Method: 采用Liquid Haskell的精细类型技术，将SMT求解器集成到编译器静态检查中，并通过编译器绑定范围的案例研究进行验证

Result: 开发了Liquid Haskell有限映射理论的原型实现，支持案例研究，证明了SMT求解器在普通编程中的可行性

Conclusion: 精细类型和SMT求解器的结合能够让普通编程更简单、更愉快，为日常编程工具链带来重大改进

Abstract: This paper advocates for the broader application of SMT solvers in everyday
programming, challenging the conventional wisdom that these tools are solely
for formal methods and verification. We claim that SMT solvers, when seamlessly
integrated into a compiler's static checks, significantly enhance the
capabilities of ordinary type checkers in program composition. Specifically, we
argue that refinement types, as embodied by Liquid Haskell, enable the use of
SMT solvers in mundane programming tasks. Through a case study on handling
binder scopes in compilers, we envision a future where ordinary programming is
made simpler and more enjoyable with the aid of refinement types and SMT
solvers. As a secondary contribution, we present a prototype implementation of
a theory of finite maps for Liquid Haskell's solver, developed to support our
case study.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [3] [SWE-QA: Can Language Models Answer Repository-level Code Questions?](https://arxiv.org/abs/2509.14635)
*Weihan Peng,Yuling Shi,Yuhang Wang,Xinyun Zhang,Beijun Shen,Xiaodong Gu*

Main category: cs.CL

TL;DR: SWE-QA是一个仓库级代码问答基准数据集，包含576个高质量问答对，涵盖多文件推理和依赖分析等复杂场景，旨在推动真实代码环境中的自动化问答系统研究。


<details>
  <summary>Details</summary>
Motivation: 现有基准如CoSQA和CodeQA主要关注小型自包含代码片段，无法捕捉真实软件仓库的复杂性，需要理解多文件、软件架构和长距离代码依赖。

Method: 从11个流行仓库的77,100个GitHub问题中提取开发者问题，建立两级分类法，为每个类别手动构建和验证问答对，并开发SWE-QA-Agent代理框架进行自动推理。

Result: 评估了6个先进LLM在不同上下文增强策略下的表现，结果显示LLMs特别是SWE-QA-Agent框架在仓库级问答方面具有潜力。

Conclusion: SWE-QA为仓库级代码问答研究提供了重要基准，揭示了当前挑战并指明了未来研究方向，LLM代理框架展现出解决复杂代码推理问题的前景。

Abstract: Understanding and reasoning about entire software repositories is an
essential capability for intelligent software engineering tools. While existing
benchmarks such as CoSQA and CodeQA have advanced the field, they predominantly
focus on small, self-contained code snippets. These setups fail to capture the
complexity of real-world repositories, where effective understanding and
reasoning often require navigating multiple files, understanding software
architecture, and grounding answers in long-range code dependencies. In this
paper, we present SWE-QA, a repository-level code question answering (QA)
benchmark designed to facilitate research on automated QA systems in realistic
code environments. SWE-QA involves 576 high-quality question-answer pairs
spanning diverse categories, including intention understanding, cross-file
reasoning, and multi-hop dependency analysis. To construct SWE-QA, we first
crawled 77,100 GitHub issues from 11 popular repositories. Based on an analysis
of naturally occurring developer questions extracted from these issues, we
developed a two-level taxonomy of repository-level questions and constructed a
set of seed questions for each category. For each category, we manually curated
and validated questions and collected their corresponding answers. As a
prototype application, we further develop SWE-QA-Agent, an agentic framework in
which LLM agents reason and act to find answers automatically. We evaluate six
advanced LLMs on SWE-QA under various context augmentation strategies.
Experimental results highlight the promise of LLMs, particularly our
SWE-QA-Agent framework, in addressing repository-level QA, while also revealing
open challenges and pointing to future research directions.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [A Taxonomy of Prompt Defects in LLM Systems](https://arxiv.org/abs/2509.14404)
*Haoye Tian,Chong Wang,BoYang Yang,Lyuye Zhang,Yang Liu*

Main category: cs.SE

TL;DR: 本文首次系统性地调查和分类了提示缺陷，将提示缺陷分为6个维度，提供了具体的缺陷示例、根本原因分析和缓解策略，旨在提高LLM驱动系统的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型已成为现代软件的关键组件，但提示设计仍主要依赖经验，小错误可能导致不可靠、不安全或低效的行为，需要系统化的缺陷分类和缓解方法。

Method: 通过系统调查和分类学方法，将提示缺陷组织为6个维度：规范和意图、输入和内容、结构和格式、上下文和内存、性能和效率、可维护性和工程化，每个维度细分为子类型并提供具体示例和根本原因分析。

Result: 建立了完整的提示缺陷分类体系，为每种缺陷类型提供了缓解策略，包括新兴的提示工程模式、自动化护栏、测试框架和评估框架，并总结了连接缺陷、影响和补救措施的主分类法。

Conclusion: 提出了面向工程的严格方法学需求，以确保LLM驱动系统在设计上就是可靠的，并指出了开放的研究挑战。

Abstract: Large Language Models (LLMs) have become key components of modern software,
with prompts acting as their de-facto programming interface. However, prompt
design remains largely empirical and small mistakes can cascade into
unreliable, insecure, or inefficient behavior. This paper presents the first
systematic survey and taxonomy of prompt defects, recurring ways that prompts
fail to elicit their intended behavior from LLMs. We organize defects along six
dimensions: (1) Specification and Intent, (2) Input and Content, (3) Structure
and Formatting, (4) Context and Memory, (5) Performance and Efficiency, and (6)
Maintainability and Engineering. Each dimension is refined into fine-grained
subtypes, illustrated with concrete examples and root cause analysis. Grounded
in software engineering principles, we show how these defects surface in real
development workflows and examine their downstream effects. For every subtype,
we distill mitigation strategies that span emerging prompt engineering
patterns, automated guardrails, testing harnesses, and evaluation frameworks.
We then summarize these strategies in a master taxonomy that links defect,
impact, and remedy. We conclude with open research challenges and a call for
rigorous engineering-oriented methodologies to ensure that LLM-driven systems
are dependable by design.

</details>


### [5] [Automating Modelica Module Generation Using Large Language Models: A Case Study on Building Control Description Language](https://arxiv.org/abs/2509.14623)
*Hanlong Wan,Xing Lu,Yan Chen,Karthik Devaprasad,Laura Hinkle*

Main category: cs.SE

TL;DR: 本文研究使用大型语言模型自动生成Modelica控制模块，开发了结合标准化提示、库感知、自动编译和人工评估的工作流程。GPT-4o零样本模式失败，Claude Sonnet 4在精心设计的提示下对基础逻辑模块达到完全成功，控制模块成功率83%，开发时间减少40-60%。


<details>
  <summary>Details</summary>
Motivation: Modelica作为广泛使用的基于方程的语言，开发控制模块劳动密集且需要专业知识，需要自动化生成方法来提高效率。

Method: 开发结构化工作流程，包括标准化提示支架、库感知接地、OpenModelica自动编译和人工循环评估，在基础逻辑任务和控制模块上进行实验。

Result: GPT-4o零样本模式无法生成可执行代码，Claude Sonnet 4在基础逻辑块上达到完全成功，控制模块成功率83%，失败输出需要中等程度人工修复（1-8小时），开发时间从10-20小时减少到4-6小时。

Conclusion: LLM辅助工作流程显示出潜力但存在局限，需要未来研究关注预模拟验证、更强接地和闭环评估。

Abstract: Dynamic energy systems and controls require advanced modeling frameworks to
design and test supervisory and fault tolerant strategies. Modelica is a widely
used equation based language, but developing control modules is labor intensive
and requires specialized expertise. This paper examines the use of large
language models (LLMs) to automate the generation of Control Description
Language modules in the Building Modelica Library as a case study. We developed
a structured workflow that combines standardized prompt scaffolds, library
aware grounding, automated compilation with OpenModelica, and human in the loop
evaluation. Experiments were carried out on four basic logic tasks (And, Or,
Not, and Switch) and five control modules (chiller enable/disable, bypass valve
control, cooling tower fan speed, plant requests, and relief damper control).
The results showed that GPT 4o failed to produce executable Modelica code in
zero shot mode, while Claude Sonnet 4 achieved up to full success for basic
logic blocks with carefully engineered prompts. For control modules, success
rates reached 83 percent, and failed outputs required medium level human repair
(estimated one to eight hours). Retrieval augmented generation often produced
mismatches in module selection (for example, And retrieved as Or), while a
deterministic hard rule search strategy avoided these errors. Human evaluation
also outperformed AI evaluation, since current LLMs cannot assess simulation
results or validate behavioral correctness. Despite these limitations, the LLM
assisted workflow reduced the average development time from 10 to 20 hours down
to 4 to 6 hours per module, corresponding to 40 to 60 percent time savings.
These results highlight both the potential and current limitations of LLM
assisted Modelica generation, and point to future research in pre simulation
validation, stronger grounding, and closed loop evaluation.

</details>


### [6] [SALT4Decompile: Inferring Source-level Abstract Logic Tree for LLM-Based Binary Decompilation](https://arxiv.org/abs/2509.14646)
*Yongpan Wang,Xin Xu,Xiaojie Zhu,Xiaodong Gu,Beijun Shen*

Main category: cs.SE

TL;DR: SALTM是一种新颖的二进制反编译方法，通过抽象二进制和源代码之间的稳定逻辑特征，构建源级抽象逻辑树来指导LLM进行语义恢复，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的反编译方法将汇编代码视为线性指令序列，忽略了二进制文件固有的任意跳转模式和孤立数据段，这严重阻碍了从汇编代码正确推断源代码语义的能力。

Method: SALTM方法：1）从汇编代码构建源级抽象逻辑树(SALT)来近似高级语言的逻辑结构；2）使用重构的SALT微调LLM生成反编译代码；3）通过错误校正和符号恢复来优化输出可读性和正确性。

Result: 在三个知名数据集上的实验表明，SALTM在恢复源代码逻辑方面非常有效，显著优于最先进方法（如在Decompile-Eval上达到70.4%的TCP率，提升10.6%），对四种常用混淆技术具有鲁棒性。

Conclusion: SALTM通过抽象二进制级操作为高级逻辑框架，有效指导LLM进行语义恢复，为人类分析人员理解二进制函数提供了优越的帮助，验证了该方法在二进制反编译领域的有效性。

Abstract: Decompilation is widely used in reverse engineering to recover high-level
language code from binary executables. While recent approaches leveraging Large
Language Models (LLMs) have shown promising progress, they typically treat
assembly code as a linear sequence of instructions, overlooking arbitrary jump
patterns and isolated data segments inherent to binary files. This limitation
significantly hinders their ability to correctly infer source code semantics
from assembly code. To address this limitation, we propose \saltm, a novel
binary decompilation method that abstracts stable logical features shared
between binary and source code. The core idea of \saltm is to abstract selected
binary-level operations, such as specific jumps, into a high-level logic
framework that better guides LLMs in semantic recovery. Given a binary
function, \saltm constructs a Source-level Abstract Logic Tree (\salt) from
assembly code to approximate the logic structure of high-level language. It
then fine-tunes an LLM using the reconstructed \salt to generate decompiled
code. Finally, the output is refined through error correction and symbol
recovery to improve readability and correctness. We compare \saltm to three
categories of baselines (general-purpose LLMs, commercial decompilers, and
decompilation methods) using three well-known datasets (Decompile-Eval, MBPP,
Exebench). Our experimental results demonstrate that \saltm is highly effective
in recovering the logic of the source code, significantly outperforming
state-of-the-art methods (e.g., 70.4\% TCP rate on Decompile-Eval with a 10.6\%
improvement). The results further validate its robustness against four commonly
used obfuscation techniques. Additionally, analyses of real-world software and
a user study confirm that our decompiled output offers superior assistance to
human analysts in comprehending binary functions.

</details>


### [7] [Code Less to Code More: Streamlining Language Server Protocol and Type System Development for Language Families](https://arxiv.org/abs/2509.15150)
*Federico Bruzzone,Walter Cazzola,Luca Favalli*

Main category: cs.SE

TL;DR: 这篇论文提出了Typelang语言家族和模块化语言服务器生成方案，通过类型系统重用和自动化插件生成，大幅减少编辑支持的开发工作量


<details>
  <summary>Details</summary>
Motivation: 解决多语言多编辑器支持的复杂性问题，LSP协议已简化了语言-编辑器组合，但语言组件的重复实现仍是挑战，现有语言工作台在模块化、可重用性和利用类型系统生成语言服务器方面存在不足

Method: 提出(i)Typelang域特定语言家族用于模块化、可组合、可重用的类型系统实现；(ii)模块化语言服务器生成过程；(iii)变体导向编程范式和跨产物协调层；(iv)LSP插件生成器自动化多编辑器插件创建

Result: 在Neverlang中实现Typelang，为每个产物生成语言服务器并为三个编辑器生成LSP插件。经验评估显示：类型系统实现需要的字符数减少93.48%，LSP插件生成完全自动化(100%)，显著降低了语言家族编辑支持的开发工作量

Conclusion: 该方法通过模块化类型系统实现和自动化语言服务器生成，最终将语言-编辑器组合从L×E简化为N×1(N远小于T)，为语言家族提供了高效的编辑支持解决方案

Abstract: Developing editing support for $L$ languages in $E$ editors is complex and
time-consuming. Some languages do not provide dedicated editors, while others
offer a single native editor. The $\textit{language server protocol}$ (LSP)
reduces the language-editor combinations $L \times E$ to $L + E$, where a
single language server communicates with editors via LSP plugins. However,
overlapping implementations of linguistic components remain an issue. Existing
language workbenches struggle with modularity, reusability, and leveraging type
systems for language server generation. In this work, we propose: (i) Typelang,
a family of domain-specific languages for modular, composable, and reusable
type system implementation, (ii) a modular language server generation process,
producing servers for languages built in a modular workbench, (iii) the
variant-oriented programming paradigm and a cross-artifact coordination layer
to manage interdependent software variants, and (iv) an LSP plugin generator,
reducing $E$ to $1$ by automating plugin creation for multiple editors. To
simplify editing support for language families, each language artifact
integrates its own Typelang variant, used to generate language servers. This
reduces combinations to $T \times 1$, where $T = L$ represents the number of
type systems. Further reuse of language artifacts across languages lowers this
to $N \times 1$, where $N << T$, representing unique type systems. We implement
Typelang in Neverlang, generating language servers for each artifact and LSP
plugins for three editors. Empirical evaluation shows a 93.48% reduction in
characters needed for type system implementation and 100% automation of LSP
plugin generation, significantly lowering effort for editing support in
language families, especially when artifacts are reused.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [8] [Weighted Automata for Exact Inference in Discrete Probabilistic Programs](https://arxiv.org/abs/2509.15074)
*Dominik Geißler,Tobias Winkler*

Main category: cs.FL

TL;DR: 将概率编程中的推理问题转化为加权自动机构造，通过概率生成函数编码分布，实现从先验到后验分布的有效转换


<details>
  <summary>Details</summary>
Motivation: 概率编程中的推理问题需要确定程序在观察指令条件下的后验分布，精确推理具有挑战性

Method: 将N^k上的分布编码为具有k个符号的交换字母表上的加权自动机，将各种命令式编程语句的语义映射到自动机理论构造

Result: 对于丰富的程序类，实现了从先验到后验分布的有效转换，两者都编码为自动机

Conclusion: 该方法相对于标准操作程序语义是可靠的，为精确概率推理提供了自动机理论基础

Abstract: In probabilistic programming, the inference problem asks to determine a
program's posterior distribution conditioned on its "observe" instructions.
Inference is challenging, especially when exact rather than approximate results
are required. Inspired by recent work on probability generating functions
(PGFs), we propose encoding distributions on $\mathbb{N}^k$ as weighted
automata over a commutative alphabet with $k$ symbols. Based on this, we map
the semantics of various imperative programming statements to
automata-theoretic constructions. For a rich class of programs, this results in
an effective translation from prior to posterior distribution, both encoded as
automata. We prove that our approach is sound with respect to a standard
operational program semantics.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [9] [Theorem Provers: One Size Fits All?](https://arxiv.org/abs/2509.15015)
*Harrison Oates,Hyeonggeun Yun,Nikhila Gurusinghe*

Main category: cs.LO

TL;DR: 通过对比Coq和Idris2两种定理证明器在插入排序正确性证明中的表现，为用户选择适合的形式验证工具提供指导


<details>
  <summary>Details</summary>
Motivation: 不同的交互式定理证明系统具有不同的设计特性和使用体验，需要通过实际案例对比来帮助用户做出明智选择

Method: 使用Coq和Idris2两种定理证明器实现插入排序算法的正确性证明，并进行质性评估和社区库支持对比

Result: 获得了两种工具在实际证明任务中的性能表现数据，以及它们的社区活跃度和库资源情况

Conclusion: 该研究为形式验证工作者选择适合的定理证明器提供了实践指南，同时为开发者提供了可借鉴的设计思路

Abstract: Theorem provers are important tools for people working in formal
verification. There are a myriad of interactive systems available today, with
varying features and approaches motivating their development. These design
choices impact their usability, alongside the problem domain in which they are
employed. We test-drive two such provers, Coq and Idris2, by proving the
correctness of insertion sort, before providing a qualitative evaluation of
their performance. We then compare their community and library support. This
work helps users to make an informed choice of system, and highlight approaches
in other systems that developers might find useful.

</details>
