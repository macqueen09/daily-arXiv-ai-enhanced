{"id": "2509.16246", "pdf": "https://arxiv.org/pdf/2509.16246", "abs": "https://arxiv.org/abs/2509.16246", "authors": ["Juxin Niu", "Yuxin Du", "Dan Niu", "Xi Wang", "Zhe Jiang", "Nan Guan"], "title": "VerilogMonkey: Exploring Parallel Scaling for Automated Verilog Code Generation with LLMs", "categories": ["cs.PL", "cs.AR"], "comment": null, "summary": "We present VerilogMonkey, an empirical study of parallel scaling for the\nunder-explored task of automated Verilog generation. Parallel scaling improves\nLLM performance by sampling many outputs in parallel. Across multiple\nbenchmarks and mainstream LLMs, we find that scaling to hundreds of samples is\ncost-effective in both time and money and, even without any additional\nenhancements such as post-training or agentic methods, surpasses prior results\non LLM-based Verilog generation. We further dissect why parallel scaling\ndelivers these gains and show how output randomness in LLMs affects its\neffectiveness."}
{"id": "2509.16248", "pdf": "https://arxiv.org/pdf/2509.16248", "abs": "https://arxiv.org/abs/2509.16248", "authors": ["Savini Kashmira", "Jayanaka Dantanarayana", "Thamirawaran Sathiyalogeswaran", "Yichao Yuan", "Nishil Talati", "Krisztian Flautner", "Lingjia Tang", "Jason Mars"], "title": "GraphMend: Code Transformations for Fixing Graph Breaks in PyTorch 2", "categories": ["cs.PL", "cs.LG", "cs.SE"], "comment": null, "summary": "This paper presents GraphMend, a high-level compiler that eliminates FX graph\nbreaks in PyTorch 2 programs. Although PyTorch 2 introduced TorchDynamo and\nTorchInductor to enable just-in-time graph compilation, unresolved dynamic\ncontrol flow and unsupported Python constructs often fragment models into\nmultiple FX graphs. These fragments force frequent fallbacks to eager mode,\nincur costly CPU-to-GPU synchronizations, and reduce optimization\nopportunities. GraphMend addresses this limitation by analyzing and\ntransforming source code before execution. Built on the Jac compilation\nframework, GraphMend introduces two code transformations that remove graph\nbreaks due to dynamic control flow and Python I/O functions. This design allows\nPyTorch's compilation pipeline to capture larger, uninterrupted FX graphs\nwithout requiring manual refactoring by developers. Evaluation across eight\nHugging Face models shows that GraphMend removes all fixable graph breaks due\nto dynamic control flow and Python I/O functions, driving the break count to 0\nin 6 models and reducing it from 5 to 2 in another model. On NVIDIA RTX 3090\nand A40 GPUs, GraphMend achieves up to 75% latency reductions and up to 8%\nhigher end-to-end throughput. These results demonstrate that high-level code\ntransformation is an effective complement to PyTorch's dynamic JIT compilation\npipeline, substantially improving both usability and performance."}
{"id": "2509.17795", "pdf": "https://arxiv.org/pdf/2509.17795", "abs": "https://arxiv.org/abs/2509.17795", "authors": ["Parosh Aziz Abdulla", "Samuel Grahn", "Bengt Jonsson", "Shankaranarayanan Krishna", "Om Swostik Mishra"], "title": "Efficient Linearizability Monitoring", "categories": ["cs.PL"], "comment": null, "summary": "This paper revisits the fundamental problem of monitoring the linearizability\nof concurrent stacks, queues, sets, and multisets. Given a history of a library\nimplementing one of these abstract data types, the monitoring problem is to\nanswer whether the given history is linearizable. For stacks, queues, and\n(multi)sets, we present monitoring algorithms with complexities\n$\\mathcal{O}(n^2)$, $\\mathcal{O}(n\\; log\\, n)$, and $\\mathcal{O}{(n)}$,\nrespectively, where $n$ is the number of operations in the input history. For\nstacks and queues, our results hold under the standard assumption of {\\it\ndata-independence}, i.e., the behavior of the library is not sensitive to the\nactual values stored in the data structure. Past works to solve the same\nproblems have cubic time complexity and (more seriously) have correctness\nissues: they either (i) lack correctness proofs or (ii) the suggested\ncorrectness proofs are erroneous (we present counter-examples), or (iii) have\nincorrect algorithms. Our improved complexity results rely on substantially\ndifferent algorithms for which we provide detailed proofs of correctness. We\nhave implemented our stack and queue algorithms in LiMo (Linearizability\nMonitor). We evaluate LiMo and compare it with the state-of-the-art tool Violin\n-- whose correctness proofs we have found errors in -- which checks for\nlinearizability violations. Our experimental evaluation confirms that LiMo\noutperforms Violin regarding both efficiency and scalability."}
{"id": "2509.16205", "pdf": "https://arxiv.org/pdf/2509.16205", "abs": "https://arxiv.org/abs/2509.16205", "authors": ["Juhani Merilehto"], "title": "A 200-Line Python Micro-Benchmark Suite for NISQ Circuit Compilers", "categories": ["cs.ET", "cs.PL"], "comment": "9 pages, 1 figure. Includes reproducibility instructions and code\n  artifacts. Companion repository:\n  https://github.com/juhanimerilehto/microbench", "summary": "We present microbench.py, a compact (approx. 200 lines) Python script that\nautomates the collection of key compiler metrics, i.e., gate depth,\ntwo-qubit-gate count, wall-clock compilation time, and memory footprint, across\nmultiple open-source quantum circuit transpilers. The suite ships with six\ndidactic circuits (3 to 8 qubits) implementing fundamental quantum algorithms\nand supports Qiskit, tket, Cirq, and the Qiskit-Braket provider; in this paper\nwe showcase results for Qiskit 0.46 and Braket 1.16. The entire run completes\nin under three minutes on a laptop, emits a single CSV plus publisheable plot,\nand reproduces the figure here with one command. We release the code under the\nMIT licence to serve as a quick-start regression harness for NISQ compiler\nresearch."}
{"id": "2509.16215", "pdf": "https://arxiv.org/pdf/2509.16215", "abs": "https://arxiv.org/abs/2509.16215", "authors": ["Izavan dos S. Correia", "Henrique C. T. Santos", "Tiago A. E. Ferreira"], "title": "Discovering Software Parallelization Points Using Deep Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.NE", "cs.PL", "cs.SE"], "comment": "17 pages, 10 figures", "summary": "This study proposes a deep learning-based approach for discovering loops in\nprogramming code according to their potential for parallelization. Two genetic\nalgorithm-based code generators were developed to produce two distinct types of\ncode: (i) independent loops, which are parallelizable, and (ii) ambiguous\nloops, whose dependencies are unclear, making them impossible to define if the\nloop is parallelizable or not. The generated code snippets were tokenized and\npreprocessed to ensure a robust dataset. Two deep learning models - a Deep\nNeural Network (DNN) and a Convolutional Neural Network (CNN) - were\nimplemented to perform the classification. Based on 30 independent runs, a\nrobust statistical analysis was employed to verify the expected performance of\nboth models, DNN and CNN. The CNN showed a slightly higher mean performance,\nbut the two models had a similar variability. Experiments with varying dataset\nsizes highlighted the importance of data diversity for model performance. These\nresults demonstrate the feasibility of using deep learning to automate the\nidentification of parallelizable structures in code, offering a promising tool\nfor software optimization and performance improvement."}
{"id": "2509.16239", "pdf": "https://arxiv.org/pdf/2509.16239", "abs": "https://arxiv.org/abs/2509.16239", "authors": ["Jhet Chan"], "title": "GÃ¶del Mirror: A Formal System For Contradiction-Driven Recursion", "categories": ["cs.LO", "cs.PL", "03B70, 68Q42", "F.4.1; F.4.2; F.4.3; D.3.1"], "comment": "10 pages. Preprint submitted to Logical Methods in Computer Science\n  (LMCS)", "summary": "We introduce the G\\\"odel Mirror, a formal system defined in Lean 4 that\ntreats contradiction as a control signal for recursive structural evolution.\n  Inspired by G\\\"odelian self-reference, our system's operational semantics\nencode symbolic paradoxes as deterministic transitions. Unlike systems designed\nto guarantee normalization, the G\\\"odel Mirror is a minimal and verifiable\narchitecture that leverages a controlled, non-terminating loop as a productive\nfeature.\n  Our Lean 4 mechanization proves that self-referential paradoxes are\ndeterministically encapsulated and resolved into new structures without leading\nto logical explosion, yielding a paraconsistent inference loop: Paradox ->\nEncapsulate -> Reenter -> Node\n  We argue that this calculus opens a new class of symbolic systems in which\ncontradiction is metabolized into structure, providing a formal basis for\nagents capable of resolving internal inconsistencies."}
{"id": "2509.16241", "pdf": "https://arxiv.org/pdf/2509.16241", "abs": "https://arxiv.org/abs/2509.16241", "authors": ["Eishkaran Singh", "Tanav Singh Bajaj", "Siddharth Nayak"], "title": "REAMS: Reasoning Enhanced Algorithm for Maths Solving", "categories": ["cs.CL", "cs.AI", "cs.PL"], "comment": null, "summary": "The challenges of solving complex university-level mathematics problems,\nparticularly those from MIT, and Columbia University courses, and selected\ntasks from the MATH dataset, remain a significant obstacle in the field of\nartificial intelligence. Conventional methods have consistently fallen short in\nthis domain, highlighting the need for more advanced approaches. In this paper,\nwe introduce a language-based solution that leverages zero-shot learning and\nmathematical reasoning to effectively solve, explain, and generate solutions\nfor these advanced math problems. By integrating program synthesis, our method\nreduces reliance on large-scale training data while significantly improving\nproblem-solving accuracy. Our approach achieves an accuracy of 90.15%,\nrepresenting a substantial improvement over the previous benchmark of 81% and\nsetting a new standard in automated mathematical problem-solving. These\nfindings highlight the significant potential of advanced AI methodologies to\naddress and overcome the challenges presented by some of the most complex\nmathematical courses and datasets."}
{"id": "2509.16443", "pdf": "https://arxiv.org/pdf/2509.16443", "abs": "https://arxiv.org/abs/2509.16443", "authors": ["Ryan Tomich", "Zhizhen Zhong", "Dirk Englund"], "title": "LightCode: Compiling LLM Inference for Photonic-Electronic Systems", "categories": ["physics.app-ph", "cs.AI", "cs.PL"], "comment": "9 pages, 8 figures", "summary": "The growing demand for low-latency, energy-efficient inference in large\nlanguage models (LLMs) has catalyzed interest in heterogeneous architectures.\nWhile GPUs remain dominant, they are poorly suited for integration with\nemerging domain-specific accelerators like the Photonic Tensor Units (PTUs),\nwhich offer low-power, high-throughput linear computation. This motivates\nhybrid compilation strategies that combine photonic and electronic resources.\nWe present LightCode, a compiler framework and simulator for mapping LLM\ninference workloads across hybrid photonic-electronic systems. LightCode\nintroduces the Stacked Graph, an intermediate representation that encodes\nmultiple hardware-specific realizations of each tensor operation. Hardware\nassignment is formulated as a constrained subgraph selection problem optimized\nfor latency or energy under parametric cost models. We evaluate LightCode on\nthe prefill stage of GPT-2 and Llama-7B showing that under our workload and\nhardware assumptions, (i) Photonic hardware reduced energy by up to 50% in our\nsimulated workloads at maximum sequence length; (ii) multiplexing and\nassignment strategy yielded latency improvements exceeding 10x; and (iii)\nOptimizing for latency or energy resulted in distinct hardware mappings in our\nsimulations. LightCode offers a module, foundational framework and simulator\nfor compiling LLMs to emerging photonic accelerators."}
{"id": "2509.16497", "pdf": "https://arxiv.org/pdf/2509.16497", "abs": "https://arxiv.org/abs/2509.16497", "authors": ["Ange-Thierry Ishimwe", "Raghuveer Shivakumar", "Heewoo Kim", "Tamara Lehman", "Joseph Izraelevitz"], "title": "PrediPrune: Reducing Verification Overhead in Souper with Machine Learning Driven Pruning", "categories": ["cs.ET", "cs.PL", "cs.SE"], "comment": null, "summary": "Souper is a powerful enumerative superoptimizer that enhances the runtime\nperformance of programs by optimizing LLVM intermediate representation (IR)\ncode. However, its verification process, which relies on a computationally\nexpensive SMT solver to validate optimization candidates, must explore a large\nsearch space. This large search space makes the verification process\nparticularly expensive, increasing the burden to incorporate Souper into\ncompilation tools. We propose PrediPrune, a stochastic candidate pruning\nstrategy that effectively reduces the number of invalid candidates passed to\nthe SMT solver. By utilizing machine learning techniques to predict the\nvalidity of candidates based on features extracted from the code, PrediPrune\nprunes unlikely candidates early, decreasing the verification workload. When\ncombined with the state-of-the-art approach (Dataflow), PrediPrune decreases\ncompilation time by 51% compared to the Baseline and by 12% compared to using\nonly Dataflow, emphasizing the effectiveness of the combined approach that\nintegrates a purely ML-based method (PrediPrune) with a purely non-ML based\n(Dataflow) method. Additionally, PrediPrune offers a flexible interface to\ntrade-off compilation time and optimization opportunities, allowing end users\nto adjust the balance according to their needs."}
{"id": "2509.17343", "pdf": "https://arxiv.org/pdf/2509.17343", "abs": "https://arxiv.org/abs/2509.17343", "authors": ["Liyi Li", "Federico Zahariev", "Chandeepa Dissanayake", "Jae Swanepoel", "Amr Sabry", "Mark S. Gordon"], "title": "Quantum Simulation Programming via Typing", "categories": ["quant-ph", "cs.PL"], "comment": "Paper accepted to the Quantum Programming Languages (QPL) 2025\n  conference; available from: https://qpl2025.github.io/accepted/", "summary": "Quantum simulations are designed to model quantum systems, and many\ncompilation frameworks have been developed for executing such simulations on\nquantum computers. Most compilers leverage the capabilities of digital and\nanalog quantum computers by representing quantum particle systems with Pauli\nstrings or digital quantum circuits, making it challenging for users in\nphysics, chemistry, and biology to program simulations effectively. QBLUE is\nproposed as the first programming language for describing the behaviors of\nquantum systems in terms of second quantization Hamiltonians. Within QBLUE, a\nnovel type system is proposed to clearly define states across different quantum\nsystems and treat quantum computers as quantum particle systems of specific\ntypes. The type system is compatible with the compilation of quantum\nsimulations expressed in QBLUE for digital and analog quantum computers. With\nQBLUE, users can specify the desired quantum particle system and model the\nsystem on quantum computers."}
