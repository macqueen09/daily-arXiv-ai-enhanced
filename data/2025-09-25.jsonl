{"id": "2509.19607", "pdf": "https://arxiv.org/pdf/2509.19607", "abs": "https://arxiv.org/abs/2509.19607", "authors": ["William J. Bowman"], "title": "Macro-embedding Compiler Intermediate Languages in Racket", "categories": ["cs.PL"], "comment": null, "summary": "We present the design and implementation of a macro-embedding of a family of\ncompiler intermediate languages, from a Scheme-like language to x86-64, into\nRacket. This embedding is used as part of a testing framework for a compilers\ncourse to derive interpreters for all the intermediate languages. The embedding\nimplements features including safe, functional abstractions as well as unsafe\nassembly features, and the interactions between the two at various intermediate\nstages.\n  This paper aims to demonstrate language-oriented techniques and abstractions\nfor implementing (1) a large family of languages and (2) interoperability\nbetween low- and high-level languages. The primary strength of this approach is\nthe high degree of code reuse and interoperability compared to implementing\neach interpreter separately. The design emphasizes modularity and\ncompositionality of an open set of language features by local macro expansion\ninto a single host language, rather than implementing a language pre-defined by\na closed set of features. This enables reuse from both the host language\n(Racket) and between intermediate languages, and enables interoperability\nbetween high- and low-level features, simplifying development of the\nintermediate language semantics. It also facilitates extending or redefining\nindividual language features in intermediate languages, and exposing multiple\ninterfaces to the embedded languages."}
{"id": "2509.19613", "pdf": "https://arxiv.org/pdf/2509.19613", "abs": "https://arxiv.org/abs/2509.19613", "authors": ["William J. Bowman"], "title": "Compilation as Multi-Language Semantics", "categories": ["cs.PL"], "comment": null, "summary": "Modeling interoperability between programs in different languages is a key\nproblem when modeling verified and secure compilation, which has been\nsuccessfully addressed using multi-language semantics. Unfortunately, existing\nmodels of compilation using multi-language semantics define two variants of\neach compiler pass: a syntactic translation on open terms to model compilation,\nand a run-time translation of closed terms at multi-language boundaries to\nmodel interoperability.\n  In this talk, I discuss work-in-progress approach to uniformly model a\ncompiler entirely as a reduction system on open term in a multi-language\nsemantics, rather than as a syntactic translation. This simultaneously defines\nthe compiler and the interoperability semantics, reducing duplication. It also\nprovides interesting semantic insights. Normalization of the cross-language\nredexes performs ahead-of-time (AOT) compilation. Evaluation in the\nmulti-language models just-in-time (JIT) compilation. Confluence of\nmulti-language reduction implies compiler correctness, and part of the secure\ncompilation proof (full abstraction), enabling focus on the difficult part of\nthe proof. Subject reduction of the multi-language reduction implies\ntype-preservation of the compiler."}
{"id": "2509.20020", "pdf": "https://arxiv.org/pdf/2509.20020", "abs": "https://arxiv.org/abs/2509.20020", "authors": ["Maurice Wenig", "Paul G. Rump", "Mark Blacher", "Joachim Giesen"], "title": "The Syntax and Semantics of einsum", "categories": ["cs.PL", "cs.LG", "cs.MS", "cs.SC", "F.2.2; I.1.2; I.1.3"], "comment": "21 pages, 1 figure. Includes formal definitions, proofs of algebraic\n  properties, and nesting/denesting rules for the einsum notation", "summary": "In 2011, einsum was introduced to NumPy as a practical and convenient\nnotation for tensor expressions in machine learning, quantum circuit\nsimulation, and other fields. It has since been implemented in additional\nPython frameworks such as PyTorch and TensorFlow, as well as in other\nprogramming languages such as Julia. Despite its practical success, the einsum\nnotation still lacks a solid theoretical basis, and is not unified across the\ndifferent frameworks, limiting opportunities for formal reasoning and\nsystematic optimization. In this work, we discuss the terminology of tensor\nexpressions and provide a formal definition of the einsum language. Based on\nthis definition, we formalize and prove important equivalence rules for tensor\nexpressions and highlight their relevance in practical applications."}
{"id": "2509.19459", "pdf": "https://arxiv.org/pdf/2509.19459", "abs": "https://arxiv.org/abs/2509.19459", "authors": ["Yutong Guo", "Weiyu Luo", "Brian Demsky"], "title": "Automated Insertion of Flushes and Fences for Persistency", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "CXL shared memory and persistent memory allow the contents of memory to\npersist beyond crashes. Stores to persistent or CXL memory are typically not\nimmediately made persistent; developers must manually flush the corresponding\ncache lines to force the data to be written to the underlying storage.\nCorrectly using flush and fence operations is known to be challenging. While\nstate-of-the-art tools can find missing flush instructions, they often require\nbug-revealing test cases. No existing tools can ensure the absence of missing\nflush bugs.\n  In this paper, we present PMRobust, a compiler that automatically inserts\nflush and fence operations to ensure that code using persistent memory is free\nfrom missing flush and fence bugs. PMRobust employs a novel static analysis\nwith optimizations that target newly allocated objects. We have evaluated\nPMRobust on persistent memory libraries and several persistent memory data\nstructures and measured a geometric mean overhead of 0.26% relative to the\noriginal benchmarks with hand-placed flush and fence operations."}
