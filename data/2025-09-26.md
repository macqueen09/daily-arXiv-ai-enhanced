<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Dual-Language General-Purpose Self-Hosted Visual Language and new Textual Programming Language for Applications](https://arxiv.org/abs/2509.20426)
*Mahmoud Samir Fayed*

Main category: cs.PL

TL;DR: 开发了PWCT2，这是一个双语言（阿拉伯语/英语）、通用、自托管的可视化编程语言，通过使用Ring文本编程语言构建，实现了比前代PWCT快36倍的代码生成速度和20倍的存储效率提升。


<details>
  <summary>Details</summary>
Motivation: 大多数可视化编程语言都是领域特定的，而通用VPL如PWCT需要文本编程来改进。作者希望创建一个自托管的通用VPL，能够用自身来开发自身。

Method: 首先设计Ring文本编程语言，然后用PWCT开发Ring编译器，再基于Ring开发PWCT2。PWCT2包含92,000行Ring代码和394个可视化组件，支持将Ring代码转换为可视化代码。

Result: PWCT2代码生成速度快36倍，存储需求减少20倍。在Steam平台上有1772用户启动，总使用时间超过17,000小时，获得积极反馈。

Conclusion: 成功创建了自托管的通用可视化编程语言PWCT2，证明了用可视化语言开发自身是可行的，为未来研究开发提供了基础。

Abstract: Most visual programming languages (VPLs) are domain-specific, with few
general-purpose VPLs like Programming Without Coding Technology (PWCT). These
general-purpose VPLs are developed using textual programming languages and
improving them requires textual programming. In this thesis, we designed and
developed PWCT2, a dual-language (Arabic/English), general-purpose,
self-hosting visual programming language. Before doing so, we specifically
designed a textual programming language called Ring for its development. Ring
is a dynamically typed language with a lightweight implementation, offering
syntax customization features. It permits the creation of domain-specific
languages through new features that extend object-oriented programming,
allowing for specialized languages resembling Cascading Style Sheets (CSS) or
Supernova language. The Ring Compiler and Virtual Machine are designed using
the PWCT visual programming language where the visual implementation is
composed of 18,945 components that generate 24,743 lines of C code, which
increases the abstraction level and hides unnecessary details. Using PWCT to
develop Ring allowed us to realize several issues in PWCT, which led to the
development of the PWCT2 visual programming language using the Ring textual
programming language. PWCT2 provides approximately 36 times faster code
generation and requires 20 times less storage for visual source files. It also
allows for the conversion of Ring code into visual code, enabling the creation
of a self-hosting VPL that can be developed using itself. PWCT2 consists of
approximately 92,000 lines of Ring code and comes with 394 visual components.
PWCT2 is distributed to many users through the Steam platform and has received
positive feedback, On Steam, 1772 users have launched the software, and the
total recorded usage time exceeds 17,000 hours, encouraging further research
and development.

</details>


### [2] [Efficient Symbolic Computation vis Hash Consing](https://arxiv.org/abs/2509.20534)
*Bowen Zhu,Aayush Sabharwal,Songchen Tan,Yingbo Ma,Alan Edelman,Christopher Rackauckas*

Main category: cs.PL

TL;DR: 该论文将hash consing技术集成到JuliaSymbolics中，通过全局弱引用哈希表消除重复表达式存储，显著提升符号计算性能和内存效率。


<details>
  <summary>Details</summary>
Motivation: 符号计算系统存在内存效率低下的问题，结构相同的子表达式被重复存储（表达式膨胀），这降低了经典计算机代数和新兴AI驱动数学推理工具的性能。

Method: 在JuliaSymbolics中集成hash consing技术，使用全局弱引用哈希表对表达式进行规范化处理，消除重复存储。

Result: 基准测试显示显著改进：符号计算加速达3.2倍，内存使用减少达2倍，代码生成加速达5倍，函数编译加速达10倍，大型模型的数值评估加速达100倍。

Conclusion: hash consing对于扩展符号计算至关重要，为未来将hash consing与e-graphs集成以实现AI驱动管道中增强的等价感知表达式共享铺平了道路。

Abstract: Symbolic computation systems suffer from memory inefficiencies due to
redundant storage of structurally identical subexpressions, commonly known as
expression swell, which degrades performance in both classical computer algebra
and emerging AI-driven mathematical reasoning tools. In this paper, we present
the first integration of hash consing into JuliaSymbolics, a high-performance
symbolic toolkit in Julia, by employing a global weak-reference hash table that
canonicalizes expressions and eliminates duplication. This approach reduces
memory consumption and accelerates key operations such as differentiation,
simplification, and code generation, while seamlessly integrating with Julia's
metaprogramming and just-in-time compilation infrastructure. Benchmark
evaluations across different computational domains reveal substantial
improvements: symbolic computations are accelerated by up to 3.2 times, memory
usage is reduced by up to 2 times, code generation is up to 5 times faster,
function compilation up to 10 times faster, and numerical evaluation up to 100
times faster for larger models. While certain workloads with fewer duplicate
unknown-variable expressions show more modest gains or even slight overhead in
initial computation stages, downstream processing consistently benefits
significantly. These findings underscore the importance of hash consing in
scaling symbolic computation and pave the way for future work integrating hash
consing with e-graphs for enhanced equivalence-aware expression sharing in
AI-driven pipelines.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation](https://arxiv.org/abs/2509.20380)
*Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes*

Main category: cs.SE

TL;DR: ACCeLLiuM是专门为数据并行循环生成OpenACC指令而微调的两个开源大语言模型，显著提升了OpenACC指令生成的准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 随着GPU的普及，其硬件和并行编程框架日益复杂。虽然基于指令的并行编程标准如OpenACC在一定程度上简化了GPU编程，但有效使用这些指令仍需要相当的专业知识。

Method: 构建了包含4,033个OpenACC pragma-loop对的监督微调数据集，其中3,223对用于训练，810对用于测试。基于此数据集对LLM进行专门微调。

Result: 在测试集上，基础LLM无法一致生成有效的pragma，而微调后的LLM能够为87%的数据并行循环生成具有正确指令类型的有效pragma，其中50%的案例能够生成完全准确的pragma。

Conclusion: ACCeLLiuM显著降低了自动化GPU卸载的障碍，为LLM驱动的OpenACC pragma生成建立了可复现的基准，即使在不完全准确的情况下，生成的pragma也经常包含有用的额外子句，具有实际应用价值。

Abstract: The increasing ubiquity of GPUs is accompanied by the increasing complexity
of their hardware and parallel programming frameworks. Directive-based parallel
programming standards like OpenACC simplify GPU programming to some extent by
abstracting away low-level complexities, but a fair amount of expertise is
still required in order to use those directives effectively.
  We introduce ACCeLLiuM, two open weights Large Language Models specifically
fine-tuned for generating expert OpenACC directives for data-parallel loops,
along with the supervised fine-tuning dataset that was used to train them. The
ACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from
public GitHub C/C++ repositories, with 3,223 pairs for training and 810 for
testing. Experimental evaluations show a pronounced performance gap in
generating correct OpenACC pragmas between base LLMs and our fine-tuned
versions. On the held-out test set, base LLMs fail to consistently generate
valid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid
pragmas with the correct directive type for $87\%$ of the data-parallel loops,
and exact pragmas--including directives, clauses, clause order, and clause
variables--for $50\%$ of the cases. Even when not exact, generated pragmas
frequently incorporate the correct clauses in a different order than the
ground-truth label, or include additional clauses that enable finer control
over parallel execution, data movement, and concurrency, offering practical
value beyond strict string-matching. By publicly releasing the code, models,
and dataset as ACCeLLiuM we hope to establish a reproducible benchmark for
LLM-powered OpenACC pragma generation, and lower the barrier to automated GPU
offloading of serially written programs.

</details>


### [4] [Enhancing Python Programming Education with an AI-Powered Code Helper: Design, Implementation, and Impact](https://arxiv.org/abs/2509.20518)
*Sayed Mahbub Hasan Amiri,Md Mainul Islam*

Main category: cs.SE

TL;DR: 开发了一个基于AI-Python的聊天机器人，通过结合静态代码分析、动态执行追踪和大型语言模型，帮助学生学习编程，在错误解决、调试时间和编程能力提升方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统IDE和静态分析工具缺乏机器人辅助，而AI代码助手如GitHub Copilot主要关注代码完成而非教育。本研究旨在填补这一空白，开发一个专门用于编程教育的AI助手。

Method: 采用混合架构：使用CodeLlama进行代码嵌入，GPT-4处理自然语言交互，Docker沙箱确保安全执行。结合静态代码分析和动态执行追踪技术。

Result: 在1,500份学生提交的评估中，系统错误解决成功率达85%，优于pylint（62%）和GPT-4（73%）。调试时间减少59.3%，编程能力提升34%，特别是在递归和异常处理方面。

Conclusion: 该研究展示了AI如何增强人类教学，在编程教育中促进更深层次的概念理解，为优先考虑教育公平和长期技能保留的AI工具提供了蓝图。

Abstract: This is the study that presents an AI-Python-based chatbot that helps
students to learn programming by demonstrating solutions to such problems as
debugging errors, solving syntax problems or converting abstract theoretical
concepts to practical implementations. Traditional coding tools like Integrated
Development Environments (IDEs) and static analyzers do not give robotic help
while AI-driven code assistants such as GitHub Copilot focus on getting things
done. To close this gap, our chatbot combines static code analysis, dynamic
execution tracing, and large language models (LLMs) to provide the students
with relevant and practical advice, hence promoting the learning process. The
chatbots hybrid architecture employs CodeLlama for code embedding, GPT-4 for
natural language interactions, and Docker-based sandboxing for secure
execution. Evaluated through a mixed-methods approach involving 1,500 student
submissions, the system demonstrated an 85% error resolution success rate,
outperforming standalone tools like pylint (62%) and GPT-4 (73%). Quantitative
results revealed a 59.3% reduction in debugging time among users, with pre- and
post-test assessments showing a 34% improvement in coding proficiency,
particularly in recursion and exception handling. Qualitative feedback from 120
students highlighted the chatbots clarity, accessibility, and
confidence-building impact, though critiques included occasional latency and
restrictive code sanitization. By balancing technical innovation with
pedagogical empathy, this research provides a blueprint for AI tools that
prioritize educational equity and long-term skill retention over mere code
completion. The chatbot exemplifies how AI can augment human instruction,
fostering deeper conceptual understanding in programming education.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [5] [Mojo: MLIR-Based Performance-Portable HPC Science Kernels on GPUs for the Python Ecosystem](https://arxiv.org/abs/2509.21039)
*William F. Godoy,Tatiana Melnichenko,Pedro Valero-Lara,Wael Elwasif,Philip Fackler,Rafael Ferreira Da Silva,Keita Teranishi,Jeffrey S. Vetter*

Main category: cs.DC

TL;DR: 本文评估了Mojo语言在GPU上科学计算工作负载的性能和可移植性，比较了在NVIDIA H100和AMD MI300A GPU上与CUDA和HIP的性能表现


<details>
  <summary>Details</summary>
Motivation: Mojo作为首个基于LLVM MLIR编译器基础设施的语言，旨在通过结合Python的互操作性和类似CUDA的语法来缩小性能和生产力差距，实现编译时可移植的GPU编程

Method: 针对四种科学计算工作负载进行测试：七点模板（内存受限）、BabelStream（内存受限）、miniBUDE（计算受限）和Hartree-Fock（具有原子操作的计算受限），并与供应商基线进行比较

Result: Mojo在内存受限内核上的性能与CUDA和HIP相当，但在AMD GPU上的原子操作以及AMD和NVIDIA GPU上的快速数学计算受限内核存在性能差距

Conclusion: 尽管学习曲线和编程要求仍然相当底层，但Mojo可以在科学计算和AI融合的碎片化Python生态系统中缩小显著差距

Abstract: We explore the performance and portability of the novel Mojo language for
scientific computing workloads on GPUs. As the first language based on the
LLVM's Multi-Level Intermediate Representation (MLIR) compiler infrastructure,
Mojo aims to close performance and productivity gaps by combining Python's
interoperability and CUDA-like syntax for compile-time portable GPU
programming. We target four scientific workloads: a seven-point stencil
(memory-bound), BabelStream (memory-bound), miniBUDE (compute-bound), and
Hartree-Fock (compute-bound with atomic operations); and compare their
performance against vendor baselines on NVIDIA H100 and AMD MI300A GPUs. We
show that Mojo's performance is competitive with CUDA and HIP for memory-bound
kernels, whereas gaps exist on AMD GPUs for atomic operations and for fast-math
compute-bound kernels on both AMD and NVIDIA GPUs. Although the learning curve
and programming requirements are still fairly low-level, Mojo can close
significant gaps in the fragmented Python ecosystem in the convergence of
scientific computing and AI.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [6] [R1-Fuzz: Specializing Language Models for Textual Fuzzing via Reinforcement Learning](https://arxiv.org/abs/2509.20384)
*Jiayi Lin,Liangcai Su,Junzhe Li,Chenxiong Qian*

Main category: cs.CR

TL;DR: R1-Fuzz是一个利用强化学习专门化成本效益高的语言模型进行复杂文本模糊测试输入生成的框架，通过覆盖切片式问题构建和基于距离的奖励计算，使小型模型在真实世界模糊测试中媲美甚至超越更大模型。


<details>
  <summary>Details</summary>
Motivation: 针对编译器、解释器和数据库引擎等复杂目标的模糊测试面临输入需满足复杂语法语义约束的挑战，现有语言模型方法存在对深层程序逻辑探索不足和大型模型成本高的问题。

Method: 提出R1-Fuzz框架，采用强化学习后训练成本效益高的语言模型，包含覆盖切片式问题构建和基于距离的奖励计算两个关键设计，将语言模型紧密集成到模糊测试工作流中以推理深层程序语义。

Result: 在多样化真实世界目标上的评估显示，R1-Fuzz-7B小型模型能够媲美甚至超越更大模型，比最先进的模糊测试工具实现高达75%的覆盖率提升，并发现了29个先前未知的漏洞。

Conclusion: R1-Fuzz证明了通过强化学习专门化小型语言模型在复杂文本模糊测试中的实用性，为成本效益高的漏洞发现提供了有效解决方案。

Abstract: Fuzzing is effective for vulnerability discovery but struggles with complex
targets such as compilers, interpreters, and database engines, which accept
textual input that must satisfy intricate syntactic and semantic constraints.
Although language models (LMs) have attracted interest for this task due to
their vast latent knowledge and reasoning potential, their practical adoption
has been limited. The major challenges stem from insufficient exploration of
deep program logic among real-world codebases, and the high cost of leveraging
larger models. To overcome these challenges, we propose R1-Fuzz, the first
framework that leverages reinforcement learning (RL) to specialize
cost-efficient LMs and integrate them for complex textual fuzzing input
generation. R1-Fuzz introduces two key designs: coverage-slicing-based question
construction and a distance-based reward calculation. Through RL-based
post-training of a model with our constructed dataset, R1-Fuzz designs a
fuzzing workflow that tightly integrates LMs to reason deep program semantics
during fuzzing. Evaluations on diverse real-world targets show that our design
enables a small model, named R1-Fuzz-7B, to rival or even outperform much
larger models in real-world fuzzing. Notably, R1-Fuzz achieves up to 75\%
higher coverage than state-of-the-art fuzzers and discovers 29 previously
unknown vulnerabilities, demonstrating its practicality.

</details>
