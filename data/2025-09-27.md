<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Dual-Language General-Purpose Self-Hosted Visual Language and new Textual Programming Language for Applications](https://arxiv.org/abs/2509.20426)
*Mahmoud Samir Fayed*

Main category: cs.PL

TL;DR: 该论文介绍了PWCT2的开发，这是一个双语言（阿拉伯语/英语）、通用、自托管的可视化编程语言。通过先设计Ring文本编程语言，然后用PWCT开发Ring编译器，最终用Ring开发了改进的PWCT2，实现了自托管VPL。


<details>
  <summary>Details</summary>
Motivation: 现有的通用可视化编程语言（如PWCT）都是用文本编程语言开发的，改进它们需要文本编程。作者希望创建一个能够自我开发的可视化编程语言，实现真正的自托管。

Method: 1. 设计Ring文本编程语言（轻量级动态类型语言，支持语法定制）
2. 用PWCT开发Ring编译器和虚拟机（18,945个组件生成24,743行C代码）
3. 用Ring开发PWCT2可视化编程语言（92,000行Ring代码，394个可视化组件）

Result: PWCT2实现了36倍更快的代码生成速度，可视化源文件存储需求减少20倍。支持将Ring代码转换为可视化代码，实现自托管。在Steam平台上有1,772用户使用，总使用时间超过17,000小时。

Conclusion: 成功开发了自托管的通用可视化编程语言PWCT2，通过Ring和PWCT的协同开发，解决了VPL自我改进的难题，为可视化编程语言的发展提供了新方向。

Abstract: Most visual programming languages (VPLs) are domain-specific, with few
general-purpose VPLs like Programming Without Coding Technology (PWCT). These
general-purpose VPLs are developed using textual programming languages and
improving them requires textual programming. In this thesis, we designed and
developed PWCT2, a dual-language (Arabic/English), general-purpose,
self-hosting visual programming language. Before doing so, we specifically
designed a textual programming language called Ring for its development. Ring
is a dynamically typed language with a lightweight implementation, offering
syntax customization features. It permits the creation of domain-specific
languages through new features that extend object-oriented programming,
allowing for specialized languages resembling Cascading Style Sheets (CSS) or
Supernova language. The Ring Compiler and Virtual Machine are designed using
the PWCT visual programming language where the visual implementation is
composed of 18,945 components that generate 24,743 lines of C code, which
increases the abstraction level and hides unnecessary details. Using PWCT to
develop Ring allowed us to realize several issues in PWCT, which led to the
development of the PWCT2 visual programming language using the Ring textual
programming language. PWCT2 provides approximately 36 times faster code
generation and requires 20 times less storage for visual source files. It also
allows for the conversion of Ring code into visual code, enabling the creation
of a self-hosting VPL that can be developed using itself. PWCT2 consists of
approximately 92,000 lines of Ring code and comes with 394 visual components.
PWCT2 is distributed to many users through the Steam platform and has received
positive feedback, On Steam, 1772 users have launched the software, and the
total recorded usage time exceeds 17,000 hours, encouraging further research
and development.

</details>


### [2] [Efficient Symbolic Computation vis Hash Consing](https://arxiv.org/abs/2509.20534)
*Bowen Zhu,Aayush Sabharwal,Songchen Tan,Yingbo Ma,Alan Edelman,Christopher Rackauckas*

Main category: cs.PL

TL;DR: 本文首次将哈希一致性技术集成到JuliaSymbolics中，通过全局弱引用哈希表规范化表达式并消除重复，显著提升了符号计算的性能和内存效率。


<details>
  <summary>Details</summary>
Motivation: 符号计算系统存在内存效率低下的问题，由于结构相同的子表达式的冗余存储（称为表达式膨胀），这降低了经典计算机代数和新兴AI驱动数学推理工具的性能。

Method: 在JuliaSymbolics中集成哈希一致性技术，使用全局弱引用哈希表来规范化表达式并消除重复存储。

Result: 基准测试显示显著改进：符号计算加速达3.2倍，内存使用减少达2倍，代码生成加速达5倍，函数编译加速达10倍，大型模型的数值评估加速达100倍。

Conclusion: 哈希一致性对于扩展符号计算至关重要，为未来将哈希一致性与e-graphs集成以增强AI驱动管道中的等价感知表达式共享铺平了道路。

Abstract: Symbolic computation systems suffer from memory inefficiencies due to
redundant storage of structurally identical subexpressions, commonly known as
expression swell, which degrades performance in both classical computer algebra
and emerging AI-driven mathematical reasoning tools. In this paper, we present
the first integration of hash consing into JuliaSymbolics, a high-performance
symbolic toolkit in Julia, by employing a global weak-reference hash table that
canonicalizes expressions and eliminates duplication. This approach reduces
memory consumption and accelerates key operations such as differentiation,
simplification, and code generation, while seamlessly integrating with Julia's
metaprogramming and just-in-time compilation infrastructure. Benchmark
evaluations across different computational domains reveal substantial
improvements: symbolic computations are accelerated by up to 3.2 times, memory
usage is reduced by up to 2 times, code generation is up to 5 times faster,
function compilation up to 10 times faster, and numerical evaluation up to 100
times faster for larger models. While certain workloads with fewer duplicate
unknown-variable expressions show more modest gains or even slight overhead in
initial computation stages, downstream processing consistently benefits
significantly. These findings underscore the importance of hash consing in
scaling symbolic computation and pave the way for future work integrating hash
consing with e-graphs for enhanced equivalence-aware expression sharing in
AI-driven pipelines.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation](https://arxiv.org/abs/2509.20380)
*Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes*

Main category: cs.SE

TL;DR: ACCeLLiuM是专门为数据并行循环生成OpenACC指令的微调大语言模型，显著提升了OpenACC指令生成的准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: GPU硬件和并行编程框架日益复杂，虽然基于指令的并行编程标准如OpenACC简化了GPU编程，但仍需要专业知识才能有效使用这些指令。

Method: 开发了两个开源大语言模型，通过监督微调专门用于生成OpenACC指令，使用了从GitHub C/C++仓库挖掘的4,033个OpenACC pragma-loop对作为训练数据。

Result: 在测试集上，基础LLM无法一致生成有效指令，而微调后的模型能生成正确指令类型的pragma达87%，完全匹配的pragma达50%。即使不完全匹配，生成的指令也经常包含正确的子句和额外控制选项。

Conclusion: 通过公开代码、模型和数据集，ACCeLLiuM为LLM驱动的OpenACC指令生成建立了可复现的基准，降低了串行程序自动GPU卸载的门槛。

Abstract: The increasing ubiquity of GPUs is accompanied by the increasing complexity
of their hardware and parallel programming frameworks. Directive-based parallel
programming standards like OpenACC simplify GPU programming to some extent by
abstracting away low-level complexities, but a fair amount of expertise is
still required in order to use those directives effectively.
  We introduce ACCeLLiuM, two open weights Large Language Models specifically
fine-tuned for generating expert OpenACC directives for data-parallel loops,
along with the supervised fine-tuning dataset that was used to train them. The
ACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from
public GitHub C/C++ repositories, with 3,223 pairs for training and 810 for
testing. Experimental evaluations show a pronounced performance gap in
generating correct OpenACC pragmas between base LLMs and our fine-tuned
versions. On the held-out test set, base LLMs fail to consistently generate
valid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid
pragmas with the correct directive type for $87\%$ of the data-parallel loops,
and exact pragmas--including directives, clauses, clause order, and clause
variables--for $50\%$ of the cases. Even when not exact, generated pragmas
frequently incorporate the correct clauses in a different order than the
ground-truth label, or include additional clauses that enable finer control
over parallel execution, data movement, and concurrency, offering practical
value beyond strict string-matching. By publicly releasing the code, models,
and dataset as ACCeLLiuM we hope to establish a reproducible benchmark for
LLM-powered OpenACC pragma generation, and lower the barrier to automated GPU
offloading of serially written programs.

</details>


### [4] [Enhancing Python Programming Education with an AI-Powered Code Helper: Design, Implementation, and Impact](https://arxiv.org/abs/2509.20518)
*Sayed Mahbub Hasan Amiri,Md Mainul Islam*

Main category: cs.SE

TL;DR: 本文介绍了一个基于AI-Python的聊天机器人，旨在通过调试错误、解决语法问题和将抽象理论概念转化为实际实现来帮助学生学习编程。该系统结合静态代码分析、动态执行跟踪和大型语言模型，提供相关且实用的建议，促进学习过程。


<details>
  <summary>Details</summary>
Motivation: 传统的编码工具如集成开发环境（IDE）和静态分析器不提供机器人帮助，而AI驱动的代码助手如GitHub Copilot专注于完成任务。为了弥补这一差距，本研究开发了一个聊天机器人，结合多种技术为学生提供实用的学习支持。

Method: 聊天机器人采用混合架构，使用CodeLlama进行代码嵌入，GPT-4进行自然语言交互，以及基于Docker的沙箱进行安全执行。通过静态代码分析、动态执行跟踪和大型语言模型的结合，提供个性化的学习建议。

Result: 通过对1,500份学生提交的混合方法评估，系统展示了85%的错误解决成功率，优于pylint（62%）和GPT-4（73%）。定量结果显示用户调试时间减少了59.3%，前后测试评估显示编码熟练度提高了34%，特别是在递归和异常处理方面。

Conclusion: 本研究通过平衡技术创新与教学同理心，为AI工具提供了一个蓝图，优先考虑教育公平和长期技能保留，而不仅仅是代码完成。聊天机器人展示了AI如何增强人类教学，促进编程教育中更深层次的概念理解。

Abstract: This is the study that presents an AI-Python-based chatbot that helps
students to learn programming by demonstrating solutions to such problems as
debugging errors, solving syntax problems or converting abstract theoretical
concepts to practical implementations. Traditional coding tools like Integrated
Development Environments (IDEs) and static analyzers do not give robotic help
while AI-driven code assistants such as GitHub Copilot focus on getting things
done. To close this gap, our chatbot combines static code analysis, dynamic
execution tracing, and large language models (LLMs) to provide the students
with relevant and practical advice, hence promoting the learning process. The
chatbots hybrid architecture employs CodeLlama for code embedding, GPT-4 for
natural language interactions, and Docker-based sandboxing for secure
execution. Evaluated through a mixed-methods approach involving 1,500 student
submissions, the system demonstrated an 85% error resolution success rate,
outperforming standalone tools like pylint (62%) and GPT-4 (73%). Quantitative
results revealed a 59.3% reduction in debugging time among users, with pre- and
post-test assessments showing a 34% improvement in coding proficiency,
particularly in recursion and exception handling. Qualitative feedback from 120
students highlighted the chatbots clarity, accessibility, and
confidence-building impact, though critiques included occasional latency and
restrictive code sanitization. By balancing technical innovation with
pedagogical empathy, this research provides a blueprint for AI tools that
prioritize educational equity and long-term skill retention over mere code
completion. The chatbot exemplifies how AI can augment human instruction,
fostering deeper conceptual understanding in programming education.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [5] [R1-Fuzz: Specializing Language Models for Textual Fuzzing via Reinforcement Learning](https://arxiv.org/abs/2509.20384)
*Jiayi Lin,Liangcai Su,Junzhe Li,Chenxiong Qian*

Main category: cs.CR

TL;DR: R1-Fuzz是一个利用强化学习专门化成本效益高的语言模型进行复杂文本模糊测试输入生成的框架，通过覆盖切片式问题构建和基于距离的奖励计算，使小型模型在真实世界模糊测试中媲美甚至超越大型模型。


<details>
  <summary>Details</summary>
Motivation: 模糊测试在复杂目标（如编译器、解释器、数据库引擎）中效果有限，这些目标需要满足复杂语法和语义约束的文本输入。虽然语言模型具有潜力，但实际应用受到深层程序逻辑探索不足和大型模型成本高的限制。

Method: 提出R1-Fuzz框架，采用强化学习对成本效益高的语言模型进行专门化训练，包含覆盖切片式问题构建和基于距离的奖励计算两个关键设计，通过RL后训练实现模糊测试工作流与语言模型的紧密集成。

Result: 评估显示，R1-Fuzz-7B小型模型在真实世界模糊测试中能够媲美甚至超越大型模型，覆盖率达到最先进模糊测试工具的75%以上，并发现了29个先前未知的漏洞。

Conclusion: R1-Fuzz框架通过强化学习专门化小型语言模型，有效解决了复杂文本模糊测试的挑战，证明了其在真实世界应用中的实用性。

Abstract: Fuzzing is effective for vulnerability discovery but struggles with complex
targets such as compilers, interpreters, and database engines, which accept
textual input that must satisfy intricate syntactic and semantic constraints.
Although language models (LMs) have attracted interest for this task due to
their vast latent knowledge and reasoning potential, their practical adoption
has been limited. The major challenges stem from insufficient exploration of
deep program logic among real-world codebases, and the high cost of leveraging
larger models. To overcome these challenges, we propose R1-Fuzz, the first
framework that leverages reinforcement learning (RL) to specialize
cost-efficient LMs and integrate them for complex textual fuzzing input
generation. R1-Fuzz introduces two key designs: coverage-slicing-based question
construction and a distance-based reward calculation. Through RL-based
post-training of a model with our constructed dataset, R1-Fuzz designs a
fuzzing workflow that tightly integrates LMs to reason deep program semantics
during fuzzing. Evaluations on diverse real-world targets show that our design
enables a small model, named R1-Fuzz-7B, to rival or even outperform much
larger models in real-world fuzzing. Notably, R1-Fuzz achieves up to 75\%
higher coverage than state-of-the-art fuzzers and discovers 29 previously
unknown vulnerabilities, demonstrating its practicality.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [6] [Mojo: MLIR-Based Performance-Portable HPC Science Kernels on GPUs for the Python Ecosystem](https://arxiv.org/abs/2509.21039)
*William F. Godoy,Tatiana Melnichenko,Pedro Valero-Lara,Wael Elwasif,Philip Fackler,Rafael Ferreira Da Silva,Keita Teranishi,Jeffrey S. Vetter*

Main category: cs.DC

TL;DR: 评估Mojo语言在GPU上科学计算工作负载的性能和可移植性，与CUDA和HIP进行对比


<details>
  <summary>Details</summary>
Motivation: Mojo作为首个基于LLVM MLIR编译器基础设施的语言，旨在通过结合Python的互操作性和类CUDA语法来弥合性能和生产力差距，实现编译时便携的GPU编程

Method: 针对四种科学计算工作负载（七点模板、BabelStream、miniBUDE、Hartree-Fock）在NVIDIA H100和AMD MI300A GPU上测试Mojo性能，并与供应商基线对比

Result: Mojo在内存限制内核上的性能与CUDA和HIP相当，但在AMD GPU上的原子操作以及AMD和NVIDIA GPU上的快速数学计算限制内核存在差距

Conclusion: 虽然学习曲线和编程要求仍较低级，但Mojo可以在科学计算和AI融合的碎片化Python生态系统中弥合显著差距

Abstract: We explore the performance and portability of the novel Mojo language for
scientific computing workloads on GPUs. As the first language based on the
LLVM's Multi-Level Intermediate Representation (MLIR) compiler infrastructure,
Mojo aims to close performance and productivity gaps by combining Python's
interoperability and CUDA-like syntax for compile-time portable GPU
programming. We target four scientific workloads: a seven-point stencil
(memory-bound), BabelStream (memory-bound), miniBUDE (compute-bound), and
Hartree-Fock (compute-bound with atomic operations); and compare their
performance against vendor baselines on NVIDIA H100 and AMD MI300A GPUs. We
show that Mojo's performance is competitive with CUDA and HIP for memory-bound
kernels, whereas gaps exist on AMD GPUs for atomic operations and for fast-math
compute-bound kernels on both AMD and NVIDIA GPUs. Although the learning curve
and programming requirements are still fairly low-level, Mojo can close
significant gaps in the fragmented Python ecosystem in the convergence of
scientific computing and AI.

</details>
