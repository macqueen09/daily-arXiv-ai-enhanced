<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Dual-Language General-Purpose Self-Hosted Visual Language and new Textual Programming Language for Applications](https://arxiv.org/abs/2509.20426)
*Mahmoud Samir Fayed*

Main category: cs.PL

TL;DR: 开发了PWCT2，这是一个自托管的通用可视化编程语言，使用Ring文本编程语言开发，相比前代PWCT代码生成速度快36倍，存储需求减少20倍，并能实现Ring代码到可视化代码的转换。


<details>
  <summary>Details</summary>
Motivation: 现有通用可视化编程语言如PWCT使用文本编程语言开发，改进需要文本编程，限制了可视化编程语言的自举能力。

Method: 首先设计Ring文本编程语言，然后用PWCT开发Ring编译器，最后用Ring开发PWCT2可视化编程语言，实现自托管。

Result: PWCT2包含92,000行Ring代码和394个可视化组件，在Steam平台获得1772用户使用，总使用时间超过17,000小时。

Conclusion: 成功实现了自托管的可视化编程语言PWCT2，证明了可视化编程语言可以自我改进和开发，为未来研究提供了基础。

Abstract: Most visual programming languages (VPLs) are domain-specific, with few
general-purpose VPLs like Programming Without Coding Technology (PWCT). These
general-purpose VPLs are developed using textual programming languages and
improving them requires textual programming. In this thesis, we designed and
developed PWCT2, a dual-language (Arabic/English), general-purpose,
self-hosting visual programming language. Before doing so, we specifically
designed a textual programming language called Ring for its development. Ring
is a dynamically typed language with a lightweight implementation, offering
syntax customization features. It permits the creation of domain-specific
languages through new features that extend object-oriented programming,
allowing for specialized languages resembling Cascading Style Sheets (CSS) or
Supernova language. The Ring Compiler and Virtual Machine are designed using
the PWCT visual programming language where the visual implementation is
composed of 18,945 components that generate 24,743 lines of C code, which
increases the abstraction level and hides unnecessary details. Using PWCT to
develop Ring allowed us to realize several issues in PWCT, which led to the
development of the PWCT2 visual programming language using the Ring textual
programming language. PWCT2 provides approximately 36 times faster code
generation and requires 20 times less storage for visual source files. It also
allows for the conversion of Ring code into visual code, enabling the creation
of a self-hosting VPL that can be developed using itself. PWCT2 consists of
approximately 92,000 lines of Ring code and comes with 394 visual components.
PWCT2 is distributed to many users through the Steam platform and has received
positive feedback, On Steam, 1772 users have launched the software, and the
total recorded usage time exceeds 17,000 hours, encouraging further research
and development.

</details>


### [2] [Efficient Symbolic Computation vis Hash Consing](https://arxiv.org/abs/2509.20534)
*Bowen Zhu,Aayush Sabharwal,Songchen Tan,Yingbo Ma,Alan Edelman,Christopher Rackauckas*

Main category: cs.PL

TL;DR: 在JuliaSymbolics中首次集成哈希一致性技术，通过全局弱引用哈希表规范化表达式并消除重复，显著减少内存使用并加速关键操作


<details>
  <summary>Details</summary>
Motivation: 符号计算系统因存储结构相同的子表达式冗余而存在内存效率问题，这会影响经典计算机代数和新兴AI驱动数学推理工具的性能

Method: 在JuliaSymbolics中实现哈希一致性，使用全局弱引用哈希表来规范化表达式并消除重复存储

Result: 符号计算加速达3.2倍，内存使用减少达2倍，代码生成加速达5倍，函数编译加速达10倍，大型模型的数值评估加速达100倍

Conclusion: 哈希一致性对于扩展符号计算至关重要，为未来将哈希一致性与e-graphs集成以增强AI驱动管道中的等价感知表达式共享铺平了道路

Abstract: Symbolic computation systems suffer from memory inefficiencies due to
redundant storage of structurally identical subexpressions, commonly known as
expression swell, which degrades performance in both classical computer algebra
and emerging AI-driven mathematical reasoning tools. In this paper, we present
the first integration of hash consing into JuliaSymbolics, a high-performance
symbolic toolkit in Julia, by employing a global weak-reference hash table that
canonicalizes expressions and eliminates duplication. This approach reduces
memory consumption and accelerates key operations such as differentiation,
simplification, and code generation, while seamlessly integrating with Julia's
metaprogramming and just-in-time compilation infrastructure. Benchmark
evaluations across different computational domains reveal substantial
improvements: symbolic computations are accelerated by up to 3.2 times, memory
usage is reduced by up to 2 times, code generation is up to 5 times faster,
function compilation up to 10 times faster, and numerical evaluation up to 100
times faster for larger models. While certain workloads with fewer duplicate
unknown-variable expressions show more modest gains or even slight overhead in
initial computation stages, downstream processing consistently benefits
significantly. These findings underscore the importance of hash consing in
scaling symbolic computation and pave the way for future work integrating hash
consing with e-graphs for enhanced equivalence-aware expression sharing in
AI-driven pipelines.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation](https://arxiv.org/abs/2509.20380)
*Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes*

Main category: cs.SE

TL;DR: ACCeLLiuM是专门为生成OpenACC指令而微调的大型语言模型，显著提升了为数据并行循环生成正确OpenACC编译指示的能力。


<details>
  <summary>Details</summary>
Motivation: GPU硬件和并行编程框架日益复杂，虽然基于指令的编程标准如OpenACC简化了GPU编程，但仍需要相当的专业知识才能有效使用这些指令。

Method: 构建了包含4,033个OpenACC编译指示-循环对的监督微调数据集，并基于此训练了两个专门用于生成OpenACC指令的大型语言模型。

Result: 在测试集上，基础LLM无法一致生成有效编译指示，而微调后的模型能为87%的数据并行循环生成具有正确指令类型的有效编译指示，50%的情况下能生成完全准确的编译指示。

Conclusion: ACCeLLiuM显著降低了自动GPU卸载串行程序的障碍，为LLM驱动的OpenACC编译指示生成建立了可复现的基准。

Abstract: The increasing ubiquity of GPUs is accompanied by the increasing complexity
of their hardware and parallel programming frameworks. Directive-based parallel
programming standards like OpenACC simplify GPU programming to some extent by
abstracting away low-level complexities, but a fair amount of expertise is
still required in order to use those directives effectively.
  We introduce ACCeLLiuM, two open weights Large Language Models specifically
fine-tuned for generating expert OpenACC directives for data-parallel loops,
along with the supervised fine-tuning dataset that was used to train them. The
ACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from
public GitHub C/C++ repositories, with 3,223 pairs for training and 810 for
testing. Experimental evaluations show a pronounced performance gap in
generating correct OpenACC pragmas between base LLMs and our fine-tuned
versions. On the held-out test set, base LLMs fail to consistently generate
valid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid
pragmas with the correct directive type for $87\%$ of the data-parallel loops,
and exact pragmas--including directives, clauses, clause order, and clause
variables--for $50\%$ of the cases. Even when not exact, generated pragmas
frequently incorporate the correct clauses in a different order than the
ground-truth label, or include additional clauses that enable finer control
over parallel execution, data movement, and concurrency, offering practical
value beyond strict string-matching. By publicly releasing the code, models,
and dataset as ACCeLLiuM we hope to establish a reproducible benchmark for
LLM-powered OpenACC pragma generation, and lower the barrier to automated GPU
offloading of serially written programs.

</details>


### [4] [Enhancing Python Programming Education with an AI-Powered Code Helper: Design, Implementation, and Impact](https://arxiv.org/abs/2509.20518)
*Sayed Mahbub Hasan Amiri,Md Mainul Islam*

Main category: cs.SE

TL;DR: 开发了一个基于AI-Python的聊天机器人，通过结合静态代码分析、动态执行追踪和大型语言模型，帮助学生解决编程问题，提升学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统IDE和静态分析工具缺乏交互式指导，而现有AI代码助手如GitHub Copilot主要关注代码完成而非教育。需要开发一个能提供实际建议、促进学习过程的工具。

Method: 采用混合架构：使用CodeLlama进行代码嵌入，GPT-4处理自然语言交互，Docker沙盒实现安全执行。结合静态代码分析和动态执行追踪。

Result: 在1500份学生提交中达到85%的错误解决成功率，优于pylint(62%)和GPT-4(73%)。调试时间减少59.3%，编程能力提升34%，特别是在递归和异常处理方面。

Conclusion: 该研究展示了AI工具如何通过平衡技术创新与教学同理心，优先考虑教育公平和长期技能保留，而非仅仅完成代码，从而增强编程教育中的概念理解。

Abstract: This is the study that presents an AI-Python-based chatbot that helps
students to learn programming by demonstrating solutions to such problems as
debugging errors, solving syntax problems or converting abstract theoretical
concepts to practical implementations. Traditional coding tools like Integrated
Development Environments (IDEs) and static analyzers do not give robotic help
while AI-driven code assistants such as GitHub Copilot focus on getting things
done. To close this gap, our chatbot combines static code analysis, dynamic
execution tracing, and large language models (LLMs) to provide the students
with relevant and practical advice, hence promoting the learning process. The
chatbots hybrid architecture employs CodeLlama for code embedding, GPT-4 for
natural language interactions, and Docker-based sandboxing for secure
execution. Evaluated through a mixed-methods approach involving 1,500 student
submissions, the system demonstrated an 85% error resolution success rate,
outperforming standalone tools like pylint (62%) and GPT-4 (73%). Quantitative
results revealed a 59.3% reduction in debugging time among users, with pre- and
post-test assessments showing a 34% improvement in coding proficiency,
particularly in recursion and exception handling. Qualitative feedback from 120
students highlighted the chatbots clarity, accessibility, and
confidence-building impact, though critiques included occasional latency and
restrictive code sanitization. By balancing technical innovation with
pedagogical empathy, this research provides a blueprint for AI tools that
prioritize educational equity and long-term skill retention over mere code
completion. The chatbot exemplifies how AI can augment human instruction,
fostering deeper conceptual understanding in programming education.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [5] [R1-Fuzz: Specializing Language Models for Textual Fuzzing via Reinforcement Learning](https://arxiv.org/abs/2509.20384)
*Jiayi Lin,Liangcai Su,Junzhe Li,Chenxiong Qian*

Main category: cs.CR

TL;DR: R1-Fuzz是一个基于强化学习的框架，专门用于复杂文本输入模糊测试，通过训练小型语言模型来生成满足语法和语义约束的测试用例，在真实目标上实现了比现有方法更高的覆盖率和漏洞发现能力。


<details>
  <summary>Details</summary>
Motivation: 传统模糊测试在处理编译器、解释器等复杂目标时效果有限，这些目标需要满足复杂的语法和语义约束。虽然语言模型具有潜力，但实际应用受到深度程序逻辑探索不足和大型模型成本高昂的限制。

Method: 提出R1-Fuzz框架，使用强化学习专门化成本效益高的语言模型，包含两个关键设计：基于覆盖切片的问题构建和基于距离的奖励计算，通过RL后训练模型来推理深层程序语义。

Result: 评估显示，R1-Fuzz-7B小模型在真实世界模糊测试中能够匹敌甚至超越更大模型，比最先进的模糊测试器实现高达75%的覆盖率提升，并发现了29个先前未知的漏洞。

Conclusion: R1-Fuzz证明了通过强化学习专门化小型语言模型在复杂文本模糊测试中的实用性，为成本效益高的漏洞发现提供了可行方案。

Abstract: Fuzzing is effective for vulnerability discovery but struggles with complex
targets such as compilers, interpreters, and database engines, which accept
textual input that must satisfy intricate syntactic and semantic constraints.
Although language models (LMs) have attracted interest for this task due to
their vast latent knowledge and reasoning potential, their practical adoption
has been limited. The major challenges stem from insufficient exploration of
deep program logic among real-world codebases, and the high cost of leveraging
larger models. To overcome these challenges, we propose R1-Fuzz, the first
framework that leverages reinforcement learning (RL) to specialize
cost-efficient LMs and integrate them for complex textual fuzzing input
generation. R1-Fuzz introduces two key designs: coverage-slicing-based question
construction and a distance-based reward calculation. Through RL-based
post-training of a model with our constructed dataset, R1-Fuzz designs a
fuzzing workflow that tightly integrates LMs to reason deep program semantics
during fuzzing. Evaluations on diverse real-world targets show that our design
enables a small model, named R1-Fuzz-7B, to rival or even outperform much
larger models in real-world fuzzing. Notably, R1-Fuzz achieves up to 75\%
higher coverage than state-of-the-art fuzzers and discovers 29 previously
unknown vulnerabilities, demonstrating its practicality.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [6] [Mojo: MLIR-Based Performance-Portable HPC Science Kernels on GPUs for the Python Ecosystem](https://arxiv.org/abs/2509.21039)
*William F. Godoy,Tatiana Melnichenko,Pedro Valero-Lara,Wael Elwasif,Philip Fackler,Rafael Ferreira Da Silva,Keita Teranishi,Jeffrey S. Vetter*

Main category: cs.DC

TL;DR: 评估Mojo语言在GPU科学计算中的性能和可移植性，与CUDA和HIP对比，发现内存密集型任务性能相当，但原子操作和快速数学计算密集型任务存在差距


<details>
  <summary>Details</summary>
Motivation: 探索基于MLIR的Mojo语言能否在科学计算中弥合性能和生产力差距，结合Python互操作性和类CUDA语法实现可移植GPU编程

Method: 在NVIDIA H100和AMD MI300A GPU上测试四个科学计算负载：七点模板（内存密集型）、BabelStream（内存密集型）、miniBUDE（计算密集型）和Hartree-Fock（含原子操作的计算密集型），并与厂商基准对比

Result: Mojo在内存密集型内核上性能与CUDA和HIP相当，但在AMD GPU的原子操作以及AMD和NVIDIA GPU的快速数学计算密集型内核上存在性能差距

Conclusion: 虽然学习曲线和编程要求仍较底层，但Mojo能在科学计算与AI融合的碎片化Python生态中弥合重要差距

Abstract: We explore the performance and portability of the novel Mojo language for
scientific computing workloads on GPUs. As the first language based on the
LLVM's Multi-Level Intermediate Representation (MLIR) compiler infrastructure,
Mojo aims to close performance and productivity gaps by combining Python's
interoperability and CUDA-like syntax for compile-time portable GPU
programming. We target four scientific workloads: a seven-point stencil
(memory-bound), BabelStream (memory-bound), miniBUDE (compute-bound), and
Hartree-Fock (compute-bound with atomic operations); and compare their
performance against vendor baselines on NVIDIA H100 and AMD MI300A GPUs. We
show that Mojo's performance is competitive with CUDA and HIP for memory-bound
kernels, whereas gaps exist on AMD GPUs for atomic operations and for fast-math
compute-bound kernels on both AMD and NVIDIA GPUs. Although the learning curve
and programming requirements are still fairly low-level, Mojo can close
significant gaps in the fragmented Python ecosystem in the convergence of
scientific computing and AI.

</details>
