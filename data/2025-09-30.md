<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.CL](#cs.CL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Efficient Cost Bounds with Linear Maps](https://arxiv.org/abs/2509.22982)
*David M Kahn,Jan Hoffmann,Thomas Reps,Jessie Grosen*

Main category: cs.PL

TL;DR: 提出了一种使用线性映射表示成本无关类型的新方法，通过矩阵不等式解决成本边界推理问题，显著提高了类型推断效率


<details>
  <summary>Details</summary>
Motivation: 传统AARA方法中成本无关类型推断效率低下，且现有启发式方法仅适用于多项式成本边界，无法处理指数边界等问题

Method: 使用线性映射表示成本无关类型，通过矩阵不等式进行代数推理，利用现成的线性规划工具求解

Result: 原型实现表明，线性映射推断比现有最优算法效率呈指数级提升

Conclusion: 线性映射方法为成本边界分析提供了高效且通用的解决方案，特别适用于非多项式成本边界

Abstract: The Automatic Amortized Resource Analysis (AARA) derives program-execution
cost bounds using types. To do so, AARA often makes use of cost-free types,
which are critical for the composition of types and cost bounds. However,
inferring cost-free types using the current state-of-the-art algorithm is
expensive due to recursive dependence on additional cost-free types.
Furthermore, that algorithm uses a heuristic only applicable to polynomial cost
bounds, and not, e.g., exponential bounds. This paper presents a new approach
to these problems by representing the cost-free types of a function in a new
way: with a linear map, which can stand for infinitely many cost-free types.
Such maps enable an algebraic flavor of reasoning about cost bounds (including
non-polynomial bounds) via matrix inequalities. These inequalities can be
solved with off-the-shelf linear-programming tools for many programs, so that
types can always be efficiently checked and often be efficiently inferred. An
experimental evaluation with a prototype implementation shows that-when it is
applicable-the inference of linear maps is exponentially more efficient than
the state-of-the-art algorithm.

</details>


### [2] [Local Success Does Not Compose: Benchmarking Large Language Models for Compositional Formal Verification](https://arxiv.org/abs/2509.23061)
*Xu Xu,Xin Li,Xingwei Qu,Jie Fu,Binhang Yuan*

Main category: cs.PL

TL;DR: DafnyCOMP是一个用于评估大型语言模型在Dafny组合式规范生成能力的基准测试，包含300个自动合成的多函数程序，显示LLM在组合任务上表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注单函数任务，缺乏对多函数交互和数据依赖的组合式规范生成的评估，需要跨组件边界的推理能力。

Method: 构建包含300个自动合成的多函数程序的基准测试DafnyCOMP，评估多个最先进的LLM家族在组合式规范生成任务上的表现。

Result: LLM在单函数验证上表现良好，但在组合任务上性能急剧下降，分析显示存在跨函数推理的系统性失败，包括脆弱规范、实现与证明不对齐和不稳定推理。

Conclusion: DafnyCOMP提供了一个诊断工具，用于衡量LLM在可靠、可验证和组合式代码生成方面的进展。

Abstract: We introduce DafnyCOMP, a benchmark for evaluating large language models
(LLMs) on compositional specification generation in Dafny. Unlike prior
benchmarks that focus on single-function tasks, DafnyCOMP targets programs
composed of multiple interacting functions with data dependencies, requiring
reasoning across component boundaries. The benchmark consists of 300
automatically synthesized multi-function programs. We evaluate several
state-of-the-art LLM families and find that, while they perform well on
single-function verification, their performance drops sharply on compositional
tasks. Analysis reveals systematic failures in cross-functional reasoning,
including fragile specifications, misalignment between implementations and
proofs, and unstable reasoning. DafnyCOMP thus provides a diagnostic tool for
measuring progress toward reliable, verifiable, and compositional code
generation with LLMs.

</details>


### [3] [Fine-Grained Reasoning About Container-Internal Pointers with Logical Pinning](https://arxiv.org/abs/2509.23229)
*Yawen Guan,Clément Pit-Claudel*

Main category: cs.PL

TL;DR: 提出逻辑固定（logical pinning）方法，允许在分离逻辑中跟踪容器内部指针，解决传统方法难以验证暴露内部指针的容器API的问题。


<details>
  <summary>Details</summary>
Motivation: 传统分离逻辑隐藏容器内部指针以实现模块化，但这使得难以指定和验证那些临时暴露内部指针的容器API。

Method: 基于轻量级借用模型，推广魔术棒操作符，允许在逻辑层面选择性跟踪容器内部指针，仅改变表示谓词和规范的编写方式。

Result: 验证了具有代表性的指针操作程序，推导出更精确的容器规范，能够涵盖已知证明模式、简化复杂证明，并支持传统规范无法处理的程序模式。

Conclusion: 逻辑固定方法实用且兼容大多数分离逻辑变体，在Rocq证明助手中通过CFML库进行了机械化验证。

Abstract: Most separation logics hide container-internal pointers for modularity. This
makes it difficult to specify container APIs that temporarily expose those
pointers to the outside, and to verify programs that use these APIs. We present
logical pinning, a lightweight borrowing model for sequential programs that
allows users to selectively track container-internal pointers at the logical
level. Our model generalizes the magic-wand operator, making it easy to write
and prove precise specifications, including pointer-stability properties.
Because it only changes how representation predicates and specifications are
written, our approach is compatible with most separation logic variants. We
demonstrate the practicality of logical pinning by verifying small but
representative pointer-manipulating programs, and deriving more precise
versions of common container specifications. In doing so, we show that our
approach subsumes some well-known proof patterns, simplifies some complex
proofs, and enables reasoning about program patterns not supported by
traditional specifications. All of our results are mechanized in the Rocq proof
assistant, using the CFML library.

</details>


### [4] [From Affine to Polynomial: Synthesizing Loops with Branches via Algebraic Geometry](https://arxiv.org/abs/2509.25114)
*Erdenebayar Bayarmagnai,Fatemeh Mohammadi,Rémi Prébet*

Main category: cs.PL

TL;DR: 本文提出了一种从多项式不变量合成循环程序的新方法，支持具有多项式更新映射、不等式守卫条件和任意形式多项式不变量的循环。


<details>
  <summary>Details</summary>
Motivation: 现有方法只能从多项式不变量合成无守卫条件的仿射循环，而实际程序通常包含更复杂的循环结构，因此需要更通用的合成方法。

Method: 使用代数几何工具设计算法，生成多项式方程组，其解对应满足给定不变量的所有非确定性分支循环。对于特定不变量类，提出了更高效的算法。

Result: 实现了将循环合成问题转化为有理数域上多元多项式系统求解问题，并通过SMT求解器处理最终求解步骤。

Conclusion: 该方法扩展了循环合成的适用范围，能够处理更复杂的循环结构，为程序验证提供了更强大的工具。

Abstract: Ensuring software correctness remains a fundamental challenge in formal
program verification. One promising approach relies on finding polynomial
invariants for loops. Polynomial invariants are properties of a program loop
that hold before and after each iteration. Generating such invariants is a
crucial task in loop analysis, but it is undecidable in the general case.
Recently, an alternative approach to this problem has emerged, focusing on
synthesizing loops from invariants. However, existing methods only synthesize
affine loops without guard conditions from polynomial invariants. In this
paper, we address a more general problem, allowing loops to have polynomial
update maps with a given structure, inequations in the guard condition, and
polynomial invariants of arbitrary form.
  We use algebraic geometry tools to design and implement an algorithm that
computes a finite set of polynomial equations whose solutions correspond to all
nondeterministic branching loops satisfying the given invariants. Furthermore,
we introduce a new class of invariants for which we present a significantly
more efficient algorithm. In other words, we reduce the problem of synthesizing
loops to find solutions of multivariate polynomial systems with rational
entries. This final step is handled in our software using an SMT solver.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [A benchmark for vericoding: formally verified program synthesis](https://arxiv.org/abs/2509.22908)
*Sergiu Bursuc,Theodore Ehrenborg,Shaowei Lin,Lacramioara Astefanoaei,Ionel Emilian Chiosa,Jure Kukovec,Alok Singh,Oliver Butterley,Adem Bizid,Quinn Dougherty,Miranda Zhao,Max Tan,Max Tegmark*

Main category: cs.SE

TL;DR: 本文提出了最大的验证编码基准测试，包含12,504个形式规范，在Dafny、Verus/Rust和Lean三种语言中测试LLM生成形式验证代码的能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统自然语言编程可能产生错误代码的问题，建立形式化验证代码生成的基准测试。

Method: 使用12,504个形式规范（其中6,174个是新问题），在Dafny、Verus/Rust和Lean三种语言中测试现成LLM的验证编码能力。

Result: 验证编码成功率：Lean 27%、Verus/Rust 44%、Dafny 82%。添加自然语言描述不会显著提升性能。Dafny验证在一年内从68%提升到96%。

Conclusion: 验证编码是可行的，不同语言表现差异显著，Dafny表现最佳，LLM在形式验证方面进步迅速。

Abstract: We present and test the largest benchmark for vericoding, LLM-generation of
formally verified code from formal specifications - in contrast to vibe coding,
which generates potentially buggy code from a natural language description. Our
benchmark contains 12,504 formal specifications, with 3,029 in Dafny, 2,334 in
Verus/Rust and 7,141 in Lean. Of these, 6,174 are new unseen problems. We find
vericoding success rates of 27% in Lean, 44% in Verus/Rust and 82% in Dafny
using off-the-shelf LLMs. Adding natural-language descriptions does not
significantly improve performance. We also find that LLM progress has improved
progress on pure Dafny verification from 68% to 96% over the past year. The
benchmark and vericoding results are shared at
https://github.com/Beneficial-AI-Foundation/vericoding-benchmark

</details>


### [6] [Agentic Specification Generator for Move Programs](https://arxiv.org/abs/2509.24515)
*Yu-Fu Fu,Meng Xu,Taesoo Kim*

Main category: cs.SE

TL;DR: MSG是一个为Move智能合约设计的自动化规范生成工具，展示了LLM在非主流编程语言中的强大代码理解和生成能力，能够为84%的测试函数生成可验证规范，并通过模块化设计和验证工具链反馈显著提升规范质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的规范生成工具主要关注主流编程语言（如C、Java、Solidity），而忽略了新兴且面向验证的语言如Move。MSG旨在探索将LLM应用于新生态系统时的独特见解。

Method: 采用基于代理的模块化设计，明确利用规范语言特性，并整合验证工具链的反馈机制。

Result: MSG成功为84%的测试Move函数生成可验证规范，甚至发现了专家忽略的条款。模块化设计比传统设计多生成57%的可验证条款，整合验证工具链反馈后使可验证规范数量增加30%。

Conclusion: LLM在非主流语言中仍表现出强大的代码理解和生成能力，通过模块化设计和验证工具链反馈可以显著提升规范生成质量，为新兴编程语言的规范生成提供了有效解决方案。

Abstract: While LLM-based specification generation is gaining traction, existing tools
primarily focus on mainstream programming languages like C, Java, and even
Solidity, leaving emerging and yet verification-oriented languages like Move
underexplored. In this paper, we introduce MSG, an automated specification
generation tool designed for Move smart contracts. MSG aims to highlight key
insights that uniquely present when applying LLM-based specification generation
to a new ecosystem. Specifically, MSG demonstrates that LLMs exhibit robust
code comprehension and generation capabilities even for non-mainstream
languages. MSG successfully generates verifiable specifications for 84% of
tested Move functions and even identifies clauses previously overlooked by
experts. Additionally, MSG shows that explicitly leveraging specification
language features through an agentic, modular design improves specification
quality substantially (generating 57% more verifiable clauses than conventional
designs). Incorporating feedback from the verification toolchain further
enhances the effectiveness of MSG, leading to a 30% increase in generated
verifiable specifications.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [7] [TF-Bench: Evaluating Program Semantics Reasoning with Type Inference in System F](https://arxiv.org/abs/2509.23686)
*Yifeng He,Luning Yang,Christopher Castro Gaw Gonzalo,Hao Chen*

Main category: cs.CL

TL;DR: TF-Bench是一个基于System F类型推断的基准测试，用于评估LLM的程序语义推理能力，通过去除语义无关的自然语言构建纯语义版本TF-Bench_pure，揭示了当前最先进LLM在程序语义推理方面的严重局限性。


<details>
  <summary>Details</summary>
Motivation: 当前代码推理基准缺乏正式的程序中心演绎框架，无法评估模型是否真正理解程序语义还是仅利用自然语言和代码标记之间的表面关联。

Method: 基于System F类型推断构建TF-Bench基准，通过验证转换去除语义无关的自然语言创建TF-Bench_pure纯语义版本，并提出两个新指标评估鲁棒性和测试时推理效果。

Result: 最先进的LLM（Claude-3.7-sonnet）在TF-Bench_pure上仅达到55.85%的准确率，显示出严重的能力限制。

Conclusion: 当前LLM在程序语义推理方面存在重大缺陷，需要未来研究重点关注和改进。

Abstract: Large Language Models (LLMs) are increasingly integrated into the software
engineering ecosystem. Their test-time compute (TTC) reasoning capabilities
show significant potential for understanding program logic and semantics beyond
mere token recognition. However, current benchmarks for code reasoning lack a
formal, program-centric deductive framework to ensure sound evaluation, and are
incapable of assessing whether models genuinely reason about program semantics
or merely exploit superficial associations between natural language and code
tokens. To bridge this gap, we introduce TF-Bench, a benchmark designed to
evaluate LLM reasoning based on type inference in System F, a task we refer to
as program semantics reasoning. By employing verified transformations to remove
semantically irrelevant natural language, we construct TF-Bench_pure, a purely
semantics-driven variant of TF-Bench. Our analysis reveals substantial
limitations in state-of-the-art LLMs, with the best-performing LLM
(Claude-3.7-sonnet) achieving only 55.85% accuracy on TF-Bench_pure.
Additionally, we propose two novel metrics to assess robustness and the
effectiveness of test-time reasoning, underscoring critical limitations in
current LLM capabilities and highlighting essential directions for future
research.

</details>
