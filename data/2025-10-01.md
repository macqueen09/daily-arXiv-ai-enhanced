<div id=toc></div>

# Table of Contents

- [cs.SE](#cs.SE) [Total: 4]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [1] [APRIL: API Synthesis with Automatic Prompt Optimization and Reinforcement Learning](https://arxiv.org/abs/2509.25196)
*Hua Zhong,Shan Jiang,Sarfraz Khurshid*

Main category: cs.SE

TL;DR: APRIL结合LLM合成、自动提示优化(APO)和基于可验证奖励的强化学习(RLVR)，显著提升了大型库中API合成的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统组件合成方法搜索空间大且依赖人工规范，而LLM生成代码存在幻觉和上下文信息不足的问题，需要更可靠的API合成方案。

Method: 使用APO迭代优化提示，同时通过RLVR对策略进行微调以实现功能正确性，构建高效合成流水线。

Result: 在81个真实API上评估，相比专家提示指导的未微调LLM，APRIL取得显著改进。

Conclusion: APO和RLVR的集成为大型库中的组件式API合成提供了稳健、可扩展的路径。

Abstract: APIs are central to modern software development, yet composing new APIs from
large libraries is difficult due to the exponential search space; traditional
component-based synthesis relies on costly exploration and hand-crafted
specifications. While large language models (LLMs) can generate implementations
from natural language, hallucinations and limited access to up-to-date
contextual information often yield incorrect code. In this paper, we present
APRIL, an approach that combines LLM-based synthesis with Automatic Prompt
Optimization (APO) and Reinforcement Learning from Verifiable Rewards (RLVR):
APO iteratively refines prompts for a frozen model, while RLVR fine-tunes the
policy toward functional correctness, producing an efficient synthesis
pipeline. Evaluated on 81 real-world APIs from widely used scientific Python
libraries and benchmarked against instruction-tuned but unfine-tuned LLMs
guided by expert prompts, APRIL achieves substantial improvements. These
results indicate that integrating APO and RLVR provides a robust, scalable path
for component-based API synthesis in large libraries.

</details>


### [2] [Towards Repository-Level Program Verification with Large Language Models](https://arxiv.org/abs/2509.25197)
*Si Cheng Zhong,Xujie Si*

Main category: cs.SE

TL;DR: RVBench是首个针对仓库级验证的基准，RagVerus框架结合检索增强生成和上下文感知提示，显著提升了多模块仓库的证明合成能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM方法主要关注孤立的函数级验证任务，忽略了跨模块依赖和全局上下文等关键挑战，难以扩展到真实世界项目的自动化形式验证。

Method: 引入RVBench仓库级验证基准，并开发RagVerus框架，该框架结合检索增强生成和上下文感知提示来自动化多模块仓库的证明合成。

Result: RagVerus在受限模型推理预算下，将现有基准的证明通过率提高了三倍，在更具挑战性的RVBench基准上实现了27%的相对改进。

Conclusion: RagVerus提供了一个可扩展且样本高效的验证解决方案，能够有效处理仓库级的形式验证挑战。

Abstract: Recent advancements in large language models (LLMs) suggest great promises in
code and proof generations. However, scaling automated formal verification to
real-world projects requires resolving cross-module dependencies and global
contexts, which are crucial challenges overlooked by existing LLM-based methods
with a special focus on targeting isolated, function-level verification tasks.
To systematically explore and address the significant challenges of verifying
entire software repositories, we introduce RVBench, the first verification
benchmark explicitly designed for repository-level evaluation, constructed from
four diverse and complex open-source Verus projects.
  We further introduce RagVerus, an extensible framework that synergizes
retrieval-augmented generation with context-aware prompting to automate proof
synthesis for multi-module repositories. RagVerus triples proof pass rates on
existing benchmarks under constrained model inference budgets, and achieves a
27% relative improvement on the more challenging RVBench benchmark,
demonstrating a scalable and sample-efficient verification solution.

</details>


### [3] [BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software](https://arxiv.org/abs/2509.25248)
*Zehua Zhang,Ati Priya Bajaj,Divij Handa,Siyu Liu,Arvind S Raj,Hongkai Chen,Hulin Wang,Yibo Liu,Zion Leonahenahe Basque,Souradip Nath,Vishal Juneja,Nikhil Chapre,Yan Shoshitaishvili,Adam Doupé,Chitta Baral,Ruoyu Wang*

Main category: cs.SE

TL;DR: 提出了一个更真实和具有挑战性的开源软件编译基准BUILD-BENCH，以及一个基于LLM的智能体OSS-BUILD-AGENT，该系统在BUILD-BENCH上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的开源软件编译方法依赖手动制定的规则和工作流，无法适应需要定制配置或环境设置的开源软件。最近使用大语言模型的尝试只对高评分开源软件子集进行评估，低估了真实编译挑战。

Method: 提出了OSS-BUILD-AGENT智能体系统，具有增强的构建指令检索模块，能够适应异构开源软件特性。

Result: OSS-BUILD-AGENT在BUILD-BENCH基准上实现了最先进的性能，并提供了不同编译方法设计选择及其对整体任务影响的详细分析。

Conclusion: BUILD-BENCH的性能能够真实反映智能体处理复杂软件工程任务的能力，该基准将推动软件开发和软件安全领域的创新。

Abstract: Automatically compiling open-source software (OSS) projects is a vital,
labor-intensive, and complex task, which makes it a good challenge for LLM
Agents. Existing methods rely on manually curated rules and workflows, which
cannot adapt to OSS that requires customized configuration or environment
setup. Recent attempts using Large Language Models (LLMs) used selective
evaluation on a subset of highly rated OSS, a practice that underestimates the
realistic challenges of OSS compilation. In practice, compilation instructions
are often absent, dependencies are undocumented, and successful builds may even
require patching source files or modifying build scripts. We propose a more
challenging and realistic benchmark, BUILD-BENCH, comprising OSS that are more
diverse in quality, scale, and characteristics. Furthermore, we propose a
strong baseline LLM-based agent, OSS-BUILD-AGENT, an effective system with
enhanced build instruction retrieval module that achieves state-of-the-art
performance on BUILD-BENCH and is adaptable to heterogeneous OSS
characteristics. We also provide detailed analysis regarding different
compilation method design choices and their influence to the whole task,
offering insights to guide future advances. We believe performance on
BUILD-BENCH can faithfully reflect an agent's ability to tackle compilation as
a complex software engineering tasks, and, as such, our benchmark will spur
innovation with a significant impact on downstream applications in the fields
of software development and software security.

</details>


### [4] [Black-box Context-free Grammar Inference for Readable & Natural Grammars](https://arxiv.org/abs/2509.26616)
*Mohammad Rifat Arefin,Shanto Rahman,Christoph Csallner*

Main category: cs.SE

TL;DR: NatGI是一个基于LLM引导的语法推断框架，通过括号引导的探索、LLM驱动的语法片段生成和层次化delta调试，显著提升了黑盒上下文无关语法推断的准确性、可扩展性和可读性。


<details>
  <summary>Details</summary>
Motivation: 现有的语法推断工具（如Arvada、TreeVada、Kedavra）在处理大型复杂语言时存在可扩展性、可读性和准确性不足的问题。

Method: 1. 括号引导的语法片段探索：利用括号等语法线索提出结构良好的语法片段
2. LLM驱动的语法片段生成和非终端标签：生成有意义的非终端名称并选择更有前景的合并
3. 层次化delta调试：系统性地简化语法树，减少不必要的规则

Result: 在从小型语言到大型语言（如lua、c、mysql）的综合基准测试中，NatGI平均F1分数达到0.57，比最佳基线TreeVada高出25个百分点，在可解释性方面显著优于现有方法。

Conclusion: NatGI通过LLM引导的方法在保持高准确性的同时，生成了更紧凑、可解释的语法规则，使开发者和研究人员能够轻松检查、验证和理解推断出的语法结构和语义。

Abstract: Black-box context-free grammar inference is crucial for program analysis,
reverse engineering, and security, yet existing tools such as Arvada, TreeVada,
and Kedavra struggle with scalability, readability, and accuracy on large,
complex languages. We present NatGI, a novel LLM-guided grammar inference
framework that extends TreeVada's parse tree recovery with three key
innovations: bracket-guided bubble exploration, LLM-driven bubble generation
and non-terminal labeling, and hierarchical delta debugging (HDD) for
systematic tree simplification. Bracket-guided exploration leverages syntactic
cues such as parentheses to propose well-structured grammar fragments, while
LLM guidance produces meaningful non-terminal names and selects more promising
merges. Finally, HDD incrementally reduces unnecessary rules, which makes the
grammars both compact and interpretable. In our experiments, we evaluate NatGI
on a comprehensive benchmark suite ranging from small languages to larger ones
such as lua, c, and mysql. Our results show that NatGI consistently outperforms
strong baselines in terms of F1 score. On average, NatGI achieves an F1 score
of 0.57, which is 25pp (percentage points) higher than the best-performing
baseline, TreeVada. In the case of interpretability, our generated grammars
perform significantly better than those produced by existing approaches.
Leveraging LLM-based node renaming and bubble exploration, NatGI produces rules
with meaningful non-terminal names and compact structures that align more
closely with human intuition. As a result, developers and researchers can
achieve higher accuracy while still being able to easily inspect, verify, and
reason about the structure and semantics of the induced grammars.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [5] [Monoid Structures on Indexed Containers](https://arxiv.org/abs/2509.25879)
*Michele De Pascalis,Tarmo Uustalu,Niccolò Veltrì*

Main category: cs.LO

TL;DR: 本文研究了索引容器的幺半群结构，给出了该幺半范畴中幺半元的组合特征，并证明这些幺半元精确对应于Set^I上诱导自函子的单子。


<details>
  <summary>Details</summary>
Motivation: 为了更好地适应依赖类型编程的范围，索引容器推广了容器的概念。研究索引容器的幺半群结构有助于理解单子的组合性质。

Method: 考虑I-索引容器范畴的幺半群结构，其中张量积描述相应诱导自函子的复合。给出该幺半范畴中幺半元的组合特征化。

Result: 证明了这些幺半元精确对应于Set^I上诱导自函子的单子，并提供了包括两个单子的积、状态和writer单子的索引变体以及自由单子等实例。

Conclusion: 索引容器的幺半群结构为理解单子的组合提供了新的视角，结果在Cubical Agda中进行了形式化验证。

Abstract: Containers represent a wide class of type constructions relevant for
functional programming and (co)inductive reasoning. Indexed containers
generalize this notion to better fit the scope of dependently typed
programming. When interpreting types to be sets, a container describes an
endofunctor on the category of sets while an I-indexed container describes an
endofunctor on the category Set^I of I-indexed families of sets.
  We consider the monoidal structure on the category of I-indexed containers
whose tensor product of containers describes the composition of the respective
induced endofunctors. We then give a combinatorial characterization of monoids
in this monoidal category, and we show how these monoids correspond precisely
to monads on the induced endofunctors on Set^I. Lastly, we conclude by
presenting some examples of monads on Set^I that fall under our
characterization, including the product of two monads, indexed variants of the
state and the writer monads and an example of a free monad. The technical
results of this work are accompanied by a formalization in the proof assistant
Cubical Agda.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [Lita: Light Agent Uncovers the Agentic Coding Capabilities of LLMs](https://arxiv.org/abs/2509.25873)
*Hankun Dai,Maoquan Wang,Mengnan Qi,Yikai Zhang,Zijian Jin,Yongqiang Yao,Yufan Huang,Shengyu Fu,Elsie Nallipogu*

Main category: cs.AI

TL;DR: Lita (Lite Agent) 是一个轻量级代码代理框架，通过最小化手动设计来评估LLMs的真实编程能力，在保持竞争力的同时减少token消耗和设计工作量。


<details>
  <summary>Details</summary>
Motivation: 当前代码代理设计过度依赖复杂的手工工作流程和工具集，导致性能对提示调优敏感、人类干预掩盖模型真实能力、构建维护成本高，且存在数据泄露风险。

Method: 引入Lita框架，操作化"轻量"原则，在保留完全自主代理基本要素的同时最小化手动设计，实现更忠实和统一的评估。

Result: 在Aider Polyglot和SWE-Bench上的实验表明，Lita相比基于工作流程和代理基线实现了竞争性或更优的性能，同时消耗更少token且设计工作量显著降低。

Conclusion: Lita足以揭示现代LLMs的底层编程能力，并提出代理复杂度定律：随着核心模型改进，不同复杂度代理间的性能差距将缩小至可忽略程度。

Abstract: Large language models (LLMs) are increasingly being applied to programming
tasks, ranging from single-turn code completion to autonomous agents. Current
code agent designs frequently depend on complex, hand-crafted workflows and
tool sets. However, this reliance on elaborate scaffolding presents several
challenges: agent performance becomes overly dependent on prompt tuning and
custom design choices, heavy human intervention obscures a model's true
underlying capabilities, and intricate pipelines are costly to build and
maintain. Furthermore, optimizing complex task prompts increases the risk of
data leakage. Currently, when introducing new models, LLM providers like OpenAI
and Anthropic often publish benchmark scores to demonstrate their models'
coding proficiency, but keep their proprietary evaluation frameworks
confidential. To address these limitations, we introduce Lita (Lite Agent),
which operationalizes liteness, a principle of minimizing manual design while
retaining the essential elements of a fully autonomous agent. Lita enables a
more faithful and unified evaluation without elaborate scaffolding. Experiments
on the Aider Polyglot and SWE-Bench with frontier models demonstrate that Lita
achieves competitive or superior performance compared to workflow-based and
agentic baselines. Crucially, Lita also consumes fewer tokens and requires
significantly less design effort. Our results suggest that Lita is sufficient
to reveal the underlying coding competence of modern LLMs. Finally, we propose
the Agent Complexity Law: the performance gap between agents of varying
complexity, from simple to sophisticated designs, will shrink as the core model
improves, ultimately converging to a negligible difference.

</details>
