{"id": "2509.25196", "pdf": "https://arxiv.org/pdf/2509.25196", "abs": "https://arxiv.org/abs/2509.25196", "authors": ["Hua Zhong", "Shan Jiang", "Sarfraz Khurshid"], "title": "APRIL: API Synthesis with Automatic Prompt Optimization and Reinforcement Learning", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL"], "comment": null, "summary": "APIs are central to modern software development, yet composing new APIs from\nlarge libraries is difficult due to the exponential search space; traditional\ncomponent-based synthesis relies on costly exploration and hand-crafted\nspecifications. While large language models (LLMs) can generate implementations\nfrom natural language, hallucinations and limited access to up-to-date\ncontextual information often yield incorrect code. In this paper, we present\nAPRIL, an approach that combines LLM-based synthesis with Automatic Prompt\nOptimization (APO) and Reinforcement Learning from Verifiable Rewards (RLVR):\nAPO iteratively refines prompts for a frozen model, while RLVR fine-tunes the\npolicy toward functional correctness, producing an efficient synthesis\npipeline. Evaluated on 81 real-world APIs from widely used scientific Python\nlibraries and benchmarked against instruction-tuned but unfine-tuned LLMs\nguided by expert prompts, APRIL achieves substantial improvements. These\nresults indicate that integrating APO and RLVR provides a robust, scalable path\nfor component-based API synthesis in large libraries.", "AI": {"tldr": "APRIL\u7ed3\u5408LLM\u5408\u6210\u3001\u81ea\u52a8\u63d0\u793a\u4f18\u5316(APO)\u548c\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60(RLVR)\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u5e93\u4e2dAPI\u5408\u6210\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7ec4\u4ef6\u5408\u6210\u65b9\u6cd5\u641c\u7d22\u7a7a\u95f4\u5927\u4e14\u4f9d\u8d56\u4eba\u5de5\u89c4\u8303\uff0c\u800cLLM\u751f\u6210\u4ee3\u7801\u5b58\u5728\u5e7b\u89c9\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684API\u5408\u6210\u65b9\u6848\u3002", "method": "\u4f7f\u7528APO\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\uff0c\u540c\u65f6\u901a\u8fc7RLVR\u5bf9\u7b56\u7565\u8fdb\u884c\u5fae\u8c03\u4ee5\u5b9e\u73b0\u529f\u80fd\u6b63\u786e\u6027\uff0c\u6784\u5efa\u9ad8\u6548\u5408\u6210\u6d41\u6c34\u7ebf\u3002", "result": "\u572881\u4e2a\u771f\u5b9eAPI\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u4e13\u5bb6\u63d0\u793a\u6307\u5bfc\u7684\u672a\u5fae\u8c03LLM\uff0cAPRIL\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "APO\u548cRLVR\u7684\u96c6\u6210\u4e3a\u5927\u578b\u5e93\u4e2d\u7684\u7ec4\u4ef6\u5f0fAPI\u5408\u6210\u63d0\u4f9b\u4e86\u7a33\u5065\u3001\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2509.25197", "pdf": "https://arxiv.org/pdf/2509.25197", "abs": "https://arxiv.org/abs/2509.25197", "authors": ["Si Cheng Zhong", "Xujie Si"], "title": "Towards Repository-Level Program Verification with Large Language Models", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": "Accepted to LMPL 2025", "summary": "Recent advancements in large language models (LLMs) suggest great promises in\ncode and proof generations. However, scaling automated formal verification to\nreal-world projects requires resolving cross-module dependencies and global\ncontexts, which are crucial challenges overlooked by existing LLM-based methods\nwith a special focus on targeting isolated, function-level verification tasks.\nTo systematically explore and address the significant challenges of verifying\nentire software repositories, we introduce RVBench, the first verification\nbenchmark explicitly designed for repository-level evaluation, constructed from\nfour diverse and complex open-source Verus projects.\n  We further introduce RagVerus, an extensible framework that synergizes\nretrieval-augmented generation with context-aware prompting to automate proof\nsynthesis for multi-module repositories. RagVerus triples proof pass rates on\nexisting benchmarks under constrained model inference budgets, and achieves a\n27% relative improvement on the more challenging RVBench benchmark,\ndemonstrating a scalable and sample-efficient verification solution.", "AI": {"tldr": "RVBench\u662f\u9996\u4e2a\u9488\u5bf9\u4ed3\u5e93\u7ea7\u9a8c\u8bc1\u7684\u57fa\u51c6\uff0cRagVerus\u6846\u67b6\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u5757\u4ed3\u5e93\u7684\u8bc1\u660e\u5408\u6210\u80fd\u529b\u3002", "motivation": "\u73b0\u6709LLM\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b64\u7acb\u7684\u51fd\u6570\u7ea7\u9a8c\u8bc1\u4efb\u52a1\uff0c\u5ffd\u7565\u4e86\u8de8\u6a21\u5757\u4f9d\u8d56\u548c\u5168\u5c40\u4e0a\u4e0b\u6587\u7b49\u5173\u952e\u6311\u6218\uff0c\u96be\u4ee5\u6269\u5c55\u5230\u771f\u5b9e\u4e16\u754c\u9879\u76ee\u7684\u81ea\u52a8\u5316\u5f62\u5f0f\u9a8c\u8bc1\u3002", "method": "\u5f15\u5165RVBench\u4ed3\u5e93\u7ea7\u9a8c\u8bc1\u57fa\u51c6\uff0c\u5e76\u5f00\u53d1RagVerus\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\u6765\u81ea\u52a8\u5316\u591a\u6a21\u5757\u4ed3\u5e93\u7684\u8bc1\u660e\u5408\u6210\u3002", "result": "RagVerus\u5728\u53d7\u9650\u6a21\u578b\u63a8\u7406\u9884\u7b97\u4e0b\uff0c\u5c06\u73b0\u6709\u57fa\u51c6\u7684\u8bc1\u660e\u901a\u8fc7\u7387\u63d0\u9ad8\u4e86\u4e09\u500d\uff0c\u5728\u66f4\u5177\u6311\u6218\u6027\u7684RVBench\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e8627%\u7684\u76f8\u5bf9\u6539\u8fdb\u3002", "conclusion": "RagVerus\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u6837\u672c\u9ad8\u6548\u7684\u9a8c\u8bc1\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u4ed3\u5e93\u7ea7\u7684\u5f62\u5f0f\u9a8c\u8bc1\u6311\u6218\u3002"}}
{"id": "2509.25248", "pdf": "https://arxiv.org/pdf/2509.25248", "abs": "https://arxiv.org/abs/2509.25248", "authors": ["Zehua Zhang", "Ati Priya Bajaj", "Divij Handa", "Siyu Liu", "Arvind S Raj", "Hongkai Chen", "Hulin Wang", "Yibo Liu", "Zion Leonahenahe Basque", "Souradip Nath", "Vishal Juneja", "Nikhil Chapre", "Yan Shoshitaishvili", "Adam Doup\u00e9", "Chitta Baral", "Ruoyu Wang"], "title": "BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Automatically compiling open-source software (OSS) projects is a vital,\nlabor-intensive, and complex task, which makes it a good challenge for LLM\nAgents. Existing methods rely on manually curated rules and workflows, which\ncannot adapt to OSS that requires customized configuration or environment\nsetup. Recent attempts using Large Language Models (LLMs) used selective\nevaluation on a subset of highly rated OSS, a practice that underestimates the\nrealistic challenges of OSS compilation. In practice, compilation instructions\nare often absent, dependencies are undocumented, and successful builds may even\nrequire patching source files or modifying build scripts. We propose a more\nchallenging and realistic benchmark, BUILD-BENCH, comprising OSS that are more\ndiverse in quality, scale, and characteristics. Furthermore, we propose a\nstrong baseline LLM-based agent, OSS-BUILD-AGENT, an effective system with\nenhanced build instruction retrieval module that achieves state-of-the-art\nperformance on BUILD-BENCH and is adaptable to heterogeneous OSS\ncharacteristics. We also provide detailed analysis regarding different\ncompilation method design choices and their influence to the whole task,\noffering insights to guide future advances. We believe performance on\nBUILD-BENCH can faithfully reflect an agent's ability to tackle compilation as\na complex software engineering tasks, and, as such, our benchmark will spur\ninnovation with a significant impact on downstream applications in the fields\nof software development and software security.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u66f4\u771f\u5b9e\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u5f00\u6e90\u8f6f\u4ef6\u7f16\u8bd1\u57fa\u51c6BUILD-BENCH\uff0c\u4ee5\u53ca\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53OSS-BUILD-AGENT\uff0c\u8be5\u7cfb\u7edf\u5728BUILD-BENCH\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5f00\u6e90\u8f6f\u4ef6\u7f16\u8bd1\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u5236\u5b9a\u7684\u89c4\u5219\u548c\u5de5\u4f5c\u6d41\uff0c\u65e0\u6cd5\u9002\u5e94\u9700\u8981\u5b9a\u5236\u914d\u7f6e\u6216\u73af\u5883\u8bbe\u7f6e\u7684\u5f00\u6e90\u8f6f\u4ef6\u3002\u6700\u8fd1\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5c1d\u8bd5\u53ea\u5bf9\u9ad8\u8bc4\u5206\u5f00\u6e90\u8f6f\u4ef6\u5b50\u96c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u4f4e\u4f30\u4e86\u771f\u5b9e\u7f16\u8bd1\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86OSS-BUILD-AGENT\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5177\u6709\u589e\u5f3a\u7684\u6784\u5efa\u6307\u4ee4\u68c0\u7d22\u6a21\u5757\uff0c\u80fd\u591f\u9002\u5e94\u5f02\u6784\u5f00\u6e90\u8f6f\u4ef6\u7279\u6027\u3002", "result": "OSS-BUILD-AGENT\u5728BUILD-BENCH\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e0d\u540c\u7f16\u8bd1\u65b9\u6cd5\u8bbe\u8ba1\u9009\u62e9\u53ca\u5176\u5bf9\u6574\u4f53\u4efb\u52a1\u5f71\u54cd\u7684\u8be6\u7ec6\u5206\u6790\u3002", "conclusion": "BUILD-BENCH\u7684\u6027\u80fd\u80fd\u591f\u771f\u5b9e\u53cd\u6620\u667a\u80fd\u4f53\u5904\u7406\u590d\u6742\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u8be5\u57fa\u51c6\u5c06\u63a8\u52a8\u8f6f\u4ef6\u5f00\u53d1\u548c\u8f6f\u4ef6\u5b89\u5168\u9886\u57df\u7684\u521b\u65b0\u3002"}}
{"id": "2509.25873", "pdf": "https://arxiv.org/pdf/2509.25873", "abs": "https://arxiv.org/abs/2509.25873", "authors": ["Hankun Dai", "Maoquan Wang", "Mengnan Qi", "Yikai Zhang", "Zijian Jin", "Yongqiang Yao", "Yufan Huang", "Shengyu Fu", "Elsie Nallipogu"], "title": "Lita: Light Agent Uncovers the Agentic Coding Capabilities of LLMs", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.PL", "cs.SE"], "comment": null, "summary": "Large language models (LLMs) are increasingly being applied to programming\ntasks, ranging from single-turn code completion to autonomous agents. Current\ncode agent designs frequently depend on complex, hand-crafted workflows and\ntool sets. However, this reliance on elaborate scaffolding presents several\nchallenges: agent performance becomes overly dependent on prompt tuning and\ncustom design choices, heavy human intervention obscures a model's true\nunderlying capabilities, and intricate pipelines are costly to build and\nmaintain. Furthermore, optimizing complex task prompts increases the risk of\ndata leakage. Currently, when introducing new models, LLM providers like OpenAI\nand Anthropic often publish benchmark scores to demonstrate their models'\ncoding proficiency, but keep their proprietary evaluation frameworks\nconfidential. To address these limitations, we introduce Lita (Lite Agent),\nwhich operationalizes liteness, a principle of minimizing manual design while\nretaining the essential elements of a fully autonomous agent. Lita enables a\nmore faithful and unified evaluation without elaborate scaffolding. Experiments\non the Aider Polyglot and SWE-Bench with frontier models demonstrate that Lita\nachieves competitive or superior performance compared to workflow-based and\nagentic baselines. Crucially, Lita also consumes fewer tokens and requires\nsignificantly less design effort. Our results suggest that Lita is sufficient\nto reveal the underlying coding competence of modern LLMs. Finally, we propose\nthe Agent Complexity Law: the performance gap between agents of varying\ncomplexity, from simple to sophisticated designs, will shrink as the core model\nimproves, ultimately converging to a negligible difference.", "AI": {"tldr": "Lita (Lite Agent) \u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u4ee3\u7801\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u624b\u52a8\u8bbe\u8ba1\u6765\u8bc4\u4f30LLMs\u7684\u771f\u5b9e\u7f16\u7a0b\u80fd\u529b\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u51cf\u5c11token\u6d88\u8017\u548c\u8bbe\u8ba1\u5de5\u4f5c\u91cf\u3002", "motivation": "\u5f53\u524d\u4ee3\u7801\u4ee3\u7406\u8bbe\u8ba1\u8fc7\u5ea6\u4f9d\u8d56\u590d\u6742\u7684\u624b\u5de5\u5de5\u4f5c\u6d41\u7a0b\u548c\u5de5\u5177\u96c6\uff0c\u5bfc\u81f4\u6027\u80fd\u5bf9\u63d0\u793a\u8c03\u4f18\u654f\u611f\u3001\u4eba\u7c7b\u5e72\u9884\u63a9\u76d6\u6a21\u578b\u771f\u5b9e\u80fd\u529b\u3001\u6784\u5efa\u7ef4\u62a4\u6210\u672c\u9ad8\uff0c\u4e14\u5b58\u5728\u6570\u636e\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u5f15\u5165Lita\u6846\u67b6\uff0c\u64cd\u4f5c\u5316\"\u8f7b\u91cf\"\u539f\u5219\uff0c\u5728\u4fdd\u7559\u5b8c\u5168\u81ea\u4e3b\u4ee3\u7406\u57fa\u672c\u8981\u7d20\u7684\u540c\u65f6\u6700\u5c0f\u5316\u624b\u52a8\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u66f4\u5fe0\u5b9e\u548c\u7edf\u4e00\u7684\u8bc4\u4f30\u3002", "result": "\u5728Aider Polyglot\u548cSWE-Bench\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLita\u76f8\u6bd4\u57fa\u4e8e\u5de5\u4f5c\u6d41\u7a0b\u548c\u4ee3\u7406\u57fa\u7ebf\u5b9e\u73b0\u4e86\u7ade\u4e89\u6027\u6216\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u540c\u65f6\u6d88\u8017\u66f4\u5c11token\u4e14\u8bbe\u8ba1\u5de5\u4f5c\u91cf\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "Lita\u8db3\u4ee5\u63ed\u793a\u73b0\u4ee3LLMs\u7684\u5e95\u5c42\u7f16\u7a0b\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4ee3\u7406\u590d\u6742\u5ea6\u5b9a\u5f8b\uff1a\u968f\u7740\u6838\u5fc3\u6a21\u578b\u6539\u8fdb\uff0c\u4e0d\u540c\u590d\u6742\u5ea6\u4ee3\u7406\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u5c06\u7f29\u5c0f\u81f3\u53ef\u5ffd\u7565\u7a0b\u5ea6\u3002"}}
{"id": "2509.25879", "pdf": "https://arxiv.org/pdf/2509.25879", "abs": "https://arxiv.org/abs/2509.25879", "authors": ["Michele De Pascalis", "Tarmo Uustalu", "Niccol\u00f2 Veltr\u00ec"], "title": "Monoid Structures on Indexed Containers", "categories": ["cs.LO", "cs.PL"], "comment": "In Proceedings LSFA 2025, arXiv:2509.23739", "summary": "Containers represent a wide class of type constructions relevant for\nfunctional programming and (co)inductive reasoning. Indexed containers\ngeneralize this notion to better fit the scope of dependently typed\nprogramming. When interpreting types to be sets, a container describes an\nendofunctor on the category of sets while an I-indexed container describes an\nendofunctor on the category Set^I of I-indexed families of sets.\n  We consider the monoidal structure on the category of I-indexed containers\nwhose tensor product of containers describes the composition of the respective\ninduced endofunctors. We then give a combinatorial characterization of monoids\nin this monoidal category, and we show how these monoids correspond precisely\nto monads on the induced endofunctors on Set^I. Lastly, we conclude by\npresenting some examples of monads on Set^I that fall under our\ncharacterization, including the product of two monads, indexed variants of the\nstate and the writer monads and an example of a free monad. The technical\nresults of this work are accompanied by a formalization in the proof assistant\nCubical Agda.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7d22\u5f15\u5bb9\u5668\u7684\u5e7a\u534a\u7fa4\u7ed3\u6784\uff0c\u7ed9\u51fa\u4e86\u8be5\u5e7a\u534a\u8303\u7574\u4e2d\u5e7a\u534a\u5143\u7684\u7ec4\u5408\u7279\u5f81\uff0c\u5e76\u8bc1\u660e\u8fd9\u4e9b\u5e7a\u534a\u5143\u7cbe\u786e\u5bf9\u5e94\u4e8eSet^I\u4e0a\u8bf1\u5bfc\u81ea\u51fd\u5b50\u7684\u5355\u5b50\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u9002\u5e94\u4f9d\u8d56\u7c7b\u578b\u7f16\u7a0b\u7684\u8303\u56f4\uff0c\u7d22\u5f15\u5bb9\u5668\u63a8\u5e7f\u4e86\u5bb9\u5668\u7684\u6982\u5ff5\u3002\u7814\u7a76\u7d22\u5f15\u5bb9\u5668\u7684\u5e7a\u534a\u7fa4\u7ed3\u6784\u6709\u52a9\u4e8e\u7406\u89e3\u5355\u5b50\u7684\u7ec4\u5408\u6027\u8d28\u3002", "method": "\u8003\u8651I-\u7d22\u5f15\u5bb9\u5668\u8303\u7574\u7684\u5e7a\u534a\u7fa4\u7ed3\u6784\uff0c\u5176\u4e2d\u5f20\u91cf\u79ef\u63cf\u8ff0\u76f8\u5e94\u8bf1\u5bfc\u81ea\u51fd\u5b50\u7684\u590d\u5408\u3002\u7ed9\u51fa\u8be5\u5e7a\u534a\u8303\u7574\u4e2d\u5e7a\u534a\u5143\u7684\u7ec4\u5408\u7279\u5f81\u5316\u3002", "result": "\u8bc1\u660e\u4e86\u8fd9\u4e9b\u5e7a\u534a\u5143\u7cbe\u786e\u5bf9\u5e94\u4e8eSet^I\u4e0a\u8bf1\u5bfc\u81ea\u51fd\u5b50\u7684\u5355\u5b50\uff0c\u5e76\u63d0\u4f9b\u4e86\u5305\u62ec\u4e24\u4e2a\u5355\u5b50\u7684\u79ef\u3001\u72b6\u6001\u548cwriter\u5355\u5b50\u7684\u7d22\u5f15\u53d8\u4f53\u4ee5\u53ca\u81ea\u7531\u5355\u5b50\u7b49\u5b9e\u4f8b\u3002", "conclusion": "\u7d22\u5f15\u5bb9\u5668\u7684\u5e7a\u534a\u7fa4\u7ed3\u6784\u4e3a\u7406\u89e3\u5355\u5b50\u7684\u7ec4\u5408\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u7ed3\u679c\u5728Cubical Agda\u4e2d\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002"}}
{"id": "2509.26616", "pdf": "https://arxiv.org/pdf/2509.26616", "abs": "https://arxiv.org/abs/2509.26616", "authors": ["Mohammad Rifat Arefin", "Shanto Rahman", "Christoph Csallner"], "title": "Black-box Context-free Grammar Inference for Readable & Natural Grammars", "categories": ["cs.SE", "cs.FL", "cs.PL", "68Q42, 68Q45 (Primary), 68T50 (Secondary)", "D.2.5; F.4.2"], "comment": "20 pages", "summary": "Black-box context-free grammar inference is crucial for program analysis,\nreverse engineering, and security, yet existing tools such as Arvada, TreeVada,\nand Kedavra struggle with scalability, readability, and accuracy on large,\ncomplex languages. We present NatGI, a novel LLM-guided grammar inference\nframework that extends TreeVada's parse tree recovery with three key\ninnovations: bracket-guided bubble exploration, LLM-driven bubble generation\nand non-terminal labeling, and hierarchical delta debugging (HDD) for\nsystematic tree simplification. Bracket-guided exploration leverages syntactic\ncues such as parentheses to propose well-structured grammar fragments, while\nLLM guidance produces meaningful non-terminal names and selects more promising\nmerges. Finally, HDD incrementally reduces unnecessary rules, which makes the\ngrammars both compact and interpretable. In our experiments, we evaluate NatGI\non a comprehensive benchmark suite ranging from small languages to larger ones\nsuch as lua, c, and mysql. Our results show that NatGI consistently outperforms\nstrong baselines in terms of F1 score. On average, NatGI achieves an F1 score\nof 0.57, which is 25pp (percentage points) higher than the best-performing\nbaseline, TreeVada. In the case of interpretability, our generated grammars\nperform significantly better than those produced by existing approaches.\nLeveraging LLM-based node renaming and bubble exploration, NatGI produces rules\nwith meaningful non-terminal names and compact structures that align more\nclosely with human intuition. As a result, developers and researchers can\nachieve higher accuracy while still being able to easily inspect, verify, and\nreason about the structure and semantics of the induced grammars.", "AI": {"tldr": "NatGI\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u5f15\u5bfc\u7684\u8bed\u6cd5\u63a8\u65ad\u6846\u67b6\uff0c\u901a\u8fc7\u62ec\u53f7\u5f15\u5bfc\u7684\u63a2\u7d22\u3001LLM\u9a71\u52a8\u7684\u8bed\u6cd5\u7247\u6bb5\u751f\u6210\u548c\u5c42\u6b21\u5316delta\u8c03\u8bd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9ed1\u76d2\u4e0a\u4e0b\u6587\u65e0\u5173\u8bed\u6cd5\u63a8\u65ad\u7684\u51c6\u786e\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u8bfb\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u6cd5\u63a8\u65ad\u5de5\u5177\uff08\u5982Arvada\u3001TreeVada\u3001Kedavra\uff09\u5728\u5904\u7406\u5927\u578b\u590d\u6742\u8bed\u8a00\u65f6\u5b58\u5728\u53ef\u6269\u5c55\u6027\u3001\u53ef\u8bfb\u6027\u548c\u51c6\u786e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "1. \u62ec\u53f7\u5f15\u5bfc\u7684\u8bed\u6cd5\u7247\u6bb5\u63a2\u7d22\uff1a\u5229\u7528\u62ec\u53f7\u7b49\u8bed\u6cd5\u7ebf\u7d22\u63d0\u51fa\u7ed3\u6784\u826f\u597d\u7684\u8bed\u6cd5\u7247\u6bb5\n2. LLM\u9a71\u52a8\u7684\u8bed\u6cd5\u7247\u6bb5\u751f\u6210\u548c\u975e\u7ec8\u7aef\u6807\u7b7e\uff1a\u751f\u6210\u6709\u610f\u4e49\u7684\u975e\u7ec8\u7aef\u540d\u79f0\u5e76\u9009\u62e9\u66f4\u6709\u524d\u666f\u7684\u5408\u5e76\n3. \u5c42\u6b21\u5316delta\u8c03\u8bd5\uff1a\u7cfb\u7edf\u6027\u5730\u7b80\u5316\u8bed\u6cd5\u6811\uff0c\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u89c4\u5219", "result": "\u5728\u4ece\u5c0f\u578b\u8bed\u8a00\u5230\u5927\u578b\u8bed\u8a00\uff08\u5982lua\u3001c\u3001mysql\uff09\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cNatGI\u5e73\u5747F1\u5206\u6570\u8fbe\u52300.57\uff0c\u6bd4\u6700\u4f73\u57fa\u7ebfTreeVada\u9ad8\u51fa25\u4e2a\u767e\u5206\u70b9\uff0c\u5728\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "NatGI\u901a\u8fc7LLM\u5f15\u5bfc\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u751f\u6210\u4e86\u66f4\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u7684\u8bed\u6cd5\u89c4\u5219\uff0c\u4f7f\u5f00\u53d1\u8005\u548c\u7814\u7a76\u4eba\u5458\u80fd\u591f\u8f7b\u677e\u68c0\u67e5\u3001\u9a8c\u8bc1\u548c\u7406\u89e3\u63a8\u65ad\u51fa\u7684\u8bed\u6cd5\u7ed3\u6784\u548c\u8bed\u4e49\u3002"}}
