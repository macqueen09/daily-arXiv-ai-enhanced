<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [PLSEMANTICSBENCH: Large Language Models As Programming Language Interpreters](https://arxiv.org/abs/2510.03415)
*Aditya Thimmaiah,Jiyang Zhang,Jayanth Srinivasa,Junyi Jessy Li,Milos Gligoric*

Main category: cs.PL

TL;DR: 研究大型语言模型能否基于形式语义作为编程语言解释器执行程序，发现模型在标准语义下表现良好但在非标准语义下性能下降，表明其语义理解不够稳健。


<details>
  <summary>Details</summary>
Motivation: 探索LLM能否基于编程语言的形式语义执行程序，以实现新编程语言和语言特性的快速原型开发。

Method: 使用IMP语言（C的子集），通过小步操作语义和重写语义形式化，创建三个评估集，评估模型在最终状态预测、语义规则预测和执行轨迹预测三个任务上的表现。

Result: 模型在标准语义下表现良好，但在非标准语义下性能显著下降；在复杂程序上表现优异；提供形式语义对简单程序有帮助但对复杂程序可能有害。

Conclusion: LLM有潜力作为编程语言解释器，但其语义理解缺乏稳健性。

Abstract: As large language models (LLMs) excel at code reasoning, a natural question
arises: can an LLM execute programs (i.e., act as an interpreter) purely based
on a programming language's formal semantics? If so, it will enable rapid
prototyping of new programming languages and language features. We study this
question using the imperative language IMP (a subset of C), formalized via
small-step operational semantics (SOS) and rewriting-based operational
semantics (K-semantics). We introduce three evaluation sets-Human-Written,
LLM-Translated, and Fuzzer- Generated-whose difficulty is controlled by
code-complexity metrics spanning the size, control-flow, and data-flow axes.
Given a program and its semantics formalized with SOS/K-semantics, models are
evaluated on three tasks ranging from coarse to fine: (1) final-state
prediction, (2) semantic rule prediction, and (3) execution trace prediction.
To distinguish pretraining memorization from semantic competence, we define two
nonstandard semantics obtained through systematic mutations of the standard
rules. Across strong code/reasoning LLMs, performance drops under nonstandard
semantics despite high performance under the standard one. We further find that
(i) there are patterns to different model failures, (ii) most reasoning models
perform exceptionally well on coarse grained tasks involving reasoning about
highly complex programs often containing nested loop depths beyond five, and
surprisingly, (iii) providing formal semantics helps on simple programs but
often hurts on more complex ones. Overall, the results show a promise that LLMs
could serve as programming language interpreters, but points to the lack of
their robust semantics understanding. We release the benchmark and the
supporting code at https://github.com/EngineeringSoftware/PLSemanticsBench.

</details>


### [2] [Encoding Numeric Computations and Infusing Heuristic Knowledge Using Integrity Constraints in stableKanren](https://arxiv.org/abs/2510.04049)
*Xiangyu Guo,Ajay Bansal*

Main category: cs.PL

TL;DR: stableKanren通过完整性约束支持数值计算，在关系编程中平衡符号和数值计算，避免将所有数字接地为符号，并展示如何通过启发式知识提高求解性能。


<details>
  <summary>Details</summary>
Motivation: 扩展关系编程语言以支持数值计算，提供更直接的数值表示，平衡符号和数值计算，简化语法，并提高组合搜索问题的求解效率。

Method: 使用完整性约束构建约束存储，支持稳定模型语义下的正常逻辑程序，通过声明式生成和测试范式进行组合搜索，并注入启发式知识优化求解。

Result: stableKanren在SEND+MORE=MONEY谜题中展示了不同编程或查询方法对求解器性能的影响，性能随着启发式知识的注入逐渐提升，并实现了混合解决方案。

Conclusion: stableKanren通过约束存储构建提供了直接的数值表示，平衡了符号和数值计算，简化了语法，并通过启发式知识显著提高了组合搜索问题的求解效率。

Abstract: This paper presents examples of using integrity constraints in stableKanren
to encode numeric computations for problem solving. Then, we use one of the
examples to introduce multiple ways to infuse heuristic knowledge and reduce
solving time. stableKanren is an extension of miniKanren that supports normal
logic programs under stable model semantics. stableKanren further supports
numeric computation by constructing a constraint store for integrity
constraints. There are three ways to extend a relational programming language
with numeric computations: relational number representation, grounding numbers
to symbols, and constraint store construction. We demonstrate that the numeric
computations in stableKanren have a straightforward numerical representation
compared to relational number representations. More importantly, stableKanren
balances symbolic and numeric computation in relational programming by avoiding
the grounding of all numbers to symbols. Lastly, it also has simpler syntax
compared to other constraint store construction approaches. stableKanren
supports combinatorial search problem solving under a declarative generate and
test paradigm. Such a paradigm generates all possible combinations of solutions
to the problem, then applies a set of constraints to prune out the unwanted
solutions. We demonstrate that different approaches to writing programs or
queries affect the solver's performance in the SEND+MORE=MONEY puzzle. The
performance gradually improves as more heuristic knowledge is infused through
the programs or queries. Additionally, we show how to use an external function
to achieve a hybrid solution.

</details>


### [3] [Retrofitting Control Flow Graphs in LLVM IR for Auto Vectorization](https://arxiv.org/abs/2510.04890)
*Shihan Fang,Wenxin Zheng*

Main category: cs.PL

TL;DR: 提出了一种新的向量化流水线，通过SIR和VIR两种专用IR扩展来改进控制流分析和指令依赖分析，显著提升了自动向量化的范围和效率


<details>
  <summary>Details</summary>
Motivation: 现代处理器依赖SIMD指令集提升性能，但现有编译器如LLVM和GCC无法充分利用向量化机会，主要由于分离的向量化过程和有限的可扩展性

Method: 引入包含SIR和VIR两种IR扩展的向量化流水线：SIR编码高层次结构信息，VIR通过数据依赖分析显式表示指令依赖关系，构建灵活可扩展的向量化框架

Result: 实验评估显示，相比LLVM和GCC分别实现了最高53%和58%的性能加速

Conclusion: 提出的向量化流水线通过改进的IR设计显著提升了向量化过程的互操作性和指令同构识别能力，有效增强了自动向量化的范围和效率

Abstract: Modern processors increasingly rely on SIMD instruction sets, such as AVX and
RVV, to significantly enhance parallelism and computational performance.
However, production-ready compilers like LLVM and GCC often fail to fully
exploit available vectorization opportunities due to disjoint vectorization
passes and limited extensibility. Although recent attempts in heuristics and
intermediate representation (IR) designs have attempted to address these
problems, efficiently simplifying control flow analysis and accurately
identifying vectorization opportunities remain challenging tasks.
  To address these issues, we introduce a novel vectorization pipeline
featuring two specialized IR extensions: SIR, which encodes high-level
structural information, and VIR, which explicitly represents instruction
dependencies through data dependency analysis. Leveraging the detailed
dependency information provided by VIR, we develop a flexible and extensible
vectorization framework. This approach substantially improves interoperability
across vectorization passes and expands the search space for identifying
isomorphic instructions, ultimately enhancing both the scope and efficiency of
automatic vectorization. Experimental evaluations demonstrate that our proposed
vectorization pipeline achieves significant performance improvements,
delivering speedups of up to 53% and 58% compared to LLVM and GCC,
respectively.

</details>


### [4] [concurrentKanren: miniKanren for parallel execution](https://arxiv.org/abs/2510.04994)
*Sjoerd Dost*

Main category: cs.PL

TL;DR: 在Go语言中实现了miniKanren的并行版本，展示了可行性并提升了性能，支持隐式并行让传统程序受益


<details>
  <summary>Details</summary>
Motivation: 并发逻辑编程早于miniKanren，但miniKanren的并发实现尚未充分探索，需要研究并行实现的可行性和性能潜力

Method: 在Go语言中开发并行miniKanren实现，利用隐式并行机制，允许传统程序无需修改即可受益于并行执行

Result: 证明了并行miniKanren的可行性，实现了性能提升，为未来语言无关模型奠定了基础

Conclusion: 并行miniKanren实现是可行的，能够带来性能改进，为开发语言无关的并发逻辑编程模型提供了基础

Abstract: Concurrent logic programming predates miniKanren, but concurrent
implementations of miniKanren have remained largely unexplored. In this work we
present a parallel implementation of miniKanren in Go, demonstrating its
feasibility and potential for performance improvements. Our approach leverages
implicit parallelism allowing legacy programs to benefit from parallel
execution. We discuss implementation strategies and evaluate the impact of
parallelism, laying groundwork for future language-agnostic models.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [5] [Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning](https://arxiv.org/abs/2510.04081)
*Honglin Lin,Qizhi Pei,Xin Gao,Zhuoshi Pan,Yu Li,Juntao Li,Conghui He,Lijun Wu*

Main category: cs.CL

TL;DR: 提出了Caco框架，通过代码驱动的增强方法自动合成高质量、可验证且多样化的推理数据，以解决LLMs推理能力不可靠和扩展性差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法存在生成不可控、质量不足和推理路径多样性有限的问题，而基于代码的方法通常局限于预定义的数学问题，阻碍了可扩展性和泛化性。

Method: 首先在统一代码格式上微调基于代码的CoT生成器，然后扩展到大量多样化推理轨迹，通过代码执行和基于规则的过滤进行自动验证，最后将过滤输出反向工程为自然语言指令和语言CoT。

Result: 在创建的Caco-1.3M数据集上的实验表明，Caco训练模型在数学推理基准上实现了强大的竞争性能，优于现有基线。

Conclusion: Caco建立了一个无需人工干预构建自维持、可信赖推理系统的范式，其代码锚定验证和指令多样性有助于在未见任务上实现优越泛化。

Abstract: Reasoning capability is pivotal for Large Language Models (LLMs) to solve
complex tasks, yet achieving reliable and scalable reasoning remains
challenging. While Chain-of-Thought (CoT) prompting has become a mainstream
approach, existing methods often suffer from uncontrolled generation,
insufficient quality, and limited diversity in reasoning paths. Recent efforts
leverage code to enhance CoT by grounding reasoning in executable steps, but
such methods are typically constrained to predefined mathematical problems,
hindering scalability and generalizability. In this work, we propose Caco
(Code-Assisted Chain-of-ThOught), a novel framework that automates the
synthesis of high-quality, verifiable, and diverse instruction-CoT reasoning
data through code-driven augmentation. Unlike prior work, Caco first fine-tunes
a code-based CoT generator on existing math and programming solutions in a
unified code format, then scales the data generation to a large amount of
diverse reasoning traces. Crucially, we introduce automated validation via code
execution and rule-based filtering to ensure logical correctness and structural
diversity, followed by reverse-engineering filtered outputs into natural
language instructions and language CoTs to enrich task adaptability. This
closed-loop process enables fully automated, scalable synthesis of reasoning
data with guaranteed executability. Experiments on our created Caco-1.3M
dataset demonstrate that Caco-trained models achieve strong competitive
performance on mathematical reasoning benchmarks, outperforming existing strong
baselines. Further analysis reveals that Caco's code-anchored verification and
instruction diversity contribute to superior generalization across unseen
tasks. Our work establishes a paradigm for building self-sustaining,
trustworthy reasoning systems without human intervention.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [6] [An Empirical Study of Rational Tree Unification for miniKanren](https://arxiv.org/abs/2510.03789)
*Eridan Domoratskiy,Dmitrii Kosarev,Dmitry Boulytchev*

Main category: cs.LO

TL;DR: 研究miniKanren中理性树的统一化，包括定义、算法、性质证明、优化启发式及其性能评估，并讨论理性与常规统一化算法的关系。


<details>
  <summary>Details</summary>
Motivation: 在关系编程背景下，研究理性树的统一化问题，探索其算法特性和优化方法。

Method: 定义理性树，指定统一化算法并证明其性质，引入启发式优化并在相关基准测试中进行评估。

Result: 提出了理性树统一化算法及其优化方法，通过基准测试验证了性能改进。

Conclusion: 理性树统一化在关系编程中具有重要价值，可与常规统一化算法共存，为不同场景提供解决方案。

Abstract: We present a study of unification for rational trees in the context of
miniKanren. We give the definition of rational trees, specify the unification
algorithm and prove some of its properties. We also introduce a number of
heuristic optimizations and evaluate them for a number of relevant benchmarks.
Finally we discuss the relations between rational and conventional unification
algorithms and possible scenarios of their coexistence in the context of
relational programming.

</details>
