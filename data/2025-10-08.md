<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Constraint-Level Design of zkEVMs: Architectures, Trade-offs, and Evolution](https://arxiv.org/abs/2510.05376)
*Yahya Hassanzadeh-Nazarabadi,Sanaz Taheri-Boshrooyeh*

Main category: cs.CR

TL;DR: 本文系统分析了zkEVM实现中的核心矛盾：EVM的透明顺序执行与零知识证明的代数电路表示之间的冲突，比较了不同架构在算术化方案、调度机制和类型谱系三个维度的设计选择。


<details>
  <summary>Details</summary>
Motivation: 解决EVM与零知识证明之间的根本矛盾，为现有主要zkEVM实现提供系统性的比较框架，识别设计空间中的关键权衡。

Method: 开发比较框架，从三个架构维度分析：算术化方案（R1CS、PLONKish、AIR）、调度机制（选择器vs ROM）和类型谱系（Type 1-4）。

Result: 揭示了不同设计选择之间的严格权衡：PLONKish通过自定义门优雅处理复杂EVM操作码，但AIR结构与EVM不规则指令集不匹配；Type 1提供比特级兼容性但约束复杂度显著高于Type 4。

Conclusion: 识别了多个关键开放问题：性能障碍、形式验证缺失、标准化基准框架不足，以及在混合设计、去中心化证明者协调、隐私保护和互操作性方面的架构空白。

Abstract: Zero-knowledge Ethereum Virtual Machines (zkEVMs) must reconcile a
fundamental contradiction: the Ethereum Virtual Machine was designed for
transparent sequential execution, while zero-knowledge proofs require algebraic
circuit representations. This survey provides the first systematic analysis of
how existing major production zkEVM implementations resolve this tension
through distinct constraint engineering strategies. We develop a comparative
framework that maps the design space across three architectural dimensions.
First, arithmetization schemes reveal stark trade-offs: R1CS requires
compositional gadget libraries, PLONKish achieves elegance through custom gates
that capture complex EVM opcodes in single constraints, while the homogeneous
structure of AIR fundamentally mismatches the irregular instruction set of EVM.
Second, dispatch mechanisms determine constraint activation patterns:
selector-based systems waste trace width on inactive constraints, while
ROM-based approaches trade memory lookups for execution flexibility. Third, the
Type 1-4 spectrum quantifies an inescapable trade-off: the bit-level EVM
compatibility of Type 1 demands significantly higher constraint complexity than
the custom instruction sets of Type 4. Beyond cataloging implementations, we
identify critical open problems across multiple domains: performance barriers
preventing sub-second proving, absence of formal verification for
constraint-to-EVM semantic equivalence, lack of standardized benchmarking
frameworks, and architectural gaps in hybrid zkEVM/zkVM designs, decentralized
prover coordination, privacy preservation, and interoperability.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [2] [Optimization Modeling via Semantic Anchored Alignment](https://arxiv.org/abs/2510.05115)
*Yansen Zhang,Qingcan Kang,Yujie Chen,Yufei Wang,Xiongwei Han,Tao Zhong,Mingxuan Yuan,Chen Ma*

Main category: cs.AI

TL;DR: SAC-Opt是一个基于语义锚点的后向引导修正框架，通过将原始语义锚点与生成代码重构的锚点对齐，选择性修正不匹配组件，提高LLM生成优化模型的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM优化建模方法主要依赖求解器驱动，采用单次前向生成和有限的后处理修复，存在未检测的语义错误，导致生成语法正确但逻辑有缺陷的模型。

Method: 提出SAC-Opt框架，基于语义锚点进行后向引导修正，在每个步骤中将原始语义锚点与代码重构的锚点对齐，选择性修正不匹配的组件，实现约束和目标逻辑的细粒度优化。

Result: 在7个公共数据集上的实验表明，SAC-Opt将平均建模准确率提高了7.8%，在ComplexLP数据集上最高提升21.9%。

Conclusion: 语义锚点修正对于LLM驱动的优化工作流至关重要，能够确保从问题意图到求解器可执行代码的忠实转换。

Abstract: Large language models (LLMs) have opened new paradigms in optimization
modeling by enabling the generation of executable solver code from natural
language descriptions. Despite this promise, existing approaches typically
remain solver-driven: they rely on single-pass forward generation and apply
limited post-hoc fixes based on solver error messages, leaving undetected
semantic errors that silently produce syntactically correct but logically
flawed models. To address this challenge, we propose SAC-Opt, a backward-guided
correction framework that grounds optimization modeling in problem semantics
rather than solver feedback. At each step, SAC-Opt aligns the original semantic
anchors with those reconstructed from the generated code and selectively
corrects only the mismatched components, driving convergence toward a
semantically faithful model. This anchor-driven correction enables fine-grained
refinement of constraint and objective logic, enhancing both fidelity and
robustness without requiring additional training or supervision. Empirical
results on seven public datasets demonstrate that SAC-Opt improves average
modeling accuracy by 7.8\%, with gains of up to 21.9\% on the ComplexLP
dataset. These findings highlight the importance of semantic-anchored
correction in LLM-based optimization workflows to ensure faithful translation
from problem intent to solver-executable code.

</details>
