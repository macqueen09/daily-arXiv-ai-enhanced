<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 5]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.SE](#cs.SE) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Neptune: Advanced ML Operator Fusion for Locality and Parallelism on GPUs](https://arxiv.org/abs/2510.08726)
*Yifan Zhao,Egan Johnson,Prasanth Chatarasi,Vikram Adve,Sasa Misailovic*

Main category: cs.PL

TL;DR: Neptune是一个张量编译器，通过打破循环依赖并构建代数校正表达式来实现复杂归约算子（如注意力机制）的高级融合，在多种GPU架构上平均提速1.35倍。


<details>
  <summary>Details</summary>
Motivation: 现有张量编译器难以融合涉及循环依赖的复杂归约计算，如注意力机制，这限制了深度学习算子的优化效果。

Method: Neptune采用新的高级算子融合方法，故意打破某些现有依赖关系，并通过构建代数校正表达式来确保内核产生正确结果。

Result: 在10个注意力基准测试中，Neptune从简单注意力代码和高级调度模板出发，在NVIDIA和AMD的4种GPU架构上平均比最佳替代方案快1.35倍。

Conclusion: Neptune证明了其高级算子融合方法对深度学习工作负载的有效性，特别是在处理复杂归约计算方面优于现有编译器。

Abstract: Operator fusion has become a key optimization for deep learning, which
combines multiple deep learning operators to improve data reuse and reduce
global memory transfers. However, existing tensor compilers struggle to fuse
complex reduction computations involving loop-carried dependencies, such as
attention mechanisms.
  The paper introduces Neptune, a tensor compiler for advanced operator fusion
for sequences of reduction operators. Neptune presents a new approach for
advanced operator fusion, which intentionally breaks some existing dependencies
and compensates by constructing algebraic correction expressions that allow the
kernel to produce the correct result.
  On ten attention-based benchmarks, Neptune, starting from simple attention
code and a high-level scheduling template, outperforms existing compilers like
Triton, TVM, and FlexAttention, including Triton-based implementations of
FlashAttention. Across four different GPU architectures from NVIDIA and AMD,
Neptune-generated kernels have average speedup of $1.35\times$ over the next
best alternative, demonstrating its effectiveness for deep learning workloads.

</details>


### [2] [Typestate via Revocable Capabilities](https://arxiv.org/abs/2510.08889)
*Songlin Jia,Craig Liu,Siyuan He,Haotian Deng,Yuyan Bao,Tiark Rompf*

Main category: cs.PL

TL;DR: 提出了一种统一范围基和流敏感状态管理的方法，通过将流不敏感的能力机制扩展到流敏感的类型状态跟踪，在Scala 3中实现表达性强且安全的状态管理。


<details>
  <summary>Details</summary>
Motivation: 解决状态资源管理中的安全性和表达性挑战，平衡范围基构造的易推理性和流敏感管理的细粒度控制，避免复杂的类型状态分析和显式状态跟踪负担。

Method: 扩展流不敏感能力机制到流敏感类型状态跟踪，将能力生命周期与词法范围解耦，允许函数以流敏感方式提供、撤销和返回能力，基于Scala 3的路径依赖类型和隐式解析实现。

Result: 开发了Scala 3编译器扩展原型，支持文件操作、高级锁定协议、DOM构建和会话类型等多种状态模式，实现了简洁、静态安全且表达性强的类型状态编程。

Conclusion: 证明通过最小化扩展现有基于能力的语言，可以实现表达性强且安全的状态管理，为更健壮和符合人体工程学的状态编程铺平道路。

Abstract: Managing stateful resources safely and expressively is a longstanding
challenge in programming languages, especially in the presence of aliasing.
While scope-based constructs such as Java's synchronized blocks offer ease of
reasoning, they restrict expressiveness and parallelism. Conversely,
imperative, flow-sensitive management enables fine-grained control but demands
sophisticated typestate analyses and often burdens programmers with explicit
state tracking.
  In this work, we present a novel approach that unifies the strengths of both
paradigms by extending flow-insensitive capability mechanisms into
flow-sensitive typestate tracking. Our system decouples capability lifetimes
from lexical scopes, allowing functions to provide, revoke, and return
capabilities in a flow-sensitive manner, based on the existing mechanisms
explored for the safety and ergonomics of scoped capability programming.
  We implement our approach as an extension to the Scala 3 compiler, leveraging
path-dependent types and implicit resolution to enable concise, statically
safe, and expressive typestate programming. Our prototype generically supports
a wide range of stateful patterns, including file operations, advanced locking
protocols, DOM construction, and session types. This work demonstrates that
expressive and safe typestate management can be achieved with minimal
extensions to existing capability-based languages, paving the way for more
robust and ergonomic stateful programming.

</details>


### [3] [Free to Move: Reachability Types with Flow-Sensitive Effects for Safe Deallocation and Ownership Transfer](https://arxiv.org/abs/2510.08939)
*Haotian Deng,Siyuan He,Songlin Jia,Yuyan Bao,Tiark Rompf*

Main category: cs.PL

TL;DR: 提出了一个基于可达性类型的流敏感效应系统，支持高阶不纯函数式语言中的显式内存管理，包括Rust风格的移动语义。


<details>
  <summary>Details</summary>
Motivation: 将基于可达性的推理与显式资源控制相结合，推进高阶函数式语言中安全手动内存管理的技术水平。

Method: 使用多态的use和kill效应来记录引用如何被读取、写入、转移和释放，通过限定符跟踪每个资源的操作，无需区域或线性性。

Result: 系统能够表达所有权转移、上下文新鲜度和破坏性更新，验证了释放后使用安全性，所有元理论结果都已机械化证明。

Conclusion: 该贡献整合了可达性推理与显式资源控制，为高阶函数式语言的安全手动内存管理提供了先进解决方案。

Abstract: We present a flow-sensitive effect system for reachability types that
supports explicit memory management, including Rust-style move semantics, in
higher-order impure functional languages. Our system refines the existing
reachability qualifier with polymorphic \emph{use} and \emph{kill} effects that
record how references are read, written, transferred, and deallocated. The
effect discipline tracks operations performed on each resource using
qualifiers, enabling the type system to express ownership transfer, contextual
freshness, and destructive updates without regions or linearity. We formalize
the calculus, its typing and effect rules, and a compositional operational
semantics that validates use-after-free safety. All metatheoretic results,
including preservation, progress, and effect soundness, are mechanized. The
system models idioms such as reference deallocation, move semantics, reference
swapping, while exposing precise safety guarantee. Together, these
contributions integrate reachability-based reasoning with explicit resource
control, advancing the state of the art in safe manual memory management for
higher-order functional languages.

</details>


### [4] [Concept-Based Generic Programming in C++](https://arxiv.org/abs/2510.08969)
*Bjarne Stroustrup*

Main category: cs.PL

TL;DR: 介绍C++概念编程技术，展示如何通过概念约束泛型代码，提供类型安全且高效的编程方法


<details>
  <summary>Details</summary>
Motivation: 展示C++概念编程的实用性和基本原理，说明概念如何作为C++泛型编程的核心机制，提供类型系统扩展和约束表达

Method: 使用概念编程技术，构建简单类型系统来消除窄化转换并提供范围检查，通过用户定义的概念扩展类型系统

Result: 实现了无额外符号或运行时开销的类型安全编程，展示了概念在C++泛型编程中的实用价值

Conclusion: 概念是C++泛型编程的集成部分，支持通用编程和泛型编程的统一表示，提供了强大的类型约束和扩展能力

Abstract: We present programming techniques to illustrate the facilities and principles
of C++ generic programming using concepts. Concepts are C++'s way to express
constraints on generic code. As an initial example, we provide a simple type
system that eliminates narrowing conversions and provides range checking
without unnecessary notational or run-time overheads. Concepts are used
throughout to provide user-defined extensions to the type system. The aim is to
show their utility and the fundamental ideas behind them, rather than to
provide a detailed or complete explanation of C++'s language support for
generic programming or the extensive support provided by the standard library.
Generic programming is an integral part of C++, rather than an isolated
sub-language. In particular, key facilities support general programming as well
as generic programming (e.g., uniform notation for types, lambdas, variadic
templates, and C++26 static reflection). Finally, we give design rationales and
origins for key parts of the concept design, including use patterns, the
relationship to Object-Oriented Programming, value arguments, notation, concept
type-matching, and definition checking.

</details>


### [5] [A Multilingual Python Programming Language](https://arxiv.org/abs/2510.09591)
*Saad Ahmed Bazaz,Mirza Omer Beg*

Main category: cs.PL

TL;DR: 开发了一个名为UniversalPython的语言转译器，允许用户用自己的人类语言编写Python代码，解决了编程语言对英语知识的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 现有编程语言都要求英语知识，这对许多没有时间和金钱学习英语的新手构成了主要障碍。研究表明人们用母语学习效果更好。

Method: 在Python编程语言之上构建语言转译器，能够将其他人类语言编写的代码转换为Python代码，并以乌尔都语Python为例进行演示。

Result: 成功创建了"乌尔都语Python"，证明了该转译器的可行性。转译器源代码已开源。

Conclusion: 该转译器有潜力扩展到更多人类语言，从而增加编程的可及性，降低学习门槛。

Abstract: All widely used and useful programming languages have a common problem. They
restrict entry on the basis of knowledge of the English language. The lack of
knowledge of English poses a major hurdle to many newcomers who do not have the
resources, in terms of time and money, to learn the English language. Studies
show that people learn better in their own language. Therefore, we propose a
language transpiler built on top of the Python programming language, called
UniversalPython, which allows one to write Python in their own human language.
We demonstrate the ability to create an "Urdu Python" with this transpiler. In
the future, we aim to scale the language to encapsulate more human languages to
increase the availability of programming. The source code for this transpiler
is open-source, and available at
https://github.com/universalpython/universalpython

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [Repairing Regex Vulnerabilities via Localization-Guided Instructions](https://arxiv.org/abs/2510.09037)
*Sicheol Sung,Joonghyuk Hahn,Yo-Sub Han*

Main category: cs.AI

TL;DR: 提出了LRR混合框架，结合符号分析和LLM来修复正则表达式ReDoS漏洞，解决了现有方法在精度和泛化性之间的权衡问题


<details>
  <summary>Details</summary>
Motivation: 正则表达式在现代计算中广泛应用，但存在ReDoS漏洞。现有修复方法面临两难：符号方法精确但无法处理复杂模式，LLM泛化性强但可靠性不足

Method: LRR混合框架：首先用确定性符号模块定位易受攻击的子模式，然后调用LLM为隔离片段生成语义等效的修复

Result: 成功解决了规则修复无法处理的复杂案例，避免了纯LLM方法的语义错误，修复率比最先进方法提高了15.4%

Conclusion: LRR提供了一种经过验证的自动化修复方法学，有效结合了符号分析的可靠性和LLM的泛化能力

Abstract: Regular expressions (regexes) are foundational to modern computing for
critical tasks like input validation and data parsing, yet their ubiquity
exposes systems to regular expression denial of service (ReDoS), a
vulnerability requiring automated repair methods. Current approaches, however,
are hampered by a trade-off. Symbolic, rule-based system are precise but fails
to repair unseen or complex vulnerability patterns. Conversely, large language
models (LLMs) possess the necessary generalizability but are unreliable for
tasks demanding strict syntactic and semantic correctness. We resolve this
impasse by introducing a hybrid framework, localized regex repair (LRR),
designed to harness LLM generalization while enforcing reliability. Our core
insight is to decouple problem identification from the repair process. First, a
deterministic, symbolic module localizes the precise vulnerable subpattern,
creating a constrained and tractable problem space. Then, the LLM invoked to
generate a semantically equivalent fix for this isolated segment. This combined
architecture successfully resolves complex repair cases intractable for
rule-based repair while avoiding the semantic errors of LLM-only approaches.
Our work provides a validated methodology for solving such problems in
automated repair, improving the repair rate by 15.4%p over the
state-of-the-art. Our code is available at https://github.com/cdltlehf/LRR.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?](https://arxiv.org/abs/2510.08609)
*Imranur Rahman,Jill Marley,William Enck,Laurie Williams*

Main category: cs.SE

TL;DR: 本研究通过实证分析评估了不同版本约束类型（固定版本与浮动版本）对依赖包过时和易受攻击可能性的影响，发现在npm、PyPI和Cargo生态系统中，浮动次要版本是最常见的约束类型，而浮动主要版本最不容易导致依赖过时，浮动次要版本最不容易导致易受攻击依赖。


<details>
  <summary>Details</summary>
Motivation: 开发者在依赖管理时需要在固定版本（防止破坏性变更但需手动管理）和浮动版本（自动获取修复但存在风险）之间权衡。安全实践者推荐固定版本以防止供应链攻击，但这可能导致依赖过时。目前缺乏关于不同版本约束类型对依赖状态影响的实证研究。

Method: 首先识别npm、PyPI和Cargo生态系统中依赖版本约束的使用趋势和变更模式，然后使用生存分析对依赖状态转换进行建模，评估固定版本与其他约束类型相比导致依赖过时或易受攻击的可能性。

Result: 在过时和易受攻击的依赖中，最常用的版本约束类型是浮动次要版本，固定版本次之。浮动主要版本最不容易导致依赖过时，浮动次要版本最不容易导致易受攻击依赖。

Conclusion: 研究结果为开发者选择依赖版本约束提供了实证依据，帮助他们在安全性和更新便利性之间做出更明智的权衡。

Abstract: Developers consistently use version constraints to specify acceptable
versions of the dependencies for their project. \emph{Pinning} dependencies can
reduce the likelihood of breaking changes, but comes with a cost of manually
managing the replacement of outdated and vulnerable dependencies. On the other
hand, \emph{floating} can be used to automatically get bug fixes and security
fixes, but comes with the risk of breaking changes. Security practitioners
advocate \emph{pinning} dependencies to prevent against software supply chain
attacks, e.g., malicious package updates. However, since \emph{pinning} is the
tightest version constraint, \emph{pinning} is the most likely to result in
outdated dependencies. Nevertheless, how the likelihood of becoming outdated or
vulnerable dependencies changes across version constraint types is unknown. The
goal of this study is to aid developers in making an informed dependency
version constraint choice by empirically evaluating the likelihood of
dependencies becoming outdated or vulnerable across version constraint types at
scale. In this study, we first identify the trends in dependency version
constraint usage and the patterns of version constraint type changes made by
developers in the npm, PyPI, and Cargo ecosystems. We then modeled the
dependency state transitions using survival analysis and estimated how the
likelihood of becoming outdated or vulnerable changes when using \emph{pinning}
as opposed to the rest of the version constraint types. We observe that among
outdated and vulnerable dependencies, the most commonly used version constraint
type is \emph{floating-minor}, with \emph{pinning} being the next most common.
We also find that \emph{floating-major} is the least likely to result in
outdated and \emph{floating-minor} is the least likely to result in vulnerable
dependencies.

</details>


### [8] [Literate Tracing](https://arxiv.org/abs/2510.09073)
*Matthew Sotoudeh*

Main category: cs.SE

TL;DR: 本文提出了一种称为"文学化追踪"的程序文档范式，通过带注释的具体执行追踪来解释软件系统，并开发了TReX工具来创建交互式、可视化且语义保真的文学化追踪。


<details>
  <summary>Details</summary>
Motivation: 随着计算机系统变得更大更复杂，系统专家需要向新手解释程序工作原理。现有代码注释缺乏全局上下文，设计文档又缺乏与代码的具体连接，因此需要一种更好的文档方法。

Method: 采用文学化追踪范式，通过带注释的具体执行追踪来解释软件系统。开发了TReX工具，能够创建交互式、可视化且保证与程序语义一致的追踪文档。

Result: 使用TReX工具成功为大型系统软件（包括Linux内核、Git源代码控制系统和GCC编译器）的组件编写了文学化追踪文档。

Conclusion: 文学化追踪是一种有效的程序文档方法，能够弥补代码注释和设计文档的不足，通过具体的执行追踪提供更直观的系统理解。

Abstract: As computer systems grow ever larger and more complex, a crucial task in
software development is for one person (the system expert) to communicate to
another (the system novice) how a certain program works. This paper reports on
the author's experiences with a paradigm for program documentation that we call
literate tracing. A literate trace explains a software system using annotated,
concrete execution traces of the system. Literate traces complement both
in-code comments (which often lack global context) and out-of-band design docs
(which often lack a concrete connection to the code). We also describe TReX,
our tool for making literate traces that are interactive, visual, and
guaranteed by construction to be faithful to the program semantics. We have
used TReX to write literate traces explaining components of large systems
software including the Linux kernel, Git source control system, and GCC
compiler.

</details>
