<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [HITrees: Higher-Order Interaction Trees](https://arxiv.org/abs/2510.14558)
*Amir Mohammad Fadaei Ayyam,Michael Sammler*

Main category: cs.PL

TL;DR: 提出了高阶交互树（HITrees），这是第一个在非守卫类型理论中支持高阶效应的交互树变体，通过两种关键技术实现：设计效应概念以表达高阶输入的固定点作为归纳类型，以及使用去函数化编码高阶输出为一阶表示。


<details>
  <summary>Details</summary>
Motivation: 现有交互树虽然提供了可重用的效应库实现组合语义，但其效应概念不支持高阶效应（即接受或返回单子计算的效应），而这些效应对于建模并行组合和call/cc等复杂语义特性至关重要。

Method: 1. 设计效应概念使得高阶输入效应的固定点可以在类型理论中表示为归纳类型；2. 使用去函数化技术将高阶输出编码为一阶表示；3. 在Lean证明助手中实现HITrees，并构建包含并发、递归和call/cc等效应的综合库；4. 提供HITrees的两种解释：状态转换系统和单子程序。

Result: 成功实现了支持高阶效应的交互树变体HITrees，能够表达并行组合和call/cc等复杂语义特性，为复杂系统的形式验证提供了更强大的组合语义基础。

Conclusion: HITrees是第一个在非守卫类型理论中支持高阶效应的交互树变体，通过创新的技术方法解决了现有交互树在高阶效应支持方面的局限性，为建模复杂语义特性提供了更强大的工具。

Abstract: Recent years have witnessed the rise of compositional semantics as a
foundation for formal verification of complex systems. In particular,
interaction trees have emerged as a popular denotational semantics. Interaction
trees achieve compositionality by providing a reusable library of effects.
However, their notion of effects does not support higher-order effects, i.e.,
effects that take or return monadic computations. Such effects are essential to
model complex semantic features like parallel composition and call/cc.
  We introduce Higher-Order Interaction Trees (HITrees), the first variant of
interaction trees to support higher-order effects in a non-guarded type theory.
HITrees accomplish this through two key techniques: first, by designing the
notion of effects such that the fixpoints of effects with higher-order input
can be expressed as inductive types inside the type theory; and second, using
defunctionalization to encode higher-order outputs into a first-order
representation. We implement HITrees in the Lean proof assistant, accompanied
by a comprehensive library of effects including concurrency, recursion, and
call/cc. Furthermore, we provide two interpretations of HITrees, as state
transition systems and as monadic programs. To demonstrate the expressiveness
of HITrees, we apply them to define the semantics of a language with parallel
composition and call/cc.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [2] [TokDrift: When LLM Speaks in Subwords but Code Speaks in Grammar](https://arxiv.org/abs/2510.14972)
*Yinxi Li,Yuntian Deng,Pengyu Nie*

Main category: cs.CL

TL;DR: 论文提出了TokDrift框架，发现代码LLMs对语义相同但格式不同的代码会产生不同的token化结果，导致模型行为显著变化，这揭示了当前子词tokenization在代码理解中的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前代码LLMs使用的子词tokenizer（如BPE）基于统计而非语法，导致语义相同的代码片段会因格式差异（如空格、标识符命名）而产生不同的token化结果，影响模型可靠性。

Method: 引入TokDrift框架，应用语义保持的重写规则创建仅在tokenization上不同的代码变体，在9个代码LLMs（包括超过300亿参数的大模型）上进行测试，并进行分层分析。

Result: 即使微小的格式变化也会导致模型行为显著变化，分层分析显示问题源于早期嵌入层，子词分割未能捕获语法token边界。

Conclusion: 错位的tokenization是代码理解和生成可靠性的隐藏障碍，未来的代码LLMs需要语法感知的tokenization方法。

Abstract: Large language models (LLMs) for code rely on subword tokenizers, such as
byte-pair encoding (BPE), learned from mixed natural language text and
programming language code but driven by statistics rather than grammar. As a
result, semantically identical code snippets can be tokenized differently
depending on superficial factors such as whitespace or identifier naming. To
measure the impact of this misalignment, we introduce TokDrift, a framework
that applies semantic-preserving rewrite rules to create code variants
differing only in tokenization. Across nine code LLMs, including large ones
with over 30B parameters, even minor formatting changes can cause substantial
shifts in model behavior. Layer-wise analysis shows that the issue originates
in early embeddings, where subword segmentation fails to capture grammar token
boundaries. Our findings identify misaligned tokenization as a hidden obstacle
to reliable code understanding and generation, highlighting the need for
grammar-aware tokenization for future code LLMs.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Caruca: Effective and Efficient Specification Mining for Opaque Software Components](https://arxiv.org/abs/2510.14279)
*Evangelos Lamprou,Seong-Heon Jung,Mayank Keoliya,Lukas Lazarek,Konstantinos Kallas,Michael Greenberg,Nikos Vasilakis*

Main category: cs.SE

TL;DR: Caruca是一个自动化规范挖掘系统，能够从命令的用户文档中自动生成规范，消除手动创建规范的需求。


<details>
  <summary>Details</summary>
Motivation: 现有系统需要手动创建部分规范来推理不透明组件（如Unix shell命令），但手动创建过程繁琐、易错，限制了这些系统的实用性。

Method: Caruca首先使用大语言模型将命令文档转换为结构化调用语法，然后探索语法有效的命令调用和执行环境空间，通过系统调用和文件系统级别的拦截来提取关键命令属性。

Result: 在60个GNU Coreutils、POSIX和第三方命令上的应用表明，Caruca为除一个案例外的所有情况生成了正确规范，完全消除了手动工作，并为最先进的静态分析工具提供了完整规范。

Conclusion: Caruca成功实现了命令规范的自动化挖掘，显著提高了规范依赖系统的实用性。

Abstract: A wealth of state-of-the-art systems demonstrate impressive improvements in
performance, security, and reliability on programs composed of opaque
components, such as Unix shell commands. To reason about commands, these
systems require partial specifications. However, creating such specifications
is a manual, laborious, and error-prone process, limiting the practicality of
these systems. This paper presents Caruca, a system for automatic specification
mining for opaque commands. To overcome the challenge of language diversity
across commands, Caruca first instruments a large language model to translate a
command's user-facing documentation into a structured invocation syntax. Using
this representation, Caruca explores the space of syntactically valid command
invocations and execution environments. Caruca concretely executes each
command-environment pair, interposing at the system-call and filesystem level
to extract key command properties such as parallelizability and filesystem pre-
and post-conditions. These properties can be exported in multiple specification
formats and are immediately usable by existing systems. Applying Caruca across
60 GNU Coreutils, POSIX, and third-party commands across several
specification-dependent systems shows that Caruca generates correct
specifications for all but one case, completely eliminating manual effort from
the process and currently powering the full specifications for a
state-of-the-art static analysis tool.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [Tawa: Automatic Warp Specialization for Modern GPUs with Asynchronous References](https://arxiv.org/abs/2510.14719)
*Hongzheng Chen,Bin Fan,Alexander Collins,Bastian Hagedorn,Evghenii Gaburov,Masahiro Masuda,Matthew Brookhart,Chris Sullivan,Jason Knight,Zhiru Zhang,Vinod Grover*

Main category: cs.LG

TL;DR: Tawa是一个自动化编译器，能从高级瓦片化程序自动生成高性能的warp专用代码，解决了GPU SIMT编程模型与任务并行硬件之间的不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现代GPU具有专门的硬件单元支持高性能异步数据流执行，但传统的SIMT编程模型与这种任务并行硬件不匹配，导致编程困难。硬件级的warp专用化虽然能解锁峰值性能，但需要开发者手动管理复杂的低层通信和软件流水线，工作量大且容易出错。

Method: 提出了Tawa编译器，核心是新颖的IR抽象——异步引用(aref)，能在不暴露低层硬件细节的情况下表达warp级通信。使用这种抽象，Tawa自动将程序划分为生产者-消费者角色，并管理复杂的数据流流水线。

Result: 在NVIDIA H100 GPU上的评估显示，Tawa实现了高硬件利用率，在代表性LLM内核上比高度优化的cuBLAS GEMM内核快1.1倍。对于注意力工作负载，比Triton快1.2倍，且与手工优化的CUTLASS C++ FlashAttention-3内核性能相当，但编程工作量大幅减少。

Conclusion: Tawa通过自动化warp专用化代码生成，显著降低了GPU编程的复杂性，同时保持了高性能，为解决GPU编程模型与硬件能力之间的差距提供了有效方案。

Abstract: Modern GPUs feature specialized hardware units that enable high-performance,
asynchronous dataflow execution. However, the conventional SIMT programming
model is fundamentally misaligned with this task-parallel hardware, creating a
significant programmability gap. While hardware-level warp specialization is
the key to unlocking peak performance, it forces developers to manually
orchestrate complex, low-level communication and software pipelines--a process
that is labor-intensive, error-prone, and unsustainable. To address this
challenge, we present Tawa, an automated compiler that systematically generates
high-performance, warp-specialized code from a high-level, tile-based program.
Central to our approach is a novel IR abstraction, asynchronous references
(aref), which expresses warp-level communication without exposing low-level
hardware details. Using this abstraction, Tawa automatically partitions
programs into producer-consumer roles and manages the intricate dataflow
pipeline, relieving developers of invasive kernel rewriting. Evaluation on
NVIDIA H100 GPUs across representative LLM kernels shows that Tawa delivers
high hardware utilization, achieving up to 1.1$\times$ speedup over highly
optimized cuBLAS GEMM kernels. For attention workloads, Tawa attains
1.2$\times$ speedup over Triton and matches the performance of the
hand-optimized CUTLASS C++ FlashAttention-3 kernel with far less programming
effort.

</details>
