<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Visualizing miniKanren Search with a Fine-Grained Small-Step Semantics](https://arxiv.org/abs/2510.15178)
*Brysen Pfingsten,Jason Hemann*

Main category: cs.PL

TL;DR: 提出了一个确定性小步操作语义模型，用于显式表示miniKanren执行过程中的搜索树演化，并基于此实现了一个交互式可视化工具。


<details>
  <summary>Details</summary>
Motivation: 为了精确建模miniKanren的交织搜索和目标调度过程，帮助用户理解其公平搜索行为和操作效果，特别是令人惊讶的答案顺序。

Method: 开发了确定性小步操作语义，明确表示执行过程中的搜索树演化，并基于该模型实现交互式可视化器。

Result: 通过基于属性的测试验证了语义和工具的正确性，并用多个示例进行了说明。

Conclusion: 该语义模型和可视化工具可作为教学概念机器，帮助用户推理miniKanren的公平搜索行为。

Abstract: We present a deterministic small-step operational semantics for miniKanren
that explicitly represents the evolving search tree during execution. This
semantics models interleaving and goal scheduling at fine granularity, allowing
each evaluation step-goal activation, suspension, resumption, and success -- to
be visualized precisely. Building on this model, we implement an interactive
visualizer that renders the search tree as it develops and lets users step
through execution. The tool acts as a pedagogical notional machine for
reasoning about miniKanren's fair search behavior, helping users understand
surprising answer orders and operational effects. Our semantics and tool are
validated through property-based testing and illustrated with several examples.

</details>


### [2] [Grassroots Logic Programs: A Secure, Multiagent, Concurrent, Logic Programming Language](https://arxiv.org/abs/2510.15747)
*Ehud Shapiro*

Main category: cs.PL

TL;DR: GLP是一种安全的多代理并发逻辑编程语言，用于实现基层平台，通过加密签名和认证消息提供安全通信通道，支持身份和代码完整性验证。


<details>
  <summary>Details</summary>
Motivation: 基层平台面临恶意参与者的挑战，需要安全编程支持来确保正确参与者能够可靠识别彼此、建立安全通信并验证代码完整性。

Method: 扩展逻辑程序，添加配对的单读单写逻辑变量，通过加密签名和认证消息实现安全通信，逐步构建并发GLP、多代理GLP，并增强加密安全性。

Result: 证明了GLP计算是演绎的，保持了SRSW特性、无环性和单调性，多代理GLP具有基层特性，GLP流实现了区块链安全属性，并展示了安全的基层社交网络应用。

Conclusion: GLP为基层平台提供了安全可靠的实现基础，能够建立认证的点对点连接，支持构建基层社交网络、加密货币和民主联邦等应用。

Abstract: Grassroots platforms are distributed applications run by\linebreak
cryptographically-identified people on their networked personal devices, where
multiple disjoint platform instances emerge independently and coalesce when
they interoperate. Their foundation is the grassroots social graph, upon which
grassroots social networks, grassroots cryptocurrencies, and grassroots
democratic federations can be built.
  Grassroots platforms have yet to be implemented, the key challenge being
faulty and malicious participants: without secure programming support, correct
participants cannot reliably identify each other, establish secure
communication, or verify each other's code integrity.
  We present Grassroots Logic Programs (GLP), a secure, multiagent, concurrent,
logic programming language for implementing grassroots platforms. GLP extends
logic programs with paired single-reader/single-writer (SRSW) logic variables,
providing secure communication channels among cryptographically-identified
people through encrypted, signed and attested messages, which enable identity
and code integrity verification. We present GLP progressively: logic programs,
concurrent GLP, multiagent GLP, augmenting it with cryptographic security, and
providing smartphone implementation-ready specifications. We prove safety
properties including that GLP computations are deductions, SRSW preservation,
acyclicity, and monotonicity. We prove multiagent GLP is grassroots and that
GLP streams achieve blockchain security properties. We present a grassroots
social graph protocol establishing authenticated peer-to-peer connections and
demonstrate secure grassroots social networking applications.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [Leveraging Test Driven Development with Large Language Models for Reliable and Verifiable Spreadsheet Code Generation: A Research Framework](https://arxiv.org/abs/2510.15585)
*Dr Simon Thorne,Dr Advait Sarkar*

Main category: cs.SE

TL;DR: 本文提出将测试驱动开发(TDD)与大型语言模型(LLM)生成相结合的研究框架，旨在提高生成代码的正确性和可靠性，特别是在高风险领域如金融建模和科学计算中。


<details>
  <summary>Details</summary>
Motivation: LLM在生成代码时经常出现幻觉、逻辑不一致和语法错误等问题，在需要高准确性的领域风险尤为突出。需要一种方法来增强生成输出的可靠性和用户信心。

Method: 采用"测试优先"的方法论，将TDD实践与LLM驱动生成相结合，提供技术约束和认知支撑。框架适用于多种编程环境，包括电子表格公式生成、Python脚本和Rust等强类型语言。

Result: 提出了明确的研究框架设计，包括参与者分组、评估指标和基于TDD的提示示例。通过强调测试驱动思维，旨在提高计算思维、提示工程技能和用户参与度。

Conclusion: 该框架有望改善LLM生成代码的质量，特别有利于缺乏正式编程培训的电子表格用户。邀请合作来完善和实证评估该方法，最终在教育和专业开发实践中建立负责任和可靠的LLM集成。

Abstract: Large Language Models (LLMs), such as ChatGPT, are increasingly leveraged for
generating both traditional software code and spreadsheet logic. Despite their
impressive generative capabilities, these models frequently exhibit critical
issues such as hallucinations, subtle logical inconsistencies, and syntactic
errors, risks particularly acute in high stakes domains like financial
modelling and scientific computations, where accuracy and reliability are
paramount. This position paper proposes a structured research framework that
integrates the proven software engineering practice of Test-Driven Development
(TDD) with Large Language Model (LLM) driven generation to enhance the
correctness of, reliability of, and user confidence in generated outputs. We
hypothesise that a "test first" methodology provides both technical constraints
and cognitive scaffolding, guiding LLM outputs towards more accurate,
verifiable, and comprehensible solutions. Our framework, applicable across
diverse programming contexts, from spreadsheet formula generation to scripting
languages such as Python and strongly typed languages like Rust, includes an
explicitly outlined experimental design with clearly defined participant
groups, evaluation metrics, and illustrative TDD based prompting examples. By
emphasising test driven thinking, we aim to improve computational thinking,
prompt engineering skills, and user engagement, particularly benefiting
spreadsheet users who often lack formal programming training yet face serious
consequences from logical errors. We invite collaboration to refine and
empirically evaluate this approach, ultimately aiming to establish responsible
and reliable LLM integration in both educational and professional development
practices.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [4] [ProofOptimizer: Training Language Models to Simplify Proofs without Human Demonstrations](https://arxiv.org/abs/2510.15700)
*Alex Gu,Bartosz Piotrowski,Fabian Gloeckle,Kaiyu Yang,Aram H. Markosyan*

Main category: cs.LG

TL;DR: ProofOptimizer是首个无需人工监督即可简化Lean证明的语言模型，通过专家迭代和强化学习训练，在标准基准测试中显著压缩证明长度（miniF2F减少87%，PutnamBench减少57%，IMO 2025证明减少49%）。


<details>
  <summary>Details</summary>
Motivation: 神经定理证明生成的证明过于冗长（数千行），虽然能被Lean等系统机械验证，但人类难以理解，限制了数学洞察力。证明简化成为关键瓶颈，但现有方法难以处理RL训练证明器生成的极长证明。

Method: 通过专家迭代和强化学习训练ProofOptimizer模型，使用Lean验证简化并提供训练信号。推理时采用迭代证明缩短工作流程，逐步减少证明长度。

Result: ProofOptimizer显著压缩了最先进RL训练证明器生成的证明：miniF2F减少87%，PutnamBench减少57%，Seed-Prover的IMO 2025证明减少49%。简化后的证明在Lean中检查速度更快，作为训练数据重用时还能进一步提升下游证明器性能。

Conclusion: ProofOptimizer是首个无需人工监督的Lean证明简化模型，能有效解决神经定理证明中证明冗长的问题，不仅使证明更简洁，还提高了验证效率和下游性能。

Abstract: Neural theorem proving has advanced rapidly in the past year, reaching IMO
gold-medalist capabilities and producing formal proofs that span thousands of
lines. Although such proofs are mechanically verified by formal systems like
Lean, their excessive length renders them difficult for humans to comprehend
and limits their usefulness for mathematical insight. Proof simplification is
therefore a critical bottleneck. Yet, training data for this task is scarce,
and existing methods -- mainly agentic scaffolding with off-the-shelf LLMs --
struggle with the extremely long proofs generated by RL-trained provers. We
introduce ProofOptimizer, the first language model trained to simplify Lean
proofs without requiring additional human supervision. ProofOptimizer is
trained via expert iteration and reinforcement learning, using Lean to verify
simplifications and provide training signal. At inference time, it operates
within an iterative proof-shortening workflow, progressively reducing proof
length. Experiments show that ProofOptimizer substantially compresses proofs
generated by state-of-the-art RL-trained provers on standard benchmarks,
reducing proof length by 87% on miniF2F, 57% on PutnamBench, and 49% on
Seed-Prover's IMO 2025 proofs. Beyond conciseness, the simplified proofs check
faster in Lean and further improve downstream prover performance when reused as
training data for supervised finetuning.

</details>
