<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Dependent Session Types for Verified Concurrent Programming](https://arxiv.org/abs/2510.19129)
*Qiancheng Fu,Hongwei Xi,Ankush Das*

Main category: cs.PL

TL;DR: TLLC扩展了TLL类型系统，增加了基于会话的并发机制和依赖会话类型，使得并发程序能够通过关系验证与其顺序对应程序相关联，从而验证数据结构和并发算法的正确性。


<details>
  <summary>Details</summary>
Motivation: 将依赖类型与会话类型结合，使会话协议能够指定通信消息的属性，并通过关系验证将顺序程序的正确性证明提升到并发实现。

Method: 开发了直觉主义会话类型的新形式化方法，扩展TLL类型系统，实现依赖会话类型，并构建原型编译器将TLLC程序转换为并发C代码。

Result: 证明了语言在项演算和进程演算中的元理论可靠性，实现了队列等数据结构和map-reduce等并发算法的内在正确性验证。

Conclusion: TLLC使会话类型成为验证数据结构和并发算法正确性的强大工具，其会话类型形式化方法可广泛应用于其他类型系统的集成。

Abstract: We present TLLC which extends the Two-Level Linear dependent type theory
(TLL) with session-based concurrency. Equipped with Martin-L\"{o}f style
dependency, the session types of TLLC allow protocols to specify properties of
communicated messages. When used in conjunction with the dependent type
machinery already present in TLL, dependent session types facilitate a form of
relational verification by relating concurrent programs with their idealized
sequential counterparts. Correctness properties proven for sequential programs
can be easily lifted to their corresponding concurrent implementations. TLLC
makes session types a powerful tool for intrinsically verifying the correctness
of data structures such as queues and concurrent algorithms such as map-reduce.
To extend TLL with session types, we develop a novel formulation of
intuitionistic session type which we believe to be widely applicable for
integrating session types into other type systems beyond the context of TLLC.
We study the meta-theory of our language, proving its soundness as both a term
calculus and a process calculus. To demonstrate the practicality of TLLC, we
have implemented a prototype compiler that translates TLLC programs into
concurrent C code, which has been extensively evaluated.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [QiMeng-SALV: Signal-Aware Learning for Verilog Code Generation](https://arxiv.org/abs/2510.19296)
*Yang Zhang,Rui Zhang,Jiaming Guo,Lei Huang,Di Huang,Yunpu Zhao,Shuyao Cheng,Pengwei Jin,Chongxiao Li,Zidong Du,Xing Hu,Qi Guo,Yunji Chen*

Main category: cs.LG

TL;DR: 提出QiMeng-SALV方法，通过利用功能正确输出信号的代码片段来优化Verilog代码生成的强化学习训练，实现从模块级到信号级的细粒度优化。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在Verilog代码生成方面进展显著，但缺乏有意义的功能奖励阻碍了基于强化学习的偏好优化，难以生成功能正确的Verilog代码。

Method: 验证生成模块中信号的功能正确性，使用抽象语法树识别信号感知代码片段，引入信号感知DPO在正确信号级代码段上进行优化，避免错误信号的噪声干扰。

Result: 在VerilogEval和RTLLM基准测试中达到最先进性能，7B参数模型匹配DeepSeek v3 671B模型的性能，显著优于在同一数据集上训练的开源模型CodeV。

Conclusion: QiMeng-SALV实现了从传统模块级到细粒度信号级优化的范式转变，解决了功能奖励不足的问题，为自动化电路设计提供了有效解决方案。

Abstract: The remarkable progress of Large Language Models (LLMs) presents promising
opportunities for Verilog code generation which is significantly important for
automated circuit design. The lacking of meaningful functional rewards hinders
the preference optimization based on Reinforcement Learning (RL) for producing
functionally correct Verilog code. In this paper, we propose Signal-Aware
Learning for Verilog code generation (QiMeng-SALV) by leveraging code segments
of functionally correct output signal to optimize RL training. Considering
Verilog code specifies the structural interconnection of hardware gates and
wires so that different output signals are independent, the key insight of
QiMeng-SALV is to extract verified signal-aware implementations in partially
incorrect modules, so as to enhance the extraction of meaningful functional
rewards. Roughly, we verify the functional correctness of signals in generated
module by comparing with that of reference module in the training data. Then
abstract syntax tree (AST) is employed to identify signal-aware code segments
which can provide meaningful functional rewards from erroneous modules.
Finally, we introduce signal-aware DPO which is optimized on the correct
signal-level code segments, thereby preventing noise and interference from
incorrect signals. The proposed QiMeng-SALV underscores the paradigm shift from
conventional module-level to fine-grained signal-level optimization in Verilog
code generation, addressing the issue of insufficient functional rewards.
Experiments demonstrate that our method achieves state-of-the-art performance
on VerilogEval and RTLLM, with a 7B parameter model matching the performance of
the DeepSeek v3 671B model and significantly outperforming the leading
open-source model CodeV trained on the same dataset. Our code is available at
https://github.com/zy1xxx/SALV.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [3] [Comparative analysis of large data processing in Apache Spark using Java, Python and Scala](https://arxiv.org/abs/2510.19012)
*Ivan Borodii,Illia Fedorovych,Halyna Osukhivska,Diana Velychko,Roman Butsii*

Main category: cs.DC

TL;DR: 该研究比较了在Apache Spark平台上使用Java、Python和Scala处理大型数据集的性能差异。结果显示，编程语言对Spark算法效率有显著影响：Python在小数据量（5MB）处理中最快，而Scala和Java在复杂操作和大数据量（1.6GB）处理中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单个处理阶段，缺乏对使用Apache Iceberg的完整ETL工作流在不同编程语言下的全面性能比较。

Method: 通过执行从CSV文件下载数据、转换并加载到Apache Iceberg分析表的操作，比较三种编程语言在Spark平台上的性能表现。

Result: 处理5MB文件时Python最快（6.71秒）；处理1.6GB文件时三种语言性能相近，Python稍快（46.34秒）；复杂操作（合并两个CSV文件）中Scala最快（374.42秒），Python最慢（398.32秒）。

Conclusion: 编程语言显著影响Spark数据处理效率：Scala和Java更适合处理大数据量和复杂操作，Python在小数据量处理中具有优势。研究结果可为根据具体性能需求和数据处理量优化数据流程提供参考。

Abstract: During the study, the results of a comparative analysis of the process of
handling large datasets using the Apache Spark platform in Java, Python, and
Scala programming languages were obtained. Although prior works have focused on
individual stages, comprehensive comparisons of full ETL workflows across
programming languages using Apache Iceberg remain limited. The analysis was
performed by executing several operations, including downloading data from CSV
files, transforming and loading it into an Apache Iceberg analytical table. It
was found that the performance of the Spark algorithm varies significantly
depending on the amount of data and the programming language used. When
processing a 5-megabyte CSV file, the best result was achieved in Python: 6.71
seconds, which is superior to Scala's score of 9.13 seconds and Java's time of
9.62 seconds. For processing a large CSV file of 1.6 gigabytes, all programming
languages demonstrated similar results: the fastest performance was showed in
Python: 46.34 seconds, while Scala and Java showed results of 47.72 and 50.56
seconds, respectively. When performing a more complex operation that involved
combining two CSV files into a single dataset for further loading into an
Apache Iceberg table, Scala demonstrated the highest performance, at 374.42
seconds. Java processing was completed in 379.8 seconds, while Python was the
least efficient, with a runtime of 398.32 seconds. It follows that the
programming language significantly affects the efficiency of data processing by
the Apache Spark algorithm, with Scala and Java being more productive for
processing large amounts of data and complex operations, while Python
demonstrates an advantage in working with small amounts of data. The results
obtained can be useful for optimizing data handling processes depending on
specific performance requirements and the amount of information being
processed.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [An Empirical Study of Bitwise Operators Intuitiveness through Performance Metrics](https://arxiv.org/abs/2510.19281)
*Shubham Joshi*

Main category: cs.SE

TL;DR: 研究探讨了不同编程背景人群对位运算符的可读性和理解能力，发现某些运算符（如OR、NOT、左移）在任务完成时间上有显著差异。


<details>
  <summary>Details</summary>
Motivation: 研究位运算符在编程中的可读性和理解性差异，检验不同编程经验人群在使用位运算符时的表现差异。

Method: 采用被试内实验设计，让23名不同编程背景的参与者（从无编程经验到博士水平）完成JavaScript编程任务，记录任务完成时间和准确率。

Result: 运算符是预测响应时间的因素之一，具有小而显著的影响（R²=0.032，F(1,494)=16.5，p<.001）。OR、NOT和左移运算符在任务完成时间上表现出统计显著性。

Conclusion: 位运算符的复杂性通常不会导致更长的任务完成时间，但某些运算符不够直观，需要进一步研究和重新设计以提高可理解性。

Abstract: Objectives: This study aims to investigate the readability and
understandability of bitwise operators in programming, with the main hypothesis
that there will be a difference in the performance metrics (response time and
error rate) between participants exposed to various bitwise operators related
questions and those who are not.
  Participants: Participants in this human research study include people
without programming background, novice programmers, and university students
with varying programming experience (from freshmen to PhD level). There were 23
participants for this study.
  Study Methods: This study uses an Within-Subjects Experimental Design to
assess how people with diverse programming backgrounds understand and use
bitwise operators. Participants complete tasks in JavaScript program, and their
task completion time and accuracy of the tasks are recorded for analysis.
  Findings: The results indicate that operators can be one of the factors
predicting response time, with a small but significant effect, with R-squared
0.032, (1, 494) = 16.5, p < .001. Additionally, some operators like OR, NOT,
and Left Shift showed statistical significance in task completion times
compared to other operators.
  Conclusions: While the complexity of bitwise operators did not generally
result in longer task completion times, certain operators were found to be less
intuitive, suggesting the need for further investigation and potential redesign
for improved understandability.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [5] [Tidying Up the Address Space](https://arxiv.org/abs/2510.19765)
*Vinay Banakar,Suli Yang,Kan Wu,Andrea C. Arpaci-Dusseau,Remzi H. Arpaci-Dusseau,Kimberly Keeton*

Main category: cs.OS

TL;DR: HADES通过地址空间工程解决数据中心内存分层中的热冷数据碎片化问题，将应用程序虚拟地址空间动态重组为均匀的热区和冷区，使现有页面级分层系统能够有效管理内存。


<details>
  <summary>Details</summary>
Motivation: 数据中心内存分层未能充分发挥潜力，原因是热冷数据碎片化——热对象和冷对象在内存页面中混杂，这阻碍了基于页面的回收系统区分真正热的页面和包含大部分冷对象的页面，从根本上限制了内存效率。

Method: 引入地址空间工程：动态重组应用程序虚拟地址空间，创建均匀的热区和冷区；HADES通过编译器-运行时系统实现这种前端/后端方法，跟踪和迁移基于访问模式的对象，需要最少的开发者干预。

Result: 在十个数据结构上的评估显示，内存减少高达70%，性能开销仅为3%。

Conclusion: 地址空间工程使现有回收系统能够积极回收内存而不会降低性能。

Abstract: Memory tiering in datacenters does not achieve its full potential due to
hotness fragmentation -- the intermingling of hot and cold objects within
memory pages. This fragmentation prevents page-based reclamation systems from
distinguishing truly hot pages from pages containing mostly cold objects,
fundamentally limiting memory efficiency despite highly skewed accesses. We
introduce address-space engineering: dynamically reorganizing application
virtual address spaces to create uniformly hot and cold regions that any
page-level tiering backend can manage effectively. HADES demonstrates this
frontend/backend approach through a compiler-runtime system that tracks and
migrates objects based on access patterns, requiring minimal developer
intervention. Evaluations across ten data structures achieve up to 70% memory
reduction with 3% performance overhead, showing that address space engineering
enables existing reclamation systems to reclaim memory aggressively without
performance degradation.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [6] [Code Sharing in Healthcare Research: A Practical Guide and Recommendations for Good Practice](https://arxiv.org/abs/2510.19279)
*Lukas Hughes-Noehrer,Matthew J Parkes,Andrew Stewart,Anthony J Wilson,Gary S Collins,Richard D Riley,Maya Mathur,Matthew P Fox,Nazrul Islam,Paul N Zivich,Timothy J Feeney*

Main category: cs.CY

TL;DR: 这是一篇关于医疗研究中代码共享的实用指南，强调遵循FAIR原则来提高代码的透明度、可重复性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着健康研究中计算分析日益复杂，透明地共享分析代码对于可重复性和信任至关重要。作者旨在解决代码共享的常见障碍，帮助研究人员遵循出版商和资助机构的新标准。

Method: 提供基于开放科学实践的可操作建议，强调FAIR（可查找、可访问、可互操作、可重用）原则，指导如何使代码更健壮、可重用并接受科学审查。

Result: 该指南支持更好的科学实践，为计算驱动的实践提供更可靠的证据基础，帮助研究人员满足代码共享的新要求。

Conclusion: 透明地共享分析代码是医疗研究可重复性和信任的关键，遵循FAIR原则的代码共享实践能够提升科学质量并满足行业标准。

Abstract: As computational analysis becomes increasingly more complex in health
research, transparent sharing of analytical code is vital for reproducibility
and trust. This practical guide, aligned to open science practices, outlines
actionable recommendations for code sharing in healthcare research. Emphasising
the FAIR (Findable, Accessible, Interoperable, Reusable) principles, the
authors address common barriers and provide clear guidance to help make code
more robust, reusable, and scrutinised as part of the scientific record. This
supports better science and more reliable evidence for computationally-driven
practice and helps to adhere to new standards and guidelines of codesharing
mandated by publishers and funding bodies.

</details>
