<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 6]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Prompt Decorators: A Declarative and Composable Syntax for Reasoning, Formatting, and Control in LLMs](https://arxiv.org/abs/2510.19850)
*Mostapha Kalami Heris*

Main category: cs.PL

TL;DR: 提出了Prompt Decorators框架，通过声明式、可组合的语法控制LLM行为，使用紧凑的控制标记如+++Reasoning、+++Tone等来管理推理风格、结构和语调等行为维度。


<details>
  <summary>Details</summary>
Motivation: 传统提示工程依赖冗长的自然语言指令，限制了可重复性、模块化和可解释性。用户缺乏对LLM推理和输出表达方式的一致控制。

Method: 定义了20个核心装饰器，分为认知与生成、表达与系统两个功能家族，每个装饰器管理特定行为维度。提供了统一语法、作用域模型和确定性处理流程。

Result: 通过示例用例展示了改进的推理透明度、降低的提示复杂性和跨领域的标准化模型行为。

Conclusion: Prompt Decorators通过将任务意图与执行行为解耦，为提示设计创建了可重用和可解释的接口，对互操作性、行为一致性和可扩展AI系统的声明式接口开发具有重要意义。

Abstract: Large Language Models (LLMs) are central to reasoning, writing, and
decision-support workflows, yet users lack consistent control over how they
reason and express outputs. Conventional prompt engineering relies on verbose
natural-language instructions, limiting reproducibility, modularity, and
interpretability. This paper introduces Prompt Decorators, a declarative,
composable syntax that governs LLM behavior through compact control tokens such
as +++Reasoning, +++Tone(style=formal), and +++Import(topic="Systems
Thinking"). Each decorator modifies a behavioral dimension, such as reasoning
style, structure, or tone, without changing task content. The framework
formalizes twenty core decorators organized into two functional families
(Cognitive & Generative and Expressive & Systemic), each further decomposed
into subcategories that govern reasoning, interaction, expression, and
session-control. It defines a unified syntax, scoping model, and deterministic
processing pipeline enabling predictable and auditable behavior composition. By
decoupling task intent from execution behavior, Prompt Decorators create a
reusable and interpretable interface for prompt design. Illustrative use cases
demonstrate improved reasoning transparency, reduced prompt complexity, and
standardized model behavior across domains. The paper concludes with
implications for interoperability, behavioral consistency, and the development
of declarative interfaces for scalable AI systems.

</details>


### [2] [A Specification's Realm: Characterizing the Knowledge Required for Executing a Given Algorithm Specification](https://arxiv.org/abs/2510.19853)
*Assaf Marron,David Harel*

Main category: cs.PL

TL;DR: 本文提出算法规范的"领域"概念，即执行算法所需的前提知识集合，包括语法语义、领域知识、实体关系、因果关系规则等，这些知识可以整理成实用规模的文档。


<details>
  <summary>Details</summary>
Motivation: 为了使自然语言或伪代码算法规范能够被机械执行，需要明确执行代理所需的前提知识，这些知识应该独立于具体系统实现。

Method: 提出算法规范"领域"的概念，系统分析执行算法所需的各种知识类型，包括语言语法语义、受限领域知识、实体关系、因果关系规则等，并探讨如何自动化生成这些文档。

Result: 建立了算法规范领域的初步特征描述，表明这种前提知识可以汇总成实用规模的文档，有助于算法在不同系统中的方法化实现和形式化验证。

Conclusion: 算法规范领域的概念有助于提高算法规范的可执行性和可验证性，同时提出了执行忠实度评估的问题，这与正确性评估是不同的概念。

Abstract: An algorithm specification in natural language or pseudocode is expected to
be clear and explicit enough to enable mechanical execution. In this position
paper we contribute an initial characterization of the knowledge that an
executing agent, human or machine, should possess in order to be able to carry
out the instructions of a given algorithm specification as a stand-alone
entity, independent of any system implementation. We argue that, for that
algorithm specification, such prerequisite knowledge, whether unique or shared
with other specifications, can be summarized in a document of practical size.
We term this document the realm of the algorithm specification. The generation
of such a realm is itself a systematic analytical process, significant parts of
which can be automated with the help of large language models and the reuse of
existing documents. The algorithm-specification's realm would consist of
specification language syntax and semantics, domain knowledge restricted to the
referenced entities, inter-entity relationships, relevant underlying
cause-and-effect rules, and detailed instructions and means for carrying out
certain operations. Such characterization of the realm can contribute to
methodological implementation of the algorithm specification in diverse systems
and to its formalization for mechanical verification. The paper also touches
upon the question of assessing execution faithfulness, which is distinct from
correctness: in the absence of a reference interpretation of natural language
or pseudocode specification with a given vocabulary, how can we determine if an
observed agent's execution indeed complies with the input specification.

</details>


### [3] [Deconstructed Proto-Quipper: A Rational Reconstruction](https://arxiv.org/abs/2510.20018)
*Ryan Kavanagh,Chuta Sano,Brigitte Pientka*

Main category: cs.PL

TL;DR: Proto-Quipper-A是对Proto-Quipper量子编程语言的重构，使用线性λ演算和伴随逻辑基础来简化量子电路生成，具有简单的操作语义和可证明的归一化特性。


<details>
  <summary>Details</summary>
Motivation: Proto-Quipper语言具有复杂的操作语义，依赖于集合论操作和新鲜名称生成，这使得使用标准编程语言技术进行推理和机械化变得困难。

Method: 使用线性λ演算描述量子电路，其范式与盒线电路图紧密对应。通过伴随逻辑基础将电路语言与线性/非线性函数语言集成，重构Proto-Quipper的电路编程抽象。

Result: Proto-Quipper-A具有简单的按值调用归约语义，并且被证明是归一化的。展示了如何使用标准逻辑关系证明线性和子结构系统的归一化。

Conclusion: Proto-Quipper-A为Proto-Quipper语言提供了更易处理的基础，避免了现有线性逻辑关系的固有复杂性。

Abstract: The Proto-Quipper family of programming languages aims to provide a formal
foundation for the Quipper quantum programming language. Unfortunately,
Proto-Quipper languages have complex operational semantics: they are inherently
effectful, and they rely on set-theoretic operations and fresh name generation
to manipulate quantum circuits. This makes them difficult to reason about using
standard programming language techniques and, ultimately, to mechanize. We
introduce Proto-Quipper-A, a rational reconstruction of Proto-Quipper languages
for static circuit generation. It uses a linear $\lambda$-calculus to describe
quantum circuits with normal forms that closely correspond to box-and-wire
circuit diagrams. Adjoint-logical foundations integrate this circuit language
with a linear/non-linear functional language and let us reconstruct
Proto-Quipper's circuit programming abstractions using more primitive
adjoint-logical operations. Proto-Quipper-A enjoys a simple call-by-value
reduction semantics, and to illustrate its tractability as a foundation for
Proto-Quipper languages, we show that it is normalizing. We show how to use
standard logical relations to prove normalization of linear and substructural
systems, thereby avoiding the inherent complexity of existing linear logical
relations.

</details>


### [4] [Deciding not to Decide: Sound and Complete Effect Inference in the Presence of Higher-Rank Polymorphism](https://arxiv.org/abs/2510.20532)
*Patrycja Balik,Szymon Jędras,Piotr Polesiuk*

Main category: cs.PL

TL;DR: 提出了一种用于类型和效应系统的效应推断算法，支持子类型化、高阶多态性和直观的集合语义，通过将效应约束转换为命题逻辑公式来处理作用域问题。


<details>
  <summary>Details</summary>
Motivation: 类型和效应系统尚未广泛采用，因为现有算法在表达能力、直观性和可判定性之间做出妥协，需要更复杂的推断算法。

Method: 通过将效应约束转换为命题逻辑公式来延迟求解，处理高阶多态性的作用域问题，并在Rocq证明助手中形式化验证。

Result: 算法在声明性类型和效应系统中被证明是健全和完备的，并已在实际编程语言中成功实现。

Conclusion: 该工作提供了一种表达能力更强、更直观的类型和效应推断方法，有望促进类型和效应系统的更广泛采用。

Abstract: Type-and-effect systems help the programmer to organize data and
computational effects in a program. While for traditional type systems
expressive variants with sophisticated inference algorithms have been developed
and widely used in programming languages, type-and-effect systems did not yet
gain widespread adoption. One reason for this is that type-and-effect systems
are more complex and the existing inference algorithms make compromises between
expressiveness, intuitiveness, and decidability. In this work, we present an
effect inference algorithm for a type-and-effect system with subtyping,
expressive higher-rank polymorphism, and intuitive set-like semantics of
effects. In order to deal with scoping issues of higher-rank polymorphism, we
delay solving of effect constraints by transforming them into formulae of
propositional logic. We prove soundness and completeness of our algorithm with
respect to a declarative type-and-effect system. All the presented results have
been formalized in the Rocq proof assistant, and the algorithm has been
successfully implemented in a realistic programming language.

</details>


### [5] [Compiling the Mimosa programming language to RTOS tasks](https://arxiv.org/abs/2510.20547)
*Nikolaus Huber,Susanne Graf,Philipp Rümmer,Wang Yi*

Main category: cs.PL

TL;DR: 提出了Mimosa编程语言的编译方案，基于MIMOS计算模型，将嵌入式系统软件描述为通过FIFO队列通信的时间触发进程集合


<details>
  <summary>Details</summary>
Motivation: 为Mimosa语言开发正式的编译方案，将协调层映射到实时操作系统原语

Method: 基于Lustre编译方案的适配，针对Mimosa语义进行形式化描述

Result: 成功开发了Mimosa语言的编译方案

Conclusion: 该编译方案能够将Mimosa程序有效映射到实时操作系统环境

Abstract: This paper introduces a compilation scheme for programs written in the Mimosa
programming language, which builds upon the MIMOS model of computation. Mimosa
describes embedded systems software as a collection of time-triggered processes
which communicate through FIFO queues. We formally describe an adaptation of
the Lustre compilation scheme to the semantics of Mimosa and show how the
coordination layer can be mapped to real-time operating system primitives.

</details>


### [6] [SafeFFI: Efficient Sanitization at the Boundary Between Safe and Unsafe Code in Rust and Mixed-Language Applications](https://arxiv.org/abs/2510.20688)
*Oliver Braunsdorf,Tim Lange,Konrad Hohentanner,Julian Horsch,Johannes Kinder*

Main category: cs.PL

TL;DR: SafeFFI是一种优化Rust二进制文件中内存安全检测的系统，通过在unsafe和safe代码边界进行检测，将内存安全执行从sanitizer转移到Rust类型系统，显著减少不必要的检查。


<details>
  <summary>Details</summary>
Motivation: Unsafe Rust代码在与C/C++库互操作和实现底层数据结构时是必要的，但可能导致内存安全违规。现有sanitizer会对所有内存访问进行检查，包括Rust类型系统保证安全的部分，造成性能损失。

Method: 在unsafe和safe代码边界进行内存安全检测，将内存安全执行责任从sanitizer转移到Rust类型系统，避免昂贵的全程序分析。

Result: 相比现有方法，编译时开销显著降低（2.64倍对比8.83倍以上），在流行的Rust crate和已知漏洞代码上，减少sanitizer检查达98%，同时保持正确性并检测所有空间和时间内存安全违规。

Conclusion: SafeFFI在保持内存安全检测能力的同时，通过智能的边界检测机制大幅提升了性能，为Rust程序的运行时安全检测提供了高效解决方案。

Abstract: Unsafe Rust code is necessary for interoperability with C/C++ libraries and
implementing low-level data structures, but it can cause memory safety
violations in otherwise memory-safe Rust programs. Sanitizers can catch such
memory errors at runtime, but introduce many unnecessary checks even for memory
accesses guaranteed safe by the Rust type system. We introduce SafeFFI, a
system for optimizing memory safety instrumentation in Rust binaries such that
checks occur at the boundary between unsafe and safe code, handing over the
enforcement of memory safety from the sanitizer to the Rust type system. Unlike
previous approaches, our design avoids expensive whole-program analysis and
adds much less compile-time overhead (2.64x compared to over 8.83x). On a
collection of popular Rust crates and known vulnerable Rust code, SafeFFI
achieves superior performance compared to state-of-the-art systems, reducing
sanitizer checks by up to 98%, while maintaining correctness and flagging all
spatial and temporal memory safety violations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [7] [From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph](https://arxiv.org/abs/2510.19873)
*Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li*

Main category: cs.LG

TL;DR: ReGraphT是一个免训练的检索增强生成框架，通过构建CUDA优化轨迹的推理图，将LLM级推理能力转移到小型模型，使SLM在CUDA代码生成任务上接近LLM性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在生成优化CUDA代码方面表现良好，但存在代码泄露风险和计算成本高的问题。SLM虽然轻量且隐私友好，但在复杂CUDA生成任务中推理能力有限。

Method: 将CUDA优化轨迹组织为结构化推理图，将组合优化建模为状态转换，利用蒙特卡洛图搜索进行高效探索。

Result: ReGraphT在CUDAEval和ParEval上平均实现2.33倍加速，优于HPC专用微调模型和其他检索增强方法，使SLM接近LLM性能水平。

Conclusion: ReGraphT框架成功地将LLM级推理能力转移到SLM，解决了隐私风险和计算开销问题，为高效CUDA代码生成提供了可行方案。

Abstract: Despite significant evolution of CUDA programming and domain-specific
libraries, effectively utilizing GPUs with massively parallel engines remains
difficult. Large language models (LLMs) show strong potential in generating
optimized CUDA code from sequential code. However, using LLMs in practice faces
two major challenges: cloud-based APIs pose risks of code leakage, and local
deployment is often computationally expensive and inefficient. These drawbacks
have spurred interest in small language models (SLMs), which are more
lightweight and privacy-friendly. Encouragingly, recent studies show that SLMs
can achieve performance comparable to LLMs on specific tasks. While SLMs can
match LLMs on domain-specific tasks, their limited reasoning abilities lead to
suboptimal performance in complex CUDA generation according to our experiments.
To bridge this gap, we propose ReGraphT, a training-free, retrieval-augmented
generation framework that transfers LLM-level reasoning to smaller models.
ReGraphT organizes CUDA optimization trajectories into a structured reasoning
graph, modeling the combined CUDA optimizations as state transitions, and
leverages Monte Carlo Graph Search (MCGS) for efficient exploration. We also
present a CUDA-specific benchmark with difficulty tiers defined by reasoning
complexity to evaluate models more comprehensively. Experiments show that
ReGraphT outperforms HPC-specific fine-tuned models and other
retrieval-augmented approaches, achieving an average 2.33X speedup on CUDAEval
and ParEval. When paired with DeepSeek-Coder-V2-Lite-Instruct and
Qwen2.5-Coder-7B-Instruct, ReGraphT enables SLMs to approach LLM-level
performance without the associated privacy risks or excessive computing
overhead.

</details>
