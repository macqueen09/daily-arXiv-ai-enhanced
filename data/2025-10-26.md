<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 6]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Prompt Decorators: A Declarative and Composable Syntax for Reasoning, Formatting, and Control in LLMs](https://arxiv.org/abs/2510.19850)
*Mostapha Kalami Heris*

Main category: cs.PL

TL;DR: 提出了Prompt Decorators框架，一种声明式、可组合的语法，通过紧凑的控制令牌来管理LLM行为，将任务意图与执行行为解耦。


<details>
  <summary>Details</summary>
Motivation: 传统提示工程依赖冗长的自然语言指令，限制了可重复性、模块化和可解释性，用户缺乏对LLM推理和输出表达的一致控制。

Method: 引入Prompt Decorators框架，包含20个核心装饰器，分为认知与生成、表达与系统两个功能家族，定义统一语法、作用域模型和确定性处理流水线。

Result: 演示用例显示提高了推理透明度、减少了提示复杂性，并在多个领域实现了标准化模型行为。

Conclusion: 该框架为可扩展AI系统的互操作性、行为一致性和声明式接口开发提供了重要启示。

Abstract: Large Language Models (LLMs) are central to reasoning, writing, and
decision-support workflows, yet users lack consistent control over how they
reason and express outputs. Conventional prompt engineering relies on verbose
natural-language instructions, limiting reproducibility, modularity, and
interpretability. This paper introduces Prompt Decorators, a declarative,
composable syntax that governs LLM behavior through compact control tokens such
as +++Reasoning, +++Tone(style=formal), and +++Import(topic="Systems
Thinking"). Each decorator modifies a behavioral dimension, such as reasoning
style, structure, or tone, without changing task content. The framework
formalizes twenty core decorators organized into two functional families
(Cognitive & Generative and Expressive & Systemic), each further decomposed
into subcategories that govern reasoning, interaction, expression, and
session-control. It defines a unified syntax, scoping model, and deterministic
processing pipeline enabling predictable and auditable behavior composition. By
decoupling task intent from execution behavior, Prompt Decorators create a
reusable and interpretable interface for prompt design. Illustrative use cases
demonstrate improved reasoning transparency, reduced prompt complexity, and
standardized model behavior across domains. The paper concludes with
implications for interoperability, behavioral consistency, and the development
of declarative interfaces for scalable AI systems.

</details>


### [2] [A Specification's Realm: Characterizing the Knowledge Required for Executing a Given Algorithm Specification](https://arxiv.org/abs/2510.19853)
*Assaf Marron,David Harel*

Main category: cs.PL

TL;DR: 本文提出算法规范的"领域"概念——执行算法规范所需的前提知识文档，包括语法语义、领域知识、实体关系、因果规则和操作指令，有助于系统实现和形式化验证。


<details>
  <summary>Details</summary>
Motivation: 算法规范应该足够清晰明确以便机械执行，但当前缺乏对执行代理所需前提知识的系统化描述，这影响了算法规范的系统实现和形式化验证。

Method: 提出算法规范"领域"的概念，将其定义为执行规范所需的前提知识集合，包括语法语义、领域知识、实体关系、因果规则和操作指令，并探讨了使用大语言模型自动化生成这种文档的方法。

Result: 建立了算法规范领域的系统化特征描述，展示了这种文档可以具有实用规模，并有助于算法规范的方法论实现和形式化验证。

Conclusion: 算法规范领域的概念为算法规范的机械执行提供了理论基础，有助于提高算法规范的系统实现质量和可验证性，同时为评估执行忠实度提供了新视角。

Abstract: An algorithm specification in natural language or pseudocode is expected to
be clear and explicit enough to enable mechanical execution. In this position
paper we contribute an initial characterization of the knowledge that an
executing agent, human or machine, should possess in order to be able to carry
out the instructions of a given algorithm specification as a stand-alone
entity, independent of any system implementation. We argue that, for that
algorithm specification, such prerequisite knowledge, whether unique or shared
with other specifications, can be summarized in a document of practical size.
We term this document the realm of the algorithm specification. The generation
of such a realm is itself a systematic analytical process, significant parts of
which can be automated with the help of large language models and the reuse of
existing documents. The algorithm-specification's realm would consist of
specification language syntax and semantics, domain knowledge restricted to the
referenced entities, inter-entity relationships, relevant underlying
cause-and-effect rules, and detailed instructions and means for carrying out
certain operations. Such characterization of the realm can contribute to
methodological implementation of the algorithm specification in diverse systems
and to its formalization for mechanical verification. The paper also touches
upon the question of assessing execution faithfulness, which is distinct from
correctness: in the absence of a reference interpretation of natural language
or pseudocode specification with a given vocabulary, how can we determine if an
observed agent's execution indeed complies with the input specification.

</details>


### [3] [Deconstructed Proto-Quipper: A Rational Reconstruction](https://arxiv.org/abs/2510.20018)
*Ryan Kavanagh,Chuta Sano,Brigitte Pientka*

Main category: cs.PL

TL;DR: Proto-Quipper-A是对Proto-Quipper量子编程语言家族的重构，使用线性λ演算和伴随逻辑基础，简化了量子电路编程的语义和推理。


<details>
  <summary>Details</summary>
Motivation: Proto-Quipper语言具有复杂的操作语义，依赖集合论操作和新鲜名称生成，难以使用标准编程语言技术进行推理和机械化。

Method: 使用线性λ演算描述量子电路，结合伴随逻辑基础整合电路语言与线性/非线性函数式语言，采用简单的按值调用归约语义。

Result: Proto-Quipper-A具有归一化特性，可以使用标准逻辑关系证明线性系统的归一化，避免了现有线性逻辑关系的复杂性。

Conclusion: Proto-Quipper-A为Proto-Quipper语言提供了更易处理的形式基础，简化了量子电路编程的语义和推理过程。

Abstract: The Proto-Quipper family of programming languages aims to provide a formal
foundation for the Quipper quantum programming language. Unfortunately,
Proto-Quipper languages have complex operational semantics: they are inherently
effectful, and they rely on set-theoretic operations and fresh name generation
to manipulate quantum circuits. This makes them difficult to reason about using
standard programming language techniques and, ultimately, to mechanize. We
introduce Proto-Quipper-A, a rational reconstruction of Proto-Quipper languages
for static circuit generation. It uses a linear $\lambda$-calculus to describe
quantum circuits with normal forms that closely correspond to box-and-wire
circuit diagrams. Adjoint-logical foundations integrate this circuit language
with a linear/non-linear functional language and let us reconstruct
Proto-Quipper's circuit programming abstractions using more primitive
adjoint-logical operations. Proto-Quipper-A enjoys a simple call-by-value
reduction semantics, and to illustrate its tractability as a foundation for
Proto-Quipper languages, we show that it is normalizing. We show how to use
standard logical relations to prove normalization of linear and substructural
systems, thereby avoiding the inherent complexity of existing linear logical
relations.

</details>


### [4] [Deciding not to Decide: Sound and Complete Effect Inference in the Presence of Higher-Rank Polymorphism](https://arxiv.org/abs/2510.20532)
*Patrycja Balik,Szymon Jędras,Piotr Polesiuk*

Main category: cs.PL

TL;DR: 提出了一种针对具有子类型、高阶多态性和直观集合语义的类型与效应系统的效应推断算法，通过将效应约束转换为命题逻辑公式来处理高阶多态性的作用域问题。


<details>
  <summary>Details</summary>
Motivation: 类型与效应系统尚未广泛应用，因为现有推断算法在表达能力、直观性和可判定性之间做出妥协。本文旨在开发一个更平衡的算法。

Method: 使用命题逻辑公式延迟解决效应约束，以处理高阶多态性的作用域问题。算法基于具有子类型和集合语义的类型与效应系统。

Result: 证明了算法相对于声明式类型与效应系统的健全性和完备性，并在Rocq证明助手中形式化，在实际编程语言中成功实现。

Conclusion: 提出的效应推断算法在表达能力、直观性和可判定性之间取得了良好平衡，为类型与效应系统的实际应用提供了可行方案。

Abstract: Type-and-effect systems help the programmer to organize data and
computational effects in a program. While for traditional type systems
expressive variants with sophisticated inference algorithms have been developed
and widely used in programming languages, type-and-effect systems did not yet
gain widespread adoption. One reason for this is that type-and-effect systems
are more complex and the existing inference algorithms make compromises between
expressiveness, intuitiveness, and decidability. In this work, we present an
effect inference algorithm for a type-and-effect system with subtyping,
expressive higher-rank polymorphism, and intuitive set-like semantics of
effects. In order to deal with scoping issues of higher-rank polymorphism, we
delay solving of effect constraints by transforming them into formulae of
propositional logic. We prove soundness and completeness of our algorithm with
respect to a declarative type-and-effect system. All the presented results have
been formalized in the Rocq proof assistant, and the algorithm has been
successfully implemented in a realistic programming language.

</details>


### [5] [Compiling the Mimosa programming language to RTOS tasks](https://arxiv.org/abs/2510.20547)
*Nikolaus Huber,Susanne Graf,Philipp Rümmer,Wang Yi*

Main category: cs.PL

TL;DR: 提出了Mimosa编程语言的编译方案，该方案基于MIMOS计算模型，将嵌入式系统软件描述为通过FIFO队列通信的时间触发进程集合


<details>
  <summary>Details</summary>
Motivation: 为Mimosa编程语言开发正式的编译方案，使其能够映射到实时操作系统原语

Method: 基于Lustre编译方案的适配，正式描述Mimosa语义的编译方法，将协调层映射到实时操作系统原语

Result: 成功开发了Mimosa语言的编译方案，能够将程序协调层映射到实时操作系统

Conclusion: 提出的编译方案为Mimosa语言提供了有效的实现基础，使其能够在实时操作系统中运行

Abstract: This paper introduces a compilation scheme for programs written in the Mimosa
programming language, which builds upon the MIMOS model of computation. Mimosa
describes embedded systems software as a collection of time-triggered processes
which communicate through FIFO queues. We formally describe an adaptation of
the Lustre compilation scheme to the semantics of Mimosa and show how the
coordination layer can be mapped to real-time operating system primitives.

</details>


### [6] [SafeFFI: Efficient Sanitization at the Boundary Between Safe and Unsafe Code in Rust and Mixed-Language Applications](https://arxiv.org/abs/2510.20688)
*Oliver Braunsdorf,Tim Lange,Konrad Hohentanner,Julian Horsch,Johannes Kinder*

Main category: cs.PL

TL;DR: SafeFFI是一个优化Rust二进制文件中内存安全检测的系统，通过在unsafe和safe代码边界处进行检查，将内存安全执行从sanitizer交给Rust类型系统，显著减少不必要的检查。


<details>
  <summary>Details</summary>
Motivation: Rust中的unsafe代码对于与C/C++库互操作和实现底层数据结构是必要的，但可能导致内存安全违规。现有的sanitizer会引入许多对Rust类型系统保证安全的访问进行的不必要检查。

Method: 在unsafe和safe代码边界处进行内存安全检查，将内存安全执行从sanitizer交给Rust类型系统，避免昂贵的全程序分析。

Result: 相比现有方法，编译时开销显著降低（2.64倍对比超过8.83倍），在流行的Rust crate和已知易受攻击代码上，减少sanitizer检查高达98%，同时保持正确性并标记所有空间和时间内存安全违规。

Conclusion: SafeFFI在保持内存安全检测有效性的同时，显著提升了性能，是优化Rust程序内存安全检测的有效解决方案。

Abstract: Unsafe Rust code is necessary for interoperability with C/C++ libraries and
implementing low-level data structures, but it can cause memory safety
violations in otherwise memory-safe Rust programs. Sanitizers can catch such
memory errors at runtime, but introduce many unnecessary checks even for memory
accesses guaranteed safe by the Rust type system. We introduce SafeFFI, a
system for optimizing memory safety instrumentation in Rust binaries such that
checks occur at the boundary between unsafe and safe code, handing over the
enforcement of memory safety from the sanitizer to the Rust type system. Unlike
previous approaches, our design avoids expensive whole-program analysis and
adds much less compile-time overhead (2.64x compared to over 8.83x). On a
collection of popular Rust crates and known vulnerable Rust code, SafeFFI
achieves superior performance compared to state-of-the-art systems, reducing
sanitizer checks by up to 98%, while maintaining correctness and flagging all
spatial and temporal memory safety violations.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [7] [From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph](https://arxiv.org/abs/2510.19873)
*Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li*

Main category: cs.LG

TL;DR: ReGraphT是一个无需训练的检索增强生成框架，通过将CUDA优化轨迹组织成结构化推理图，将LLM级推理能力转移到小型模型，使SLM在CUDA代码生成任务上接近LLM性能。


<details>
  <summary>Details</summary>
Motivation: 解决使用LLM生成优化CUDA代码时面临的两个主要挑战：云API存在代码泄露风险，本地部署计算成本高且效率低。SLM虽然轻量且隐私友好，但在复杂CUDA生成任务中推理能力有限。

Method: 提出ReGraphT框架：将CUDA优化轨迹组织成结构化推理图，将组合CUDA优化建模为状态转换，利用蒙特卡洛图搜索进行高效探索。

Result: ReGraphT在CUDAEval和ParEval上平均实现2.33倍加速，优于HPC特定微调模型和其他检索增强方法。与DeepSeek-Coder-V2-Lite-Instruct和Qwen2.5-Coder-7B-Instruct配对时，SLM能够接近LLM级性能。

Conclusion: ReGraphT使SLM能够在不承担隐私风险或过高计算开销的情况下，在CUDA代码生成任务上实现接近LLM的性能，为GPU编程优化提供了实用解决方案。

Abstract: Despite significant evolution of CUDA programming and domain-specific
libraries, effectively utilizing GPUs with massively parallel engines remains
difficult. Large language models (LLMs) show strong potential in generating
optimized CUDA code from sequential code. However, using LLMs in practice faces
two major challenges: cloud-based APIs pose risks of code leakage, and local
deployment is often computationally expensive and inefficient. These drawbacks
have spurred interest in small language models (SLMs), which are more
lightweight and privacy-friendly. Encouragingly, recent studies show that SLMs
can achieve performance comparable to LLMs on specific tasks. While SLMs can
match LLMs on domain-specific tasks, their limited reasoning abilities lead to
suboptimal performance in complex CUDA generation according to our experiments.
To bridge this gap, we propose ReGraphT, a training-free, retrieval-augmented
generation framework that transfers LLM-level reasoning to smaller models.
ReGraphT organizes CUDA optimization trajectories into a structured reasoning
graph, modeling the combined CUDA optimizations as state transitions, and
leverages Monte Carlo Graph Search (MCGS) for efficient exploration. We also
present a CUDA-specific benchmark with difficulty tiers defined by reasoning
complexity to evaluate models more comprehensively. Experiments show that
ReGraphT outperforms HPC-specific fine-tuned models and other
retrieval-augmented approaches, achieving an average 2.33X speedup on CUDAEval
and ParEval. When paired with DeepSeek-Coder-V2-Lite-Instruct and
Qwen2.5-Coder-7B-Instruct, ReGraphT enables SLMs to approach LLM-level
performance without the associated privacy risks or excessive computing
overhead.

</details>
