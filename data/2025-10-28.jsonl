{"id": "2510.23517", "pdf": "https://arxiv.org/pdf/2510.23517", "abs": "https://arxiv.org/abs/2510.23517", "authors": ["Sidney Congard", "Guillaume Munch-Maccagnoni", "RÃ©mi Douence"], "title": "Linear effects, exceptions, and resource safety: a Curry-Howard correspondence for destructors", "categories": ["cs.PL", "cs.LO"], "comment": "26 pages + appendix", "summary": "We analyse the problem of combining linearity, effects, and exceptions, in\nabstract models of programming languages, as the issue of providing some kind\nof strength for a monad $T(- \\oplus E)$ in a linear setting. We consider in\nparticular for $T$ the allocation monad, which we introduce to model and study\nresource-safety properties. We apply these results to a series of two linear\neffectful calculi for which we establish their resource-safety properties.\n  The first calculus is a linear call-by-push-value language with two\nallocation effects $\\mathit{new}$ and $\\mathit{delete}$. The resource-safety\nproperties follow from the linear (and even ordered) character of the typing\nrules.\n  We then explain how to integrate exceptions on top of linearity and effects\nby adjoining default destruction actions to types, as inspired by C++/Rust\ndestructors. We see destructors as objects $\\delta : A\\rightarrow TI$ in the\nslice category over $TI$. This construction gives rise to a second calculus, an\naffine ordered call-by-push-value language with exceptions and destructors, in\nwhich the weakening rule performs a side-effect. As in C++/Rust, a ``move''\noperation is necessary to allow random-order release of resources, as opposed\nto last-in-first-out order. Moving resources is modelled as an exchange rule\nthat performs a side-effect."}
{"id": "2510.22907", "pdf": "https://arxiv.org/pdf/2510.22907", "abs": "https://arxiv.org/abs/2510.22907", "authors": ["Yifan Zhang", "Lanser Contributors"], "title": "Language Server CLI Empowers Language Agents with Process Rewards", "categories": ["cs.CL", "cs.AI", "cs.PL", "cs.SE"], "comment": "Project Page: https://github.com/yifanzhang-pro/lanser-cli", "summary": "Large language models routinely hallucinate APIs and mislocalize edits, while\nlanguage servers compute verified, IDE-grade facts about real code. We present\nLanser-CLI, a CLI-first orchestration layer that pins and mediates a Language\nServer Protocol (LSP) server for coding agents and CI, exposing deterministic,\nreplayable workflows. Our position is that language servers provide not only\nstructural information (definitions, references, types, diagnostics) but also\nan actionable process reward: machine-checked, step-wise signals that align an\nagent's planning loop with program reality. In this work, Lanser-CLI\ncontributes: (i) a robust addressing scheme beyond brittle \"file:line:col\" via\na Selector DSL (symbolic, AST-path, and content-anchored selectors) with a\nprincipled relocation algorithm; (ii) deterministic Analysis Bundles that\nnormalize Language Server responses and capture environment/capability metadata\nwith stable content hashes; (iii) a safety envelope for mutating operations\n(rename, code actions) with preview, workspace jails, and Git-aware,\ntransactional apply; and (iv) a process-reward functional derived from Language\nServer facts (diagnostic deltas, disambiguation confidence, and safe-apply\nchecks) that is computable online and replayable offline. We formalize\ndeterminism under frozen snapshots and establish a monotonicity property for\nthe process reward, making it suitable for process supervision and\ncounterfactual analysis. Project Page:\nhttps://github.com/yifanzhang-pro/lanser-cli"}
{"id": "2510.23101", "pdf": "https://arxiv.org/pdf/2510.23101", "abs": "https://arxiv.org/abs/2510.23101", "authors": ["Yifan Zhang", "Xin Zhang"], "title": "Beyond Imprecise Distance Metrics: LLM-Predicted Target Call Stacks for Directed Greybox Fuzzing", "categories": ["cs.CR", "cs.PL", "cs.SE"], "comment": "Preprint, under submission", "summary": "Directed greybox fuzzing (DGF) aims to efficiently trigger bugs at specific\ntarget locations by prioritizing seeds whose execution paths are more likely to\nmutate into triggering target bugs. However, existing DGF approaches suffer\nfrom imprecise probability calculations due to their reliance on complex\ndistance metrics derived from static analysis. The over-approximations inherent\nin static analysis cause a large number of irrelevant execution paths to be\nmistakenly considered to potentially mutate into triggering target bugs,\nsignificantly reducing fuzzing efficiency. We propose to replace static\nanalysis-based distance metrics with precise call stack representations. Call\nstacks represent precise control flows, thereby avoiding false information in\nstatic analysis. We leverage large language models (LLMs) to predict\nvulnerability-triggering call stacks for guiding seed prioritization. Our\napproach constructs call graphs through static analysis to identify methods\nthat can potentially reach target locations, then utilizes LLMs to predict the\nmost likely call stack sequence that triggers the vulnerability. Seeds whose\nexecution paths have higher overlap with the predicted call stack are\nprioritized for mutation. This is the first work to integrate LLMs into the\ncore seed prioritization mechanism of DGF. We implement our approach and\nevaluate it against several state-of-the-art fuzzers. On a suite of real-world\nprograms, our approach triggers vulnerabilities $1.86\\times$ to $3.09\\times$\nfaster compared to baselines. In addition, our approach identifies 10 new\nvulnerabilities and 2 incomplete fixes in the latest versions of programs used\nin our controlled experiments through directed patch testing, with 10 assigned\nCVE IDs."}
