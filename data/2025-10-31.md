<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.LO](#cs.LO) [Total: 2]
- [cs.CL](#cs.CL) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Fair intersection of seekable iterators](https://arxiv.org/abs/2510.26016)
*Michael Arntzenius*

Main category: cs.PL

TL;DR: 论文展示了在miniKanren中通过限制工作量的公平搜索策略，同样适用于实现最坏情况最优连接，使用可搜索迭代器接口在函数式语言中浅层嵌入。


<details>
  <summary>Details</summary>
Motivation: 将miniKanren中公平搜索策略的核心思想（通过限制工作量实现公平性）扩展到数据库连接操作中，实现最坏情况最优的连接算法。

Method: 采用可搜索迭代器接口，通过限制每个分支的工作量来公平地交错执行，实现最坏情况最优的连接算法，适合在函数式语言中浅层嵌入。

Result: 证明了基于工作量限制的公平性策略不仅适用于逻辑编程语言中的搜索，也能优雅地实现数据库中最坏情况最优的连接操作。

Conclusion: 工作量限制的公平性策略是一个通用的核心思想，可同时应用于逻辑编程的搜索策略和数据库连接算法，展现了跨领域的适用性。

Abstract: miniKanren's key semantic advance over Prolog is to implement a complete yet
efficient search strategy, fairly interleaving execution between disjuncts.
This fairness is accomplished by bounding how much work is done exploring one
disjunct before switching to the next. We show that the same idea -- fairness
via bounded work -- underlies an elegant compositional approach to implementing
worst-case optimal joins using a seekable iterator interface, suitable for
shallow embedding in functional languages.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [CHCVerif: A Portfolio-Based Solver for Constrained Horn Clauses](https://arxiv.org/abs/2510.26431)
*Mihály Dobos-Kovács,Levente Bajczi,András Vörös*

Main category: cs.SE

TL;DR: CHCVERIF是一个基于组合策略的CHC求解器，采用软件验证方法来解决约束Horn子句问题，能够重用成熟的软件验证工具处理涉及位向量和低层语义的基准测试。


<details>
  <summary>Details</summary>
Motivation: 约束Horn子句（CHCs）被广泛用作各种验证任务的中间表示，包括安全检查、不变量合成和过程间分析。本文旨在探索使用软件验证工具作为CHC求解后端的方法。

Method: 开发了CHCVERIF，一个基于组合策略的CHC求解器，采用软件验证方法，重用成熟的软件验证工具来处理CHC基准测试，特别是涉及位向量和低层语义的问题。

Result: 评估显示该方法在线性整数算术上表现一般，但在位向量基准测试上取得了适度的成功。结果证明了使用软件验证工具作为CHC求解后端的可行性和潜力。

Conclusion: 当得到精心构建的组合策略支持时，使用软件验证工具作为CHC求解后端具有可行性和发展潜力，特别是在处理位向量和低层语义问题时。

Abstract: Constrained Horn Clauses (CHCs) are widely adopted as intermediate
representations for a variety of verification tasks, including safety checking,
invariant synthesis, and interprocedural analysis. This paper introduces
CHCVERIF, a portfolio-based CHC solver that adopts a software verification
approach for solving CHCs. This approach enables us to reuse mature software
verification tools to tackle CHC benchmarks, particularly those involving
bitvectors and low-level semantics. Our evaluation shows that while the method
enjoys only moderate success with linear integer arithmetic, it achieves modest
success on bitvector benchmarks. Moreover, our results demonstrate the
viability and potential of using software verification tools as backends for
CHC solving, particularly when supported by a carefully constructed portfolio.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [3] [Finding Regular Herbrand Models for CHCs using Answer Set Programming](https://arxiv.org/abs/2510.26428)
*Gregoire Maire,Thomas Genet*

Main category: cs.LO

TL;DR: 提出使用ASP工具Clingo将带有代数数据类型的约束Horn子句编码为SAT问题，构建树自动机来识别Herbrand模型，实现半完备的可满足性检查器。


<details>
  <summary>Details</summary>
Motivation: 研究带代数数据类型的约束Horn子句的可满足性证明问题，目标是构建识别Herbrand模型的树自动机。

Method: 将CHCs与ADTs编码为ASP问题，使用Clingo SAT求解器构建树自动机来识别正则Herbrand模型。

Result: 实现了一个半完备的可满足性检查器：当存在正则Herbrand模型时找到树自动机，当问题不可满足时找到反例。

Conclusion: 提出的ASP编码方法为CHCs与ADTs的可满足性检查提供了有效的替代方案，能够处理正则模型存在或问题不可满足的情况。

Abstract: We are interested in proving satisfiability of Constrained Horn Clauses
(CHCs) over Algebraic Data Types (ADTs). We propose to prove satisfiability by
building a tree automaton recognizing the Herbrand model of the CHCs. If such
an automaton exists then the model is said to be regular, i.e., the Herbrand
model is a regular set of atoms. Kostyukov et al. have shown how to derive an
automaton when CVC4 finds a finite model of the CHCs. We propose an alternative
way to build the automaton using an encoding into a SAT problem using Clingo,
an Answer Set Programming (ASP) tool. We implemented a translation of CHCs with
ADTs into an ASP problem. Combined with Clingo, we obtain a semi-complete
satisfiability checker: it finds a tree automaton if a regular Herbrand model
exists or finds a counter-example if the problem is unsatisfiable.

</details>


### [4] [Semantic Properties of Computations Defined by Elementary Inference Systems](https://arxiv.org/abs/2510.26429)
*Salvador Lucas*

Main category: cs.LO

TL;DR: 本文提出使用基本推理系统定义集合/关系/计算，通过一阶理论Th(I)和规范模型来验证语义属性，并展示了如何通过任意模型来证明或反驳这些属性。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过推理系统和一阶逻辑来形式化分析编程语言和系统的计算属性，特别是基于重写的系统。

Method: 使用Smullyan的基本形式系统和Gentzen的推理规则记号构建基本推理系统I，通过一阶理论Th(I)的规范模型验证语义属性，并开发了使用任意模型进行验证的方法。

Result: 提出了通过任意模型验证语义属性的方法，克服了规范模型不可计算的问题，并将该方法应用于编程语言和重写系统的分析。

Conclusion: 基本推理系统结合一阶逻辑模型理论为编程语言和计算系统的形式化分析提供了有效框架，特别是对于基于重写的系统。

Abstract: We consider sets/relations/computations defined by *Elementary Inference
Systems* I, which are obtained from Smullyan's *elementary formal systems*
using Gentzen's notation for inference rules, and proof trees for atoms
P(t_1,...,t_n), where predicate P represents the considered
set/relation/computation. A first-order theory Th(I), actually a set of
definite Horn clauses, is given to I. Properties of objects defined by I are
expressed as first-order sentences F, which are proved true or false by
*satisfaction* M |= F of F in a *canonical* model M of Th(I). For this reason,
we call F a *semantic property* of I. Since canonical models are, in general,
incomputable, we show how to (dis)prove semantic properties by satisfiability
in an *arbitrary* model A of Th(I). We apply these ideas to the analysis of
properties of programming languages and systems whose computations can be
described by means of an elementary inference system. In particular,
rewriting-based systems.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [5] [SymCode: A Neurosymbolic Approach to Mathematical Reasoning via Verifiable Code Generation](https://arxiv.org/abs/2510.25975)
*Sina Bagheri Nezhad,Yao Li,Ameeta Agrawal*

Main category: cs.CL

TL;DR: SymCode是一个神经符号框架，将数学问题解决重新定义为使用SymPy库的可验证代码生成任务，显著提高了LLM在复杂数学推理中的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂数学推理中表现不佳，基于文本的生成导致未经验证和算术上不可靠的解决方案，现有提示策略缺乏确定性验证机制。

Method: 引入SymCode框架，将数学问题解决重新定义为使用SymPy库的可验证代码生成任务，通过符号引擎实现确定性验证。

Result: 在MATH-500和OlympiadBench等挑战性基准测试中，相比基线方法准确率提升高达13.6个百分点，不仅更节省token，还将模型失败从模糊的逻辑谬误转变为透明的程序化错误。

Conclusion: 通过将LLM推理建立在确定性符号引擎基础上，SymCode代表了在形式化领域实现更准确和可信AI的关键步骤。

Abstract: Large Language Models (LLMs) often struggle with complex mathematical
reasoning, where prose-based generation leads to unverified and arithmetically
unsound solutions. Current prompting strategies like Chain of Thought still
operate within this unreliable medium, lacking a mechanism for deterministic
verification. To address these limitations, we introduce SymCode, a
neurosymbolic framework that reframes mathematical problem-solving as a task of
verifiable code generation using the SymPy library. We evaluate SymCode on
challenging benchmarks, including MATH-500 and OlympiadBench, demonstrating
significant accuracy improvements of up to 13.6 percentage points over
baselines. Our analysis shows that SymCode is not only more token-efficient but
also fundamentally shifts model failures from opaque logical fallacies towards
transparent, programmatic errors. By grounding LLM reasoning in a deterministic
symbolic engine, SymCode represents a key step towards more accurate and
trustworthy AI in formal domains.

</details>


### [6] [QCoder Benchmark: Bridging Language Generation and Quantum Hardware through Simulator-Based Feedback](https://arxiv.org/abs/2510.26101)
*Taku Mikuriya,Tatsuya Ishigaki,Masayuki Kawarada,Shunya Minami,Tadashi Kadowaki,Yohichi Suzuki,Soshun Naito,Shunya Takata,Takumi Kato,Tamotsu Basseda,Reo Yamada,Hiroya Takamura*

Main category: cs.CL

TL;DR: 提出了QCoder Benchmark评估框架，用于评估大语言模型在量子编程任务中的表现，支持量子模拟器反馈和与人类代码的对比分析。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在需要与硬件设备交互的领域（如量子编程）表现不足，缺乏专门的评估框架。

Method: 开发了QCoder Benchmark，包含量子模拟器环境评估和真实编程竞赛中的人类代码对比分析。

Result: 实验显示GPT-4o准确率仅18.97%，而基于推理的o3模型达到78%准确率，超过了人类代码的平均成功率（39.98%）。

Conclusion: QCoder Benchmark揭示了量子编程任务的挑战性，推理模型表现优于指令跟随模型，并发布了数据集和评估API以支持进一步研究。

Abstract: Large language models (LLMs) have increasingly been applied to automatic
programming code generation. This task can be viewed as a language generation
task that bridges natural language, human knowledge, and programming logic.
However, it remains underexplored in domains that require interaction with
hardware devices, such as quantum programming, where human coders write Python
code that is executed on a quantum computer. To address this gap, we introduce
QCoder Benchmark, an evaluation framework that assesses LLMs on quantum
programming with feedback from simulated hardware devices. Our benchmark offers
two key features. First, it supports evaluation using a quantum simulator
environment beyond conventional Python execution, allowing feedback of
domain-specific metrics such as circuit depth, execution time, and error
classification, which can be used to guide better generation. Second, it
incorporates human-written code submissions collected from real programming
contests, enabling both quantitative comparisons and qualitative analyses of
LLM outputs against human-written codes. Our experiments reveal that even
advanced models like GPT-4o achieve only around 18.97% accuracy, highlighting
the difficulty of the benchmark. In contrast, reasoning-based models such as o3
reach up to 78% accuracy, outperforming averaged success rates of human-written
codes (39.98%). We release the QCoder Benchmark dataset and public evaluation
API to support further research.

</details>
