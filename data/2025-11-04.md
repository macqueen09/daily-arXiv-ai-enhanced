<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 5]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.LO](#cs.LO) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Equality Saturation Guided by Large Language Models](https://arxiv.org/abs/2511.00403)
*Wentao Peng,Ruyi Ji,Yingfei Xiong*

Main category: cs.PL

TL;DR: LGuess通过将e-graphs作为LLMs与重写系统之间的中间层，解决了LLMs无法保证正确性的问题。它只向LLM查询高层次的重写检查点，使用e-graphs提供这些检查点之间的低层次重写链。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型无法保证正确性，虽然可以将其应用于形式重写系统来解决这个问题，但当前的LLMs在生成可靠的重写链方面仍不足够。

Method: 提出LLM引导的等式饱和方法LGuess，将e-graphs作为中间层。从LLM学习概率模型来预测可能的检查点，从饱和的e-graph中有效提取合适的检查点。

Result: 在多元多项式因式分解问题上，LGuess相比直接等式饱和和直接查询LLM重写链的方法表现出显著优势。

Conclusion: LGuess通过结合LLMs的高层次指导和e-graphs的低层次重写能力，有效解决了LLMs在形式重写系统中的可靠性问题。

Abstract: One critical issue with large language models (LLMs) is their inability to
guarantee correctness. Although this problem can be addressed by applying LLMs
to formal rewrite systems, current LLMs are still far from adequate to generate
sound rewrite chains. To bridge this gap, this paper proposes LLM-guided
equality saturation, dubbed LGuess, by incorporating e-graphs as an
intermediate layer between LLMs and rewrite systems. LGuess queries LLMs only
for high-level rewrite checkpoints and uses e-graphs to supply low-level
rewrite chains between these checkpoints. The key technical challenge in this
procedure lies in effectively extracting a suitable checkpoint from a saturated
e-graph, which LGuess addresses by learning a probabilistic model from the LLM.
The model predicts probable checkpoints while remaining simple enough for
effective extraction. We implement a prototype of LGuess and evaluate it on the
problem of factorizing multivariable polynomials. The results demonstrate a
significant advantage of LGuess compared to both straightforward equality
saturation and the approach that queries the LLM directly for the rewrite
chain.

</details>


### [2] [\texttt{ReMind}: Understanding Deductive Code Reasoning in LLMs](https://arxiv.org/abs/2511.00488)
*Jun Gao,Yun Peng,Xiaoxue Ren*

Main category: cs.PL

TL;DR: 本文提出ReMind多智能体框架，通过Mutator、Executor和Inspector的协同工作，解决LLMs在演绎代码推理中的三个关键挑战，显著提升推理能力和零样本泛化性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在代码相关任务上取得显著进展，但实证研究表明它们在演绎代码推理（推理程序执行过程）方面仍存在困难，而这一局限性的根本原因尚未得到充分探索。

Method: 提出ReMind多智能体框架，包含三个组件：Mutator生成代码变体以减少对代码源的偏见；Executor逐步跟踪变量状态以暴露不一致性；Inspector识别有问题的推理步骤并提供控制流细化来弥合推理差距。

Result: 在两个基准测试和五个LLMs上的广泛实验表明，ReMind在演绎代码推理方面相比基线方法具有显著优势，实现了出色的性能和稳健的零样本泛化。

Conclusion: ReMind框架通过系统识别和细化推理缺陷，有效解决了LLMs在演绎代码推理中的关键挑战，为提升代码推理能力提供了有效解决方案。

Abstract: Large Language Models (LLMs) have achieved remarkable progress in
code-related tasks. Despite their advancement, empirical evidence reveals that
they still struggle with \emph{deductive code reasoning}, the ability to reason
about the program execution process. While prior studies have recognized this
limitation, the underlying causes remain largely underexplored. In this paper,
we begin by presenting a comprehensive empirical study that reveals three key
challenges undermining deductive code reasoning: (1) an intrinsic gap between
generation and reasoning abilities, (2) a consistent bias towards code sources,
and (3) weak zero-shot generalization on complex benchmarks. In light of these
challenges, we propose \texttt{ReMind}, a multi-agent framework composed of
\texttt{Mutator}, \texttt{Executor}, and \texttt{Inspector}. The
\texttt{Mutator} generates code variants to mitigate bias towards code sources,
the \texttt{Executor} traces variable states step-by-step to expose
inconsistency, and the \texttt{Inspector} identifies problematic reasoning
steps and provides control-flow refinement to bridge the intrinsic reasoning
gap. Through their coordinated collaboration, \texttt{ReMind} systematically
identifies and refines reasoning flaws, achieving outstanding performance and
enabling robust zero-shot generalization. Extensive experiments on two
benchmarks with five LLMs demonstrate the superior advantages of
\texttt{ReMind} compared to baseline approaches in deductive code reasoning.

</details>


### [3] [Agentic Auto-Scheduling: An Experimental Study of LLM-Guided Loop Optimization](https://arxiv.org/abs/2511.00592)
*Massinissa Merouani,Islem Kara Bernou,Riyadh Baghdadi*

Main category: cs.PL

TL;DR: ComPilot是一个使用大型语言模型(LLMs)作为交互式优化代理的代码优化框架，通过与编译器建立闭环反馈机制，在PolyBench基准测试中实现了2.66x-3.54x的几何平均加速比。


<details>
  <summary>Details</summary>
Motivation: 自动代码优化在现代硬件上仍然是一个困难挑战，特别是对于复杂的循环嵌套。本文研究一种新颖的方法，让大型语言模型通过与编译器的闭环交互来指导优化过程。

Method: 提出ComPilot框架，利用现成的LLMs作为交互式优化代理，无需特定任务微调。建立反馈循环：LLM向编译器提出循环嵌套的变换建议，编译器尝试变换并报告合法性状态和性能变化，LLM利用具体反馈迭代优化策略。

Result: 在PolyBench基准测试套件上的广泛评估显示，ComPilot相比原始代码实现了2.66x(单次运行)和3.54x(5次运行最佳)的几何平均加速比。在许多情况下优于最先进的Pluto多面体优化器。

Conclusion: 实验研究表明，当通过编译器反馈进行基础化时，通用LLMs可以有效指导代码优化过程，为代码优化中的代理AI开辟了有前景的研究方向。

Abstract: Automatic code optimization remains a difficult challenge, particularly for
complex loop nests on modern hardware. This paper investigates a novel approach
to code optimization where Large Language Models (LLMs) guide the process
through a closed-loop interaction with a compiler. We present ComPilot, an
experimental framework that leverages off-the-shelf LLMs, without any
task-specific fine-tuning, as interactive optimization agents. ComPilot
establishes a feedback loop where an LLM proposes transformations for a given
loop nest to a compiler. The compiler attempts the transformations, reporting
back legality status and measured speedup or slowdown. The LLM utilizes this
concrete feedback to iteratively refine its optimization strategy. Our
extensive evaluation across the PolyBench benchmark suite demonstrates the
effectiveness of this zero-shot approach. ComPilot achieves geometric mean
speedups of 2.66x (single run) and 3.54x (best-of-5 runs) over the original
code. Furthermore, ComPilot demonstrates competitive performance against the
state-of-the-art Pluto polyhedral optimizer, outperforming it in many cases.
This experimental study demonstrates that general-purpose LLMs can effectively
guide the code optimization process when grounded by compiler feedback, opening
promising research directions for agentic AI in code optimization.

</details>


### [4] [Typed Embedding of miniKanren for Functional Conversion](https://arxiv.org/abs/2511.00740)
*Igor Engel,Ekaterina Verbitskaia*

Main category: cs.PL

TL;DR: 本文提出了一种类型化的无标记最终嵌入方法，将miniKanren嵌入到Haskell中，解决了之前转换方法在类型感知、确定性标注和隐式生成器线程方面的问题。


<details>
  <summary>Details</summary>
Motivation: 之前的函数式转换方法存在性能开销，且存在类型不敏感、需要确定性标注和隐式生成器线程的问题，这些问题影响了代码的优雅性和可用性。

Method: 采用类型化的无标记最终嵌入方法将miniKanren嵌入到Haskell中，这种方法能够减少样板代码并保持性能优势。

Result: 新方法显著减少了样板代码，同时保持甚至增强了之前的性能提升。

Conclusion: 类型化的无标记最终嵌入方法成功解决了之前转换方法的缺陷，提供了更优雅和高效的miniKanren嵌入方案。

Abstract: Relational programming enables program synthesis through a verifier-to-solver
approach. An earlier paper introduced a functional conversion that mitigated
some of the inherent performance overhead. However, the conversion was
inelegant: it was oblivious to types, demanded determinism annotations, and
implicit generator threading. In this paper, we address these issues by
providing a typed tagless-final embedding of miniKanren into Haskell. This
improvement significantly reduces boilerplate while preserving, and sometimes
enhancing, earlier speedups.

</details>


### [5] [Cobble: Compiling Block Encodings for Quantum Computational Linear Algebra](https://arxiv.org/abs/2511.01736)
*Charles Yuan*

Main category: cs.PL

TL;DR: Cobble是一种用于量子计算线性代数编程的语言，能够自动将高级矩阵表示编译为正确的量子电路，相比现有电路优化器在基准测试中实现了2.6x-25.4x的加速。


<details>
  <summary>Details</summary>
Motivation: 量子线性代数算法虽然承诺指数级加速，但开发人员需要手动实现复杂的矩阵算术量子电路，且传统优化方法如子表达式重用在量子成本模型中可能不适用或不划算。

Method: 开发Cobble语言，支持开发者使用高级符号表达和操作量子矩阵表示（块编码），自动编译为正确量子电路，包含时间空间使用分析以及使用量子奇异值变换等领先技术的优化。

Result: 在模拟、回归、搜索等应用的基准测试中，Cobble相比现有电路优化器实现了2.6x-25.4x的加速效果。

Conclusion: Cobble通过提供高级编程抽象和自动化优化，显著简化了量子线性代数算法的开发过程，并实现了显著的性能提升。

Abstract: Quantum algorithms for computational linear algebra promise up to exponential
speedups for applications such as simulation and regression, making them prime
candidates for hardware realization. But these algorithms execute in a model
that cannot efficiently store matrices in memory like a classical algorithm
does, instead requiring developers to implement complex expressions for matrix
arithmetic in terms of correct and efficient quantum circuits. Among the
challenges for the developer is navigating a cost model in which conventional
optimizations for linear algebra, such as subexpression reuse, can be
inapplicable or unprofitable.
  In this work, we present Cobble, a language for programming with quantum
computational linear algebra. Cobble enables developers to express and
manipulate the quantum representations of matrices, known as block encodings,
using high-level notation that automatically compiles to correct quantum
circuits. Cobble features analyses that estimate leading factors in time and
space usage of programs, as well as optimizations that reduce overhead and
generate efficient circuits using leading techniques such as the quantum
singular value transformation. We evaluate Cobble on benchmark kernels for
simulation, regression, search, and other applications, showing 2.6x-25.4x
speedups not achieved by existing circuit optimizers on these benchmarks.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [6] [FlowLog: Efficient and Extensible Datalog via Incrementality](https://arxiv.org/abs/2511.00865)
*Hangdong Zhao,Zhenghong Yu,Srinag Rao,Simon Frisk,Zhiwei Fan,Paraschos Koutris*

Main category: cs.DB

TL;DR: FlowLog是一个新的Datalog引擎，通过显式关系IR分离递归控制和逻辑计划，结合Datalog特定优化和数据库原语，在递归工作负载上优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 现有Datalog系统在效率和可扩展性之间存在权衡：专用引擎效率高但缺乏灵活性，模块化系统灵活性好但难以集成Datalog特定优化。

Method: 使用每规则显式关系IR分离递归控制和逻辑计划，在逻辑层应用SQL优化，采用稳健性优先方法结合结构优化器和侧向信息传递，基于Differential Dataflow构建。

Result: FlowLog在广泛的递归工作负载上优于最先进的Datalog引擎和现代数据库，实现了卓越的可扩展性。

Conclusion: FlowLog通过创新的架构设计成功平衡了Datalog系统的效率和可扩展性，为递归计算提供了高性能且易于扩展的解决方案。

Abstract: Datalog-based languages are regaining popularity as a powerful abstraction
for expressing recursive computations in domains such as program analysis and
graph processing. However, existing systems often face a trade-off between
efficiency and extensibility. Engines like Souffle achieve high efficiency
through domain-specific designs, but lack general-purpose flexibility. Others,
like RecStep, offer modularity by layering Datalog on traditional databases,
but struggle to integrate Datalog-specific optimizations.
  This paper bridges this gap by presenting FlowLog, a new Datalog engine that
uses an explicit relational IR per-rule to cleanly separate recursive control
(e.g., semi-naive execution) from each rule's logical plan. This boundary lets
us retain fine-grained, Datalog-aware optimizations at the logical layer, but
also reuse off-the-shelf database primitives at execution. At the logical level
(i.e. IR), we apply proven SQL optimizations, such as logic fusion and subplan
reuse. To address high volatility in recursive workloads, we adopt a
robustness-first approach that pairs a structural optimizer (avoiding
worst-case joins) with sideways information passing (early filtering). Built
atop Differential Dataflow--a mature framework for streaming analytics--FlowLog
supports both batch and incremental Datalog and adds novel recursion-aware
optimizations called Boolean (or algebraic) specialization. Our evaluation
shows that FlowLog outperforms state-of-the-art Datalog engines and modern
databases across a broad range of recursive workloads, achieving superior
scalability while preserving a simple and extensible architecture.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Inferring multiple helper Dafny assertions with LLMs](https://arxiv.org/abs/2511.00125)
*Álvaro Silva,Alexandra Mendes,Ruben Martins*

Main category: cs.SE

TL;DR: 使用大型语言模型自动推断Dafny程序中缺失的辅助断言，开发了DAISY工具，在单断言缺失和多断言缺失情况下分别实现了63.4%和31.7%的程序验证成功率。


<details>
  <summary>Details</summary>
Motivation: Dafny验证器虽然提供强正确性保证，但需要大量手动辅助断言，这成为采用的重要障碍。

Method: 扩展DafnyBench基准测试集，引入断言类型分类法，通过结合LLM预测和错误消息启发式的混合方法改进故障定位，开发DAISY工具。

Result: DAISY在单断言缺失情况下验证了63.4%的程序，在多断言缺失情况下验证了31.7%的程序，且许多程序可以用比原始更少的断言进行验证。

Conclusion: 自动断言推断可以显著减少证明工程工作量，是迈向更可扩展和易访问的形式验证的一步。

Abstract: The Dafny verifier provides strong correctness guarantees but often requires
numerous manual helper assertions, creating a significant barrier to adoption.
We investigate the use of Large Language Models (LLMs) to automatically infer
missing helper assertions in Dafny programs, with a primary focus on cases
involving multiple missing assertions. To support this study, we extend the
DafnyBench benchmark with curated datasets where one, two, or all assertions
are removed, and we introduce a taxonomy of assertion types to analyze
inference difficulty. Our approach refines fault localization through a hybrid
method that combines LLM predictions with error-message heuristics. We
implement this approach in a new tool called DAISY (Dafny Assertion Inference
SYstem). While our focus is on multiple missing assertions, we also evaluate
DAISY on single-assertion cases. DAISY verifies 63.4% of programs with one
missing assertion and 31.7% with multiple missing assertions. Notably, many
programs can be verified with fewer assertions than originally present,
highlighting that proofs often admit multiple valid repair strategies and that
recovering every original assertion is unnecessary. These results demonstrate
that automated assertion inference can substantially reduce proof engineering
effort and represent a step toward more scalable and accessible formal
verification.

</details>


### [8] [Hidden in Plain Sight: Where Developers Confess Self-Admitted Technical Debt](https://arxiv.org/abs/2511.01529)
*Murali Sridharan,Mikel Robredo,Leevi Rantala,Matteo Esposito,Valentina Lenarduzzi,Mika Mantyla*

Main category: cs.SE

TL;DR: 该研究将自承认技术债务(SATD)注释与源代码结构关联，发现SATD主要出现在定义、条件语句和异常处理等代码构造附近，表明这是开发者面对不确定性和权衡时的有意信号。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要关注SATD的检测和优先级排序，很少关注受SATD影响的源代码。本研究旨在将SATD注释与其周围的源代码构造联系起来。

Method: 利用包含9000多个Java开源软件仓库代码注释的PENTACET数据集，定量推断SATD最常见出现的位置及其最常影响的代码构造/语句。

Result: 大规模研究将超过225,000个SATD注释与其周围代码关联，显示SATD主要出现在定义、条件语句和异常处理等内联代码附近。

Conclusion: SATD在开发者面临不确定性和权衡时出现，揭示了这是变更过程中的有意意识信号，而不仅仅是疏忽。

Abstract: Context. Detecting Self-Admitted Technical Debt (SATD) is crucial for
proactive software maintenance. Previous research has primarily targeted
detecting and prioritizing SATD, with little focus on the source code afflicted
with SATD. Our goal in this work is to connect the SATD comments with source
code constructs that surround them.
  Method. We leverage the extensive SATD dataset PENTACET, containing code
comments from over 9000 Java Open Source Software (OSS) repositories. We
quantitatively infer where SATD most commonly occurs and which code
constructs/statements it most frequently affects.
  Results and Conclusions. Our large-scale study links over 225,000 SATD
comments to their surrounding code, showing that SATD mainly arises in inline
code near definitions, conditionals, and exception handling, where developers
face uncertainty and trade-offs, revealing it as an intentional signal of
awareness during change rather than mere neglect.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [9] [Proceedings Twelfth Workshop on Fixed Points in Computer Science](https://arxiv.org/abs/2511.00626)
*Alexis Saurin*

Main category: cs.LO

TL;DR: 这是第十二届计算机科学中不动点国际研讨会的论文集，收录了2024年2月在意大利那不勒斯举行的研讨会精选论文


<details>
  <summary>Details</summary>
Motivation: 汇集计算机科学中不动点理论相关的最新研究成果，作为计算机科学逻辑国际会议的卫星会议

Method: 通过研讨会形式收集和筛选相关研究论文，形成正式论文集

Result: 出版了包含研讨会精选论文的EPTCS卷册

Conclusion: 成功组织了不动点理论在计算机科学中的应用研讨会，并出版了相关研究成果

Abstract: This EPTCS volume contains the post-proceedings of the Twelfth International
Workshop on Fixed Points in Computer Science, presenting a selection of the
works presented during the workshop that took place in Naples (Italy) on the
19th and 20th of February 2024 as a satellite of the International Conference
on Computer Science Logic (CSL 2024).

</details>


### [10] [SM-based Semantics for Answer Set Programs Containing Conditional Literals and Arithmetic](https://arxiv.org/abs/2511.01753)
*Zachary Hansen,Yuliya Lierler*

Main category: cs.LO

TL;DR: 本文提出了基于SM算子的条件文字和算术逻辑程序语义，无需依赖无穷命题逻辑的翻译，建立了与现有语义的精确对应关系。


<details>
  <summary>Details</summary>
Motivation: 现代ASP求解器支持条件文字等高级语言构造，提高了逻辑程序的表达力和简洁性。条件文字在规则体中形成"子公式"，使规则形式更接近一阶逻辑的宽松语法，是知识表示的有用工具。

Method: 基于SM算子提出逻辑程序的条件文字和算术语义，不依赖传统方法中需要将程序翻译为无穷命题逻辑的步骤。

Result: 建立了所提语义与现有语义之间的精确对应关系，证明了新语义的有效性。

Conclusion: 提出的基于SM算子的语义为条件文字和算术逻辑程序提供了更直接的语义基础，避免了传统方法中的复杂翻译过程。

Abstract: Modern answer set programming solvers such as CLINGO support advanced
language constructs that improve the expressivity and conciseness of logic
programs. Conditional literals are one such construct. They form "subformulas"
that behave as nested implications within the bodies of logic rules. Their
inclusion brings the form of rules closer to the less restrictive syntax of
first-order logic. These qualities make conditional literals useful tools for
knowledge representation. In this paper, we propose a semantics for logic
programs with conditional literals and arithmetic based on the SM operator.
These semantics do not require grounding, unlike the established semantics for
such programs that relies on a translation to infinitary propositional logic.
The main result of this paper establishes the precise correspondence between
the proposed and existing semantics.

</details>
