<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Modular abstract syntax trees (MAST): substitution tensors with second-class sorts](https://arxiv.org/abs/2511.03946)
*Marcelo P. Fiore,Ohad Kammar,Georg Moser,Sam Staton*

Main category: cs.PL

TL;DR: 本文扩展了Fiore等人的抽象语法理论，以处理具有第二类排序的语言，如CBV和CBPV演算，通过将表征从幺半范畴中的幺半群改为actegories中的动作，并用双范畴论证重现了大部分理论发展。


<details>
  <summary>Details</summary>
Motivation: 处理具有第二类排序的编程演算（如CBV和CBPV）中的抽象语法、绑定、替换和空洞问题，这些语言禁止第二类排序出现在变量上下文中。

Method: 将Fiore等人的抽象语法理论从幺半范畴中的幺半群表征扩展到actegories中的动作表征，使用双范畴论证重现理论发展。

Result: 成功开发了适用于第二类排序语言的抽象语法理论，并应用该理论证明了CBV变体的替换引理。

Conclusion: 通过将抽象语法表征从幺半群改为动作，可以有效地处理具有第二类排序的语言，为这类编程演算提供了坚实的理论基础。

Abstract: We adapt Fiore, Plotkin, and Turi's treatment of abstract syntax with
binding, substitution, and holes to account for languages with second-class
sorts. These situations include programming calculi such as the Call-by-Value
lambda-calculus (CBV) and Levy's Call-by-Push-Value (CBPV). Prohibiting
second-class sorts from appearing in variable contexts changes the
characterisation of the abstract syntax from monoids in monoidal categories to
actions in actegories. We reproduce much of the development through
bicategorical arguments. We apply the resulting theory by proving substitution
lemmata for varieties of CBV.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [How Natural Language Proficiency Shapes GenAI Code for Software Engineering Tasks](https://arxiv.org/abs/2511.04115)
*Ruksit Rojpaisarnkit,Youmei Fan,Kenichi Matsumoto,Raula Gaikovina Kula*

Main category: cs.SE

TL;DR: 本文研究发现，在软件工程中使用基础模型时，提示的英语语言熟练度会影响LLM生成代码的正确性，高级熟练度的提示能产生更正确的代码。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型在软件工程中的广泛应用，自然语言提示成为开发者与大型语言模型的关键接口。虽然已有研究关注提示结构，但自然语言熟练度作为影响生成代码质量的因素尚未充分探索。

Method: 使用HumanEval数据集，对164个编程任务系统性地改变提示的英语熟练度（从基础到高级），测量生成的代码熟练度和正确性。

Result: LLM默认使用中级（B2）自然语言水平。虽然对代码熟练度的影响因模型而异，但高级熟练度提示在所有模型中都能产生更正确的代码。

Conclusion: 自然语言熟练度是控制代码生成的关键因素，能帮助开发者定制AI输出并提高解决方案的可靠性。

Abstract: With the widespread adoption of Foundation Model (FM)-powered tools in
software engineering, the natural language prompt has become a critical
interface between developers and Large Language Models (LLMs). While much
research has focused on prompt structure, the natural language proficiency is
an underexplored factor that can influence the quality of generated code. This
paper investigates whether the English language proficiency itself independent
of the prompting technique affects the proficiency and correctness of code
generated by LLMs. Using the HumanEval dataset, we systematically varied the
English proficiency of prompts from basic to advanced for 164 programming tasks
and measured the resulting code proficiency and correctness. Our findings show
that LLMs default to an intermediate (B2) natural language level. While the
effect on the resulting code proficiency was model-dependent, we found that
higher-proficiency prompts consistently yielded more correct code across all
models. These results demonstrate that natural language proficiency is a key
lever for controlling code generation, helping developers tailor AI output and
improve the reliability of solutions.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [3] [OMPILOT: Harnessing Transformer Models for Auto Parallelization to Shared Memory Computing Paradigms](https://arxiv.org/abs/2511.03866)
*Arijit Bhattacharjee,Ali TehraniJamsaz,Le Chen,Niranjan Hasabnis,Mihai Capota,Nesreen Ahmed,Ali Jannesari*

Main category: cs.DC

TL;DR: OMPILOT是一个专门用于将C++代码翻译为OpenMP的领域特定编码器-解码器转换器，通过自定义预训练目标和混合学习策略实现函数级并行化转换。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注循环级转换，缺乏对更广泛语义上下文的捕捉能力，且传统代码翻译指标无法充分评估OpenMP并行构造的正确性和质量。

Method: 采用领域特定编码器-解码器转换器架构，结合包含并行构造语义的自定义预训练目标，使用无监督和有监督混合学习策略，在函数级别进行操作以捕获更广泛的语义上下文。

Result: 开发了OMPBLEU评估指标，专门用于评估OpenMP并行构造的正确性和质量，解决了传统翻译指标的局限性。

Conclusion: OMPILOT通过函数级转换和定制化评估指标，为C++到OpenMP的代码翻译提供了更准确和鲁棒的解决方案。

Abstract: Recent advances in large language models (LLMs) have significantly
accelerated progress in code translation, enabling more accurate and efficient
transformation across programming languages. While originally developed for
natural language processing, LLMs have shown strong capabilities in modeling
programming language syntax and semantics, outperforming traditional rule-based
systems in both accuracy and flexibility. These models have streamlined
cross-language conversion, reduced development overhead, and accelerated legacy
code migration. In this paper, we introduce OMPILOT, a novel domain-specific
encoder-decoder transformer tailored for translating C++ code into OpenMP,
enabling effective shared-memory parallelization. OMPILOT leverages custom
pre-training objectives that incorporate the semantics of parallel constructs
and combines both unsupervised and supervised learning strategies to improve
code translation robustness. Unlike previous work that focused primarily on
loop-level transformations, OMPILOT operates at the function level to capture a
wider semantic context. To evaluate our approach, we propose OMPBLEU, a novel
composite metric specifically crafted to assess the correctness and quality of
OpenMP parallel constructs, addressing limitations in conventional translation
metrics.

</details>
