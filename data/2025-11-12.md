<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Dynamic Stability of LLM-Generated Code](https://arxiv.org/abs/2511.07463)
*Prateek Rajput,Abdoul Aziz Bonkoungou,Yewei Song,Abdoul Kader Kabore,Iyiola E. Olatunji,Jacques Klein,Tegewende Bissyande*

Main category: cs.PL

TL;DR: 提出一个评估代码生成动态稳定性的框架，通过SCTD和DCTD两个指标来衡量算法结构多样性和运行时行为方差，发现LLM在生成功能正确代码时存在显著的算法方差和不稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代码生成评估只关注功能正确性，忽略了算法复杂度差异，导致功能正确但性能差异巨大的解决方案被同等对待，无法反映实际生产环境中的性能成本差异。

Method: 引入基于操作码分布的两个指标：静态规范轨迹分歧(SCTD)衡量算法结构多样性，动态规范轨迹分歧(DCTD)量化运行时行为方差，两者比值构成行为表达因子(BEF)作为诊断信号。

Result: 在BigOBench和CodeContests上的实验表明，最先进的LLM即使在功能正确的输出中也表现出显著的算法方差。提高采样温度能改善pass@1率但会降低稳定性，揭示了正确性与行为一致性之间的权衡。

Conclusion: 需要在代码生成中引入稳定性感知目标，并建立包含渐近测试用例的新基准，以实现对LLM更稳健、面向实际应用的评估。

Abstract: Current evaluations of LLMs for code generation emphasize functional correctness, overlooking the fact that functionally correct solutions can differ significantly in algorithmic complexity. For instance, an $(O(n^2))$ versus $(O(n \log n))$ sorting algorithm may yield similar output but incur vastly different performance costs in production. This discrepancy reveals a critical limitation in current evaluation methods: they fail to capture the behavioral and performance diversity among correct solutions. To address this, we introduce a principled framework for evaluating the dynamic stability of generated code. We propose two metrics derived from opcode distributions: Static Canonical Trace Divergence (SCTD), which captures algorithmic structure diversity across generated solutions, and Dynamic Canonical Trace Divergence (DCTD), which quantifies runtime behavioral variance. Their ratio, the Behavioral Expression Factor (BEF), serves as a diagnostic signal: it indicates critical runtime instability when BEF $\ll$ 1 and functional redundancy when BEF $\gg$ 1. Empirical results on BigOBench and CodeContests show that state-of-the-art LLMs exhibit significant algorithmic variance even among functionally correct outputs. Notably, increasing sampling temperature improves pass@1 rates but degrades stability, revealing an unrecognized trade-off: searching for correct solutions in diverse output spaces introduces a "penalty of instability" between correctness and behavioral consistency. Our findings call for stability-aware objectives in code generation and new benchmarks with asymptotic test cases for robust, real-world LLM evaluation.

</details>


### [2] [Streaming Tensor Program: A streaming abstraction for dynamic parallelism](https://arxiv.org/abs/2511.07776)
*Gina Sohn,Genghan Zhang,Konstantin Hossfeld,Jungwoo Kim,Nathan Sobotka,Nathan Zhang,Olivia Hsu,Kunle Olukotun*

Main category: cs.PL

TL;DR: STeP是一个新的流式抽象，用于在空间数据流加速器上高效运行动态张量工作负载，通过引入灵活的路由操作符、显式内存层次结构和符号形状语义来支持动态行为。


<details>
  <summary>Details</summary>
Motivation: 当前的空间数据流加速器编程抽象表达能力有限，无法有效处理动态形状张量和数据相关控制流，导致动态行为需要静态实现或缺乏性能关键决策的可见性。

Method: 提出STeP流式抽象，包括灵活的路由操作符、显式内存层次结构、符号形状语义，以及动态分块、动态并行化和配置时分复用等优化技术。

Result: 在代表性LLM层上使用真实世界轨迹进行周期近似模拟，动态分块将片上内存需求减少2.18倍，动态并行化将延迟改善1.5倍，配置时分复用将计算利用率提高2.57倍。

Conclusion: STeP能够有效适应动态行为，同时保持数据流效率，为动态张量工作负载在空间数据流加速器上的高效执行提供了新的解决方案。

Abstract: Dynamic behaviors are becoming prevalent in many tensor applications. In machine learning, for example, the input tensors are dynamically shaped or ragged, and data-dependent control flow is widely used in many models. However, the limited expressiveness of prior programming abstractions for spatial dataflow accelerators forces the dynamic behaviors to be implemented statically or lacks the visibility for performance-critical decisions. To address these challenges, we present the Streaming Tensor Program (STeP), a new streaming abstraction that enables dynamic tensor workloads to run efficiently on spatial dataflow accelerators. STeP introduces flexible routing operators, an explicit memory hierarchy, and symbolic shape semantics that expose dynamic data rates and tensor dimensions. These capabilities unlock new optimizations-dynamic tiling, dynamic parallelization, and configuration time-multiplexing-that adapt to dynamic behaviors while preserving dataflow efficiency. Using a cycle-approximate simulator on representative LLM layers with real-world traces, dynamic tiling reduces on-chip memory requirement by 2.18x, dynamic parallelization improves latency by 1.5x, and configuration time-multiplexing improves compute utilization by 2.57x over implementations available in prior abstractions.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [3] [Blockly2Hooks: Smart Contracts for Everyone with the XRP Ledger and Google Blockly](https://arxiv.org/abs/2511.08403)
*Lucian Trestioreanu,Wazen Shbair,Flaviene Scheidt de Cristo,Radu State*

Main category: cs.CR

TL;DR: 开发了Blockly2Hooks工具，使用可视化编程语言帮助非专家用户学习智能合约开发，特别针对XRP Ledger上的C语言智能合约。


<details>
  <summary>Details</summary>
Motivation: 智能合约面临知识用户和工具短缺的问题，当前主要由专业开发者处理，学习曲线陡峭，可用性研究不足。需要降低入门门槛让非专家也能创建智能合约。

Method: 设计开发Blockly2Hooks解决方案，利用Google的Blockly可视化编程库，采用可视化编程语言教学方法，针对XRP Ledger上的C语言智能合约场景。

Result: 平台经过开发和测试，结果显示能够使学习智能合约开发更加顺畅，前景良好。

Conclusion: Blockly2Hooks通过可视化编程方法成功降低了智能合约的学习门槛，为非专家用户提供了有效的学习工具。

Abstract: Recent technologies such as inter-ledger payments, non-fungible tokens, and smart contracts are all fruited from the ongoing development of Distributed Ledger Technologies. The foreseen trend is that they will play an increasingly visible role in daily life, which will have to be backed by appropriate operational resources. For example, due to increasing demand, smart contracts could soon face a shortage of knowledgeable users and tools to handle them in practice. Widespread smart contract adoption is currently limited by security, usability and costs aspects. Because of a steep learning curve, the handling of smart contracts is currently performed by specialised developers mainly, and most of the research effort is focusing on smart contract security, while other aspects like usability being somewhat neglected. Specific tools would lower the entry barrier, enabling interested non-experts to create smart contracts.
  In this paper we designed, developed and tested Blockly2Hooks, a solution towards filling this gap even in challenging scenarios such as when the smart contracts are written in an advanced language like C. With the XRP Ledger as a concrete working case, Blockly2Hooks helps interested non-experts from the community to learn smart contracts easily and adopt the technology, through leveraging well-proven teaching methodologies like Visual Programming Languages, and more specifically, the Blockly Visual Programming library from Google. The platform was developed and tested and the results are promising to make learning smart contract development smoother.

</details>


### [4] [QLCoder: A Query Synthesizer For Static Analysis of Security Vulnerabilities](https://arxiv.org/abs/2511.08462)
*Claire Wang,Ziyang Li,Saikat Dutta,Mayur Naik*

Main category: cs.CR

TL;DR: QLCoder是一个基于LLM的代理框架，能够直接从CVE元数据自动合成CodeQL安全查询，通过执行反馈和结构化约束提高查询生成准确性。


<details>
  <summary>Details</summary>
Motivation: 编写静态分析工具的安全查询需要安全知识和程序分析专业知识，这具有挑战性。QLCoder旨在自动化这一过程，直接从CVE生成有效的CodeQL查询。

Method: QLCoder将LLM嵌入到合成循环中，使用执行反馈机制，并通过自定义MCP接口约束推理过程，该接口允许与语言服务器协议（语法指导）和RAG数据库（语义检索）进行结构化交互。

Result: 在111个Java项目的176个CVE上评估，QLCoder成功合成了53.4%的正确查询（在易受攻击版本中检测到CVE但在修补版本中不检测），而仅使用Claude Code只能合成10%的正确查询。

Conclusion: QLCoder通过结合LLM、执行反馈和结构化约束，显著提高了从CVE自动生成有效安全查询的能力，证明了代理框架在静态分析查询合成中的有效性。

Abstract: Static analysis tools provide a powerful means to detect security vulnerabilities by specifying queries that encode vulnerable code patterns. However, writing such queries is challenging and requires diverse expertise in security and program analysis. To address this challenge, we present QLCoder - an agentic framework that automatically synthesizes queries in CodeQL, a powerful static analysis engine, directly from a given CVE metadata. QLCode embeds an LLM in a synthesis loop with execution feedback, while constraining its reasoning using a custom MCP interface that allows structured interaction with a Language Server Protocol (for syntax guidance) and a RAG database (for semantic retrieval of queries and documentation). This approach allows QLCoder to generate syntactically and semantically valid security queries. We evaluate QLCode on 176 existing CVEs across 111 Java projects. Building upon the Claude Code agent framework, QLCoder synthesizes correct queries that detect the CVE in the vulnerable but not in the patched versions for 53.4% of CVEs. In comparison, using only Claude Code synthesizes 10% correct queries.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [5] [Can Large Language Models Simulate Symbolic Execution Output Like KLEE?](https://arxiv.org/abs/2511.08530)
*Rong Feng,Vanisha Gupta,Vivek Patel,Viroopaksh Reddy Ernampati,Suman Saha*

Main category: cs.SE

TL;DR: 探索使用GPT-4o模拟KLEE符号执行工具的输出，特别是识别程序中最受约束的执行路径，以评估LLM替代部分符号执行的可能性。


<details>
  <summary>Details</summary>
Motivation: KLEE等符号执行工具在处理复杂程序时资源消耗大、速度慢，希望探索LLM能否替代部分符号执行功能以节省时间和资源。

Method: 使用GPT-4o在100个C程序数据集上预测KLEE输出和识别最受约束路径（具有最多符号条件的执行路径）。

Result: GPT-4o在生成KLEE类输出和识别最受约束路径方面达到约20%的准确率。

Conclusion: 虽然准确率不高，但这项早期工作展示了当前LLM在模拟符号执行方面的能力和局限性。

Abstract: Symbolic execution helps check programs by exploring different paths based on symbolic inputs. Tools like KLEE are commonly used because they can automatically detect bugs and create test cases. But one of KLEE's biggest issues is how slow it can get when programs have lots of branching paths-it often becomes too resource-heavy to run on large or complex code. In this project, we wanted to see if a large language model like GPT-4o could simulate the kinds of outputs that KLEE generates. The idea was to explore whether LLMs could one day replace parts of symbolic execution to save time and resources.
  One specific goal was to have GPT-4o identify the most constrained path in a program, this is the execution path with the most symbolic conditions. These paths are especially important because they often represent edge cases that are harder to test and more likely to contain deep bugs. However, figuring this out usually requires fully running KLEE, which can be expensive. So, we tested whether GPT-4o could predict the KLEE outputs and the most complex path using a dataset of 100 C programs. Our results showed about 20% accuracy in generating KLEE-like outputs and identifying the most constrained path. While not highly accurate, this early work helps show what current LLMs can and can't do when it comes to simulating symbolic execution.

</details>
