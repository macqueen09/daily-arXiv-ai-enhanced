<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.DC](#cs.DC) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Soteria: Efficient Symbolic Execution as a Functional Library](https://arxiv.org/abs/2511.08729)
*Sacha-Élie Ayoun,Opale Sjöstedt,Azalea Raad*

Main category: cs.PL

TL;DR: Soteria是一个轻量级OCaml库，用于直接为源语言构建符号执行引擎，避免了中间语言的性能、准确性和功能支持权衡。


<details>
  <summary>Details</summary>
Motivation: 传统符号执行工具依赖中间语言存在性能、准确性和语言特性支持之间的权衡问题，直接为每种源语言构建符号执行引擎更简单有效。

Method: 开发Soteria库，采用函数式编程风格，直接在源语言语义上构建符号执行引擎，支持可配置性和组合推理。

Result: 基于Soteria构建了支持Rust Tree Borrows模型的Soteria^Rust和组合式C符号执行引擎Soteria^C，在性能和bug检测数量上优于Kani、Pulse、CBMC和Gillian-C等最先进工具。

Conclusion: Soteria证明了无需中间语言的妥协，即可实现声音、高效、准确和表达力强的符号执行。

Abstract: Symbolic execution (SE) tools often rely on intermediate languages (ILs) to support multiple programming languages, promising reusability and efficiency. In practice, this approach introduces trade-offs between performance, accuracy, and language feature support. We argue that building SE engines \emph{directly} for each source language is both simpler and more effective. We present Soteria, a lightweight OCaml library for writing SE engines in a functional style, without compromising on performance, accuracy or feature support. Soteria enables developers to construct SE engines that operate directly over source-language semantics, offering \emph{configurability}, compositional reasoning, and ease of implementation. Using Soteria, we develop Soteria$^{\text{Rust}}$, the \emph{first} Rust SE engine supporting Tree Borrows (the intricate aliasing model of Rust), and Soteria$^{\text{C}}$, a compositional SE engine for C. Both tools are competitive with or outperform state-of-the-art tools such as Kani, Pulse, CBMC and Gillian-C in performance and the number of bugs detected. We formalise the theoretical foundations of Soteria and prove its soundness, demonstrating that sound, efficient, accurate, and expressive SE can be achieved without the compromises of ILs.

</details>


### [2] [Galois Slicing as Automatic Differentiation](https://arxiv.org/abs/2511.09203)
*Robert Atkey,Roly Perera*

Main category: cs.PL

TL;DR: 本文通过将Galois切片与可微分编程类比，使用CHAD自动微分方法重新表述Galois切片，并探索其在定量区间分析中的扩展应用。


<details>
  <summary>Details</summary>
Motivation: 探索Galois切片与可微分编程之间的类比关系，将切片的前向和后向实现视为一种自动微分，以澄清现有方法中的隐式选择。

Method: 使用Vákár等人提出的CHAD自动微分方法，通过范畴语义重新表述Galois切片，并扩展到定量区间分析。

Result: 成功建立了Galois切片与自动微分之间的形式化联系，澄清了现有方法中的隐式选择，并展示了在定量区间分析中的扩展应用。

Conclusion: 通过范畴语义重新表述Galois切片，不仅澄清了现有方法，还为扩展到更复杂的分析（如定量区间分析）提供了理论基础。

Abstract: Galois slicing is a technique for program slicing for provenance, developed by Perera and collaborators. Galois slicing aims to explain program executions by demonstrating how to track approximations of the input and output forwards and backwards along a particular execution. In this paper, we explore an analogy between Galois slicing and differentiable programming, seeing the implementation of forwards and backwards slicing as a kind of automatic differentiation. Using the CHAD approach to automatic differentiation due to Vákár and collaborators, we reformulate Galois slicing via a categorical semantics. In doing so, we are able to explore extensions of the Galois slicing idea to quantitative interval analysis, and to clarify the implicit choices made in existing instantiations of this approach.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [Hey Pentti, We Did (More of) It!: A Vector-Symbolic Lisp With Residue Arithmetic](https://arxiv.org/abs/2511.08767)
*Connor Hanley,Eilene Tomkins-Flanaganm,Mary Alexandria Kelly*

Main category: cs.LG

TL;DR: 本文通过使用频域全息缩减表示(FHRRs)扩展了Lisp 1.5的向量符号架构(VSA)编码，添加了基于残差超维计算(RHC)的算术运算原语，在高维向量空间中编码图灵完备语法，增强神经网络状态的表达能力。


<details>
  <summary>Details</summary>
Motivation: 提高神经网络状态的表达能力，使网络状态能够包含任意结构化的、固有可解释的表示，从而开发出比现有智能体更通用的智能代理。

Method: 使用频域全息缩减表示(FHRRs)扩展向量符号架构(VSA)对Lisp 1.5的编码，引入基于残差超维计算(RHC)的算术运算原语，在高维向量空间中实现图灵完备语法的编码。

Result: 成功在高维向量空间中编码了图灵完备的语法，使神经网络状态能够包含结构化表示，这些表示具有固有的可解释性。

Conclusion: VSA编码在机器学习任务中具有潜在应用价值，编码结构化表示和设计对其表示结构敏感行为的神经网络对于开发更通用的智能代理具有重要意义。

Abstract: Using Frequency-domain Holographic Reduced Representations (FHRRs), we extend a Vector-Symbolic Architecture (VSA) encoding of Lisp 1.5 with primitives for arithmetic operations using Residue Hyperdimensional Computing (RHC). Encoding a Turing-complete syntax over a high-dimensional vector space increases the expressivity of neural network states, enabling network states to contain arbitrarily structured representations that are inherently interpretable. We discuss the potential applications of the VSA encoding in machine learning tasks, as well as the importance of encoding structured representations and designing neural networks whose behavior is sensitive to the structure of their representations in virtue of attaining more general intelligent agents than exist at present.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [4] [An MLIR pipeline for offloading Fortran to FPGAs via OpenMP](https://arxiv.org/abs/2511.08713)
*Gabriel Rodriguez-Canal,David Katz,Nick Brown*

Main category: cs.DC

TL;DR: 首次在MLIR中通过OpenMP目标指令实现选择性代码卸载到FPGA，结合OpenMP方言和HLS方言提供可移植的FPGA编译流程。


<details>
  <summary>Details</summary>
Motivation: 随着摩尔定律放缓，FPGA等异构计算平台在加速HPC工作负载方面日益受到关注，需要更灵活的FPGA加速方法。

Method: 将MLIR OpenMP方言与高级综合(HLS)方言结合，支持任何MLIR兼容前端(如Flang)，利用现有MLIR构建模块减少开发工作量。

Result: 实现了基于指令的FPGA加速，支持通过标准OpenMP指令手动优化卸载内核，展示了MLIR生态系统的可组合性优势。

Conclusion: 建立了一个灵活且可扩展的基于指令的FPGA加速路径，集成在MLIR生态系统中，为异构计算提供了新的编译方法。

Abstract: With the slowing of Moore's Law, heterogeneous computing platforms such as Field Programmable Gate Arrays (FPGAs) have gained increasing interest for accelerating HPC workloads. In this work we present, to the best of our knowledge, the first implementation of selective code offloading to FPGAs via the OpenMP target directive within MLIR. Our approach combines the MLIR OpenMP dialect with a High-Level Synthesis (HLS) dialect to provide a portable compilation flow targeting FPGAs. Unlike prior OpenMP FPGA efforts that rely on custom compilers, by contrast we integrate with MLIR and so support any MLIR-compatible front end, demonstrated here with Flang. Building upon a range of existing MLIR building blocks significantly reduces the effort required and demonstrates the composability benefits of the MLIR ecosystem. Our approach supports manual optimisation of offloaded kernels through standard OpenMP directives, and this work establishes a flexible and extensible path for directive-based FPGA acceleration integrated within the MLIR ecosystem.

</details>


### [5] [SPADA: A Spatial Dataflow Architecture Programming Language](https://arxiv.org/abs/2511.09447)
*Lukas Gianinazzi,Tal Ben-Nun,Torsten Hoefler*

Main category: cs.DC

TL;DR: SPADA是一个针对空间数据流架构的编程语言，为Cerebras晶圆级引擎等架构提供精确的数据放置、数据流模式和异步操作控制，同时抽象底层细节，显著减少代码量并实现接近理想的弱扩展性能。


<details>
  <summary>Details</summary>
Motivation: 空间数据流架构在AI和科学计算中表现出色，但由于需要显式编排数据移动和异步计算，编程难度大。现有FPGA和CGRA编程模型忽视了空间数据流架构的独特能力，特别是高效的数据流和复杂路由管理。

Method: 开发SPADA编程语言，提供严格的数据流语义框架，定义路由正确性、数据竞争和死锁。设计并实现针对Cerebras CSL的多级编译器，支持领域特定语言作为中间表示。

Result: SPADA使开发者能够用比CSL少6-8倍的代码表达复杂的并行模式，包括流水线归约和多维模板，在三个数量级范围内实现接近理想的弱扩展。

Conclusion: SPADA通过统一空间数据流架构的编程模型，推进了这些新兴高性能计算平台的理论基础和实践可用性。

Abstract: Spatial dataflow architectures like the Cerebras Wafer-Scale Engine achieve exceptional performance in AI and scientific applications by leveraging distributed memory across processing elements (PEs) and localized computation. However, programming these architectures remains challenging due to the need for explicit orchestration of data movement through reconfigurable networks-on-chip and asynchronous computation triggered by data arrival. Existing FPGA and CGRA programming models emphasize loop scheduling but overlook the unique capabilities of spatial dataflow architectures, particularly efficient dataflow over regular grids and intricate routing management.
  We present SPADA, a programming language that provides precise control over data placement, dataflow patterns, and asynchronous operations while abstracting architecture-specific low-level details. We introduce a rigorous dataflow semantics framework for SPADA that defines routing correctness, data races, and deadlocks. Additionally, we design and implement a compiler targeting Cerebras CSL with multi-level lowering.
  SPADA serves as both a high-level programming interface and an intermediate representation for domain-specific languages (DSLs), which we demonstrate with the GT4Py stencil DSL. SPADA enables developers to express complex parallel patterns -- including pipelined reductions and multi-dimensional stencils -- in 6--8x less code than CSL with near-ideal weak scaling across three orders of magnitude. By unifying programming for spatial dataflow architectures under a single model, SPADA advances both the theoretical foundations and practical usability of these emerging high-performance computing platforms.

</details>
