{"id": "2511.08729", "pdf": "https://arxiv.org/pdf/2511.08729", "abs": "https://arxiv.org/abs/2511.08729", "authors": ["Sacha-\u00c9lie Ayoun", "Opale Sj\u00f6stedt", "Azalea Raad"], "title": "Soteria: Efficient Symbolic Execution as a Functional Library", "categories": ["cs.PL"], "comment": null, "summary": "Symbolic execution (SE) tools often rely on intermediate languages (ILs) to support multiple programming languages, promising reusability and efficiency. In practice, this approach introduces trade-offs between performance, accuracy, and language feature support. We argue that building SE engines \\emph{directly} for each source language is both simpler and more effective. We present Soteria, a lightweight OCaml library for writing SE engines in a functional style, without compromising on performance, accuracy or feature support. Soteria enables developers to construct SE engines that operate directly over source-language semantics, offering \\emph{configurability}, compositional reasoning, and ease of implementation. Using Soteria, we develop Soteria$^{\\text{Rust}}$, the \\emph{first} Rust SE engine supporting Tree Borrows (the intricate aliasing model of Rust), and Soteria$^{\\text{C}}$, a compositional SE engine for C. Both tools are competitive with or outperform state-of-the-art tools such as Kani, Pulse, CBMC and Gillian-C in performance and the number of bugs detected. We formalise the theoretical foundations of Soteria and prove its soundness, demonstrating that sound, efficient, accurate, and expressive SE can be achieved without the compromises of ILs.", "AI": {"tldr": "Soteria\u662f\u4e00\u4e2a\u8f7b\u91cf\u7ea7OCaml\u5e93\uff0c\u7528\u4e8e\u76f4\u63a5\u4e3a\u6e90\u8bed\u8a00\u6784\u5efa\u7b26\u53f7\u6267\u884c\u5f15\u64ce\uff0c\u907f\u514d\u4e86\u4e2d\u95f4\u8bed\u8a00\u7684\u6027\u80fd\u3001\u51c6\u786e\u6027\u548c\u529f\u80fd\u652f\u6301\u6743\u8861\u3002", "motivation": "\u4f20\u7edf\u7b26\u53f7\u6267\u884c\u5de5\u5177\u4f9d\u8d56\u4e2d\u95f4\u8bed\u8a00\u5b58\u5728\u6027\u80fd\u3001\u51c6\u786e\u6027\u548c\u8bed\u8a00\u7279\u6027\u652f\u6301\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u76f4\u63a5\u4e3a\u6bcf\u79cd\u6e90\u8bed\u8a00\u6784\u5efa\u7b26\u53f7\u6267\u884c\u5f15\u64ce\u66f4\u7b80\u5355\u6709\u6548\u3002", "method": "\u5f00\u53d1Soteria\u5e93\uff0c\u91c7\u7528\u51fd\u6570\u5f0f\u7f16\u7a0b\u98ce\u683c\uff0c\u76f4\u63a5\u5728\u6e90\u8bed\u8a00\u8bed\u4e49\u4e0a\u6784\u5efa\u7b26\u53f7\u6267\u884c\u5f15\u64ce\uff0c\u652f\u6301\u53ef\u914d\u7f6e\u6027\u548c\u7ec4\u5408\u63a8\u7406\u3002", "result": "\u57fa\u4e8eSoteria\u6784\u5efa\u4e86\u652f\u6301Rust Tree Borrows\u6a21\u578b\u7684Soteria^Rust\u548c\u7ec4\u5408\u5f0fC\u7b26\u53f7\u6267\u884c\u5f15\u64ceSoteria^C\uff0c\u5728\u6027\u80fd\u548cbug\u68c0\u6d4b\u6570\u91cf\u4e0a\u4f18\u4e8eKani\u3001Pulse\u3001CBMC\u548cGillian-C\u7b49\u6700\u5148\u8fdb\u5de5\u5177\u3002", "conclusion": "Soteria\u8bc1\u660e\u4e86\u65e0\u9700\u4e2d\u95f4\u8bed\u8a00\u7684\u59a5\u534f\uff0c\u5373\u53ef\u5b9e\u73b0\u58f0\u97f3\u3001\u9ad8\u6548\u3001\u51c6\u786e\u548c\u8868\u8fbe\u529b\u5f3a\u7684\u7b26\u53f7\u6267\u884c\u3002"}}
{"id": "2511.09203", "pdf": "https://arxiv.org/pdf/2511.09203", "abs": "https://arxiv.org/abs/2511.09203", "authors": ["Robert Atkey", "Roly Perera"], "title": "Galois Slicing as Automatic Differentiation", "categories": ["cs.PL"], "comment": null, "summary": "Galois slicing is a technique for program slicing for provenance, developed by Perera and collaborators. Galois slicing aims to explain program executions by demonstrating how to track approximations of the input and output forwards and backwards along a particular execution. In this paper, we explore an analogy between Galois slicing and differentiable programming, seeing the implementation of forwards and backwards slicing as a kind of automatic differentiation. Using the CHAD approach to automatic differentiation due to V\u00e1k\u00e1r and collaborators, we reformulate Galois slicing via a categorical semantics. In doing so, we are able to explore extensions of the Galois slicing idea to quantitative interval analysis, and to clarify the implicit choices made in existing instantiations of this approach.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c06Galois\u5207\u7247\u4e0e\u53ef\u5fae\u5206\u7f16\u7a0b\u7c7b\u6bd4\uff0c\u4f7f\u7528CHAD\u81ea\u52a8\u5fae\u5206\u65b9\u6cd5\u91cd\u65b0\u8868\u8ff0Galois\u5207\u7247\uff0c\u5e76\u63a2\u7d22\u5176\u5728\u5b9a\u91cf\u533a\u95f4\u5206\u6790\u4e2d\u7684\u6269\u5c55\u5e94\u7528\u3002", "motivation": "\u63a2\u7d22Galois\u5207\u7247\u4e0e\u53ef\u5fae\u5206\u7f16\u7a0b\u4e4b\u95f4\u7684\u7c7b\u6bd4\u5173\u7cfb\uff0c\u5c06\u5207\u7247\u7684\u524d\u5411\u548c\u540e\u5411\u5b9e\u73b0\u89c6\u4e3a\u4e00\u79cd\u81ea\u52a8\u5fae\u5206\uff0c\u4ee5\u6f84\u6e05\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u9690\u5f0f\u9009\u62e9\u3002", "method": "\u4f7f\u7528V\u00e1k\u00e1r\u7b49\u4eba\u63d0\u51fa\u7684CHAD\u81ea\u52a8\u5fae\u5206\u65b9\u6cd5\uff0c\u901a\u8fc7\u8303\u7574\u8bed\u4e49\u91cd\u65b0\u8868\u8ff0Galois\u5207\u7247\uff0c\u5e76\u6269\u5c55\u5230\u5b9a\u91cf\u533a\u95f4\u5206\u6790\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86Galois\u5207\u7247\u4e0e\u81ea\u52a8\u5fae\u5206\u4e4b\u95f4\u7684\u5f62\u5f0f\u5316\u8054\u7cfb\uff0c\u6f84\u6e05\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u9690\u5f0f\u9009\u62e9\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u5b9a\u91cf\u533a\u95f4\u5206\u6790\u4e2d\u7684\u6269\u5c55\u5e94\u7528\u3002", "conclusion": "\u901a\u8fc7\u8303\u7574\u8bed\u4e49\u91cd\u65b0\u8868\u8ff0Galois\u5207\u7247\uff0c\u4e0d\u4ec5\u6f84\u6e05\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u8fd8\u4e3a\u6269\u5c55\u5230\u66f4\u590d\u6742\u7684\u5206\u6790\uff08\u5982\u5b9a\u91cf\u533a\u95f4\u5206\u6790\uff09\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.08713", "pdf": "https://arxiv.org/pdf/2511.08713", "abs": "https://arxiv.org/abs/2511.08713", "authors": ["Gabriel Rodriguez-Canal", "David Katz", "Nick Brown"], "title": "An MLIR pipeline for offloading Fortran to FPGAs via OpenMP", "categories": ["cs.DC", "cs.PL"], "comment": "Author accepted version of paper published in SC25 LLVM workshop", "summary": "With the slowing of Moore's Law, heterogeneous computing platforms such as Field Programmable Gate Arrays (FPGAs) have gained increasing interest for accelerating HPC workloads. In this work we present, to the best of our knowledge, the first implementation of selective code offloading to FPGAs via the OpenMP target directive within MLIR. Our approach combines the MLIR OpenMP dialect with a High-Level Synthesis (HLS) dialect to provide a portable compilation flow targeting FPGAs. Unlike prior OpenMP FPGA efforts that rely on custom compilers, by contrast we integrate with MLIR and so support any MLIR-compatible front end, demonstrated here with Flang. Building upon a range of existing MLIR building blocks significantly reduces the effort required and demonstrates the composability benefits of the MLIR ecosystem. Our approach supports manual optimisation of offloaded kernels through standard OpenMP directives, and this work establishes a flexible and extensible path for directive-based FPGA acceleration integrated within the MLIR ecosystem.", "AI": {"tldr": "\u9996\u6b21\u5728MLIR\u4e2d\u901a\u8fc7OpenMP\u76ee\u6807\u6307\u4ee4\u5b9e\u73b0\u9009\u62e9\u6027\u4ee3\u7801\u5378\u8f7d\u5230FPGA\uff0c\u7ed3\u5408OpenMP\u65b9\u8a00\u548cHLS\u65b9\u8a00\u63d0\u4f9b\u53ef\u79fb\u690d\u7684FPGA\u7f16\u8bd1\u6d41\u7a0b\u3002", "motivation": "\u968f\u7740\u6469\u5c14\u5b9a\u5f8b\u653e\u7f13\uff0cFPGA\u7b49\u5f02\u6784\u8ba1\u7b97\u5e73\u53f0\u5728\u52a0\u901fHPC\u5de5\u4f5c\u8d1f\u8f7d\u65b9\u9762\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684FPGA\u52a0\u901f\u65b9\u6cd5\u3002", "method": "\u5c06MLIR OpenMP\u65b9\u8a00\u4e0e\u9ad8\u7ea7\u7efc\u5408(HLS)\u65b9\u8a00\u7ed3\u5408\uff0c\u652f\u6301\u4efb\u4f55MLIR\u517c\u5bb9\u524d\u7aef(\u5982Flang)\uff0c\u5229\u7528\u73b0\u6709MLIR\u6784\u5efa\u6a21\u5757\u51cf\u5c11\u5f00\u53d1\u5de5\u4f5c\u91cf\u3002", "result": "\u5b9e\u73b0\u4e86\u57fa\u4e8e\u6307\u4ee4\u7684FPGA\u52a0\u901f\uff0c\u652f\u6301\u901a\u8fc7\u6807\u51c6OpenMP\u6307\u4ee4\u624b\u52a8\u4f18\u5316\u5378\u8f7d\u5185\u6838\uff0c\u5c55\u793a\u4e86MLIR\u751f\u6001\u7cfb\u7edf\u7684\u53ef\u7ec4\u5408\u6027\u4f18\u52bf\u3002", "conclusion": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u7075\u6d3b\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u6307\u4ee4\u7684FPGA\u52a0\u901f\u8def\u5f84\uff0c\u96c6\u6210\u5728MLIR\u751f\u6001\u7cfb\u7edf\u4e2d\uff0c\u4e3a\u5f02\u6784\u8ba1\u7b97\u63d0\u4f9b\u4e86\u65b0\u7684\u7f16\u8bd1\u65b9\u6cd5\u3002"}}
{"id": "2511.08767", "pdf": "https://arxiv.org/pdf/2511.08767", "abs": "https://arxiv.org/abs/2511.08767", "authors": ["Connor Hanley", "Eilene Tomkins-Flanaganm", "Mary Alexandria Kelly"], "title": "Hey Pentti, We Did (More of) It!: A Vector-Symbolic Lisp With Residue Arithmetic", "categories": ["cs.LG", "cs.AI", "cs.PL"], "comment": "11 pages, 1 figure, conference paper at IJCNN 2025 Rome", "summary": "Using Frequency-domain Holographic Reduced Representations (FHRRs), we extend a Vector-Symbolic Architecture (VSA) encoding of Lisp 1.5 with primitives for arithmetic operations using Residue Hyperdimensional Computing (RHC). Encoding a Turing-complete syntax over a high-dimensional vector space increases the expressivity of neural network states, enabling network states to contain arbitrarily structured representations that are inherently interpretable. We discuss the potential applications of the VSA encoding in machine learning tasks, as well as the importance of encoding structured representations and designing neural networks whose behavior is sensitive to the structure of their representations in virtue of attaining more general intelligent agents than exist at present.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4f7f\u7528\u9891\u57df\u5168\u606f\u7f29\u51cf\u8868\u793a(FHRRs)\u6269\u5c55\u4e86Lisp 1.5\u7684\u5411\u91cf\u7b26\u53f7\u67b6\u6784(VSA)\u7f16\u7801\uff0c\u6dfb\u52a0\u4e86\u57fa\u4e8e\u6b8b\u5dee\u8d85\u7ef4\u8ba1\u7b97(RHC)\u7684\u7b97\u672f\u8fd0\u7b97\u539f\u8bed\uff0c\u5728\u9ad8\u7ef4\u5411\u91cf\u7a7a\u95f4\u4e2d\u7f16\u7801\u56fe\u7075\u5b8c\u5907\u8bed\u6cd5\uff0c\u589e\u5f3a\u795e\u7ecf\u7f51\u7edc\u72b6\u6001\u7684\u8868\u8fbe\u80fd\u529b\u3002", "motivation": "\u63d0\u9ad8\u795e\u7ecf\u7f51\u7edc\u72b6\u6001\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4f7f\u7f51\u7edc\u72b6\u6001\u80fd\u591f\u5305\u542b\u4efb\u610f\u7ed3\u6784\u5316\u7684\u3001\u56fa\u6709\u53ef\u89e3\u91ca\u7684\u8868\u793a\uff0c\u4ece\u800c\u5f00\u53d1\u51fa\u6bd4\u73b0\u6709\u667a\u80fd\u4f53\u66f4\u901a\u7528\u7684\u667a\u80fd\u4ee3\u7406\u3002", "method": "\u4f7f\u7528\u9891\u57df\u5168\u606f\u7f29\u51cf\u8868\u793a(FHRRs)\u6269\u5c55\u5411\u91cf\u7b26\u53f7\u67b6\u6784(VSA)\u5bf9Lisp 1.5\u7684\u7f16\u7801\uff0c\u5f15\u5165\u57fa\u4e8e\u6b8b\u5dee\u8d85\u7ef4\u8ba1\u7b97(RHC)\u7684\u7b97\u672f\u8fd0\u7b97\u539f\u8bed\uff0c\u5728\u9ad8\u7ef4\u5411\u91cf\u7a7a\u95f4\u4e2d\u5b9e\u73b0\u56fe\u7075\u5b8c\u5907\u8bed\u6cd5\u7684\u7f16\u7801\u3002", "result": "\u6210\u529f\u5728\u9ad8\u7ef4\u5411\u91cf\u7a7a\u95f4\u4e2d\u7f16\u7801\u4e86\u56fe\u7075\u5b8c\u5907\u7684\u8bed\u6cd5\uff0c\u4f7f\u795e\u7ecf\u7f51\u7edc\u72b6\u6001\u80fd\u591f\u5305\u542b\u7ed3\u6784\u5316\u8868\u793a\uff0c\u8fd9\u4e9b\u8868\u793a\u5177\u6709\u56fa\u6709\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "VSA\u7f16\u7801\u5728\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u5177\u6709\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\uff0c\u7f16\u7801\u7ed3\u6784\u5316\u8868\u793a\u548c\u8bbe\u8ba1\u5bf9\u5176\u8868\u793a\u7ed3\u6784\u654f\u611f\u884c\u4e3a\u7684\u795e\u7ecf\u7f51\u7edc\u5bf9\u4e8e\u5f00\u53d1\u66f4\u901a\u7528\u7684\u667a\u80fd\u4ee3\u7406\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2511.09447", "pdf": "https://arxiv.org/pdf/2511.09447", "abs": "https://arxiv.org/abs/2511.09447", "authors": ["Lukas Gianinazzi", "Tal Ben-Nun", "Torsten Hoefler"], "title": "SPADA: A Spatial Dataflow Architecture Programming Language", "categories": ["cs.DC", "cs.PL"], "comment": null, "summary": "Spatial dataflow architectures like the Cerebras Wafer-Scale Engine achieve exceptional performance in AI and scientific applications by leveraging distributed memory across processing elements (PEs) and localized computation. However, programming these architectures remains challenging due to the need for explicit orchestration of data movement through reconfigurable networks-on-chip and asynchronous computation triggered by data arrival. Existing FPGA and CGRA programming models emphasize loop scheduling but overlook the unique capabilities of spatial dataflow architectures, particularly efficient dataflow over regular grids and intricate routing management.\n  We present SPADA, a programming language that provides precise control over data placement, dataflow patterns, and asynchronous operations while abstracting architecture-specific low-level details. We introduce a rigorous dataflow semantics framework for SPADA that defines routing correctness, data races, and deadlocks. Additionally, we design and implement a compiler targeting Cerebras CSL with multi-level lowering.\n  SPADA serves as both a high-level programming interface and an intermediate representation for domain-specific languages (DSLs), which we demonstrate with the GT4Py stencil DSL. SPADA enables developers to express complex parallel patterns -- including pipelined reductions and multi-dimensional stencils -- in 6--8x less code than CSL with near-ideal weak scaling across three orders of magnitude. By unifying programming for spatial dataflow architectures under a single model, SPADA advances both the theoretical foundations and practical usability of these emerging high-performance computing platforms.", "AI": {"tldr": "SPADA\u662f\u4e00\u4e2a\u9488\u5bf9\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u7684\u7f16\u7a0b\u8bed\u8a00\uff0c\u4e3aCerebras\u6676\u5706\u7ea7\u5f15\u64ce\u7b49\u67b6\u6784\u63d0\u4f9b\u7cbe\u786e\u7684\u6570\u636e\u653e\u7f6e\u3001\u6570\u636e\u6d41\u6a21\u5f0f\u548c\u5f02\u6b65\u64cd\u4f5c\u63a7\u5236\uff0c\u540c\u65f6\u62bd\u8c61\u5e95\u5c42\u7ec6\u8282\uff0c\u663e\u8457\u51cf\u5c11\u4ee3\u7801\u91cf\u5e76\u5b9e\u73b0\u63a5\u8fd1\u7406\u60f3\u7684\u5f31\u6269\u5c55\u6027\u80fd\u3002", "motivation": "\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u5728AI\u548c\u79d1\u5b66\u8ba1\u7b97\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7531\u4e8e\u9700\u8981\u663e\u5f0f\u7f16\u6392\u6570\u636e\u79fb\u52a8\u548c\u5f02\u6b65\u8ba1\u7b97\uff0c\u7f16\u7a0b\u96be\u5ea6\u5927\u3002\u73b0\u6709FPGA\u548cCGRA\u7f16\u7a0b\u6a21\u578b\u5ffd\u89c6\u4e86\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u7684\u72ec\u7279\u80fd\u529b\uff0c\u7279\u522b\u662f\u9ad8\u6548\u7684\u6570\u636e\u6d41\u548c\u590d\u6742\u8def\u7531\u7ba1\u7406\u3002", "method": "\u5f00\u53d1SPADA\u7f16\u7a0b\u8bed\u8a00\uff0c\u63d0\u4f9b\u4e25\u683c\u7684\u6570\u636e\u6d41\u8bed\u4e49\u6846\u67b6\uff0c\u5b9a\u4e49\u8def\u7531\u6b63\u786e\u6027\u3001\u6570\u636e\u7ade\u4e89\u548c\u6b7b\u9501\u3002\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u9488\u5bf9Cerebras CSL\u7684\u591a\u7ea7\u7f16\u8bd1\u5668\uff0c\u652f\u6301\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\u3002", "result": "SPADA\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u7528\u6bd4CSL\u5c116-8\u500d\u7684\u4ee3\u7801\u8868\u8fbe\u590d\u6742\u7684\u5e76\u884c\u6a21\u5f0f\uff0c\u5305\u62ec\u6d41\u6c34\u7ebf\u5f52\u7ea6\u548c\u591a\u7ef4\u6a21\u677f\uff0c\u5728\u4e09\u4e2a\u6570\u91cf\u7ea7\u8303\u56f4\u5185\u5b9e\u73b0\u63a5\u8fd1\u7406\u60f3\u7684\u5f31\u6269\u5c55\u3002", "conclusion": "SPADA\u901a\u8fc7\u7edf\u4e00\u7a7a\u95f4\u6570\u636e\u6d41\u67b6\u6784\u7684\u7f16\u7a0b\u6a21\u578b\uff0c\u63a8\u8fdb\u4e86\u8fd9\u4e9b\u65b0\u5174\u9ad8\u6027\u80fd\u8ba1\u7b97\u5e73\u53f0\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u53ef\u7528\u6027\u3002"}}
