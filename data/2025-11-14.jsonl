{"id": "2511.09987", "pdf": "https://arxiv.org/pdf/2511.09987", "abs": "https://arxiv.org/abs/2511.09987", "authors": ["Shiv Sundram", "Akhilesh Balasingam", "Nathan Zhang", "Kunle Olukotun", "Fredrik Kjolstad"], "title": "Cyclotron: Compilation of Recurrences to Distributed and Systolic Architectures", "categories": ["cs.PL"], "comment": null, "summary": "We present Cyclotron, a framework and compiler for using recurrence equations to express streaming dataflow algorithms, which then get portably compiled to distributed topologies of interlinked processors. Our framework provides an input language of recurrences over logical tensors, which then gets lowered into an intermediate language of recurrences over logical iteration spaces, and finally into programs of send, receive, and computation operations specific to each individual processor. In Cyclotron's IR, programs are optimized such that external memory interactions are confined to the boundaries of the iteration space. Within inner iteration spaces, all data accesses become local: data accesses target values residing in local fast memory or on neighboring processing units, avoiding costly memory movement. We provide a scheduling language allowing users to define how data gets streamed and broadcasted between processors, enabling pipelined execution of computation kernels over distributed topologies of processing elements. We demonstrate the portability of our approach by compiling our IR to a reconfigurable simulator of systolic arrays and chiplet style distributed hardware, as well as to distributed-memory CPU clusters. In the simulated reconfigurable setting, we use our compiler for hardware design space exploration in which link costs and latencies can be specified. In the distributed CPU setting, we show how to use recurrences and our scheduling language to express various matrix multiplication routines (Cannon, SUMMA, PUMMA, weight stationary) and solvers (Triangular solve and Cholesky). For matrix multiplication and the triangular solve, we generate distributed implementations competitive with ScaLAPACK."}
{"id": "2511.10343", "pdf": "https://arxiv.org/pdf/2511.10343", "abs": "https://arxiv.org/abs/2511.10343", "authors": ["Alistair O'Brien", "Didier RÃ©my", "Gabriel Scherer"], "title": "Omnidirectional type inference for ML: principality any way", "categories": ["cs.PL"], "comment": "39 pages + appendices", "summary": "The Damas-Hindley-Milner (ML) type system owes its success to principality, the property that every well-typed expression has a unique most general type. This makes inference predictable and efficient. Unfortunately, many extensions of ML (GADTs, higher-rank polymorphism, and static overloading) endanger princpality by introducing _fragile_ constructs that resist principal inference. Existing approaches recover principality through directional inference algorithms, which propagate _known_ type information in a fixed (or static) order (e.g. as in bidirectional typing) to disambiguate such constructs. However, the rigidity of a static inference order often causes otherwise well-typed programs to be rejected.\n  We propose _omnidirectional_ type inference, where type information flows in a dynamic order. Typing constraints may be solved in any order, suspending when progress requires known type information and resuming once it becomes available, using _suspended match constraints_. This approach is straightforward for simply typed systems, but extending it to ML is challenging due to let-generalization. Existing ML inference algorithms type let-bindings (let x = e1 in e2) in a fixed order: type e1, generalize its type, and then type e2. To overcome this, we introduce _incremental instantiation_, allowing partially solved type schemes containing suspended constraints to be instantiated, with a mechanism to incrementally update instances as the scheme is refined.\n  Omnidirectionality provides a general framework for restoring principality in the presence of fragile features. We demonstrate its versatility on two fundamentally different features of OCaml: static overloading of record labels and datatype constructors and semi-explicit first-class polymorphism. In both cases, we obtain a principal type inference algorithm that is more expressive than OCaml's current typechecker."}
{"id": "2511.10361", "pdf": "https://arxiv.org/pdf/2511.10361", "abs": "https://arxiv.org/abs/2511.10361", "authors": ["Rodrigo Mesquita", "Bernardo Toninho"], "title": "Lazy Linearity for a Core Functional Language", "categories": ["cs.PL"], "comment": "Extended version of POPL 2026 paper", "summary": "Traditionally, in linearly typed languages, consuming a linear resource is synonymous with its syntactic occurrence in the program. However, under the lens of non-strict evaluation, linearity can be further understood semantically, where a syntactic occurrence of a resource does not necessarily entail using that resource when the program is executed. While this distinction has been largely unexplored, it turns out to be inescapable in Haskell's optimising compiler, which heavily rewrites the source program in ways that break syntactic linearity but preserve the program's semantics. We introduce Linear Core, a novel system which accepts the lazy semantics of linearity statically and is suitable for lazy languages such as the Core intermediate language of the Glasgow Haskell Compiler. We prove that Linear Core is sound, guaranteeing linear resource usage, and that multiple optimising transformations preserve linearity in Linear Core while failing to do so in Core. We have implemented Linear Core as a compiler plugin to validate the system against linearity-heavy libraries, including linear-base."}
{"id": "2511.10374", "pdf": "https://arxiv.org/pdf/2511.10374", "abs": "https://arxiv.org/abs/2511.10374", "authors": ["Somashekaracharya G Bhaskaracharya", "Aravind Acharya", "Bastian Hagedorn", "Vinod Grover"], "title": "Modeling Layout Abstractions Using Integer Set Relations", "categories": ["cs.PL"], "comment": null, "summary": "Modern deep learning compilers rely on layout abstractions to manage the complex mapping between logical tensor structures and physical memory arrangements. CuTe layouts and Triton linear layouts are widely adopted industry standards. However, these layout systems operate independently with distinct mathematical underpinnings, preventing unified formal analysis and cross-system reasoning. We bridge this gap by introducing a novel approach that leverages the Integer Set Library (ISL) to create a unified mathematical representation for both layout systems through integer set relations, thereby enabling rigorous formal analysis, correctness verification, and the foundation for future cross-system optimization strategies. Our approach models CuTe layouts through integer set relations that encode the transformation from multi-dimensional coordinates to linear indices using stride-based calculations, including sophisticated swizzle operations that perform bit-level manipulations for enhanced memory access patterns. For Triton linear layouts, we construct integer set relations that model the binary vector space transformations where arithmetic operations follow finite field F_2 rules. We implement a complete suite of layout manipulation algorithms for composition, inversion, complement using built-in operations in ISL to ensure mathematical correctness and preserve layout semantics. Experimental evaluation shows that the system handles the full spectrum of layout complexity, from elementary identity transformations to sophisticated multi-dimensional tensor arrangements with complex stride configurations and swizzle patterns, validating the mathematical modeling approach across different layout paradigms."}
{"id": "2511.10565", "pdf": "https://arxiv.org/pdf/2511.10565", "abs": "https://arxiv.org/abs/2511.10565", "authors": ["Rahul Krishnan", "Ashley Samuelson", "Emily Yao", "Ethan Cecchetti"], "title": "zkStruDul: Programming zkSNARKs with Structural Duality", "categories": ["cs.PL", "cs.CR"], "comment": null, "summary": "Non-Interactive Zero Knowledge (NIZK) proofs, such as zkSNARKS, let one prove knowledge of private data without revealing it or interacting with a verifier. While existing tooling focuses on specifying the predicate to be proven, real-world applications optimize predicate definitions to minimize proof generation overhead, but must correspondingly transform predicate inputs. Implementing these two steps separately duplicates logic that must precisely match to avoid catastrophic security flaws. We address this shortcoming with zkStruDul, a language that unifies input transformations and predicate definitions into a single combined abstraction from which a compiler can project both procedures, eliminating duplicate code and problematic mismatches. zkStruDul provides a high-level abstraction to layer on top of existing NIZK technology and supports important features like recursive proofs. We provide a source-level semantics and prove its behavior is identical to the projected semantics, allowing straightforward standard reasoning."}
