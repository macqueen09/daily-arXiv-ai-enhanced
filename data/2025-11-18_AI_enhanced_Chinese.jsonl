{"id": "2511.11939", "pdf": "https://arxiv.org/pdf/2511.11939", "abs": "https://arxiv.org/abs/2511.11939", "authors": ["Manya Bansal", "Daniel Sainati", "Joseph W. Cutler", "Saman Amarasinghe", "Jonathan Ragan-Kelley"], "title": "Modular GPU Programming with Typed Perspectives", "categories": ["cs.PL", "cs.DC"], "comment": null, "summary": "To achieve peak performance on modern GPUs, one must balance two frames of mind: issuing instructions to individual threads to control their behavior, while simultaneously tracking the convergence of many threads acting in concert to perform collective operations like Tensor Core instructions. The tension between these two mindsets makes modular programming error prone. Functions that encapsulate collective operations, despite being called per-thread, must be executed cooperatively by groups of threads.\n  In this work, we introduce Prism, a new GPU language that restores modularity while still giving programmers the low-level control over collective operations necessary for high performance. Our core idea is typed perspectives, which materialize, at the type level, the granularity at which the programmer is controlling the behavior of threads. We describe the design of Prism, implement a compiler for it, and lay its theoretical foundations in a core calculus called Bundl. We implement state-of-the-art GPU kernels in Prism and find that it offers programmers the safety guarantees needed to confidently write modular code without sacrificing performance.", "AI": {"tldr": "Prism\u662f\u4e00\u4e2a\u65b0\u7684GPU\u7f16\u7a0b\u8bed\u8a00\uff0c\u901a\u8fc7\u7c7b\u578b\u5316\u89c6\u89d2\u5728\u7c7b\u578b\u5c42\u9762\u4f53\u73b0\u7ebf\u7a0b\u63a7\u5236\u7c92\u5ea6\uff0c\u89e3\u51b3\u4e86GPU\u7f16\u7a0b\u4e2d\u4e2a\u4f53\u7ebf\u7a0b\u63a7\u5236\u4e0e\u96c6\u4f53\u64cd\u4f5c\u4e4b\u95f4\u7684\u6a21\u5757\u5316\u77db\u76fe\uff0c\u65e2\u4fdd\u8bc1\u4e86\u5b89\u5168\u6027\u53c8\u4e0d\u727a\u7272\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3GPU\u7f16\u7a0b\u9700\u8981\u5728\u63a7\u5236\u5355\u4e2a\u7ebf\u7a0b\u884c\u4e3a\u7684\u540c\u65f6\u8ddf\u8e2a\u591a\u4e2a\u7ebf\u7a0b\u534f\u540c\u6267\u884c\u96c6\u4f53\u64cd\u4f5c\uff08\u5982Tensor Core\u6307\u4ee4\uff09\uff0c\u8fd9\u79cd\u77db\u76fe\u4f7f\u5f97\u6a21\u5757\u5316\u7f16\u7a0b\u5bb9\u6613\u51fa\u9519\u3002\u5c01\u88c5\u96c6\u4f53\u64cd\u4f5c\u7684\u51fd\u6570\u867d\u7136\u6309\u7ebf\u7a0b\u8c03\u7528\uff0c\u4f46\u5fc5\u987b\u7531\u7ebf\u7a0b\u7ec4\u534f\u4f5c\u6267\u884c\u3002", "method": "\u5f15\u5165Prism\u8bed\u8a00\uff0c\u6838\u5fc3\u601d\u60f3\u662f\u7c7b\u578b\u5316\u89c6\u89d2\uff0c\u5728\u7c7b\u578b\u5c42\u9762\u4f53\u73b0\u7a0b\u5e8f\u5458\u63a7\u5236\u7ebf\u7a0b\u884c\u4e3a\u7684\u7c92\u5ea6\u3002\u8bbe\u8ba1\u4e86Prism\u8bed\u8a00\uff0c\u5b9e\u73b0\u4e86\u7f16\u8bd1\u5668\uff0c\u5e76\u57fa\u4e8e\u6838\u5fc3\u6f14\u7b97Bundl\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\u3002", "result": "\u5728Prism\u4e2d\u5b9e\u73b0\u4e86\u5148\u8fdb\u7684GPU\u5185\u6838\uff0c\u53d1\u73b0\u5b83\u63d0\u4f9b\u4e86\u8db3\u591f\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u4f7f\u7a0b\u5e8f\u5458\u80fd\u591f\u81ea\u4fe1\u5730\u7f16\u5199\u6a21\u5757\u5316\u4ee3\u7801\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u6027\u80fd\u3002", "conclusion": "Prism\u901a\u8fc7\u7c7b\u578b\u5316\u89c6\u89d2\u6210\u529f\u6062\u590d\u4e86GPU\u7f16\u7a0b\u7684\u6a21\u5757\u6027\uff0c\u540c\u65f6\u4e3a\u7a0b\u5e8f\u5458\u63d0\u4f9b\u4e86\u5bf9\u96c6\u4f53\u64cd\u4f5c\u7684\u5fc5\u8981\u4f4e\u7ea7\u63a7\u5236\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u6027\u4e0e\u9ad8\u6027\u80fd\u7684\u5e73\u8861\u3002"}}
{"id": "2511.12253", "pdf": "https://arxiv.org/pdf/2511.12253", "abs": "https://arxiv.org/abs/2511.12253", "authors": ["Harrison Goldstein", "Hila Peleg", "Cassia Torczon", "Daniel Sainati", "Leonidas Lampropoulos", "Benjamin C. Pierce"], "title": "The Search for Constrained Random Generators", "categories": ["cs.PL"], "comment": null, "summary": "Among the biggest challenges in property-based testing (PBT) is the constrained random generation problem: given a predicate on program values, randomly sample from the set of all values satisfying that predicate, and only those values. Efficient solutions to this problem are critical, since the executable specifications used by PBT often have preconditions that input values must satisfy in order to be valid test cases, and satisfying values are often sparsely distributed.\n  We propose a novel approach to this problem using ideas from deductive program synthesis. We present a set of synthesis rules, based on a denotational semantics of generators, that give rise to an automatic procedure for synthesizing correct generators. Our system handles recursive predicates by rewriting them as catamorphisms and then matching with appropriate anamorphisms; this is theoretically simpler than other approaches to synthesis for recursive functions, yet still extremely expressive.\n  Our implementation, Palamedes, is an extensible library for the Lean theorem prover. The synthesis algorithm itself is built on standard proof-search tactics, reducing implementation burden and allowing the algorithm to benefit from further advances in Lean proof automation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6f14\u7ece\u7a0b\u5e8f\u7efc\u5408\u7684\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u57fa\u4e8e\u5c5e\u6027\u6d4b\u8bd5\u4e2d\u7684\u7ea6\u675f\u968f\u673a\u751f\u6210\u95ee\u9898\uff0c\u901a\u8fc7\u5c06\u9012\u5f52\u8c13\u8bcd\u91cd\u5199\u4e3acatamorphisms\u5e76\u4e0e\u9002\u5f53\u7684anamorphisms\u5339\u914d\u6765\u5408\u6210\u6b63\u786e\u7684\u751f\u6210\u5668\u3002", "motivation": "\u57fa\u4e8e\u5c5e\u6027\u6d4b\u8bd5\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u662f\u7ea6\u675f\u968f\u673a\u751f\u6210\u95ee\u9898\uff1a\u7ed9\u5b9a\u7a0b\u5e8f\u503c\u7684\u8c13\u8bcd\uff0c\u9700\u8981\u4ece\u6ee1\u8db3\u8be5\u8c13\u8bcd\u7684\u6240\u6709\u503c\u4e2d\u968f\u673a\u91c7\u6837\u3002\u7531\u4e8ePBT\u4e2d\u4f7f\u7528\u7684\u53ef\u6267\u884c\u89c4\u8303\u901a\u5e38\u6709\u8f93\u5165\u503c\u5fc5\u987b\u6ee1\u8db3\u7684\u524d\u63d0\u6761\u4ef6\uff0c\u4e14\u6ee1\u8db3\u6761\u4ef6\u7684\u503c\u5f80\u5f80\u7a00\u758f\u5206\u5e03\uff0c\u56e0\u6b64\u9ad8\u6548\u89e3\u51b3\u6b64\u95ee\u9898\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u751f\u6210\u5668\u6307\u79f0\u8bed\u4e49\u7684\u7efc\u5408\u89c4\u5219\u96c6\uff0c\u5f62\u6210\u81ea\u52a8\u5408\u6210\u6b63\u786e\u751f\u6210\u5668\u7684\u7a0b\u5e8f\u3002\u7cfb\u7edf\u901a\u8fc7\u5c06\u9012\u5f52\u8c13\u8bcd\u91cd\u5199\u4e3acatamorphisms\u5e76\u4e0e\u9002\u5f53\u7684anamorphisms\u5339\u914d\u6765\u5904\u7406\u9012\u5f52\u8c13\u8bcd\u3002\u5b9e\u73b0\u4e3aLean\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u7684\u53ef\u6269\u5c55\u5e93Palamedes\uff0c\u7efc\u5408\u7b97\u6cd5\u57fa\u4e8e\u6807\u51c6\u8bc1\u660e\u641c\u7d22\u7b56\u7565\u6784\u5efa\u3002", "result": "\u5f00\u53d1\u4e86Palamedes\u5b9e\u73b0\uff0c\u8fd9\u662f\u4e00\u4e2a\u5728Lean\u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u7684\u53ef\u6269\u5c55\u5e93\u3002\u8be5\u65b9\u6cd5\u7406\u8bba\u4e0a\u6bd4\u5176\u4ed6\u9012\u5f52\u51fd\u6570\u7efc\u5408\u65b9\u6cd5\u66f4\u7b80\u5355\uff0c\u540c\u65f6\u4ecd\u4fdd\u6301\u6781\u9ad8\u7684\u8868\u8fbe\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6f14\u7ece\u7a0b\u5e8f\u7efc\u5408\u6280\u672f\u6709\u6548\u89e3\u51b3\u4e86PBT\u4e2d\u7684\u7ea6\u675f\u968f\u673a\u751f\u6210\u95ee\u9898\uff0c\u5229\u7528\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u8bc1\u660e\u81ea\u52a8\u5316\u80fd\u529b\u964d\u4f4e\u4e86\u5b9e\u73b0\u8d1f\u62c5\uff0c\u5e76\u4e3a\u5904\u7406\u9012\u5f52\u8c13\u8bcd\u63d0\u4f9b\u4e86\u7406\u8bba\u7b80\u5355\u4e14\u8868\u8fbe\u529b\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12638", "pdf": "https://arxiv.org/pdf/2511.12638", "abs": "https://arxiv.org/abs/2511.12638", "authors": ["Kshitij Dubey", "Benjamin Driscoll", "Anjiang Wei", "Neeraj Kayal", "Rahul Sharma", "Alex Aiken"], "title": "Equivalence Checking of ML GPU Kernels", "categories": ["cs.PL"], "comment": null, "summary": "With the rapid progress of deep learning and large language models (LLMs), companies now spend enormous sums executing GPU kernels. These kernels have, therefore, become prime targets for aggressive optimization. Recent efforts increasingly leverage LLMs to generate GPU kernels, but make no formal guarantees about the generated kernels. We present the first equivalence checker for GPU kernels and use it to formally verify the correctness of machine learning (ML) kernels optimized by hand, by LLMs, and by compilers. We show that our equivalence checker is sound and, for a well-defined class of GPU kernels which includes the programs of interest, complete. Our implementation, VOLTA, can verify ML computations such as convolutions, matrix multiplications, and various attention mechanisms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2aGPU\u5185\u6838\u7b49\u4ef7\u68c0\u67e5\u5668VOLTA\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u9a8c\u8bc1\u624b\u5de5\u4f18\u5316\u3001LLM\u751f\u6210\u548c\u7f16\u8bd1\u5668\u4f18\u5316\u7684\u673a\u5668\u5b66\u4e60\u5185\u6838\u7684\u6b63\u786e\u6027\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0cGPU\u5185\u6838\u6267\u884c\u6210\u672c\u9ad8\u6602\uff0c\u6210\u4e3a\u4f18\u5316\u7684\u91cd\u8981\u76ee\u6807\u3002\u4f46\u73b0\u6709LLM\u751f\u6210\u7684\u5185\u6838\u7f3a\u4e4f\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff0c\u9700\u8981\u9a8c\u8bc1\u5176\u6b63\u786e\u6027\u3002", "method": "\u5f00\u53d1\u4e86VOLTA\u7b49\u4ef7\u68c0\u67e5\u5668\uff0c\u9488\u5bf9\u7279\u5b9a\u7c7b\u522b\u7684GPU\u5185\u6838\uff08\u5305\u62ec\u673a\u5668\u5b66\u4e60\u8ba1\u7b97\uff09\u8fdb\u884c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u5176\u5bf9\u4e8e\u8be5\u7c7b\u5185\u6838\u662f\u5b8c\u5907\u7684\u3002", "result": "VOLTA\u80fd\u591f\u9a8c\u8bc1\u5377\u79ef\u3001\u77e9\u9635\u4e58\u6cd5\u548c\u5404\u79cd\u6ce8\u610f\u529b\u673a\u5236\u7b49\u673a\u5668\u5b66\u4e60\u8ba1\u7b97\uff0c\u4e3aGPU\u5185\u6838\u4f18\u5316\u63d0\u4f9b\u4e86\u5f62\u5f0f\u5316\u9a8c\u8bc1\u5de5\u5177\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86GPU\u5185\u6838\u5f62\u5f0f\u5316\u9a8c\u8bc1\u7684\u7a7a\u767d\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u5185\u6838\u4f18\u5316\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u6b63\u786e\u6027\u4fdd\u8bc1\u3002"}}
{"id": "2511.13663", "pdf": "https://arxiv.org/pdf/2511.13663", "abs": "https://arxiv.org/abs/2511.13663", "authors": ["Qiuhan Gu", "Avaljot Singh", "Gagandeep Singh"], "title": "Cost-Driven Synthesis of Sound Abstract Interpreters", "categories": ["cs.PL", "cs.LG"], "comment": "37 pages, 20 figures", "summary": "Constructing abstract interpreters that provide global soundness guarantees remains a major obstacle in abstract interpretation. We investigate whether modern LLMs can reduce this burden by leveraging them to synthesize sound, non-trivial abstract interpreters across multiple abstract domains in the setting of neural network verification. We formulate synthesis as a constrained optimization problem and introduce a novel mathematically grounded cost function for measuring unsoundness under strict syntactic and semantic constraints. Based on this formulation, we develop a unified framework that unifies LLM-based generation with syntactic and semantic validation and a quantitative cost-guided feedback mechanism. Empirical results demonstrate that our framework not only matches the quality of handcrafted transformers, but more importantly, discovers sound, high-precision transformers for complex nonlinear operators that are absent from existing literature.", "AI": {"tldr": "\u4f7f\u7528\u73b0\u4ee3LLM\u5408\u6210\u5168\u5c40\u53ef\u9760\u7684\u62bd\u8c61\u89e3\u91ca\u5668\uff0c\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\uff0c\u901a\u8fc7\u7ea6\u675f\u4f18\u5316\u548c\u6570\u5b66\u57fa\u7840\u7684\u6210\u672c\u51fd\u6570\u6765\u4fdd\u8bc1\u58f0\u97f3\u6027\u3002", "motivation": "\u6784\u5efa\u63d0\u4f9b\u5168\u5c40\u53ef\u9760\u6027\u4fdd\u8bc1\u7684\u62bd\u8c61\u89e3\u91ca\u5668\u4ecd\u7136\u662f\u62bd\u8c61\u89e3\u91ca\u4e2d\u7684\u4e3b\u8981\u969c\u788d\uff0c\u7814\u7a76\u662f\u5426\u53ef\u4ee5\u5229\u7528\u73b0\u4ee3LLM\u6765\u51cf\u8f7b\u8fd9\u4e00\u8d1f\u62c5\u3002", "method": "\u5c06\u5408\u6210\u5efa\u6a21\u4e3a\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u5f15\u5165\u57fa\u4e8e\u6570\u5b66\u7684\u6210\u672c\u51fd\u6570\u6765\u8861\u91cf\u58f0\u97f3\u6027\uff0c\u5f00\u53d1\u7edf\u4e00\u6846\u67b6\u7ed3\u5408LLM\u751f\u6210\u3001\u8bed\u6cd5\u8bed\u4e49\u9a8c\u8bc1\u548c\u6210\u672c\u5f15\u5bfc\u53cd\u9988\u673a\u5236\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u4e0d\u4ec5\u5339\u914d\u624b\u5de5\u6784\u5efa\u7684\u8f6c\u6362\u5668\u8d28\u91cf\uff0c\u66f4\u91cd\u8981\u7684\u662f\u53d1\u73b0\u4e86\u590d\u6742\u975e\u7ebf\u6027\u7b97\u5b50\u7684\u9ad8\u7cbe\u5ea6\u53ef\u9760\u8f6c\u6362\u5668\uff0c\u8fd9\u4e9b\u5728\u73b0\u6709\u6587\u732e\u4e2d\u7f3a\u5931\u3002", "conclusion": "LLM\u80fd\u591f\u6210\u529f\u5408\u6210\u8de8\u591a\u4e2a\u62bd\u8c61\u57df\u7684\u975e\u5e73\u51e1\u62bd\u8c61\u89e3\u91ca\u5668\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\u63d0\u4f9b\u53ef\u9760\u4fdd\u8bc1\u3002"}}
{"id": "2511.11581", "pdf": "https://arxiv.org/pdf/2511.11581", "abs": "https://arxiv.org/abs/2511.11581", "authors": ["Burkhard Ringlein", "Jan van Lunteren", "Radu Stoica", "Thomas Parnell"], "title": "The Anatomy of a Triton Attention Kernel", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.DC", "cs.PL"], "comment": null, "summary": "A long-standing goal in both industry and academia is to develop an LLM inference platform that is portable across hardware architectures, eliminates the need for low-level hand-tuning, and still delivers best-in-class efficiency. In this work, we demonstrate that portable, efficient cross-platform LLM inference is indeed possible and share our experience. We develop a state-of-the-art paged attention kernel, the core performance-critical component of many LLM deployments, that builds exclusively on the domain-specific just-in-time compiled language Triton to achieve state-of-the-art performance on both NVIDIA and AMD GPUs. We describe our high-level approach, the key algorithmic and system-level improvements, the parameter auto-tuning required to unlock efficiency, and the integrations into a popular inference server that are necessary to bring the performance of a generic Triton attention kernel from 19.7% of the state-of-the-art to 105.9%. Our results highlight how open-source domain-specific languages can be leveraged to unlock model portability across different GPU vendors.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eTriton\u7684\u8de8\u5e73\u53f0LLM\u63a8\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7paged attention\u5185\u6838\u5728NVIDIA\u548cAMD GPU\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5c06\u901a\u7528Triton\u6ce8\u610f\u529b\u5185\u6838\u6027\u80fd\u4ece19.7%\u63d0\u5347\u5230105.9%\u3002", "motivation": "\u5b9e\u73b0\u8de8\u786c\u4ef6\u67b6\u6784\u7684\u53ef\u79fb\u690dLLM\u63a8\u7406\u5e73\u53f0\uff0c\u6d88\u9664\u4f4e\u5c42\u624b\u52a8\u8c03\u4f18\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u4f73\u6548\u7387\u3002", "method": "\u4f7f\u7528Triton\u9886\u57df\u7279\u5b9a\u5373\u65f6\u7f16\u8bd1\u8bed\u8a00\u5f00\u53d1\u6700\u5148\u8fdb\u7684paged attention\u5185\u6838\uff0c\u7ed3\u5408\u7b97\u6cd5\u548c\u7cfb\u7edf\u7ea7\u6539\u8fdb\u3001\u53c2\u6570\u81ea\u52a8\u8c03\u4f18\uff0c\u5e76\u96c6\u6210\u5230\u6d41\u884c\u63a8\u7406\u670d\u52a1\u5668\u4e2d\u3002", "result": "\u5728NVIDIA\u548cAMD GPU\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5c06\u901a\u7528Triton\u6ce8\u610f\u529b\u5185\u6838\u6027\u80fd\u4ece19.7%\u63d0\u5347\u5230105.9%\u3002", "conclusion": "\u5f00\u6e90\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u53ef\u4ee5\u7528\u4e8e\u89e3\u9501\u8de8\u4e0d\u540cGPU\u5382\u5546\u7684\u6a21\u578b\u53ef\u79fb\u690d\u6027\u3002"}}
{"id": "2511.12276", "pdf": "https://arxiv.org/pdf/2511.12276", "abs": "https://arxiv.org/abs/2511.12276", "authors": ["L. Thomas van Binsbergen", "Christopher A. Esterhuyse", "Tim M\u00fcller"], "title": "Reflections on the design, applications and implementations of the normative specification language eFLINT", "categories": ["cs.SE", "cs.PL"], "comment": "27 pages", "summary": "Checking the compliance of software against laws, regulations and contracts is increasingly important and costly as the embedding of software into societal practices is getting more pervasive. Moreover, the digitalised services provided by governmental organisations and companies are governed by an increasing amount of laws and regulations, requiring highly adaptable compliance practices. A potential solution is to automate compliance using software. However, automating compliance is difficult for various reasons. Legal practices involve subjective processes such as interpretation and qualification. New laws and regulations come into effect regularly and laws and regulations, as well as their interpretations, are subjected to constant revision. In addition, computational reasoning with laws requires a cross-disciplinary process involving both legal and software expertise.\n  This paper reflects on the domain-specific software language eFLINT developed to experiment with novel solutions. The language combines declarative and procedural elements to reason about situations and scenarios respectively, explicates and formalises connections between legal concepts and computational concepts, and is designed to automate compliance checks both before, during and after a software system runs. The various goals and applications areas for the language give rise to (conflicting) requirements. This paper reflects on the current design of the language by recalling various applications, the requirements they imposed, and subsequent design decisions. As such, this paper reports on results and insights of an investigation that can benefit language developers within the field of automated compliance.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86eFLINT\u9886\u57df\u7279\u5b9a\u8f6f\u4ef6\u8bed\u8a00\uff0c\u8be5\u8bed\u8a00\u7ed3\u5408\u58f0\u660e\u5f0f\u548c\u8fc7\u7a0b\u5f0f\u5143\u7d20\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6cd5\u5f8b\u5408\u89c4\u68c0\u67e5\uff0c\u6db5\u76d6\u8f6f\u4ef6\u7cfb\u7edf\u8fd0\u884c\u524d\u3001\u4e2d\u3001\u540e\u7684\u5408\u89c4\u9a8c\u8bc1\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u5728\u793e\u4f1a\u5b9e\u8df5\u4e2d\u7684\u666e\u53ca\uff0c\u8f6f\u4ef6\u5408\u89c4\u6027\u68c0\u67e5\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u4e14\u6210\u672c\u9ad8\u6602\u3002\u6cd5\u5f8b\u548c\u6cd5\u89c4\u4e0d\u65ad\u66f4\u65b0\uff0c\u4e3b\u89c2\u7684\u6cd5\u5f8b\u89e3\u91ca\u8fc7\u7a0b\u4ee5\u53ca\u6cd5\u5f8b\u4e0e\u8f6f\u4ef6\u4e13\u4e1a\u77e5\u8bc6\u7684\u4ea4\u53c9\u9700\u6c42\u4f7f\u5f97\u81ea\u52a8\u5316\u5408\u89c4\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u5f00\u53d1\u4e86eFLINT\u9886\u57df\u7279\u5b9a\u8f6f\u4ef6\u8bed\u8a00\uff0c\u8be5\u8bed\u8a00\u7ed3\u5408\u58f0\u660e\u5f0f\u5143\u7d20\uff08\u7528\u4e8e\u63a8\u7406\u60c5\u51b5\uff09\u548c\u8fc7\u7a0b\u5f0f\u5143\u7d20\uff08\u7528\u4e8e\u63a8\u7406\u573a\u666f\uff09\uff0c\u5f62\u5f0f\u5316\u6cd5\u5f8b\u6982\u5ff5\u4e0e\u8ba1\u7b97\u6982\u5ff5\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "result": "eFLINT\u8bed\u8a00\u80fd\u591f\u81ea\u52a8\u5316\u6267\u884c\u8f6f\u4ef6\u7cfb\u7edf\u8fd0\u884c\u524d\u3001\u8fd0\u884c\u4e2d\u548c\u8fd0\u884c\u540e\u7684\u5408\u89c4\u68c0\u67e5\uff0c\u5e76\u901a\u8fc7\u5404\u79cd\u5e94\u7528\u573a\u666f\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "eFLINT\u8bed\u8a00\u7684\u8bbe\u8ba1\u7ecf\u9a8c\u548c\u5e94\u7528\u6848\u4f8b\u4e3a\u81ea\u52a8\u5316\u5408\u89c4\u9886\u57df\u7684\u8bed\u8a00\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u5e73\u8861\u51b2\u7a81\u9700\u6c42\u5e76\u5b9e\u73b0\u6709\u6548\u7684\u5408\u89c4\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.12823", "pdf": "https://arxiv.org/pdf/2511.12823", "abs": "https://arxiv.org/abs/2511.12823", "authors": ["Sajed Jalil", "Shuvo Saha", "Hossain Mohammad Seym"], "title": "Enhancing LLM Code Generation Capabilities through Test-Driven Development and Code Interpreter", "categories": ["cs.SE", "cs.LG", "cs.PL"], "comment": "AACL-IJCNLP 2025 Workshop BLP Shared Task 2, 6 pages, 7 figures, 3 tables", "summary": "Over the past few years, improving LLM code generation capabilities has been a key focus in NLP research. Despite Bengali having 242 million native speakers worldwide, it receives little attention when it comes to training LLMs. More recently, various fine-tuning and augmented generation techniques have been employed to significantly enhance code generation performance. However, they require considerable expertise and resources to utilize effectively as an end user. The goal of our work is to democratize access to powerful code generation tools in resource-constrained emerging markets, enabling users to leverage them in their native language.\n  We introduce a novel approach that combines Test-Driven Development (TDD) and Code Interpreter (CI), utilizing open-weight models, which improves the baseline accuracy for code generation with Bengali prompts and achieves an overall accuracy of 85%. Our approach requires no finetuning and proves that even the smallest models in the same family can attain up to 98% accuracy compared to the largest models. All of our results are publicly shared in GitHub for validation and reproducibility.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1(TDD)\u548c\u4ee3\u7801\u89e3\u91ca\u5668(CI)\u7684\u65b0\u65b9\u6cd5\uff0c\u4f7f\u7528\u5f00\u6e90\u6a21\u578b\u63d0\u5347\u5b5f\u52a0\u62c9\u8bed\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u8fbe\u523085%\u51c6\u786e\u7387\uff0c\u6700\u5c0f\u6a21\u578b\u53ef\u8fbe\u6700\u5927\u6a21\u578b98%\u7684\u6027\u80fd\u3002", "motivation": "\u5b5f\u52a0\u62c9\u8bed\u62e5\u67092.42\u4ebf\u6bcd\u8bed\u4f7f\u7528\u8005\uff0c\u4f46\u5728LLM\u8bad\u7ec3\u4e2d\u5173\u6ce8\u4e0d\u8db3\u3002\u73b0\u6709\u4ee3\u7801\u751f\u6210\u6280\u672f\u9700\u8981\u5927\u91cf\u4e13\u4e1a\u77e5\u8bc6\u548c\u8d44\u6e90\uff0c\u76ee\u6807\u662f\u4e3a\u8d44\u6e90\u53d7\u9650\u7684\u65b0\u5174\u5e02\u573a\u7528\u6237\u63d0\u4f9b\u6bcd\u8bed\u4ee3\u7801\u751f\u6210\u5de5\u5177\u3002", "method": "\u7ed3\u5408\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1(TDD)\u548c\u4ee3\u7801\u89e3\u91ca\u5668(CI)\uff0c\u4f7f\u7528\u5f00\u6e90\u6743\u91cd\u6a21\u578b\uff0c\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u63d0\u5347\u5b5f\u52a0\u62c9\u8bed\u63d0\u793a\u7684\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002", "result": "\u5c06\u5b5f\u52a0\u62c9\u8bed\u4ee3\u7801\u751f\u6210\u7684\u57fa\u7ebf\u51c6\u786e\u7387\u63d0\u5347\u81f385%\uff0c\u540c\u4e00\u7cfb\u5217\u4e2d\u6700\u5c0f\u7684\u6a21\u578b\u53ef\u8fbe\u5230\u6700\u5927\u6a21\u578b98%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5b5f\u52a0\u62c9\u8bed\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u65e0\u9700\u5fae\u8c03\u5373\u53ef\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6027\u80fd\u4ee3\u7801\u751f\u6210\uff0c\u6240\u6709\u7ed3\u679c\u5df2\u5728GitHub\u516c\u5f00\u3002"}}
