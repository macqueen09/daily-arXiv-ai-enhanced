<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Filling the Gaps of Polarity: Implementing Dependent Data and Codata Types with Implicit Arguments](https://arxiv.org/abs/2511.15819)
*Bohdan Liesnikov,David Binder,Tim Süberkrüb*

Main category: cs.PL

TL;DR: 本文提出了Polarity语言的算法类型系统和隐式参数推理算法，该语言对称处理归纳类型和余归纳类型，解决了表达式问题中的两种扩展性权衡。


<details>
  <summary>Details</summary>
Motivation: 解决依赖类型语言中归纳类型和余归纳类型支持不对称的问题，为Polarity语言提供完整的算法类型系统和隐式参数推理能力。

Method: 开发了完整的算法类型系统描述、统一的归纳和余归纳类型统一算法、归约语义规则、转换检查规则和模式匹配统一算法。

Result: 实现了Polarity语言的算法类型系统，提供了处理任意归纳和余归纳类型的统一算法，并有一个进行中的实现。

Conclusion: 该工作为对称支持归纳和余归纳类型的依赖类型语言提供了蓝图，特别是统一算法和设计决策对其他类似语言具有参考价值。

Abstract: The expression problem describes a fundamental tradeoff between two types of extensibility: extending a type with new operations, such as by pattern matching on an algebraic data type in functional programming, and extending a type with new constructors, such as by adding a new object implementing an interface in object-oriented programming. Most dependently typed languages have good support for the former style through inductive types, but support for the latter style through coinductive types is usually much poorer. Polarity is a language that treats both kinds of types symmetrically and allows the developer to switch between type representations.However, it currently lacks several features expected of a state-of-the-art dependently typed language, such as implicit arguments. The central aim of this paper is to provide an algorithmic type system and inference algorithm for implicit arguments that respect the core symmetry of the language. Our work provides two key contributions: a complete algorithmic description of the type system backing Polarity, and a comprehensive description of a unification algorithm that covers arbitrary inductive and coinductive types. We give rules for reduction semantics, conversion checking, and a unification algorithm for pattern-matching, which are essential for a usable implementation. A work-in-progress implementation of the algorithms in this paper is available at https://polarity-lang.github.io/. We expect that the comprehensive account of the unification algorithm and our design decisions can serve as a blueprint for other dependently typed languages that support inductive and coinductive types symmetrically.

</details>


### [2] [Chorex: Restartable, Language-Integrated Choreographies](https://arxiv.org/abs/2511.15820)
*Ashton Wiersdorf,Ben Greenman*

Main category: cs.PL

TL;DR: Chorex是一个将编排编程引入Elixir的语言，通过元编程实现完整的编排功能，支持演员故障恢复，并通过检查点机制实现状态恢复。


<details>
  <summary>Details</summary>
Motivation: 为构建健壮的分布式应用程序，需要一种能够容忍演员故障的编排编程语言，同时实现与宿主语言的紧密集成。

Method: 使用元编程在Elixir中实现编排编程，通过检查点机制保存状态，当演员崩溃时自动生成新进程并恢复状态，更新所有演员的网络配置。

Result: 成功实现了支持故障恢复的编排语言Chorex，能够静态检测编排要求与演员实现之间的不匹配，并在多个示例中验证了其有效性。

Conclusion: Chorex的输出无状态函数集的投影策略是支持可重启演员的可行方法，可为其他语言提供参考。

Abstract: We built Chorex, a language that brings choreographic programming to Elixir as a path toward robust distributed applications. Chorex is unique among choreographic languages because it tolerates failure among actors: when an actor crashes, Chorex spawns a new process, restores state using a checkpoint, and updates the network configuration for all actors. Chorex also proves that full-featured choreographies can be implemented via metaprogramming, and that doing so achieves tight integration with the host language. For example, mismatches between choreography requirements and an actor implementation are reported statically and in terms of source code rather than macro-expanded code. This paper illustrates Chorex on several examples, ranging from a higher-order bookseller to a secure remote password protocol, details its implementation, and measures the overhead of checkpointing. We conjecture that Chorex's projection strategy, which outputs sets of stateless functions, is a viable approach for other languages to support restartable actors.

</details>


### [3] [BlueScript: A Disaggregated Virtual Machine for Microcontrollers](https://arxiv.org/abs/2511.15821)
*Fumika Mochizuki,Tetsuro Yamazaki,Shigeru Chiba*

Main category: cs.PL

TL;DR: 提出了一种分解式虚拟机，将尽可能多的组件卸载到主机上，为内存受限的微控制器提供丰富的功能特性


<details>
  <summary>Details</summary>
Motivation: 微控制器虚拟机由于内存限制功能有限，现有虚拟机缺乏交互响应性和高执行速度，需要解决这一限制

Method: 设计并实现了BlueScript虚拟机，通过在主机上创建镜像微控制器执行状态的影子机数据结构，将大部分组件卸载到主机

Result: 卸载组件不会严重损害预期收益，卸载的增量编译器比MicroPython和Espruino执行速度更快，同时保持与MicroPython相当的交互性

Conclusion: 证明了即使在内存受限的微控制器上，通过组件卸载也能提供丰富功能的可行性

Abstract: Virtual machines (VMs) are highly beneficial for microcontroller development. 
In particular, interactive programming environments greatly facilitate iterative development processes, 
and higher execution speeds expand the range of applications that can be developed. 
However, due to their limited memory size, microcontroller VMs provide a limited set of features. 
Widely used VMs for microcontrollers often lack interactive responsiveness and/or high execution speed. 
While researchers have investigated offloading certain VM components to other machines,the types of components that can be offloaded are still restricted. 
In this paper, we propose a disaggregated VM that offloads as many components as possible to a host machine. 
This makes it possible to exploit the abundant memory of the host machine and its powerful processing capability to provide rich features through the VM. 
As an instance of a disaggregated VM, we design and implement a BlueScript VM. 
The BlueScript VM is a virtual machine for microcontrollers that provides an interactive development environment. 
We offload most of the components of the BlueScript VM to a host machine. 
To reduce communication overhead between the host machine and the microcontroller,  
we employed a data structure called a shadow machine on the host machine, 
which mirrors the execution state of the microcontroller. 
Through our experiments, we confirmed that offloading components does not seriously compromise their expected benefits.  
We assess that an offloaded incremental compiler results in faster execution speed than MicroPython and Espruino,  
while keeping interactivity comparable with MicroPython.  
In addition, our experiments observe that the offloaded dynamic compiler improves VM performance. 
Through this investigation, we demonstrate the feasibility of providing rich features even on VMs for memory-limited microcontrollers.

</details>


### [4] [Operon: Incremental Construction of Ragged Data via Named Dimensions](https://arxiv.org/abs/2511.16080)
*Sungbin Moon,Jiho Park,Suyoung Hwang,Donghyun Koh,Seunghyun Moon,Minhyeong Lee*

Main category: cs.PL

TL;DR: Operon是一个基于Rust的工作流引擎，专门处理不规则数据，通过命名维度和显式依赖关系提供静态验证和动态调度，显著提升了大规模数据处理性能。


<details>
  <summary>Details</summary>
Motivation: 现代数据处理工作流经常遇到不规则数据，现有工作流引擎缺乏对可变长度元素形状和依赖关系的原生支持，用户需要手动管理复杂的索引和依赖关系。

Method: 提出Operon工作流引擎，使用命名维度和显式依赖关系的形式化方法，提供领域特定语言进行静态验证，运行时系统根据数据形状动态调度任务。

Result: Operon相比现有工作流引擎减少了14.94倍的基础开销，在负载扩展时保持接近线性的端到端输出速率，特别适合机器学习应用中的大规模数据生成管道。

Conclusion: Operon通过显式建模部分已知状态实现了稳健的持久化和恢复机制，其每任务多队列架构在异构任务类型间实现了高效并行性，为不规则数据处理提供了有效的解决方案。

Abstract: Modern data processing workflows frequently encounter ragged data: collections with variable-length elements that arise naturally in domains like natural language processing, scientific measurements, and autonomous AI agents. Existing workflow engines lack native support for tracking the shapes and dependencies inherent to ragged data, forcing users to manage complex indexing and dependency bookkeeping manually. We present Operon, a Rust-based workflow engine that addresses these challenges through a novel formalism of named dimensions with explicit dependency relations. Operon provides a domain-specific language where users declare pipelines with dimension annotations that are statically verified for correctness, while the runtime system dynamically schedules tasks as data shapes are incrementally discovered during execution. We formalize the mathematical foundation for reasoning about partial shapes and prove that Operon's incremental construction algorithm guarantees deterministic and confluent execution in parallel settings. The system's explicit modeling of partially-known states enables robust persistence and recovery mechanisms, while its per-task multi-queue architecture achieves efficient parallelism across heterogeneous task types. Empirical evaluation demonstrates that Operon outperforms an existing workflow engine with 14.94x baseline overhead reduction while maintaining near-linear end-to-end output rates as workloads scale, making it particularly suitable for large-scale data generation pipelines in machine learning applications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [5] [TB or Not TB: Coverage-Driven Direct Preference Optimization for Verilog Stimulus Generation](https://arxiv.org/abs/2511.15767)
*Bardia Nadimi,Khashayar Filom,Deming Chen,Hao Zheng*

Main category: cs.LG

TL;DR: TB or not TB是一个基于LLM的自动化激励生成框架，通过覆盖率驱动的直接偏好优化方法，显著提升硬件验证的代码覆盖率。


<details>
  <summary>Details</summary>
Motivation: 硬件设计验证是最耗时和资源密集的阶段，生成有效的测试激励既关键又劳动密集。随着大语言模型的发展，将其应用于硬件验证具有重要价值。

Method: 提出CD-DPO方法，通过PairaNet数据集对LLM进行微调，该数据集包含基于仿真覆盖率指标标注的高质量和低质量测试平台对。

Result: 在CVDP CID12基准测试中，TB or not TB优于开源和商业基线，代码覆盖率提升高达77.27%。

Conclusion: 覆盖率驱动的偏好优化对于基于LLM的硬件验证是有效的，能够显著提升验证效率。

Abstract: With the rapid advancement of Large Language Models (LLMs), there is growing interest in applying them to hardware design and verification. Among these stages, design verification remains the most time-consuming and resource-intensive phase, where generating effective stimuli for the design under test (DUT) is both critical and labor-intensive. We present {\it TB or not TB}, a framework for automated stimulus generation using LLMs fine-tuned through Coverage-Driven Direct Preference Optimization (CD-DPO). To enable preference-based training, we introduce PairaNet, a dataset derived from PyraNet that pairs high- and low-quality testbenches labeled using simulation-derived coverage metrics. The proposed CD-DPO method integrates quantitative coverage feedback directly into the optimization objective, guiding the model toward generating stimuli that maximize verification coverage. Experiments on the CVDP CID12 benchmark show that {\it TB or not TB} outperforms both open-source and commercial baselines, achieving up to 77.27\% improvement in code coverage, demonstrating the effectiveness of Coverage-driven preference optimization for LLM-based hardware verification.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [CorrectHDL: Agentic HDL Design with LLMs Leveraging High-Level Synthesis as Reference](https://arxiv.org/abs/2511.16395)
*Kangwei Xu,Grace Li Zhang,Ulf Schlichtmann,Bing Li*

Main category: cs.AI

TL;DR: 提出了CorrectHDL框架，利用HLS结果作为功能参考来纠正LLM生成的HDL设计中的潜在错误，在保持功能正确性的同时显著提升面积和功耗效率。


<details>
  <summary>Details</summary>
Motivation: LLM在硬件前端设计中表现出潜力，但其固有的幻觉倾向会在生成的HDL设计中引入功能错误，需要解决这一问题。

Method: 使用C/C++程序作为输入，通过LLM直接生成HDL设计，用RAG机制修复语法错误，并通过与HLS参考设计的仿真行为比较来迭代改进功能正确性。

Result: 实验结果显示，该框架生成的电路在面积和功耗效率上显著优于传统HLS设计，接近人工设计质量，同时保持HDL实现的正确性。

Conclusion: 该框架展示了结合LLM生成能力和传统正确性驱动IC设计流程的有效性和潜力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable potential in hardware front-end design using hardware description languages (HDLs). However, their inherent tendency toward hallucination often introduces functional errors into the generated HDL designs. To address this issue, we propose the framework CorrectHDL that leverages high-level synthesis (HLS) results as functional references to correct potential errors in LLM-generated HDL designs.The input to the proposed framework is a C/C++ program that specifies the target circuit's functionality. The program is provided to an LLM to directly generate an HDL design, whose syntax errors are repaired using a Retrieval-Augmented Generation (RAG) mechanism. The functional correctness of the LLM-generated circuit is iteratively improved by comparing its simulated behavior with an HLS reference design produced by conventional HLS tools, which ensures the functional correctness of the result but can lead to suboptimal area and power efficiency. Experimental results demonstrate that circuits generated by the proposed framework achieve significantly better area and power efficiency than conventional HLS designs and approach the quality of human-engineered circuits. Meanwhile, the correctness of the resulting HDL implementation is maintained, highlighting the effectiveness and potential of agentic HDL design leveraging the generative capabilities of LLMs and the rigor of traditional correctness-driven IC design flows.

</details>
