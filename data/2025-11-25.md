<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [TensorRight: Automated Verification of Tensor Graph Rewrites](https://arxiv.org/abs/2511.17838)
*Jai Arora,Sirui Lu,Devansh Jain,Tianfan Xu,Farzin Houshmand,Phitchaya Mangpo Phothilimthana,Mohsen Lesani,Praveen Narayanan,Karthik Srinivasa Murthy,Rastislav Bodik,Amit Sabne,Charith Mendis*

Main category: cs.PL

TL;DR: TensorRight是第一个能够验证任意秩和大小张量图重写的自动验证系统，通过引入聚合轴定义和边界验证方法来解决无界张量验证问题。


<details>
  <summary>Details</summary>
Motivation: 现有的张量编译器重写验证方法只能处理具体秩的张量，无法为任意秩和大小张量提供保证，需要开发能够验证无界张量重写正确性的自动系统。

Method: 引入TensorRight DSL核心语言，使用聚合轴定义来表示重写规则；通过证明存在秩边界，使得有界验证可推广到无界情况；使用符号执行和SMT求解器自动验证重写规则。

Result: 在XLA代数简化器的175个规则中，TensorRight能够证明115个规则在完全通用情况下的正确性，而最接近的自动有界验证系统只能表达18个规则。

Conclusion: TensorRight填补了无界张量重写验证的空白，为张量编译器提供了首个能够验证任意秩和大小张量图重写正确性的自动验证系统。

Abstract: Tensor compilers, essential for generating efficient code for deep learning models across various applications, employ tensor graph rewrites as one of the key optimizations. These rewrites optimize tensor computational graphs with the expectation of preserving semantics for tensors of arbitrary rank and size. Despite this expectation, to the best of our knowledge, there does not exist a fully automated verification system to prove the soundness of these rewrites for tensors of arbitrary rank and size. Previous works, while successful in verifying rewrites with tensors of concrete rank, do not provide guarantees in the unbounded setting.
  To fill this gap, we introduce TensorRight, the first automatic verification system that can verify tensor graph rewrites for input tensors of arbitrary rank and size. We introduce a core language, TensorRight DSL, to represent rewrite rules using a novel axis definition, called aggregated-axis, which allows us to reason about an unbounded number of axes. We achieve unbounded verification by proving that there exists a bound on tensor ranks, under which bounded verification of all instances implies the correctness of the rewrite rule in the unbounded setting. We derive an algorithm to compute this rank using the denotational semantics of TensorRight DSL. TensorRight employs this algorithm to generate a finite number of bounded-verification proof obligations, which are then dispatched to an SMT solver using symbolic execution to automatically verify the correctness of the rewrite rules. We evaluate TensorRight's verification capabilities by implementing rewrite rules present in XLA's algebraic simplifier. The results demonstrate that TensorRight can prove the correctness of 115 out of 175 rules in their full generality, while the closest automatic, bounded-verification system can express only 18 of these rules.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [2] [LockForge: Automating Paper-to-Code for Logic Locking with Multi-Agent Reasoning LLMs](https://arxiv.org/abs/2511.18531)
*Akashdeep Saha,Zeng Wang,Prithwish Basu Roy,Johann Knechtel,Ozgur Sinanoglu,Ramesh Karri*

Main category: cs.CR

TL;DR: LockForge是一个多智能体LLM框架，能够将论文中的逻辑锁定方案描述转化为可执行代码，解决了逻辑锁定领域代码复现性差的问题。


<details>
  <summary>Details</summary>
Motivation: 逻辑锁定领域进展迅速但代码复现性差，许多方案缺乏参考实现，阻碍了进一步研究和公平评估。

Method: 采用多智能体LLM框架，包含前瞻规划、实现、迭代优化和多阶段验证的完整流程，通过LLM-as-Judge和LLM-as-Examiner进行行为检查、概念机制验证和基准测试。

Result: 成功应用于10个重要逻辑锁定方案，验证了任务的复杂性，表明需要先进的推理模型和复杂多阶段框架才能实现。

Conclusion: LockForge为逻辑锁定研究提供了可复现的评估基础，证明了多智能体LLM框架在将文本描述转化为可执行代码方面的有效性。

Abstract: Despite rapid progress in logic locking (LL), reproducibility remains a challenge as codes are rarely made public. We present LockForge, a first-of-its-kind, multi-agent large language model (LLM) framework that turns LL descriptions in papers into executable and tested code. LockForge provides a carefully crafted pipeline realizing forethought, implementation, iterative refinement, and a multi-stage validation, all to systematically bridge the gap between prose and practice for complex LL schemes. For validation, we devise (i) an LLM-as-Judge stage with a scoring system considering behavioral checks, conceptual mechanisms, structural elements, and reproducibility on benchmarks, and (ii) an independent LLM-as-Examiner stage for ground-truth assessment. We apply LockForge to 10 seminal LL schemes, many of which lack reference implementations. Our evaluation on multiple SOTA LLMs, including ablation studies, reveals the significant complexity of the task. We show that an advanced reasoning model and a sophisticated, multi-stage framework like LockForge are required. We release all implementations and benchmarks, providing a reproducible and fair foundation for evaluation of further LL research.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning](https://arxiv.org/abs/2511.19422)
*David Jiahao Fu,Aryan Gupta,Aaron Councilman,David Grove,Yu-Xiong Wang,Vikram Adve*

Main category: cs.SE

TL;DR: SLMFix是一个代码生成管道，利用强化学习微调的小型语言模型来修复LLM生成程序中的语法错误，特别针对低资源编程语言，无需昂贵的大模型微调。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在代码生成中仍存在语法错误，特别是在低资源编程语言上表现不佳，而大模型微调成本高昂，需要更经济的解决方案。

Method: 使用强化学习微调小型语言模型进行程序修复，奖励函数结合静态验证器和静态语义相似度指标。

Result: 在多个领域特定语言上验证有效，静态验证器通过率超过95%，在低资源编程语言上优于监督微调的7B模型。

Conclusion: 该方法可作为传统微调方法的替代方案，展示了小型模型在代码修复任务中的潜力。

Abstract: Recent advancements in large language models (LLMs) have shown very impressive capabilities in code generation across many programming languages. However, even state-of-the-art LLMs generate programs that contains syntactic errors and fail to complete the given tasks, especially for low-resource programming languages (LRPLs). In addition, high training cost makes finetuning LLMs unaffordable with constrained computational resources, further undermining the effectiveness of LLMs for code generation. In this work, we propose SLMFix, a novel code generation pipeline that leverages a small language model (SLM) finetuned using reinforcement learning (RL) techniques to fix syntactic errors in LLM-generated programs to improve the quality of LLM-generated programs for domain-specific languages (DSLs). In specific, we applied RL on the SLM for the program repair task using a reward calculated using both a static validator and a static semantic similarity metric. Our experimental results demonstrate the effectiveness and generalizability of our approach across multiple DSLs, achieving more than 95% pass rate on the static validator. Notably, SLMFix brings substantial improvement to the base model and outperforms supervised finetuning approach even for 7B models on a LRPL, showing the potential of our approach as an alternative to traditional finetuning approaches.

</details>
