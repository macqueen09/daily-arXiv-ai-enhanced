{"id": "2511.17838", "pdf": "https://arxiv.org/pdf/2511.17838", "abs": "https://arxiv.org/abs/2511.17838", "authors": ["Jai Arora", "Sirui Lu", "Devansh Jain", "Tianfan Xu", "Farzin Houshmand", "Phitchaya Mangpo Phothilimthana", "Mohsen Lesani", "Praveen Narayanan", "Karthik Srinivasa Murthy", "Rastislav Bodik", "Amit Sabne", "Charith Mendis"], "title": "TensorRight: Automated Verification of Tensor Graph Rewrites", "categories": ["cs.PL"], "comment": "61 pages, 13 figures, published in POPL 2025", "summary": "Tensor compilers, essential for generating efficient code for deep learning models across various applications, employ tensor graph rewrites as one of the key optimizations. These rewrites optimize tensor computational graphs with the expectation of preserving semantics for tensors of arbitrary rank and size. Despite this expectation, to the best of our knowledge, there does not exist a fully automated verification system to prove the soundness of these rewrites for tensors of arbitrary rank and size. Previous works, while successful in verifying rewrites with tensors of concrete rank, do not provide guarantees in the unbounded setting.\n  To fill this gap, we introduce TensorRight, the first automatic verification system that can verify tensor graph rewrites for input tensors of arbitrary rank and size. We introduce a core language, TensorRight DSL, to represent rewrite rules using a novel axis definition, called aggregated-axis, which allows us to reason about an unbounded number of axes. We achieve unbounded verification by proving that there exists a bound on tensor ranks, under which bounded verification of all instances implies the correctness of the rewrite rule in the unbounded setting. We derive an algorithm to compute this rank using the denotational semantics of TensorRight DSL. TensorRight employs this algorithm to generate a finite number of bounded-verification proof obligations, which are then dispatched to an SMT solver using symbolic execution to automatically verify the correctness of the rewrite rules. We evaluate TensorRight's verification capabilities by implementing rewrite rules present in XLA's algebraic simplifier. The results demonstrate that TensorRight can prove the correctness of 115 out of 175 rules in their full generality, while the closest automatic, bounded-verification system can express only 18 of these rules.", "AI": {"tldr": "TensorRight\u662f\u7b2c\u4e00\u4e2a\u80fd\u591f\u9a8c\u8bc1\u4efb\u610f\u79e9\u548c\u5927\u5c0f\u5f20\u91cf\u56fe\u91cd\u5199\u7684\u81ea\u52a8\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f15\u5165\u805a\u5408\u8f74\u5b9a\u4e49\u548c\u8fb9\u754c\u9a8c\u8bc1\u65b9\u6cd5\u6765\u89e3\u51b3\u65e0\u754c\u5f20\u91cf\u9a8c\u8bc1\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5f20\u91cf\u7f16\u8bd1\u5668\u91cd\u5199\u9a8c\u8bc1\u65b9\u6cd5\u53ea\u80fd\u5904\u7406\u5177\u4f53\u79e9\u7684\u5f20\u91cf\uff0c\u65e0\u6cd5\u4e3a\u4efb\u610f\u79e9\u548c\u5927\u5c0f\u5f20\u91cf\u63d0\u4f9b\u4fdd\u8bc1\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u9a8c\u8bc1\u65e0\u754c\u5f20\u91cf\u91cd\u5199\u6b63\u786e\u6027\u7684\u81ea\u52a8\u7cfb\u7edf\u3002", "method": "\u5f15\u5165TensorRight DSL\u6838\u5fc3\u8bed\u8a00\uff0c\u4f7f\u7528\u805a\u5408\u8f74\u5b9a\u4e49\u6765\u8868\u793a\u91cd\u5199\u89c4\u5219\uff1b\u901a\u8fc7\u8bc1\u660e\u5b58\u5728\u79e9\u8fb9\u754c\uff0c\u4f7f\u5f97\u6709\u754c\u9a8c\u8bc1\u53ef\u63a8\u5e7f\u5230\u65e0\u754c\u60c5\u51b5\uff1b\u4f7f\u7528\u7b26\u53f7\u6267\u884c\u548cSMT\u6c42\u89e3\u5668\u81ea\u52a8\u9a8c\u8bc1\u91cd\u5199\u89c4\u5219\u3002", "result": "\u5728XLA\u4ee3\u6570\u7b80\u5316\u5668\u7684175\u4e2a\u89c4\u5219\u4e2d\uff0cTensorRight\u80fd\u591f\u8bc1\u660e115\u4e2a\u89c4\u5219\u5728\u5b8c\u5168\u901a\u7528\u60c5\u51b5\u4e0b\u7684\u6b63\u786e\u6027\uff0c\u800c\u6700\u63a5\u8fd1\u7684\u81ea\u52a8\u6709\u754c\u9a8c\u8bc1\u7cfb\u7edf\u53ea\u80fd\u8868\u8fbe18\u4e2a\u89c4\u5219\u3002", "conclusion": "TensorRight\u586b\u8865\u4e86\u65e0\u754c\u5f20\u91cf\u91cd\u5199\u9a8c\u8bc1\u7684\u7a7a\u767d\uff0c\u4e3a\u5f20\u91cf\u7f16\u8bd1\u5668\u63d0\u4f9b\u4e86\u9996\u4e2a\u80fd\u591f\u9a8c\u8bc1\u4efb\u610f\u79e9\u548c\u5927\u5c0f\u5f20\u91cf\u56fe\u91cd\u5199\u6b63\u786e\u6027\u7684\u81ea\u52a8\u9a8c\u8bc1\u7cfb\u7edf\u3002"}}
{"id": "2511.18531", "pdf": "https://arxiv.org/pdf/2511.18531", "abs": "https://arxiv.org/abs/2511.18531", "authors": ["Akashdeep Saha", "Zeng Wang", "Prithwish Basu Roy", "Johann Knechtel", "Ozgur Sinanoglu", "Ramesh Karri"], "title": "LockForge: Automating Paper-to-Code for Logic Locking with Multi-Agent Reasoning LLMs", "categories": ["cs.CR", "cs.PL"], "comment": null, "summary": "Despite rapid progress in logic locking (LL), reproducibility remains a challenge as codes are rarely made public. We present LockForge, a first-of-its-kind, multi-agent large language model (LLM) framework that turns LL descriptions in papers into executable and tested code. LockForge provides a carefully crafted pipeline realizing forethought, implementation, iterative refinement, and a multi-stage validation, all to systematically bridge the gap between prose and practice for complex LL schemes. For validation, we devise (i) an LLM-as-Judge stage with a scoring system considering behavioral checks, conceptual mechanisms, structural elements, and reproducibility on benchmarks, and (ii) an independent LLM-as-Examiner stage for ground-truth assessment. We apply LockForge to 10 seminal LL schemes, many of which lack reference implementations. Our evaluation on multiple SOTA LLMs, including ablation studies, reveals the significant complexity of the task. We show that an advanced reasoning model and a sophisticated, multi-stage framework like LockForge are required. We release all implementations and benchmarks, providing a reproducible and fair foundation for evaluation of further LL research.", "AI": {"tldr": "LockForge\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u8bba\u6587\u4e2d\u7684\u903b\u8f91\u9501\u5b9a\u65b9\u6848\u63cf\u8ff0\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u89e3\u51b3\u4e86\u903b\u8f91\u9501\u5b9a\u9886\u57df\u4ee3\u7801\u590d\u73b0\u6027\u5dee\u7684\u95ee\u9898\u3002", "motivation": "\u903b\u8f91\u9501\u5b9a\u9886\u57df\u8fdb\u5c55\u8fc5\u901f\u4f46\u4ee3\u7801\u590d\u73b0\u6027\u5dee\uff0c\u8bb8\u591a\u65b9\u6848\u7f3a\u4e4f\u53c2\u8003\u5b9e\u73b0\uff0c\u963b\u788d\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u516c\u5e73\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\uff0c\u5305\u542b\u524d\u77bb\u89c4\u5212\u3001\u5b9e\u73b0\u3001\u8fed\u4ee3\u4f18\u5316\u548c\u591a\u9636\u6bb5\u9a8c\u8bc1\u7684\u5b8c\u6574\u6d41\u7a0b\uff0c\u901a\u8fc7LLM-as-Judge\u548cLLM-as-Examiner\u8fdb\u884c\u884c\u4e3a\u68c0\u67e5\u3001\u6982\u5ff5\u673a\u5236\u9a8c\u8bc1\u548c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u6210\u529f\u5e94\u7528\u4e8e10\u4e2a\u91cd\u8981\u903b\u8f91\u9501\u5b9a\u65b9\u6848\uff0c\u9a8c\u8bc1\u4e86\u4efb\u52a1\u7684\u590d\u6742\u6027\uff0c\u8868\u660e\u9700\u8981\u5148\u8fdb\u7684\u63a8\u7406\u6a21\u578b\u548c\u590d\u6742\u591a\u9636\u6bb5\u6846\u67b6\u624d\u80fd\u5b9e\u73b0\u3002", "conclusion": "LockForge\u4e3a\u903b\u8f91\u9501\u5b9a\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6\u5728\u5c06\u6587\u672c\u63cf\u8ff0\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.19422", "pdf": "https://arxiv.org/pdf/2511.19422", "abs": "https://arxiv.org/abs/2511.19422", "authors": ["David Jiahao Fu", "Aryan Gupta", "Aaron Councilman", "David Grove", "Yu-Xiong Wang", "Vikram Adve"], "title": "SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Recent advancements in large language models (LLMs) have shown very impressive capabilities in code generation across many programming languages. However, even state-of-the-art LLMs generate programs that contains syntactic errors and fail to complete the given tasks, especially for low-resource programming languages (LRPLs). In addition, high training cost makes finetuning LLMs unaffordable with constrained computational resources, further undermining the effectiveness of LLMs for code generation. In this work, we propose SLMFix, a novel code generation pipeline that leverages a small language model (SLM) finetuned using reinforcement learning (RL) techniques to fix syntactic errors in LLM-generated programs to improve the quality of LLM-generated programs for domain-specific languages (DSLs). In specific, we applied RL on the SLM for the program repair task using a reward calculated using both a static validator and a static semantic similarity metric. Our experimental results demonstrate the effectiveness and generalizability of our approach across multiple DSLs, achieving more than 95% pass rate on the static validator. Notably, SLMFix brings substantial improvement to the base model and outperforms supervised finetuning approach even for 7B models on a LRPL, showing the potential of our approach as an alternative to traditional finetuning approaches.", "AI": {"tldr": "SLMFix\u662f\u4e00\u4e2a\u4ee3\u7801\u751f\u6210\u7ba1\u9053\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u6765\u4fee\u590dLLM\u751f\u6210\u7a0b\u5e8f\u4e2d\u7684\u8bed\u6cd5\u9519\u8bef\uff0c\u7279\u522b\u9488\u5bf9\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\uff0c\u65e0\u9700\u6602\u8d35\u7684\u5927\u6a21\u578b\u5fae\u8c03\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u4ecd\u5b58\u5728\u8bed\u6cd5\u9519\u8bef\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u5927\u6a21\u578b\u5fae\u8c03\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u66f4\u7ecf\u6d4e\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7a0b\u5e8f\u4fee\u590d\uff0c\u5956\u52b1\u51fd\u6570\u7ed3\u5408\u9759\u6001\u9a8c\u8bc1\u5668\u548c\u9759\u6001\u8bed\u4e49\u76f8\u4f3c\u5ea6\u6307\u6807\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u9759\u6001\u9a8c\u8bc1\u5668\u901a\u8fc7\u7387\u8d85\u8fc795%\uff0c\u5728\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u4e0a\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\u76847B\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u53ef\u4f5c\u4e3a\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5c0f\u578b\u6a21\u578b\u5728\u4ee3\u7801\u4fee\u590d\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
