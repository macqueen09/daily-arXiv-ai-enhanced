<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Mechanizing a Proof-Relevant Logical Relation for Timed Message-Passing Protocols](https://arxiv.org/abs/2511.19521)
*Tesla Zhang,Asher Kornfeld,Rui Li,Sonya Simkin,Yue Yao,Stephanie Balzer*

Main category: cs.PL

TL;DR: 本文在Rocq定理证明器中实现了Yao等人关于定时消息传递协议语义类型化的逻辑关系机械化验证，解决了轨迹代数操作和等式证明的挑战。


<details>
  <summary>Details</summary>
Motivation: 定时消息传递协议在物联网和实时系统中广泛应用，但之前的语义类型化验证缺乏机械化实现。机械化不仅能提供机器证明，还能支持未来扩展和应用的可扩展性。

Method: 在Rocq定理证明器中机械化Yao等人的逻辑关系系统，包括逻辑关系本身、可计算轨迹的代数操作（交错、分区、连接）以及相关引理和基本定理。

Result: 成功实现了逻辑关系、轨迹代数和基本定理的机械化验证，解决了在内涵类型论中处理轨迹等式证明的挑战。

Conclusion: 通过机械化语义类型化的逻辑关系，为定时消息传递协议的验证提供了可靠的机器证明基础，并为未来扩展奠定了基础。

Abstract: Semantic typing has become a powerful tool for program verification, applying the technique of logical relations as not only a proof method, but also a device for prescribing program behavior. In recent work, Yao et al. scaled semantic typing to the verification of timed message-passing protocols, which are prevalent in, e.g., IoT and real-time systems applications. The appeal of semantic typing in this context is precisely because of its ability to support typed and untyped program components alike -- including physical objects -- which caters to the heterogeneity of these applications. Another demand inherent to these applications is timing: constraining the time or time window within which a message exchange must happen. Yao et al. equipped their logical relation not only with temporal predicates, but also with computable trajectories, to supply the evidence that an inhabitant can step from one time point to another one. While Yao et al. provide the formalization for such a verification tool, it lacks a mechanization. Mechanizing the system would not only provide a machine proof for it, but also facilitate scalability for future extensions and applications.
  This paper tackles the challenge of mechanizing the resulting proof-relevant logical relation in a proof assistant. allowing trajectories to be interleaved, partitioned, and concatenated, while the intended equality on trajectories is the equality of their graphs when seen as processes indexed by time. Unfortunately, proof assistants based on intensional type theory only have modest support for such equations, forcing a prolific use of transports. This paper reports on the process of mechanizing Yao et al.'s results, comprising the logical relation, the algebra of computable trajectories with supporting lemmas, and the fundamental theorem of the logical relation, in the Rocq theorem prover.

</details>


### [2] [Understanding Accelerator Compilers via Performance Profiling](https://arxiv.org/abs/2511.19764)
*Ayaka Yorihiro,Griffin Berlstein,Pedro Pontes García,Kevin Laeufer,Adrian Sampson*

Main category: cs.PL

TL;DR: Petal是一个针对Calyx中间语言的周期级分析工具，通过插桩和跟踪分析来识别加速器设计中的性能问题，帮助开发者理解编译器决策对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 加速器设计语言(ADL)编译器复杂且难以预测，性能问题难以定位和解决。作者认为编译器永远不会完美，因此需要工具来帮助程序员理解编译器决策如何影响性能。

Method: Petal在Calyx代码中插入探针，分析寄存器传输级模拟的跟踪数据，将跟踪中的事件映射回Calyx代码中的高级控制结构，以跟踪每个结构活跃时的时钟周期。

Result: 通过案例研究证明Petal的周期级配置文件能够识别现有加速器设计中的性能问题，并指导开发者进行编译器无法自动执行的优化，其中一个应用的总周期数减少了46.9%。

Conclusion: Petal作为编译器理解工具，为ADL程序员提供了洞察编译器决策如何影响性能的能力，弥补了编译器不完美的问题。

Abstract: Accelerator design languages (ADLs), high-level languages that compile to hardware units, help domain experts quickly design efficient application-specific hardware. ADL compilers optimize datapaths and convert software-like control flow constructs into control paths. Such compilers are necessarily complex and often unpredictable: they must bridge the wide semantic gap between high-level semantics and cycle-level schedules, and they typically rely on advanced heuristics to optimize circuits. The resulting performance can be difficult to control, requiring guesswork to find and resolve performance problems in the generated hardware. We conjecture that ADL compilers will never be perfect: some performance unpredictability is endemic to the problem they solve.
  In lieu of compiler perfection, we argue for compiler understanding tools that give ADL programmers insight into how the compiler's decisions affect performance. We introduce Petal, a cycle-level Petal for the Calyx intermediate language (IL). Petal instruments the Calyx code with probes and then analyzes the trace from a register-transfer-level simulation. It maps the events in the trace back to high-level control constructs in the Calyx code to track the clock cycles when each construct was active. Using case studies, we demonstrate that Petal's cycle-level profiles can identify performance problems in existing accelerator designs. We show that these insights can also guide developers toward optimizations that the compiler was unable to perform automatically, including a reduction by 46.9\% of total cycles for one application.

</details>


### [3] [The Ghosts of Empires: Extracting Modularity from Interleaving-Based Proofs (Extended Version)](https://arxiv.org/abs/2511.20369)
*Frank Schüssele,Matthias Zumkeller,Miriam Lagunes-Rochin,Dominik Klumpp*

Main category: cs.PL

TL;DR: 将基于交错执行的正确性证明转换为线程模块化的Owicki-Gries风格证明，通过自动合成幽灵变量来捕获相关交错信息并抽象无关细节。


<details>
  <summary>Details</summary>
Motivation: 算法软件验证器中的实现错误威胁其可靠性。为正确程序生成正确性证书可以独立验证验证结果，从而帮助发现此类错误。为并发程序生成小型紧凑的正确性证明具有挑战性，因为正确性论证可能依赖于特定的交错执行，导致指数级爆炸。

Method: 将基于交错执行的正确性证明转换为线程模块化的Owicki-Gries风格证明，自动合成幽灵变量来捕获相关交错信息，并抽象掉无关细节。

Result: 评估表明该方法在实践中高效，与基线相比能生成紧凑的证明。

Conclusion: 提出的方法能够有效地将交错执行证明转换为线程模块化证明，生成紧凑的证书，有助于验证并发程序的正确性。

Abstract: Implementation bugs threaten the soundness of algorithmic software verifiers. Generating correctness certificates for correct programs allows for efficient independent validation of verification results, and thus helps to reveal such bugs. Automatic generation of small, compact correctness proofs for concurrent programs is challenging, as the correctness arguments may depend on the particular interleaving, which can lead to exponential explosion. We present an approach that converts an interleaving-based correctness proof, as generated by many algorithmic verifiers, into a thread-modular correctness proof in the style of Owicki and Gries. We automatically synthesize ghost variables that capture the relevant interleaving information, and abstract away irrelevant details. Our evaluation shows that the approach is efficient in practice and generates compact proofs, compared to a baseline.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [Translating Large-Scale C Repositories to Idiomatic Rust](https://arxiv.org/abs/2511.20617)
*Saman Dehghan,Tianran Sun,Tianxiang Wu,Zihan Li,Reyhaneh Jabbarvand*

Main category: cs.SE

TL;DR: Rustine是一个自动化C到Rust翻译管道，平衡了质量与可扩展性，相比现有方法生成更安全、更地道、更可读的Rust代码。


<details>
  <summary>Details</summary>
Motivation: 现有C到Rust翻译技术无法平衡质量与可扩展性：基于转译的方法可扩展但代码质量差，基于LLM的方法质量高但成本过高。

Method: 提出Rustine全自动管道，在23个C程序上进行评估，涵盖27到13,200行代码范围。

Result: Rustine为所有程序生成完全可编译的Rust代码，达到87%功能等价性，通过1,063,099/1,221,192个断言测试，平均函数和行覆盖率为74.7%和72.2%。

Conclusion: 相比六种现有技术，Rustine的翻译更安全、更地道、更可读，当无法完全通过测试时，开发人员平均只需4.5小时即可完成调试。

Abstract: Existing C to Rust translation techniques fail to balance quality and scalability: transpilation-based approaches scale to large projects but produce code with poor safety, idiomaticity, and readability. In contrast, LLM-based techniques are prohibitively expensive due to their reliance on frontier models (without which they cannot reliably generate compilable translations), thus limiting scalability. This paper proposes Rustine, a fully automated pipeline for effective and efficient repository-level C to idiomatic safe Rust translation. Evaluating on a diverse set of 23 C programs, ranging from 27 to 13,200 lines of code, Rustine can generate fully compilable Rust code for all and achieve 87% functional equivalence (passing 1,063,099 assertions out of 1,221,192 in test suites with average function and line coverage of 74.7% and 72.2%). Compared to six prior repository-level C to Rust translation techniques, the translations by Rustine are overall safer (fewer raw pointers, pointer arithmetic, and unsafe constructs), more idiomatic (fewer Rust linter violations), and more readable. When the translations cannot pass all tests to fulfill functional equivalence, human developers were able to complete the task in 4.5 hours, on average, using Rustine as debugging support.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [5] [CrypTorch: PyTorch-based Auto-tuning Compiler for Machine Learning with Multi-party Computation](https://arxiv.org/abs/2511.19711)
*Jinyu Liu,Gang Tan,Kiwan Maeng*

Main category: cs.CR

TL;DR: CrypTorch是一个基于MPC的机器学习编译器，通过解耦近似计算与MPC运行时，提供自动调优功能，显著提升性能同时保持精度。


<details>
  <summary>Details</summary>
Motivation: 现有MPC框架中的ML操作近似计算存在精度不足或性能瓶颈问题，且难以识别和修复。

Method: 提出CrypTorch编译器，作为PyTorch 2的扩展，解耦近似计算与MPC运行时，提供编程接口添加新近似方法，并自动选择最优近似方案。

Result: 仅自动调优即可提供1.20-1.7倍速度提升（不牺牲精度）和1.31-1.8倍速度提升（允许精度损失）；相比CrypTen框架，整体带来3.22-8.6倍端到端加速。

Conclusion: CrypTorch通过解耦近似计算和自动调优，有效解决了MPC-based ML中的近似计算瓶颈问题。

Abstract: Machine learning (ML) involves private data and proprietary model parameters. MPC-based ML allows multiple parties to collaboratively run an ML workload without sharing their private data or model parameters using multi-party computing (MPC). Because MPC cannot natively run ML operations such as Softmax or GELU, existing frameworks use different approximations. Our study shows that, on a well-optimized framework, these approximations often become the dominating bottleneck. Popular approximations are often insufficiently accurate or unnecessarily slow, and these issues are hard to identify and fix in existing frameworks. To tackle this issue, we propose a compiler for MPC-based ML, CrypTorch. CrypTorch disentangles these approximations with the rest of the MPC runtime, allows easily adding new approximations through its programming interface, and automatically selects approximations to maximize both performance and accuracy. Built as an extension to PyTorch 2's compiler, we show that CrypTorch's auto-tuning alone provides 1.20--1.7$\times$ immediate speedup without sacrificing accuracy, and 1.31--1.8$\times$ speedup when some accuracy degradation is allowed, compared to our well-optimized baseline. Combined with better engineering and adoption of state-of-the-art practices, the entire framework brings 3.22--8.6$\times$ end-to-end speedup compared to the popular framework, CrypTen.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [6] [DiverseClaire: Simulating Students to Improve Introductory Programming Course Materials for All CS1 Learners](https://arxiv.org/abs/2511.14198)
*Wendy Wong,Yuchao Jiang,Yuekang Li*

Main category: cs.CY

TL;DR: DiverseClaire是一个使用LLM模拟神经多样性学生的试点研究，通过比较UDL转换的幻灯片与传统格式，发现神经多样性学生在传统格式下学习困难，强调需要提供多种格式的课程材料。


<details>
  <summary>Details</summary>
Motivation: CS1等入门课程采用一刀切的教学形式，这会加剧认知负荷并阻碍自闭症、ADHD、阅读障碍等神经多样性学生的学习，需要采用富有同情心的教学法和通用学习设计来创建包容认知多样性的学习环境。

Method: 开发DiverseClaire试点研究，使用LLM模拟包括神经多样性特征的学生角色，基于布鲁姆分类法和UDL原则，比较UDL转换的幻灯片与传统格式的教学材料。

Result: 研究发现模拟的神经多样性学生在传统格式的幻灯片下学习困难，而UDL转换的格式表现更好，表明课程材料的可访问性对神经多样性学生至关重要。

Conclusion: 需要为不同学习偏好提供多种格式的课程材料，DiverseClaire的数据将帮助未来的CS1教师改进教学材料设计。

Abstract: Although CS programs are booming, introductory courses like CS1 still adopt a one-size-fits-all formats that can exacerbate cognitive load and discourage learners with autism, ADHD, dyslexia and other neurological conditions. These call for compassionate pedagogies and Universal Design For Learning (UDL) to create learning environments and materials where cognitive diversity is welcomed. To address this, we introduce DiverseClaire a pilot study, which simulates students including neurodiverse profiles using LLMs and diverse personas. By leveraging Bloom's Taxonomy and UDL, DiverseClaire compared UDL-transformed lecture slides with traditional formats. To evaluate DiverseClaire controlled experiments, we used the evaluation metric the average score. The findings revealed that the simulated neurodiverse students struggled with learning due to lecture slides that were in inaccessible formats. These results highlight the need to provide course materials in multiple formats for diverse learner preferences. Data from our pilot study will be made available to assist future CS1 instructors.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [7] [QiMeng-CRUX: Narrowing the Gap between Natural Language and Verilog via Core Refined Understanding eXpression](https://arxiv.org/abs/2511.20099)
*Lei Huang,Rui Zhang,Jiaming Guo,Yang Zhang,Di Huang,Shuyao Cheng,Pengwei Jin,Chongxiao Li,Zidong Du,Xing Hu,Qi Guo,Yunji Chen*

Main category: cs.LG

TL;DR: 提出了CRUX结构化中间表示空间和两阶段训练框架，用于改进从自然语言到Verilog代码的生成质量，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于自然语言的硬件描述方法存在模糊、冗余和非结构化问题，难以生成精确的Verilog代码。需要弥合开放式自然语言空间与领域特定约束目标空间之间的差距。

Method: 引入CRUX结构化中间表示空间捕获用户意图语义，设计包含联合表达建模和双空间优化的两阶段训练框架CRUX-V。

Result: 在多个Verilog生成基准测试中达到最先进性能，CRUX表示可迁移且能提升其他代码模型的生成质量。

Conclusion: CRUX有效缩小了自由形式自然语言描述与精确Verilog生成之间的差距，结构化中间表示对硬件代码生成具有重要价值。

Abstract: Large language models (LLMs) have shown promising capabilities in hardware description language (HDL) generation. However, existing approaches often rely on free-form natural language descriptions that are often ambiguous, redundant, and unstructured, which poses significant challenges for downstream Verilog code generation. We treat hardware code generation as a complex transformation from an open-ended natural language space to a domain-specific, highly constrained target space. To bridge this gap, we introduce Core Refined Understanding eXpression (CRUX), a structured intermediate space that captures the essential semantics of user intent while organizing the expression for precise Verilog code generation. We further design a two-stage training framework, comprising Joint Expression Modeling and Dual-Space Optimization, to enhance the quality of both CRUX and Verilog code. Experiments across multiple Verilog generation benchmarks demonstrate that our model, CRUX-V, achieves state-of-the-art performance among general models, particularly under challenging design tasks. Furthermore, the CRUX space proves transferable and beneficial when used as input prompts for other code models, highlighting its effectiveness in narrowing the gap between free-form natural language descriptions and precise Verilog generation.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [8] [Separating the Wheat from the Chaff: Understanding (In-)Completeness of Proof Mechanisms for Separation Logic with Inductive Definitions](https://arxiv.org/abs/2511.20193)
*Neta Elad,Adithya Murali,Sharon Shoham*

Main category: cs.LO

TL;DR: 本文研究了分离逻辑与归纳定义(SLID)的不完备性，提出了弱分离逻辑(WSL)作为更完整的框架，证明了WSL对带背景理论和归纳定义的量化蕴含是完备的，并开发了原型工具来发现反例模型。


<details>
  <summary>Details</summary>
Motivation: 分离逻辑是推理堆操作程序和共享资源的主流框架，但SLID存在多个不完备性来源，阻碍自动推理。需要深入理解证明机制失败的原因。

Method: 将SLID置于更大的弱分离逻辑(WSL)框架中，通过归约到一阶逻辑证明WSL的完备性，使用符号结构表示和发现非标准模型。

Result: 证明WSL对带背景理论和归纳定义的量化蕴含是完备的，fold/unfold机制在无理论、无量词的WSL蕴含中完备，开发的原型工具在700多个问题上发现了反例模型。

Conclusion: 证明失败源于WSL中存在但SLID不允许的非标准模型，这些模型通常是无限的，通过符号结构可以自动发现它们，为理解实际证明失败提供了新视角。

Abstract: For over two decades Separation Logic has been arguably the most popular framework for reasoning about heap-manipulating programs, as well as reasoning about shared resources and permissions. Separation Logic is often extended to include inductively-defined predicates, interpreted as least fixpoints, forming Separation Logic with Inductive Definitions (SLID). Many theoretical and practical advances have been made in developing automated proof mechanisms for SLID, but these mechanisms are imperfect, and a deeper understanding of their failures is desired. As expressive as Separation Logic is, it is not surprising that it is incomplete, and in fact, it contains several sources of incompleteness that defy automated reasoning.
  In this paper we study these sources of incompleteness and how they relate to failures of proof mechanisms. We place SLID within a larger logic, that we call Weak Separation Logic (WSL). We prove that unlike SLID, WSL is complete for a non-trivial fragment of quantified entailments with background theories and inductive definitions, via a reduction to first-order logic (FOL). Moreover, we show that the ubiquitous fold/unfold proof mechanism is sound and complete for theory-free, quantifier-free WSL entailments with inductive definitions. Through this, we understand proof failures as stemming from nonstandard models present in WSL, but not allowed in SLID. These rogue models are typically infinite, and we use the formalism of symbolic structures to represent and automatically find them.
  We present a prototype tool that implements the FOL encoding of WSL and test it on an existing benchmark, which contains over 700 quantified entailment problems with inductive definitions. Our tool is able to find counter-models to many of the examples, and we provide a partial taxonomy of the rogue models, shedding some light on real-world proof failures.

</details>
