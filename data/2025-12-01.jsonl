{"id": "2511.22075", "pdf": "https://arxiv.org/pdf/2511.22075", "abs": "https://arxiv.org/abs/2511.22075", "authors": ["Doruk Alp Mutlu"], "title": "Expanding Specification Capabilities of a Gradual Verifier with Pure Functions", "categories": ["cs.PL"], "comment": "Submitted to the 53rd ACM SIGPLAN Symposium on Principles of Programming Languages (POPL 2026) Student Research Competition", "summary": "Gradual verification soundly combines static checking and dynamic checking to provide an incremental approach for software verification. With gradual verification, programs can be partially specified first, and then the full specification of a program can be achieved in incremental steps. The first and only practicable gradual verifier based on symbolic execution, Gradual C0, supports recursive heap data structures. Despite recent efforts to improve the expressivity of Gradual C0's specification language, Gradual C0's specification language is still limited in its capabilities for complex expressions. This work explores an extension to Gradual C0's design with a common construct supported by many static verification tools, pure functions, which both extend the specification capabilities of Gradual C0 and increase the ease of encoding observer methods in Gradual C0. Our approach addresses the technical challenges related to the axiomatisation of pure functions with imprecise specifications."}
{"id": "2511.22419", "pdf": "https://arxiv.org/pdf/2511.22419", "abs": "https://arxiv.org/abs/2511.22419", "authors": ["Ken Sakayori", "Andrea Colledan", "Ugo Dal Lago"], "title": "On Circuit Description Languages, Indexed Monads, and Resource Analysis", "categories": ["cs.PL"], "comment": "Extended version of a paper to be published at POPL 2026", "summary": "In this paper, a monad-based denotational model is introduced and shown adequate for the Proto-Quipper family of calculi, themselves being idealized versions of the Quipper programming language. The use of a monadic approach allows us to separate the value to which a term reduces from the circuit that the term itself produces as a side effect. In turn, this enables the denotational interpretation and validation of rich type systems in which the size of the produced circuit can be controlled. Notably, the proposed semantic framework, through the novel concept of circuit algebra, suggests forms of effect typing guaranteeing quantitative properties about the resulting circuit, even in presence of optimizations."}
{"id": "2511.22692", "pdf": "https://arxiv.org/pdf/2511.22692", "abs": "https://arxiv.org/abs/2511.22692", "authors": ["David Castro-Perez", "Francisco Ferreira", "Sung-Shik Jongmans"], "title": "A Synthetic Reconstruction of Multiparty Session Types (with Appendix)", "categories": ["cs.PL"], "comment": null, "summary": "Multiparty session types (MPST) provide a rigorous foundation for verifying the safety and liveness of concurrent systems. However, existing approaches often force a difficult trade-off: classical, projection-based techniques are compositional but limited in expressiveness, while more recent techniques achieve higher expressiveness by relying on non-compositional, whole-system model checking, which scales poorly.\n  This paper introduces a new approach to MPST that delivers both expressiveness and compositionality, called the synthetic approach. Our key innovation is a type system that verifies each process directly against a global protocol specification, represented as a labelled transition system (LTS) in general, with global types as a special case. This approach uniquely avoids the need for intermediate local types and projection.\n  We demonstrate that our approach, while conceptually simpler, supports a benchmark of challenging protocols that were previously beyond the reach of compositional techniques in the MPST literature. We generalise our type system, showing that it can validate processes against any specification that constitutes a \"well-behaved\" LTS, supporting protocols not expressible with the standard global type syntax. The entire framework, including all theorems and many examples, has been formalised and mechanised in Agda, and we have developed a prototype implementation as an extension to VS Code."}
{"id": "2511.23283", "pdf": "https://arxiv.org/pdf/2511.23283", "abs": "https://arxiv.org/abs/2511.23283", "authors": ["Alexandre Moine", "Sam Westrick", "Joseph Tassarotti"], "title": "All for One and One for All: Program Logics for Exploiting Internal Determinism in Parallel Programs", "categories": ["cs.PL"], "comment": "32 pages, 26 figures, extended version of the same paper accepted at POPL 2026", "summary": "Nondeterminism makes parallel programs challenging to write and reason about. To avoid these challenges, researchers have developed techniques for internally deterministic parallel programming, in which the steps of a parallel computation proceed in a deterministic way. Internal determinism is useful because it lets a programmer reason about a program as if it executed in a sequential order. However, no verification framework exists to exploit this property and simplify formal reasoning about internally deterministic programs.\n  To capture the essence of why internally deterministic programs should be easier to reason about, this paper defines a property called schedule-independent safety. A program satisfies schedule-independent safety, if, to show that the program is safe across all orderings, it suffices to show that one terminating execution of the program is safe. We then present a separation logic called Musketeer for proving that a program satisfies schedule-independent safety. Once a parallel program has been shown to satisfy schedule-independent safety, we can verify it with a new logic called Angelic, which allows one to dynamically select and verify just one sequential ordering of the program.\n  Using Musketeer, we prove the soundness of MiniDet, an affine type system for enforcing internal determinism. MiniDet supports several core algorithmic primitives for internally deterministic programming that have been identified in the research literature, including a deterministic version of a concurrent hash set. Because any syntactically well-typed MiniDet program satisfies schedule-independent safety, we can apply Angelic to verify such programs.\n  All results in this paper have been verified in Rocq using the Iris separation logic framework."}
{"id": "2511.23358", "pdf": "https://arxiv.org/pdf/2511.23358", "abs": "https://arxiv.org/abs/2511.23358", "authors": ["Alexandre Moine", "Stephanie Balzer", "Alex Xu", "Sam Westrick"], "title": "TypeDis: A Type System for Disentanglement", "categories": ["cs.PL"], "comment": "34 pages, 24 figures, extended version of the same paper accepted at POPL 2026", "summary": "Disentanglement is a runtime property of parallel programs guaranteeing that parallel tasks remain oblivious to each other's allocations. As demonstrated in the MaPLe compiler and run-time system, disentanglement can be exploited for fast automatic memory management, especially task-local garbage collection with no synchronization between parallel tasks. However, as a low-level property, disentanglement can be difficult to reason about for programmers. The only means of statically verifying disentanglement so far has been DisLog, an Iris-fueled variant of separation logic, mechanized in the Rocq proof assistant. DisLog is a fully-featured program logic, allowing for proof of functional correctness as well as verification of disentanglement. Yet its employment requires significant expertise and per-program proof effort.\n  This paper explores the route of automatic verification via a type system, ensuring that any well-typed program is disentangled and lifting the burden of carrying out manual proofs from the programmer. It contributes TypeDis, a type system inspired by region types, where each type is annotated with a timestamp, identifying the task that allocated it. TypeDis supports iso-recursive types as well as polymorphism over both types and timestamps. Crucially, timestamps are allowed to change during type-checking, at join points as well as via a form of subtyping, dubbed subtiming. The paper illustrates TypeDis and its features on a range of examples. The soundness of TypeDis and the examples are mechanized in the Rocq proof assistant, using an improved version of DisLog, dubbed DisLog2."}
{"id": "2511.23472", "pdf": "https://arxiv.org/pdf/2511.23472", "abs": "https://arxiv.org/abs/2511.23472", "authors": ["Yusuke Matsushita", "Kengo Hirata", "Ryo Wakizaka", "Emanuele D'Osualdo"], "title": "RapunSL: Untangling Quantum Computing with Separation, Linear Combination and Mixing", "categories": ["cs.PL"], "comment": "Full version of the conference paper at POPL 2026. The first two authors contributed equally to this work", "summary": "Quantum Separation Logic (QSL) has been proposed as an effective tool to improve the scalability of deductive reasoning for quantum programs. In QSL, separation is interpreted as disentanglement, and the frame rule brings a notion of entanglement-local specification (one that only talks about the qubits entangled with those acted upon by the program). In this paper, we identify two notions of locality unique to the quantum domain, and we construct a novel quantum separation logic, RapunSL, which is able to soundly reduce reasoning about superposition states to reasoning about pure states (basis-locality), and reasoning about mixed states arising from measurement to reasoning about pure states (outcome-locality). To do so, we introduce two connectives, linear combination and mixing, which together with separation provide a dramatic improvement in the scalability of reasoning, as we demonstrate on a series of challenging case studies."}
{"id": "2511.21878", "pdf": "https://arxiv.org/pdf/2511.21878", "abs": "https://arxiv.org/abs/2511.21878", "authors": ["Kaiyao Ke", "Ali Reza Ibrahimzada", "Rangeet Pan", "Saurabh Sinha", "Reyhaneh Jabbarvand"], "title": "Advancing Automated In-Isolation Validation in Repository-Level Code Translation", "categories": ["cs.SE", "cs.PL"], "comment": null, "summary": "Repository-level code translation aims to migrate entire repositories across programming languages while preserving functionality automatically. Despite advancements in repository-level code translation, validating the translations remains challenging. This paper proposes TRAM, which combines context-aware type resolution with mock-based in-isolation validation to achieve high-quality translations between programming languages. Prior to translation, TRAM retrieves API documentation and contextual code information for each variable type in the source language. It then prompts a large language model (LLM) with retrieved contextual information to resolve type mappings across languages with precise semantic interpretations. Using the automatically constructed type mapping, TRAM employs a custom serialization/deserialization workflow that automatically constructs equivalent mock objects in the target language. This enables each method fragment to be validated in isolation, without the high cost of using agents for translation validation, or the heavy manual effort required by existing approaches that rely on language interoperability. TRAM demonstrates state-of-the-art performance in Java-to-Python translation, underscoring the effectiveness of its integration of RAG-based type resolution with reliable in-isolation validation."}
{"id": "2511.21994", "pdf": "https://arxiv.org/pdf/2511.21994", "abs": "https://arxiv.org/abs/2511.21994", "authors": ["Megan Zheng", "Will Crichton", "Akshay Narayan", "Deepti Raghavan", "Nikos Vasilakis"], "title": "When Are Reactive Notebooks Not Reactive?", "categories": ["cs.HC", "cs.PL", "cs.SE"], "comment": null, "summary": "Computational notebooks are convenient for programmers, but can easily become confusing and inconsistent due to the ability to incrementally edit a program that is running. Recent reactive notebook systems, such as Ipyflow, Marimo and Observable, strive to keep notebook state in sync with the current cell code by re-executing a minimal set of cells upon modification. However, each system defines reactivity a different way. Additionally, within any definition, we find simple notebook modifications that can break each system. Overall, these inconsistencies make it difficult for users to construct a mental model of their reactive notebook's implementation. This paper proposes Rex, a fine-grained test suite to discuss and assess reactivity capabilities within reactive notebook systems. We evaluate Rex on three existing reactive notebook systems and classify their failures with the aims of (i) helping programmers understand when reactivity fails and (ii) helping notebook implementations improve."}
{"id": "2511.22523", "pdf": "https://arxiv.org/pdf/2511.22523", "abs": "https://arxiv.org/abs/2511.22523", "authors": ["Jérome Ricciardi", "Sébastien Bardin", "Christophe Chareton", "Benoît Valiron"], "title": "Quantum Circuit Equivalence Checking: A Tractable Bridge From Unitary to Hybrid Circuits", "categories": ["quant-ph", "cs.PL"], "comment": "16 pages, 5 figures, 3 tables", "summary": "Equivalence checking of hybrid quantum circuits is of primary importance, given that quantum circuit transformations are omnipresent along the quantum compiler chain. While some approaches exist for automating this task, most focus on the simple case of unitary circuits. At the same time, real quantum computing requires hybrid circuits equipped with measurement operators. Moreover, the few approaches targeting the hybrid case are limited to a restricted class of problems. We propose tackling the Quantum Hybrid Circuit Equivalence Checking problem through lifting unitary circuit verification using a transformation known as deferred measurement. We show that this approach alone significantly outperforms prior work, and that, with the addition of specific unitary-level techniques we call separation and projection, it can handle much larger classes of hybrid circuit equivalence problems. We have implemented and evaluated our method over standard circuit transformations such as teleportation, one-way measurement, or the IBM Qiskit compiler, demonstrating its promises. As a side finding, we have identified and reported several unexpected behaviours with the Qiskit compiler."}
{"id": "2511.22537", "pdf": "https://arxiv.org/pdf/2511.22537", "abs": "https://arxiv.org/abs/2511.22537", "authors": ["Kinnari Dave", "Louis Lemonnier", "Romain Péchoux", "Vladimir Zamdzhiev"], "title": "A programming language combining quantum and classical control", "categories": ["cs.LO", "cs.PL", "quant-ph"], "comment": "Extended version of https://www.doi.org/10.1007/978-3-031-90897-2_8 and related to the PhD thesis at arXiv:2406.07216", "summary": "The two main notions of control in quantum programming languages are often referred to as \"quantum\" control and \"classical\" control. With the latter, the control flow is based on classical information, potentially resulting from a quantum measurement, and this paradigm is well-suited to mixed state quantum computation. Whereas with quantum control, we are primarily focused on pure quantum computation and there the \"control\" is based on superposition. The two paradigms have not mixed well traditionally and they are almost always treated separately. In this work, we show that the paradigms may be combined within the same system. The key ingredients for achieving this are: (1) syntactically: a modality for incorporating pure quantum types into a mixed state quantum type system; (2) operationally: an adaptation of the notion of \"quantum configuration\" from quantum lambda-calculi, where the quantum data is replaced with pure quantum primitives; (3) denotationally: suitable (sub)categories of Hilbert spaces, for pure computation and von Neumann algebras, for mixed state computation in the Heisenberg picture of quantum mechanics."}
