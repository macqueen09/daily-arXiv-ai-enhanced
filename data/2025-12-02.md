<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.FL](#cs.FL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [A Word Sampler for Well-Typed Functions](https://arxiv.org/abs/2512.01036)
*Breandan Considine*

Main category: cs.PL

TL;DR: 提出一种精确采样器，用于从简单类型的一阶函数式编程语言中均匀无放回地采样随机函数


<details>
  <summary>Details</summary>
Motivation: 需要一种方法从给定自动机接受的语言中均匀采样类型正确的函数，同时保持类型系统的形式化特性

Method: 通过固定参数可归约将语法导向的类型系统转换为上下文无关文法，保持类型安全性和完备性

Result: 实现了从给定自动机语言中均匀无放回采样类型正确函数的精确采样器

Conclusion: 该方法成功地将类型系统转换为形式文法，在保持类型理论鲁棒性的同时实现了精确采样

Abstract: We describe an exact sampler for a simply-typed, first-order functional programming language. Given an acyclic finite automaton, $α_{\varnothing}$, it samples a random function uniformly without replacement from well-typed functions in $\mathcal{L}(α_{\varnothing})$. This is achieved via a fixed-parameter tractable reduction from a syntax-directed type system to a context-free grammar, preserving type soundness and completeness w.r.t. $\mathcal{L}(α_{\varnothing})$, while retaining the robust metatheory of formal languages.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [2] [Faster Verified Explanations for Neural Networks](https://arxiv.org/abs/2512.00164)
*Alessandro De Palma,Greta Dolcetti,Caterina Urban*

Main category: cs.LG

TL;DR: FaVeX：一种加速计算可验证解释的新算法，通过动态批处理和序列处理以及重用先前查询信息来提高可扩展性，并提出验证器最优鲁棒解释的新定义。


<details>
  <summary>Details</summary>
Motivation: 可验证解释为神经网络决策提供理论原则性解释，但现有技术面临显著的可扩展性挑战，因为需要多次调用具有指数最坏情况复杂度的神经网络验证器。

Method: 提出FaVeX算法，通过动态结合输入特征的批处理和序列处理、重用先前查询信息（在证明特征不变性和搜索改变预测的特征分配时）来加速计算。同时提出验证器最优鲁棒解释的新层次定义，明确将验证器的不完整性纳入解释中。

Result: 综合实验评估显示FaVeX和验证器最优鲁棒解释具有优越的可扩展性，能够在具有数十万个非线性激活的网络上产生有意义的正式解释。

Conclusion: FaVeX算法和验证器最优鲁棒解释定义显著提高了可验证解释的可扩展性，使得在大型神经网络上计算正式解释变得可行。

Abstract: Verified explanations are a theoretically-principled way to explain the decisions taken by neural networks, which are otherwise black-box in nature. However, these techniques face significant scalability challenges, as they require multiple calls to neural network verifiers, each of them with an exponential worst-case complexity. We present FaVeX, a novel algorithm to compute verified explanations. FaVeX accelerates the computation by dynamically combining batch and sequential processing of input features, and by reusing information from previous queries, both when proving invariances with respect to certain input features, and when searching for feature assignments altering the prediction. Furthermore, we present a novel and hierarchical definition of verified explanations, termed verifier-optimal robust explanations, that explicitly factors the incompleteness of network verifiers within the explanation. Our comprehensive experimental evaluation demonstrates the superior scalability of both FaVeX, and of verifier-optimal robust explanations, which together can produce meaningful formal explanation on networks with hundreds of thousands of non-linear activations.

</details>


### [3] [Morphling: Fast, Fused, and Flexible GNN Training at Scale](https://arxiv.org/abs/2512.01678)
*Anubhab,Rupesh Nasre*

Main category: cs.LG

TL;DR: Morphling是一个针对图神经网络(GNN)的领域特定代码合成器，通过编译高级GNN规范为针对不同硬件后端的优化实现，显著提升训练吞吐量和内存效率。


<details>
  <summary>Details</summary>
Motivation: 现有GNN框架（如PyG和DGL）虽然注重易用性，但未能解决图神经网络中不规则、内存受限的图遍历与规则、计算密集的矩阵操作之间的执行特性差异，导致缓存局部性差、内存移动过多和中间分配过大等问题。

Method: Morphling将高级GNN规范编译为针对OpenMP、CUDA和MPI的可移植、后端专用实现，通过实例化针对每个执行环境优化的架构感知原语库，并结合运行时稀疏感知执行引擎，根据输入特征统计动态选择稠密或稀疏执行路径。

Result: 在11个真实世界数据集上的评估显示，Morphling相比PyG和DGL，在CPU上平均提升每轮训练吞吐量20倍，GPU上19倍，峰值加速达66倍。内存高效布局进一步降低峰值内存消耗达15倍，使大规模GNN训练能在普通硬件上进行。

Conclusion: 专门的架构感知代码合成为在不同并行和分布式平台上实现高性能GNN执行提供了有效且可扩展的路径。

Abstract: Graph Neural Networks (GNNs) present a fundamental hardware challenge by fusing irregular, memory-bound graph traversals with regular, compute-intensive dense matrix operations. While frameworks such as PyTorch Geometric (PyG) and Deep Graph Library (DGL) prioritize high-level usability, they fail to address these divergent execution characteristics. As a result, they rely on generic kernels that suffer from poor cache locality, excessive memory movement, and substantial intermediate allocations. To address these limitations, we present Morphling, a domain-specific code synthesizer designed to bridge this gap. Morphling compiles high-level GNN specifications into portable, backend-specialized implementations targeting OpenMP, CUDA, and MPI. It achieves this by instantiating a library of optimized, architecture-aware primitives tailored to each execution environment. Morphling also incorporates a runtime sparsity-aware execution engine that dynamically selects dense or sparse execution paths using input feature statistics, reducing unnecessary computation on zero-valued entries. We evaluate Morphling on eleven real-world datasets spanning diverse graph structures, feature dimensionalities, and sparsity regimes. The results show that Morphling improves per-epoch training throughput by an average of 20X on CPUs and 19X on GPUs over PyG and DGL, with peak speedups reaching 66X. Morphling's memory-efficient layouts further reduce peak memory consumption by up to 15X, enabling large-scale GNN training on commodity hardware. These findings demonstrate that specialized, architecture-aware code synthesis provides an effective and scalable path toward high-performance GNN execution across diverse parallel and distributed platforms.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [4] [Partial Cross-Compilation and Mixed Execution for Accelerating Dynamic Binary Translation](https://arxiv.org/abs/2512.00487)
*Yuhao Gu,Zhongchun Zheng,Nong Xiao,Yutong Lu,Xianwei Zhang*

Main category: cs.AR

TL;DR: 提出混合执行系统，结合编译与仿真，通过选择性函数卸载机制减少动态二进制翻译开销，实现最高13倍加速


<details>
  <summary>Details</summary>
Motivation: 随着指令集架构多样化，跨ISA程序执行变得普遍。动态二进制翻译性能差，跨编译虽避免仿真成本但受限于"全有或全无"模式，完全跨编译常不可行，导致程序仍有高仿真开销

Method: 提出混合执行系统，结合编译与仿真，采用选择性函数卸载机制，建立跨环境调用通道，将符合条件的函数卸载到主机进行原生执行以减少DBT开销。关键优化解决卸载成本，实现高效混合操作。基于LLVM和QEMU构建，自动适用于应用程序和库

Result: 评估显示系统相比现有DBT实现最高13倍加速，具有强大实用价值

Conclusion: 混合执行系统有效解决了跨ISA程序执行中的性能瓶颈，通过选择性函数卸载机制在编译与仿真间取得平衡，显著提升执行效率

Abstract: With the growing diversity of instruction set architectures (ISAs), cross-ISA program execution has become common. Dynamic binary translation (DBT) is the main solution but suffers from poor performance. Cross-compilation avoids emulation costs but is constrained by an "all-or-nothing" model-programs are either fully cross-compiled or entirely emulated. Complete cross-compilation is often unfeasible due to ISA-specific code or missing dependencies, leaving programs with high emulation overhead.
  We propose a hybrid execution system that combines compilation and emulation, featuring a selective function offloading mechanism. This mechanism establishes cross-environment calling channels, offloading eligible functions to the host for native execution to reduce DBT overhead. Key optimizations address offloading costs, enabling efficient hybrid operation. Built on LLVM and QEMU, the system works automatically for both applications and libraries. Evaluations show it achieves up to 13x speedups over existing DBT, with strong practical value.

</details>


<div id='cs.FL'></div>

# cs.FL [[Back]](#toc)

### [5] [Counting and Sampling Traces in Regular Languages](https://arxiv.org/abs/2512.00314)
*Alexis de Colnet,Kuldeep S. Meel,Umang Mathur*

Main category: cs.FL

TL;DR: 本文研究计算和采样与正则语言相交的Mazurkiewicz迹的数量问题，针对并发程序验证中的有界模型检测和部分序约简应用，提出了近似计数和近似均匀采样的高效算法。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机源于并发程序验证中的两个实际问题：1) 在有界模型检测中使用部分序约简时，需要预先估计约简后的状态空间大小；2) 测试并发程序时需要使用部分序感知的随机探索方法。这些问题都需要计算和采样与正则语言相交的Mazurkiewicz迹。

Method: 首先证明了计数问题即使在确定性自动机情况下也是#P-难的，然后证明了该问题对NFA和DFA都属于#P类。主要算法贡献包括：1) 完全多项式时间随机近似方案(FPRAS)，能以高概率在指定精度内近似计算所需数量；2) 完全多项式时间近似均匀采样器(FPAUS)，能生成分布接近均匀的迹。

Result: 研究结果表明：1) 计数问题对DFA是#P-难的，这与DFA单词计数问题（多项式时间可解）形成鲜明对比；2) 该问题对NFA和DFA都属于#P类；3) 成功设计了FPRAS和FPAUS算法，为并发程序验证提供了实用的近似计数和采样工具。

Conclusion: 本文为并发程序验证中的关键问题提供了理论分析和实用算法，证明了Mazurkiewicz迹计数问题的计算复杂性，并开发了高效的近似计数和采样方法，为有界模型检测和并发程序测试提供了重要工具。

Abstract: In this work, we study the problems of counting and sampling Mazurkiewicz traces that a regular language touches. Fix an alphabet $Σ$ and an independence relation $\mathbb{I} \subseteq Σ\times Σ$. The input consists of a regular language $L \subseteq Σ^*$, given by a finite automaton with $m$ states, and a natural number $n$ (in unary). For the counting problem, the goal is to compute the number of Mazurkiewicz traces (induced by $\mathbb{I}$) that intersect the $n^\text{th}$ slice $L_n = L \cap Σ^n$, i.e., traces that admit at least one linearization in $L_n$. For the sampling problem, the goal is to output a trace drawn from a distribution that is approximately uniform over all such traces. These tasks are motivated by bounded model checking with partial-order reduction, where an \emph{a priori} estimate of the reduced state space is valuable, and by testing methods for concurrent programs that use partial-order-aware random exploration.
  We first show that the counting problem is #P-hard even when $L$ is accepted by a deterministic automaton, in sharp contrast to counting words of a DFA, which is polynomial-time solvable. We then prove that the problem lies in #P for both NFAs and DFAs, irrespective of whether $L$ is trace-closed. Our main algorithmic contributions are a \emph{fully polynomial-time randomized approximation scheme} (FPRAS) that, with high probability, approximates the desired count within a prescribed accuracy, and a \emph{fully polynomial-time almost uniform sampler} (FPAUS) that generates traces whose distribution is provably close to uniform.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [6] [Generating Verifiable CoT from Execution-Traces](https://arxiv.org/abs/2512.00127)
*Shailja Thakur,Vaibhav Saxena,Rohan Kulkarni,Shivdeep Singh,Parameswaran Selvam,Hima Patel,Hiroshi Kanayama*

Main category: cs.SE

TL;DR: 该论文提出了一种基于程序执行轨迹的代码推理方法，通过捕获代码的动态行为并转化为自然语言推理步骤，确保推理过程与代码实际执行一致，从而消除逻辑幻觉。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在代码推理任务中使用的合成训练数据存在严重缺陷：推理步骤通常是教师模型生成的看似合理但未经验证的解释，而非代码实际执行的准确描述，导致模型学习到表面合理但逻辑错误的推理模式。

Method: 通过代码插桩技术捕获程序的动态执行轨迹，然后将这些经过验证的执行轨迹转化为自然语言推理步骤，构建双向（前向和后向）轨迹基础的数据集，确保每个推理步骤都反映程序的实际计算过程。

Result: 在代码推理任务（CruxEval和LiveCodeBench-Exec的前向推理，CruxEval-Input的后向推理）以及HumanEval的代码生成和解释任务上，使用该方法训练的模型取得了显著改进：输出预测提升高达30分，输入预测提升28分，同时代码生成和解释能力也得到改善。

Conclusion: 基于可验证执行轨迹的推理方法能够从根本上提升语言模型在代码相关任务上的能力，通过确保推理步骤与代码实际执行一致，有效消除了逻辑幻觉问题。

Abstract: Teaching language models to reason about code execution remains a fundamental challenge. While Chain-of-Thought (CoT) prompting has shown promise, current synthetic training data suffers from a critical weakness: the reasoning steps are often plausible-sounding explanations generated by teacher models, not verifiable accounts of what the code actually does. This creates a troubling failure mode where models learn to mimic superficially convincing but logically flawed reasoning patterns.
  We address this by grounding CoT generation directly in program execution traces. Our pipeline instruments code to capture its dynamic behavior, then narrates these verified execution traces into natural language rationales that are correct by construction. This execution-grounded approach ensures every reasoning step reflects what the program genuinely computes, eliminating logical hallucinations at the source. We evaluate our method on code reasoning tasks (forward reasoning on CruxEval and LiveCodeBench-Exec, backward reasoning on CruxEval-Input), as well as code generation and explanation tasks from HumanEval. Models trained on our bi-directional trace-grounded data achieve substantial improvements, with gains of up to 30 points on output prediction and 28 points on input prediction over base models, alongside improved explanation and code generation, demonstrating that verifiable reasoning fundamentally enhances model capabilities. https://github.ibm.com/IBM-Research-AI/Verified-Code-CoT

</details>
