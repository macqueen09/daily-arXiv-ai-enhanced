{"id": "2512.01036", "pdf": "https://arxiv.org/pdf/2512.01036", "abs": "https://arxiv.org/abs/2512.01036", "authors": ["Breandan Considine"], "title": "A Word Sampler for Well-Typed Functions", "categories": ["cs.PL", "cs.FL"], "comment": "2 pages", "summary": "We describe an exact sampler for a simply-typed, first-order functional programming language. Given an acyclic finite automaton, $\u03b1_{\\varnothing}$, it samples a random function uniformly without replacement from well-typed functions in $\\mathcal{L}(\u03b1_{\\varnothing})$. This is achieved via a fixed-parameter tractable reduction from a syntax-directed type system to a context-free grammar, preserving type soundness and completeness w.r.t. $\\mathcal{L}(\u03b1_{\\varnothing})$, while retaining the robust metatheory of formal languages.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7cbe\u786e\u91c7\u6837\u5668\uff0c\u7528\u4e8e\u4ece\u7b80\u5355\u7c7b\u578b\u7684\u4e00\u9636\u51fd\u6570\u5f0f\u7f16\u7a0b\u8bed\u8a00\u4e2d\u5747\u5300\u65e0\u653e\u56de\u5730\u91c7\u6837\u968f\u673a\u51fd\u6570", "motivation": "\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u4ece\u7ed9\u5b9a\u81ea\u52a8\u673a\u63a5\u53d7\u7684\u8bed\u8a00\u4e2d\u5747\u5300\u91c7\u6837\u7c7b\u578b\u6b63\u786e\u7684\u51fd\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u7c7b\u578b\u7cfb\u7edf\u7684\u5f62\u5f0f\u5316\u7279\u6027", "method": "\u901a\u8fc7\u56fa\u5b9a\u53c2\u6570\u53ef\u5f52\u7ea6\u5c06\u8bed\u6cd5\u5bfc\u5411\u7684\u7c7b\u578b\u7cfb\u7edf\u8f6c\u6362\u4e3a\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\uff0c\u4fdd\u6301\u7c7b\u578b\u5b89\u5168\u6027\u548c\u5b8c\u5907\u6027", "result": "\u5b9e\u73b0\u4e86\u4ece\u7ed9\u5b9a\u81ea\u52a8\u673a\u8bed\u8a00\u4e2d\u5747\u5300\u65e0\u653e\u56de\u91c7\u6837\u7c7b\u578b\u6b63\u786e\u51fd\u6570\u7684\u7cbe\u786e\u91c7\u6837\u5668", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u7c7b\u578b\u7cfb\u7edf\u8f6c\u6362\u4e3a\u5f62\u5f0f\u6587\u6cd5\uff0c\u5728\u4fdd\u6301\u7c7b\u578b\u7406\u8bba\u9c81\u68d2\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u7cbe\u786e\u91c7\u6837"}}
{"id": "2512.00127", "pdf": "https://arxiv.org/pdf/2512.00127", "abs": "https://arxiv.org/abs/2512.00127", "authors": ["Shailja Thakur", "Vaibhav Saxena", "Rohan Kulkarni", "Shivdeep Singh", "Parameswaran Selvam", "Hima Patel", "Hiroshi Kanayama"], "title": "Generating Verifiable CoT from Execution-Traces", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "Teaching language models to reason about code execution remains a fundamental challenge. While Chain-of-Thought (CoT) prompting has shown promise, current synthetic training data suffers from a critical weakness: the reasoning steps are often plausible-sounding explanations generated by teacher models, not verifiable accounts of what the code actually does. This creates a troubling failure mode where models learn to mimic superficially convincing but logically flawed reasoning patterns.\n  We address this by grounding CoT generation directly in program execution traces. Our pipeline instruments code to capture its dynamic behavior, then narrates these verified execution traces into natural language rationales that are correct by construction. This execution-grounded approach ensures every reasoning step reflects what the program genuinely computes, eliminating logical hallucinations at the source. We evaluate our method on code reasoning tasks (forward reasoning on CruxEval and LiveCodeBench-Exec, backward reasoning on CruxEval-Input), as well as code generation and explanation tasks from HumanEval. Models trained on our bi-directional trace-grounded data achieve substantial improvements, with gains of up to 30 points on output prediction and 28 points on input prediction over base models, alongside improved explanation and code generation, demonstrating that verifiable reasoning fundamentally enhances model capabilities. https://github.ibm.com/IBM-Research-AI/Verified-Code-CoT", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a0b\u5e8f\u6267\u884c\u8f68\u8ff9\u7684\u4ee3\u7801\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u6355\u83b7\u4ee3\u7801\u7684\u52a8\u6001\u884c\u4e3a\u5e76\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u6b65\u9aa4\uff0c\u786e\u4fdd\u63a8\u7406\u8fc7\u7a0b\u4e0e\u4ee3\u7801\u5b9e\u9645\u6267\u884c\u4e00\u81f4\uff0c\u4ece\u800c\u6d88\u9664\u903b\u8f91\u5e7b\u89c9\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u4e2d\u4f7f\u7528\u7684\u5408\u6210\u8bad\u7ec3\u6570\u636e\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff1a\u63a8\u7406\u6b65\u9aa4\u901a\u5e38\u662f\u6559\u5e08\u6a21\u578b\u751f\u6210\u7684\u770b\u4f3c\u5408\u7406\u4f46\u672a\u7ecf\u9a8c\u8bc1\u7684\u89e3\u91ca\uff0c\u800c\u975e\u4ee3\u7801\u5b9e\u9645\u6267\u884c\u7684\u51c6\u786e\u63cf\u8ff0\uff0c\u5bfc\u81f4\u6a21\u578b\u5b66\u4e60\u5230\u8868\u9762\u5408\u7406\u4f46\u903b\u8f91\u9519\u8bef\u7684\u63a8\u7406\u6a21\u5f0f\u3002", "method": "\u901a\u8fc7\u4ee3\u7801\u63d2\u6869\u6280\u672f\u6355\u83b7\u7a0b\u5e8f\u7684\u52a8\u6001\u6267\u884c\u8f68\u8ff9\uff0c\u7136\u540e\u5c06\u8fd9\u4e9b\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u6267\u884c\u8f68\u8ff9\u8f6c\u5316\u4e3a\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u6b65\u9aa4\uff0c\u6784\u5efa\u53cc\u5411\uff08\u524d\u5411\u548c\u540e\u5411\uff09\u8f68\u8ff9\u57fa\u7840\u7684\u6570\u636e\u96c6\uff0c\u786e\u4fdd\u6bcf\u4e2a\u63a8\u7406\u6b65\u9aa4\u90fd\u53cd\u6620\u7a0b\u5e8f\u7684\u5b9e\u9645\u8ba1\u7b97\u8fc7\u7a0b\u3002", "result": "\u5728\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\uff08CruxEval\u548cLiveCodeBench-Exec\u7684\u524d\u5411\u63a8\u7406\uff0cCruxEval-Input\u7684\u540e\u5411\u63a8\u7406\uff09\u4ee5\u53caHumanEval\u7684\u4ee3\u7801\u751f\u6210\u548c\u89e3\u91ca\u4efb\u52a1\u4e0a\uff0c\u4f7f\u7528\u8be5\u65b9\u6cd5\u8bad\u7ec3\u7684\u6a21\u578b\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\uff1a\u8f93\u51fa\u9884\u6d4b\u63d0\u5347\u9ad8\u8fbe30\u5206\uff0c\u8f93\u5165\u9884\u6d4b\u63d0\u534728\u5206\uff0c\u540c\u65f6\u4ee3\u7801\u751f\u6210\u548c\u89e3\u91ca\u80fd\u529b\u4e5f\u5f97\u5230\u6539\u5584\u3002", "conclusion": "\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u6267\u884c\u8f68\u8ff9\u7684\u63a8\u7406\u65b9\u6cd5\u80fd\u591f\u4ece\u6839\u672c\u4e0a\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\uff0c\u901a\u8fc7\u786e\u4fdd\u63a8\u7406\u6b65\u9aa4\u4e0e\u4ee3\u7801\u5b9e\u9645\u6267\u884c\u4e00\u81f4\uff0c\u6709\u6548\u6d88\u9664\u4e86\u903b\u8f91\u5e7b\u89c9\u95ee\u9898\u3002"}}
{"id": "2512.00164", "pdf": "https://arxiv.org/pdf/2512.00164", "abs": "https://arxiv.org/abs/2512.00164", "authors": ["Alessandro De Palma", "Greta Dolcetti", "Caterina Urban"], "title": "Faster Verified Explanations for Neural Networks", "categories": ["cs.LG", "cs.PL"], "comment": null, "summary": "Verified explanations are a theoretically-principled way to explain the decisions taken by neural networks, which are otherwise black-box in nature. However, these techniques face significant scalability challenges, as they require multiple calls to neural network verifiers, each of them with an exponential worst-case complexity. We present FaVeX, a novel algorithm to compute verified explanations. FaVeX accelerates the computation by dynamically combining batch and sequential processing of input features, and by reusing information from previous queries, both when proving invariances with respect to certain input features, and when searching for feature assignments altering the prediction. Furthermore, we present a novel and hierarchical definition of verified explanations, termed verifier-optimal robust explanations, that explicitly factors the incompleteness of network verifiers within the explanation. Our comprehensive experimental evaluation demonstrates the superior scalability of both FaVeX, and of verifier-optimal robust explanations, which together can produce meaningful formal explanation on networks with hundreds of thousands of non-linear activations.", "AI": {"tldr": "FaVeX\uff1a\u4e00\u79cd\u52a0\u901f\u8ba1\u7b97\u53ef\u9a8c\u8bc1\u89e3\u91ca\u7684\u65b0\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u6279\u5904\u7406\u548c\u5e8f\u5217\u5904\u7406\u4ee5\u53ca\u91cd\u7528\u5148\u524d\u67e5\u8be2\u4fe1\u606f\u6765\u63d0\u9ad8\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u63d0\u51fa\u9a8c\u8bc1\u5668\u6700\u4f18\u9c81\u68d2\u89e3\u91ca\u7684\u65b0\u5b9a\u4e49\u3002", "motivation": "\u53ef\u9a8c\u8bc1\u89e3\u91ca\u4e3a\u795e\u7ecf\u7f51\u7edc\u51b3\u7b56\u63d0\u4f9b\u7406\u8bba\u539f\u5219\u6027\u89e3\u91ca\uff0c\u4f46\u73b0\u6709\u6280\u672f\u9762\u4e34\u663e\u8457\u7684\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u56e0\u4e3a\u9700\u8981\u591a\u6b21\u8c03\u7528\u5177\u6709\u6307\u6570\u6700\u574f\u60c5\u51b5\u590d\u6742\u5ea6\u7684\u795e\u7ecf\u7f51\u7edc\u9a8c\u8bc1\u5668\u3002", "method": "\u63d0\u51faFaVeX\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u7ed3\u5408\u8f93\u5165\u7279\u5f81\u7684\u6279\u5904\u7406\u548c\u5e8f\u5217\u5904\u7406\u3001\u91cd\u7528\u5148\u524d\u67e5\u8be2\u4fe1\u606f\uff08\u5728\u8bc1\u660e\u7279\u5f81\u4e0d\u53d8\u6027\u548c\u641c\u7d22\u6539\u53d8\u9884\u6d4b\u7684\u7279\u5f81\u5206\u914d\u65f6\uff09\u6765\u52a0\u901f\u8ba1\u7b97\u3002\u540c\u65f6\u63d0\u51fa\u9a8c\u8bc1\u5668\u6700\u4f18\u9c81\u68d2\u89e3\u91ca\u7684\u65b0\u5c42\u6b21\u5b9a\u4e49\uff0c\u660e\u786e\u5c06\u9a8c\u8bc1\u5668\u7684\u4e0d\u5b8c\u6574\u6027\u7eb3\u5165\u89e3\u91ca\u4e2d\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793aFaVeX\u548c\u9a8c\u8bc1\u5668\u6700\u4f18\u9c81\u68d2\u89e3\u91ca\u5177\u6709\u4f18\u8d8a\u7684\u53ef\u6269\u5c55\u6027\uff0c\u80fd\u591f\u5728\u5177\u6709\u6570\u5341\u4e07\u4e2a\u975e\u7ebf\u6027\u6fc0\u6d3b\u7684\u7f51\u7edc\u4e0a\u4ea7\u751f\u6709\u610f\u4e49\u7684\u6b63\u5f0f\u89e3\u91ca\u3002", "conclusion": "FaVeX\u7b97\u6cd5\u548c\u9a8c\u8bc1\u5668\u6700\u4f18\u9c81\u68d2\u89e3\u91ca\u5b9a\u4e49\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u9a8c\u8bc1\u89e3\u91ca\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4f7f\u5f97\u5728\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u4e0a\u8ba1\u7b97\u6b63\u5f0f\u89e3\u91ca\u53d8\u5f97\u53ef\u884c\u3002"}}
{"id": "2512.00314", "pdf": "https://arxiv.org/pdf/2512.00314", "abs": "https://arxiv.org/abs/2512.00314", "authors": ["Alexis de Colnet", "Kuldeep S. Meel", "Umang Mathur"], "title": "Counting and Sampling Traces in Regular Languages", "categories": ["cs.FL", "cs.CC", "cs.LO", "cs.PL"], "comment": "To appear in POPL 2026. Author order is random", "summary": "In this work, we study the problems of counting and sampling Mazurkiewicz traces that a regular language touches. Fix an alphabet $\u03a3$ and an independence relation $\\mathbb{I} \\subseteq \u03a3\\times \u03a3$. The input consists of a regular language $L \\subseteq \u03a3^*$, given by a finite automaton with $m$ states, and a natural number $n$ (in unary). For the counting problem, the goal is to compute the number of Mazurkiewicz traces (induced by $\\mathbb{I}$) that intersect the $n^\\text{th}$ slice $L_n = L \\cap \u03a3^n$, i.e., traces that admit at least one linearization in $L_n$. For the sampling problem, the goal is to output a trace drawn from a distribution that is approximately uniform over all such traces. These tasks are motivated by bounded model checking with partial-order reduction, where an \\emph{a priori} estimate of the reduced state space is valuable, and by testing methods for concurrent programs that use partial-order-aware random exploration.\n  We first show that the counting problem is #P-hard even when $L$ is accepted by a deterministic automaton, in sharp contrast to counting words of a DFA, which is polynomial-time solvable. We then prove that the problem lies in #P for both NFAs and DFAs, irrespective of whether $L$ is trace-closed. Our main algorithmic contributions are a \\emph{fully polynomial-time randomized approximation scheme} (FPRAS) that, with high probability, approximates the desired count within a prescribed accuracy, and a \\emph{fully polynomial-time almost uniform sampler} (FPAUS) that generates traces whose distribution is provably close to uniform.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8ba1\u7b97\u548c\u91c7\u6837\u4e0e\u6b63\u5219\u8bed\u8a00\u76f8\u4ea4\u7684Mazurkiewicz\u8ff9\u7684\u6570\u91cf\u95ee\u9898\uff0c\u9488\u5bf9\u5e76\u53d1\u7a0b\u5e8f\u9a8c\u8bc1\u4e2d\u7684\u6709\u754c\u6a21\u578b\u68c0\u6d4b\u548c\u90e8\u5206\u5e8f\u7ea6\u7b80\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u8fd1\u4f3c\u8ba1\u6570\u548c\u8fd1\u4f3c\u5747\u5300\u91c7\u6837\u7684\u9ad8\u6548\u7b97\u6cd5\u3002", "motivation": "\u8be5\u7814\u7a76\u7684\u52a8\u673a\u6e90\u4e8e\u5e76\u53d1\u7a0b\u5e8f\u9a8c\u8bc1\u4e2d\u7684\u4e24\u4e2a\u5b9e\u9645\u95ee\u9898\uff1a1) \u5728\u6709\u754c\u6a21\u578b\u68c0\u6d4b\u4e2d\u4f7f\u7528\u90e8\u5206\u5e8f\u7ea6\u7b80\u65f6\uff0c\u9700\u8981\u9884\u5148\u4f30\u8ba1\u7ea6\u7b80\u540e\u7684\u72b6\u6001\u7a7a\u95f4\u5927\u5c0f\uff1b2) \u6d4b\u8bd5\u5e76\u53d1\u7a0b\u5e8f\u65f6\u9700\u8981\u4f7f\u7528\u90e8\u5206\u5e8f\u611f\u77e5\u7684\u968f\u673a\u63a2\u7d22\u65b9\u6cd5\u3002\u8fd9\u4e9b\u95ee\u9898\u90fd\u9700\u8981\u8ba1\u7b97\u548c\u91c7\u6837\u4e0e\u6b63\u5219\u8bed\u8a00\u76f8\u4ea4\u7684Mazurkiewicz\u8ff9\u3002", "method": "\u9996\u5148\u8bc1\u660e\u4e86\u8ba1\u6570\u95ee\u9898\u5373\u4f7f\u5728\u786e\u5b9a\u6027\u81ea\u52a8\u673a\u60c5\u51b5\u4e0b\u4e5f\u662f#P-\u96be\u7684\uff0c\u7136\u540e\u8bc1\u660e\u4e86\u8be5\u95ee\u9898\u5bf9NFA\u548cDFA\u90fd\u5c5e\u4e8e#P\u7c7b\u3002\u4e3b\u8981\u7b97\u6cd5\u8d21\u732e\u5305\u62ec\uff1a1) \u5b8c\u5168\u591a\u9879\u5f0f\u65f6\u95f4\u968f\u673a\u8fd1\u4f3c\u65b9\u6848(FPRAS)\uff0c\u80fd\u4ee5\u9ad8\u6982\u7387\u5728\u6307\u5b9a\u7cbe\u5ea6\u5185\u8fd1\u4f3c\u8ba1\u7b97\u6240\u9700\u6570\u91cf\uff1b2) \u5b8c\u5168\u591a\u9879\u5f0f\u65f6\u95f4\u8fd1\u4f3c\u5747\u5300\u91c7\u6837\u5668(FPAUS)\uff0c\u80fd\u751f\u6210\u5206\u5e03\u63a5\u8fd1\u5747\u5300\u7684\u8ff9\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff1a1) \u8ba1\u6570\u95ee\u9898\u5bf9DFA\u662f#P-\u96be\u7684\uff0c\u8fd9\u4e0eDFA\u5355\u8bcd\u8ba1\u6570\u95ee\u9898\uff08\u591a\u9879\u5f0f\u65f6\u95f4\u53ef\u89e3\uff09\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\uff1b2) \u8be5\u95ee\u9898\u5bf9NFA\u548cDFA\u90fd\u5c5e\u4e8e#P\u7c7b\uff1b3) \u6210\u529f\u8bbe\u8ba1\u4e86FPRAS\u548cFPAUS\u7b97\u6cd5\uff0c\u4e3a\u5e76\u53d1\u7a0b\u5e8f\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8fd1\u4f3c\u8ba1\u6570\u548c\u91c7\u6837\u5de5\u5177\u3002", "conclusion": "\u672c\u6587\u4e3a\u5e76\u53d1\u7a0b\u5e8f\u9a8c\u8bc1\u4e2d\u7684\u5173\u952e\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u548c\u5b9e\u7528\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86Mazurkiewicz\u8ff9\u8ba1\u6570\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u8fd1\u4f3c\u8ba1\u6570\u548c\u91c7\u6837\u65b9\u6cd5\uff0c\u4e3a\u6709\u754c\u6a21\u578b\u68c0\u6d4b\u548c\u5e76\u53d1\u7a0b\u5e8f\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2512.00487", "pdf": "https://arxiv.org/pdf/2512.00487", "abs": "https://arxiv.org/abs/2512.00487", "authors": ["Yuhao Gu", "Zhongchun Zheng", "Nong Xiao", "Yutong Lu", "Xianwei Zhang"], "title": "Partial Cross-Compilation and Mixed Execution for Accelerating Dynamic Binary Translation", "categories": ["cs.AR", "cs.PL"], "comment": null, "summary": "With the growing diversity of instruction set architectures (ISAs), cross-ISA program execution has become common. Dynamic binary translation (DBT) is the main solution but suffers from poor performance. Cross-compilation avoids emulation costs but is constrained by an \"all-or-nothing\" model-programs are either fully cross-compiled or entirely emulated. Complete cross-compilation is often unfeasible due to ISA-specific code or missing dependencies, leaving programs with high emulation overhead.\n  We propose a hybrid execution system that combines compilation and emulation, featuring a selective function offloading mechanism. This mechanism establishes cross-environment calling channels, offloading eligible functions to the host for native execution to reduce DBT overhead. Key optimizations address offloading costs, enabling efficient hybrid operation. Built on LLVM and QEMU, the system works automatically for both applications and libraries. Evaluations show it achieves up to 13x speedups over existing DBT, with strong practical value.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u6267\u884c\u7cfb\u7edf\uff0c\u7ed3\u5408\u7f16\u8bd1\u4e0e\u4eff\u771f\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u51fd\u6570\u5378\u8f7d\u673a\u5236\u51cf\u5c11\u52a8\u6001\u4e8c\u8fdb\u5236\u7ffb\u8bd1\u5f00\u9500\uff0c\u5b9e\u73b0\u6700\u9ad813\u500d\u52a0\u901f", "motivation": "\u968f\u7740\u6307\u4ee4\u96c6\u67b6\u6784\u591a\u6837\u5316\uff0c\u8de8ISA\u7a0b\u5e8f\u6267\u884c\u53d8\u5f97\u666e\u904d\u3002\u52a8\u6001\u4e8c\u8fdb\u5236\u7ffb\u8bd1\u6027\u80fd\u5dee\uff0c\u8de8\u7f16\u8bd1\u867d\u907f\u514d\u4eff\u771f\u6210\u672c\u4f46\u53d7\u9650\u4e8e\"\u5168\u6709\u6216\u5168\u65e0\"\u6a21\u5f0f\uff0c\u5b8c\u5168\u8de8\u7f16\u8bd1\u5e38\u4e0d\u53ef\u884c\uff0c\u5bfc\u81f4\u7a0b\u5e8f\u4ecd\u6709\u9ad8\u4eff\u771f\u5f00\u9500", "method": "\u63d0\u51fa\u6df7\u5408\u6267\u884c\u7cfb\u7edf\uff0c\u7ed3\u5408\u7f16\u8bd1\u4e0e\u4eff\u771f\uff0c\u91c7\u7528\u9009\u62e9\u6027\u51fd\u6570\u5378\u8f7d\u673a\u5236\uff0c\u5efa\u7acb\u8de8\u73af\u5883\u8c03\u7528\u901a\u9053\uff0c\u5c06\u7b26\u5408\u6761\u4ef6\u7684\u51fd\u6570\u5378\u8f7d\u5230\u4e3b\u673a\u8fdb\u884c\u539f\u751f\u6267\u884c\u4ee5\u51cf\u5c11DBT\u5f00\u9500\u3002\u5173\u952e\u4f18\u5316\u89e3\u51b3\u5378\u8f7d\u6210\u672c\uff0c\u5b9e\u73b0\u9ad8\u6548\u6df7\u5408\u64cd\u4f5c\u3002\u57fa\u4e8eLLVM\u548cQEMU\u6784\u5efa\uff0c\u81ea\u52a8\u9002\u7528\u4e8e\u5e94\u7528\u7a0b\u5e8f\u548c\u5e93", "result": "\u8bc4\u4f30\u663e\u793a\u7cfb\u7edf\u76f8\u6bd4\u73b0\u6709DBT\u5b9e\u73b0\u6700\u9ad813\u500d\u52a0\u901f\uff0c\u5177\u6709\u5f3a\u5927\u5b9e\u7528\u4ef7\u503c", "conclusion": "\u6df7\u5408\u6267\u884c\u7cfb\u7edf\u6709\u6548\u89e3\u51b3\u4e86\u8de8ISA\u7a0b\u5e8f\u6267\u884c\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u51fd\u6570\u5378\u8f7d\u673a\u5236\u5728\u7f16\u8bd1\u4e0e\u4eff\u771f\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u663e\u8457\u63d0\u5347\u6267\u884c\u6548\u7387"}}
{"id": "2512.01678", "pdf": "https://arxiv.org/pdf/2512.01678", "abs": "https://arxiv.org/abs/2512.01678", "authors": ["Anubhab", "Rupesh Nasre"], "title": "Morphling: Fast, Fused, and Flexible GNN Training at Scale", "categories": ["cs.LG", "cs.DC", "cs.PL"], "comment": null, "summary": "Graph Neural Networks (GNNs) present a fundamental hardware challenge by fusing irregular, memory-bound graph traversals with regular, compute-intensive dense matrix operations. While frameworks such as PyTorch Geometric (PyG) and Deep Graph Library (DGL) prioritize high-level usability, they fail to address these divergent execution characteristics. As a result, they rely on generic kernels that suffer from poor cache locality, excessive memory movement, and substantial intermediate allocations. To address these limitations, we present Morphling, a domain-specific code synthesizer designed to bridge this gap. Morphling compiles high-level GNN specifications into portable, backend-specialized implementations targeting OpenMP, CUDA, and MPI. It achieves this by instantiating a library of optimized, architecture-aware primitives tailored to each execution environment. Morphling also incorporates a runtime sparsity-aware execution engine that dynamically selects dense or sparse execution paths using input feature statistics, reducing unnecessary computation on zero-valued entries. We evaluate Morphling on eleven real-world datasets spanning diverse graph structures, feature dimensionalities, and sparsity regimes. The results show that Morphling improves per-epoch training throughput by an average of 20X on CPUs and 19X on GPUs over PyG and DGL, with peak speedups reaching 66X. Morphling's memory-efficient layouts further reduce peak memory consumption by up to 15X, enabling large-scale GNN training on commodity hardware. These findings demonstrate that specialized, architecture-aware code synthesis provides an effective and scalable path toward high-performance GNN execution across diverse parallel and distributed platforms.", "AI": {"tldr": "Morphling\u662f\u4e00\u4e2a\u9488\u5bf9\u56fe\u795e\u7ecf\u7f51\u7edc(GNN)\u7684\u9886\u57df\u7279\u5b9a\u4ee3\u7801\u5408\u6210\u5668\uff0c\u901a\u8fc7\u7f16\u8bd1\u9ad8\u7ea7GNN\u89c4\u8303\u4e3a\u9488\u5bf9\u4e0d\u540c\u786c\u4ef6\u540e\u7aef\u7684\u4f18\u5316\u5b9e\u73b0\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u541e\u5410\u91cf\u548c\u5185\u5b58\u6548\u7387\u3002", "motivation": "\u73b0\u6709GNN\u6846\u67b6\uff08\u5982PyG\u548cDGL\uff09\u867d\u7136\u6ce8\u91cd\u6613\u7528\u6027\uff0c\u4f46\u672a\u80fd\u89e3\u51b3\u56fe\u795e\u7ecf\u7f51\u7edc\u4e2d\u4e0d\u89c4\u5219\u3001\u5185\u5b58\u53d7\u9650\u7684\u56fe\u904d\u5386\u4e0e\u89c4\u5219\u3001\u8ba1\u7b97\u5bc6\u96c6\u7684\u77e9\u9635\u64cd\u4f5c\u4e4b\u95f4\u7684\u6267\u884c\u7279\u6027\u5dee\u5f02\uff0c\u5bfc\u81f4\u7f13\u5b58\u5c40\u90e8\u6027\u5dee\u3001\u5185\u5b58\u79fb\u52a8\u8fc7\u591a\u548c\u4e2d\u95f4\u5206\u914d\u8fc7\u5927\u7b49\u95ee\u9898\u3002", "method": "Morphling\u5c06\u9ad8\u7ea7GNN\u89c4\u8303\u7f16\u8bd1\u4e3a\u9488\u5bf9OpenMP\u3001CUDA\u548cMPI\u7684\u53ef\u79fb\u690d\u3001\u540e\u7aef\u4e13\u7528\u5b9e\u73b0\uff0c\u901a\u8fc7\u5b9e\u4f8b\u5316\u9488\u5bf9\u6bcf\u4e2a\u6267\u884c\u73af\u5883\u4f18\u5316\u7684\u67b6\u6784\u611f\u77e5\u539f\u8bed\u5e93\uff0c\u5e76\u7ed3\u5408\u8fd0\u884c\u65f6\u7a00\u758f\u611f\u77e5\u6267\u884c\u5f15\u64ce\uff0c\u6839\u636e\u8f93\u5165\u7279\u5f81\u7edf\u8ba1\u52a8\u6001\u9009\u62e9\u7a20\u5bc6\u6216\u7a00\u758f\u6267\u884c\u8def\u5f84\u3002", "result": "\u572811\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cMorphling\u76f8\u6bd4PyG\u548cDGL\uff0c\u5728CPU\u4e0a\u5e73\u5747\u63d0\u5347\u6bcf\u8f6e\u8bad\u7ec3\u541e\u5410\u91cf20\u500d\uff0cGPU\u4e0a19\u500d\uff0c\u5cf0\u503c\u52a0\u901f\u8fbe66\u500d\u3002\u5185\u5b58\u9ad8\u6548\u5e03\u5c40\u8fdb\u4e00\u6b65\u964d\u4f4e\u5cf0\u503c\u5185\u5b58\u6d88\u8017\u8fbe15\u500d\uff0c\u4f7f\u5927\u89c4\u6a21GNN\u8bad\u7ec3\u80fd\u5728\u666e\u901a\u786c\u4ef6\u4e0a\u8fdb\u884c\u3002", "conclusion": "\u4e13\u95e8\u7684\u67b6\u6784\u611f\u77e5\u4ee3\u7801\u5408\u6210\u4e3a\u5728\u4e0d\u540c\u5e76\u884c\u548c\u5206\u5e03\u5f0f\u5e73\u53f0\u4e0a\u5b9e\u73b0\u9ad8\u6027\u80fdGNN\u6267\u884c\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
