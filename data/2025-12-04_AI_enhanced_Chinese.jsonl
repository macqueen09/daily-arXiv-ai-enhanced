{"id": "2512.03083", "pdf": "https://arxiv.org/pdf/2512.03083", "abs": "https://arxiv.org/abs/2512.03083", "authors": ["ZeHao Yu"], "title": "Evaluate the Stack Management in Effect Handlers using the libseff C Library", "categories": ["cs.PL", "cs.SE"], "comment": null, "summary": "Effect handlers are increasingly prominent in modern programming for managing complex computational effects, including concurrency, asynchronous operations, and exception handling, in a modular and flexible manner. Efficient stack management remains a significant challenge for effect handlers due to the dynamic control flow changes they introduce. This paper explores a novel stack management approach using user-level overcommitting within the libseff C library, which leverages virtual memory mechanisms and protection-based lazy allocation combined with signal-driven memory commitment. Our user-level overcommitting implementation dynamically resizes stacks on-demand, improving memory utilization and reducing waste compared to traditional methods. We rigorously benchmark and evaluate this novel strategy against conventional fixed- size stacks, segmented stacks, and kernel-based overcommitting, using metrics such as context-switch latency, stack expansion efficiency, multi-threaded performance, and robustness under rapid stack growth conditions. Experimental results demonstrate that kernel-based overcommitting achieves an effective balance between performance and flexibility, whereas our user-level implementation, while flexible, incurs additional overheads, highlighting areas for optimization. This study provides a detailed comparative analysis of various stack management strate- gies, offering practical recommendations tailored to specific application requirements and operational constraints. Future work will focus on refining user-level overcommit- ting mechanisms, mitigating non-deterministic behaviors, and expanding benchmark frameworks to include real-world scenarios.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5728libseff C\u5e93\u4e2d\u4f7f\u7528\u7528\u6237\u7ea7\u8d85\u989d\u63d0\u4ea4\u8fdb\u884c\u6808\u7ba1\u7406\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u865a\u62df\u5185\u5b58\u673a\u5236\u548c\u57fa\u4e8e\u4fdd\u62a4\u7684\u5ef6\u8fdf\u5206\u914d\u7ed3\u5408\u4fe1\u53f7\u9a71\u52a8\u7684\u5185\u5b58\u63d0\u4ea4\uff0c\u52a8\u6001\u8c03\u6574\u6808\u5927\u5c0f\u4ee5\u63d0\u9ad8\u5185\u5b58\u5229\u7528\u7387\u3002", "motivation": "\u6548\u5e94\u5904\u7406\u5668\u5728\u73b0\u4ee3\u7f16\u7a0b\u4e2d\u65e5\u76ca\u91cd\u8981\uff0c\u7528\u4e8e\u7ba1\u7406\u5e76\u53d1\u3001\u5f02\u6b65\u64cd\u4f5c\u548c\u5f02\u5e38\u5904\u7406\u7b49\u590d\u6742\u8ba1\u7b97\u6548\u5e94\uff0c\u4f46\u5176\u5f15\u5165\u7684\u52a8\u6001\u63a7\u5236\u6d41\u53d8\u5316\u4f7f\u5f97\u9ad8\u6548\u7684\u6808\u7ba1\u7406\u6210\u4e3a\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7528\u6237\u7ea7\u8d85\u989d\u63d0\u4ea4\u7684\u6808\u7ba1\u7406\u65b9\u6cd5\uff0c\u5728libseff C\u5e93\u4e2d\u5b9e\u73b0\uff0c\u5229\u7528\u865a\u62df\u5185\u5b58\u673a\u5236\u548c\u57fa\u4e8e\u4fdd\u62a4\u7684\u5ef6\u8fdf\u5206\u914d\uff0c\u7ed3\u5408\u4fe1\u53f7\u9a71\u52a8\u7684\u5185\u5b58\u63d0\u4ea4\uff0c\u52a8\u6001\u6309\u9700\u8c03\u6574\u6808\u5927\u5c0f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5185\u6838\u7ea7\u8d85\u989d\u63d0\u4ea4\u5728\u6027\u80fd\u548c\u7075\u6d3b\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u6709\u6548\u5e73\u8861\uff0c\u800c\u7528\u6237\u7ea7\u5b9e\u73b0\u867d\u7136\u7075\u6d3b\u4f46\u5e26\u6765\u4e86\u989d\u5916\u5f00\u9500\uff0c\u7a81\u663e\u4e86\u4f18\u5316\u7a7a\u95f4\u3002\u7814\u7a76\u5bf9\u5404\u79cd\u6808\u7ba1\u7406\u7b56\u7565\u8fdb\u884c\u4e86\u8be6\u7ec6\u6bd4\u8f83\u5206\u6790\u3002", "conclusion": "\u7814\u7a76\u4e3a\u7279\u5b9a\u5e94\u7528\u9700\u6c42\u548c\u64cd\u4f5c\u7ea6\u675f\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6808\u7ba1\u7406\u7b56\u7565\u5efa\u8bae\u3002\u672a\u6765\u5de5\u4f5c\u5c06\u4e13\u6ce8\u4e8e\u6539\u8fdb\u7528\u6237\u7ea7\u8d85\u989d\u63d0\u4ea4\u673a\u5236\uff0c\u51cf\u8f7b\u975e\u786e\u5b9a\u6027\u884c\u4e3a\uff0c\u5e76\u6269\u5c55\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u4ee5\u5305\u542b\u771f\u5b9e\u573a\u666f\u3002"}}
{"id": "2512.03086", "pdf": "https://arxiv.org/pdf/2512.03086", "abs": "https://arxiv.org/abs/2512.03086", "authors": ["Le Chen", "Nuo Xu", "Winson Chen", "Bin Lei", "Pei-Hung Lin", "Dunzhi Zhou", "Rajeev Thakur", "Caiwen Ding", "Ali Jannesari", "Chunhua Liao"], "title": "Beyond Code Pairs: Dialogue-Based Data Generation for LLM Code Translation", "categories": ["cs.PL", "cs.AI", "cs.SE"], "comment": null, "summary": "Large language models (LLMs) have shown remarkable capabilities in code translation, yet their performance deteriorates in low-resource programming domains such as Fortran and emerging frameworks like CUDA, where high-quality parallel data are scarce. We present an automated dataset generation pipeline featuring a dual-LLM Questioner-Solver design that incorporates external knowledge from compilers and runtime feedback. Beyond traditional source-target code pair datasets, our approach additionally generates (1) verified translations with unit tests for assessing functional consistency, and (2) multi-turn dialogues that capture the reasoning process behind translation refinement. Applied to Fortran -> C++ and C++ -> CUDA, the pipeline yields 3.64k and 3.93k dialogues, respectively. Fine-tuning on this data yields dramatic improvements in functional correctness, boosting unit test success rates by over 56% on the challenging C++-to-CUDA task. We show this data enables a 7B open-weight model to significantly outperform larger proprietary systems on key metrics like compilation success.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u52a8\u5316\u6570\u636e\u96c6\u751f\u6210\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u53ccLLM\u95ee\u7b54\u8bbe\u8ba1\u7ed3\u5408\u7f16\u8bd1\u5668\u53cd\u9988\uff0c\u4e3a\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u7ffb\u8bd1\uff08\u5982Fortran\u2192C++\u3001C++\u2192CUDA\uff09\u751f\u6210\u5e26\u5355\u5143\u6d4b\u8bd5\u9a8c\u8bc1\u548c\u591a\u8f6e\u5bf9\u8bdd\u7684\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u5347\u7ffb\u8bd1\u529f\u80fd\u6b63\u786e\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7ffb\u8bd1\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728Fortran\u3001CUDA\u7b49\u4f4e\u8d44\u6e90\u7f16\u7a0b\u9886\u57df\u6027\u80fd\u4e0b\u964d\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u9ad8\u8d28\u91cf\u5e76\u884c\u6570\u636e\u7a00\u7f3a\u3002\u9700\u8981\u89e3\u51b3\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u7ffb\u8bd1\u7684\u6570\u636e\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u81ea\u52a8\u5316\u6570\u636e\u96c6\u751f\u6210\u6d41\u6c34\u7ebf\uff0c\u91c7\u7528\u53ccLLM\u95ee\u7b54\u8005-\u89e3\u51b3\u8005\u67b6\u6784\uff0c\u7ed3\u5408\u7f16\u8bd1\u5668\u548c\u8fd0\u884c\u65f6\u53cd\u9988\u3002\u9664\u4e86\u4f20\u7edf\u6e90-\u76ee\u6807\u4ee3\u7801\u5bf9\uff0c\u8fd8\u751f\u6210\uff1a(1)\u5e26\u5355\u5143\u6d4b\u8bd5\u7684\u9a8c\u8bc1\u7ffb\u8bd1\u4ee5\u786e\u4fdd\u529f\u80fd\u4e00\u81f4\u6027\uff1b(2)\u591a\u8f6e\u5bf9\u8bdd\u6355\u6349\u7ffb\u8bd1\u7cbe\u70bc\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u5e94\u7528\u4e8eFortran\u2192C++\u548cC++\u2192CUDA\u7ffb\u8bd1\u3002", "result": "\u751f\u62103.64k\u4e2aFortran\u2192C++\u5bf9\u8bdd\u548c3.93k\u4e2aC++\u2192CUDA\u5bf9\u8bdd\u3002\u5fae\u8c03\u540e\u529f\u80fd\u6b63\u786e\u6027\u663e\u8457\u63d0\u5347\uff0c\u5728C++\u2192CUDA\u4efb\u52a1\u4e2d\u5355\u5143\u6d4b\u8bd5\u6210\u529f\u7387\u63d0\u9ad8\u8d85\u8fc756%\u30027B\u5f00\u6e90\u6a21\u578b\u5728\u7f16\u8bd1\u6210\u529f\u7387\u7b49\u5173\u952e\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u66f4\u5927\u7684\u4e13\u6709\u7cfb\u7edf\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u52a8\u5316\u6570\u636e\u96c6\u751f\u6210\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u7ffb\u8bd1\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u901a\u8fc7\u751f\u6210\u5e26\u9a8c\u8bc1\u548c\u591a\u8f6e\u63a8\u7406\u7684\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ffb\u8bd1\u6a21\u578b\u7684\u529f\u80fd\u6b63\u786e\u6027\u548c\u7f16\u8bd1\u6210\u529f\u7387\uff0c\u4f7f\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u80fd\u591f\u8d85\u8d8a\u5927\u578b\u4e13\u6709\u7cfb\u7edf\u3002"}}
{"id": "2512.03972", "pdf": "https://arxiv.org/pdf/2512.03972", "abs": "https://arxiv.org/abs/2512.03972", "authors": ["Hassan Arafat", "David Bremner", "Kenneth B. Kent", "Julian Wang"], "title": "OOPredictor: Predicting Object-Oriented Accesses using Static Analysis", "categories": ["cs.PL"], "comment": null, "summary": "Object-oriented Programming has become one of the most dominant design paradigms as the separation of concerns and adaptability of design reduce development and maintenance costs. However, the convenience is not without cost. The added indirection inherent in such designs causes excessive pointer chasing, negatively affecting locality, which in turn degrades the performance of cache structures. Furthermore, modern hardware prefetchers are mostly stride prefetchers that are ill-equipped to handle the unpredictability of access patterns generated by pointer chasing. Most software approaches that seek to address this problem resort to profiling the program as it runs, which comes with a significant run-time overhead or requires data from previous runs. In this paper, we propose the use of compile-time static analysis to predict the most common access patterns displayed by a program during run time. Since Java is one of the most popular object-oriented languages, we implement our prototype within the OpenJ9 JVM, inside the OMR optimizer infrastructure. The outputs of our proposed predictor are Markov chains that model the expected behavior of the program. The effectiveness of the proposed predictor is evaluated by comparing the model with the actual run-time behavior of the program measured using an instrumented interpreter. Our experiments show that the proposed predictor exhibits good accuracy and can be used to inform minimally intrusive load stall mitigation strategies, e.g. informing copying GCs on more locality-friendly copying orders", "AI": {"tldr": "\u4f7f\u7528\u7f16\u8bd1\u65f6\u9759\u6001\u5206\u6790\u9884\u6d4bJava\u7a0b\u5e8f\u8fd0\u884c\u65f6\u8bbf\u95ee\u6a21\u5f0f\uff0c\u901a\u8fc7\u9a6c\u5c14\u53ef\u592b\u94fe\u5efa\u6a21\u7a0b\u5e8f\u884c\u4e3a\uff0c\u6307\u5bfc\u5783\u573e\u56de\u6536\u5668\u4f18\u5316\u5185\u5b58\u5e03\u5c40\u4ee5\u6539\u5584\u7f13\u5b58\u6027\u80fd", "motivation": "\u9762\u5411\u5bf9\u8c61\u7f16\u7a0b\u4e2d\u7684\u6307\u9488\u8ffd\u9010\u5bfc\u81f4\u7f13\u5b58\u5c40\u90e8\u6027\u5dee\uff0c\u73b0\u4ee3\u786c\u4ef6\u9884\u53d6\u5668\u96be\u4ee5\u5904\u7406\u8fd9\u79cd\u4e0d\u53ef\u9884\u6d4b\u7684\u8bbf\u95ee\u6a21\u5f0f\uff0c\u73b0\u6709\u8f6f\u4ef6\u65b9\u6cd5\u9700\u8981\u8fd0\u884c\u65f6\u5206\u6790\u5e26\u6765\u663e\u8457\u5f00\u9500", "method": "\u5728OpenJ9 JVM\u7684OMR\u4f18\u5316\u5668\u57fa\u7840\u8bbe\u65bd\u4e2d\u5b9e\u73b0\u7f16\u8bd1\u65f6\u9759\u6001\u5206\u6790\u5668\uff0c\u9884\u6d4b\u7a0b\u5e8f\u6700\u5e38\u89c1\u7684\u8bbf\u95ee\u6a21\u5f0f\uff0c\u8f93\u51fa\u9a6c\u5c14\u53ef\u592b\u94fe\u6a21\u578b\u7a0b\u5e8f\u9884\u671f\u884c\u4e3a", "result": "\u9884\u6d4b\u5668\u8868\u73b0\u51fa\u826f\u597d\u51c6\u786e\u6027\uff0c\u53ef\u901a\u8fc7\u4e0e\u63d2\u6869\u89e3\u91ca\u5668\u6d4b\u91cf\u7684\u5b9e\u9645\u8fd0\u884c\u65f6\u884c\u4e3a\u5bf9\u6bd4\u9a8c\u8bc1\uff0c\u53ef\u7528\u4e8e\u6307\u5bfc\u6700\u5c0f\u4fb5\u5165\u6027\u7684\u8d1f\u8f7d\u505c\u987f\u7f13\u89e3\u7b56\u7565", "conclusion": "\u9759\u6001\u5206\u6790\u9884\u6d4b\u5668\u80fd\u6709\u6548\u5efa\u6a21\u7a0b\u5e8f\u8bbf\u95ee\u6a21\u5f0f\uff0c\u4e3a\u5783\u573e\u56de\u6536\u5668\u63d0\u4f9b\u66f4\u53cb\u597d\u7684\u5c40\u90e8\u6027\u590d\u5236\u987a\u5e8f\uff0c\u6539\u5584\u9762\u5411\u5bf9\u8c61\u7a0b\u5e8f\u7684\u7f13\u5b58\u6027\u80fd"}}
