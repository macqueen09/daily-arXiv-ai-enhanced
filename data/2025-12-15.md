<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.LO](#cs.LO) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [The Relative Monadic Metalanguage](https://arxiv.org/abs/2512.11762)
*Jack Liell-Cock,Zev Shirazi,Sam Staton*

Main category: cs.PL

TL;DR: 将相对单子理论扩展到编程语言设计，提出了两种新的程序演算：用于分级单子的线性-非线性语言LNL-RMM，以及用于箭头的计算λ演算风格语言ARMM


<details>
  <summary>Details</summary>
Motivation: 相对单子为计算提供了受控的视角，但需要将其扩展到编程语言层面。现有文献中的程序演算需要进一步泛化和完善，特别是分级单子和箭头的语义需要更完整的理论基础

Method: 1. 将单子元语言泛化到相对设置，提供强相对单子的完整语义；2. 提出LNL-RMM语言用于分级单子，证明它是分级单子元语言的保守扩展；3. 证明箭头演算是受限的相对单子元语言，并引入ARMM语言作为箭头演算的保守扩展

Result: 1. 建立了相对单子元语言的完整语义框架；2. LNL-RMM成功扩展了分级单子元语言；3. ARMM为箭头计算提供了更完整的λ演算风格语言，保守扩展了箭头演算

Conclusion: 相对单子理论为程序语言设计提供了统一框架，能够泛化现有的程序演算。LNL-RMM和ARMM展示了相对单子视角在语言设计中的实用性，为分级单子和箭头计算提供了更完整的理论基础

Abstract: Relative monads provide a controlled view of computation. We generalise the monadic metalanguage to a relative setting and give a complete semantics with strong relative monads. Adopting this perspective, we generalise two existing program calculi from the literature. We provide a linear-non-linear language for graded monads, LNL-RMM, along with a semantic proof that it is a conservative extension of the graded monadic metalanguage. Additionally, we provide a complete semantics for the arrow calculus, showing it is a restricted relative monadic metalanguage. This motivates the introduction of ARMM, a computational lambda calculus-style language for arrows that conservatively extends the arrow calculus.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [2] [Agentic Operator Generation for ML ASICs](https://arxiv.org/abs/2512.10977)
*Alec M. Hammond,Aram Markosyan,Aman Dontula,Simon Mahns,Zacharias Fisches,Dmitrii Pedchenko,Keyur Muzumdar,Natacha Supper,Mark Saroufim,Joe Isaacson,Laura Wang,Warren Hunt,Kaustubh Gondkar,Roman Levenstein,Gabriel Synnaeve,Richard Li,Jacob Kahn,Ajit Mathews*

Main category: cs.DC

TL;DR: TritorX是一个AI系统，能够为新兴加速器平台大规模生成功能正确的Triton PyTorch ATen内核，优先考虑覆盖率和正确性而非性能。


<details>
  <summary>Details</summary>
Motivation: 传统内核生成方法主要关注有限的高使用率内核的性能优化，但缺乏对完整算子集的覆盖。新兴加速器平台需要快速、全面的PyTorch ATen后端支持，特别是在数据多样性、形状和参数模式方面。

Method: 集成开源大语言模型、自定义代码检查器、JIT编译和基于PyTorch OpInfo的测试框架。支持真实MTIA芯片和硬件仿真环境，通过自动化管道确保内核功能正确性。

Result: 成功为481个独特的ATen算子生成内核和包装器，通过超过20,000个PyTorch OpInfo测试，实现了高覆盖率和功能正确性。

Conclusion: TritorX为新兴加速器平台实现"一夜之间"生成完整PyTorch ATen后端提供了可行路径，通过AI驱动的自动化方法解决了算子覆盖的挑战。

Abstract: We present TritorX, an agentic AI system designed to generate functionally correct Triton PyTorch ATen kernels at scale for emerging accelerator platforms. TritorX integrates open-source large language models with a custom linter, JIT compilation, and a PyTorch OpInfo-based test harness. This pipeline is compatible with both real Meta Training and Inference Accelerator (MTIA) silicon and in hardware simulation environments for next-generation devices. In contrast to previous kernel-generation approaches that prioritize performance for a limited set of high-usage kernels, TritorX prioritizes coverage. Our system emphasizes correctness and generality across the entire operator set, including diverse data types, shapes, and argument patterns. In our experiments, TritorX successfully generated kernels and wrappers for 481 unique ATen operators that pass all corresponding PyTorch OpInfo tests (over 20,000 in total). TritorX paves the way for overnight generation of complete PyTorch ATen backends for new accelerator platforms.

</details>


### [3] [Theoretical Foundations of GPU-Native Compilation for Rapid Code Iteration](https://arxiv.org/abs/2512.11200)
*Adilet Metinov,Gulida M. Kudakeeva,Gulnara D. Kabaeva*

Main category: cs.DC

TL;DR: 提出三种GPU原生编译方法消除CPU-GPU数据传输瓶颈：并行传统编译、神经编译和混合架构，理论分析显示可实现10-100倍代码迭代加速


<details>
  <summary>Details</summary>
Motivation: 当前AI代码生成系统在编译、执行和测试阶段存在显著的CPU-GPU数据传输延迟瓶颈，限制了代码迭代效率

Method: 提出三种互补的GPU原生编译方法：1) 适应GPU执行的并行传统编译；2) 使用学习序列到序列翻译和概率验证的神经编译；3) 结合两者的混合架构

Result: 理论分析显示：传统GPU编译通过消除传输可获得2-5倍改进，神经编译通过大规模并行实现10-100倍加速，混合方法提供具有正确性保证的实用部署路径

Conclusion: GPU原生编译能显著加速代码迭代周期，概率验证框架允许在编译准确性和并行探索之间权衡，对自改进AI系统和未来模拟计算基板有重要影响

Abstract: Current AI code generation systems suffer from significant latency bottlenecks due to CPU-GPU data transfers during compilation, execution, and testing phases. We establish theoretical foundations for three complementary approaches to GPU-native compilation that eliminate these transfers: (1) parallel traditional compilation adapted for GPU execution, (2) neural compilation using learned sequence-to-sequence translation with probabilistic verification, and (3) hybrid architectures combining both strategies. We derive latency and energy bounds demonstrating potential speedups of 10-100x for code iteration cycles. Our analysis shows that traditional GPU compilation provides 2-5x improvements through transfer elimination, neural compilation achieves 10-100x speedups via massive parallelism, and hybrid approaches offer practical deployment paths with guaranteed correctness. We formalize the probabilistic verification framework that enables trading compilation accuracy for parallel exploration, and discuss implications for self-improving AI systems and future analog computing substrates.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [4] [Context-Dependent Effects and Concurrency in Guarded Interaction Trees](https://arxiv.org/abs/2512.11577)
*Sergei Stepanenko,Emma Nardino,Virgil Marionneau,Dan Frumin,Amin Timany,Lars Birkedal*

Main category: cs.LO

TL;DR: 扩展Guarded Interaction Trees以支持上下文相关效应（如call/cc、shift/reset）和抢占式并发，保持对上下文无关效应的推理原则不变，并提供程序逻辑和语义验证。


<details>
  <summary>Details</summary>
Motivation: 上下文相关效应（如call/cc、shift/reset）的推理具有挑战性，因为传统程序逻辑的组合性原则（如bind规则）在这些效应下不再成立。需要一种能够表示和推理上下文相关效应的方法，同时保持对上下文无关效应的现有推理原则。

Method: 扩展Guarded Interaction Trees框架，保守地添加对上下文相关效应的支持。使用该扩展为带有call/cc和delimited continuations的高阶编程语言提供直接式指称语义，并扩展程序逻辑以处理上下文相关效应。同时扩展支持抢占式并发和原子状态修改操作。

Result: 成功扩展了Guarded Interaction Trees，使其能够表示和推理上下文相关效应。证明了指称语义相对于操作语义的充分性，展示了在delimited continuations和higher-order store之间的安全互操作性，并支持抢占式并发和原子操作。

Conclusion: 该扩展为上下文相关效应提供了无痛的表示和推理方法，保持了框架的保守性和模块化特性，支持多种效应的组合，为并发数据结构和算法的实现与验证提供了基础。

Abstract: Guarded Interaction Trees are a structure and a fully formalized framework for representing higher-order computations with higher-order effects in Rocq. We present an extension of Guarded Interaction Trees to support formal reasoning about context-dependent effects. That is, effects whose behaviors depend on the evaluation context, e.g., call/cc, shift and reset. Using and reasoning about such effects is challenging since certain compositionality principles no longer hold in the presence of such effects. For example, the so-called ``bind rule'' in modern program logics is no longer valid. The goal of our extension is to support representation and reasoning about context-dependent effects in the most painless way possible. To that end, our extension is conservative: the reasoning principles for context-independent effects remain the same. We use it to give direct-style denotational semantics for higher-order programming languages with call/cc and with delimited continuations. We extend the program logic for Guarded Interaction Trees to account for context-dependent effects, and we use the program logic to prove that the denotational semantics is adequate with respect to the operational semantics. Additionally, we retain the ability to combine multiple effects in a modular way, which we demonstrate by showing type soundness for safe interoperability of a programming language with delimited continuations and a programming language with higher-order store. Furthermore, as another contribution, in addition to context-dependent effects, we show how to extend Guarded Interaction Trees with preemptive concurrency. To support implementation and verification of concurrent data structures and algorithms in the presence of preemptive concurrency one requires atomic state modification operations, e.g., compare-and-exchange.

</details>
