<div id=toc></div>

# Table of Contents

- [cs.GT](#cs.GT) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [1] [The Impact Market to Save Conference Peer Review: Decoupling Dissemination and Credentialing](https://arxiv.org/abs/2512.14104)
*Karthikeyan Sankaralingam*

Main category: cs.GT

TL;DR: 提出Impact Market系统，通过三阶段机制将论文发表与声望解耦：发表所有合格论文，通过期货市场创建稀缺声望信号，再通过3年回溯机制校准投资准确性。


<details>
  <summary>Details</summary>
Motivation: 顶级学术会议面临两个不可调和角色的压力：快速传播所有可靠研究 vs 稀缺的声望认证和职业发展。这导致了"评审轮盘赌"和匿名法庭模式，造成高风险主观性、地盘争夺和可靠研究的任意拒绝。

Method: Impact Market三阶段系统：1) 发表阶段：程序委员会评审接受所有可靠严谨论文；2) 投资阶段：通过期货市场创建稀缺声望信号，资深社区成员用代币投资已发表论文，形成透明的众包净投资分数；3) 校准阶段：3年回溯机制验证投资准确性，基于多向量影响力分数调整投资者评级。

Result: 基于代理的模拟显示，在被动市场中表现与现有协议相当，但引入投资者能动性和信念投注后，在相同条件下高影响力论文的检索率从28%提升到85%以上。

Conclusion: Impact Market模型用透明、可问责、数据驱动的市场取代了隐藏的零成本攻击系统，将即时认证与长期验证的影响力对齐，激励性自我选择是扩展同行评审所需机制。

Abstract: Top-tier academic conferences are failing under the strain of two irreconcilable roles: (1) rapid dissemination of all sound research and (2) scarce credentialing for prestige and career advancement. This conflict has created a reviewer roulette and anonymous tribunal model - a zero-cost attack system - characterized by high-stakes subjectivity, turf wars, and the arbitrary rejection of sound research (the equivalence class problem). We propose the Impact Market (IM), a novel three-phase system that decouples publication from prestige. Phase 1 (Publication): All sound and rigorous papers are accepted via a PC review, solving the "equivalence class" problem. Phase 2 (Investment): An immediate, scarce prestige signal is created via a futures market. Senior community members invest tokens into published papers, creating a transparent, crowdsourced Net Invested Score (NIS). Phase 3 (Calibration): A 3-year lookback mechanism validates these investments against a manipulation-resistant Multi-Vector Impact Score (MVIS). This MVIS adjusts each investor's future influence (their Investor Rating), imposing a quantifiable cost on bad actors and rewarding accurate speculation. The IM model replaces a hidden, zero-cost attack system with a transparent, accountable, and data-driven market that aligns immediate credentialing with long-term, validated impact. Agent-based simulations demonstrate that while a passive market matches current protocols in low-skill environments, introducing investor agency and conviction betting increases the retrieval of high-impact papers from 28% to over 85% under identical conditions, confirming that incentivized self-selection is the mechanism required to scale peer review.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [2] [A Deep Dive into Function Inlining and its Security Implications for ML-based Binary Analysis](https://arxiv.org/abs/2512.14045)
*Omar Abusabha,Jiyong Uhm,Tamer Abuhmed,Hyungjoon Koo*

Main category: cs.CR

TL;DR: 函数内联优化虽然提升性能，但会显著改变二进制文件的静态特征，影响基于机器学习的二进制分析安全性。研究发现极端内联设置可被利用来规避ML模型检测。


<details>
  <summary>Details</summary>
Motivation: 函数内联是现代编译器中广泛使用的优化技术，但会显著影响机器指令和控制流图等静态特征，而这些特征对二进制分析至关重要。尽管影响广泛，但函数内联对安全性的影响尚未得到充分研究。

Method: 1) 剖析LLVM成本模型中的内联决策流程；2) 探索超越标准优化级别的极端内联编译器选项组合；3) 针对5个ML辅助的二进制安全分析任务，使用20个独特模型系统评估其在极端内联场景下的鲁棒性。

Result: 1) 函数内联虽然意图良性，但可直接或间接影响ML模型行为，可能被利用来规避判别式或生成式ML模型；2) 依赖静态特征的ML模型对内联高度敏感；3) 微妙的编译器设置可被用于故意制作规避性二进制变体；4) 内联比率在不同应用和构建配置中差异很大，破坏了ML模型训练和评估的一致性假设。

Conclusion: 函数内联对基于机器学习的二进制分析安全任务有显著影响，极端内联设置可被恶意利用来规避检测。研究揭示了编译器优化与ML模型鲁棒性之间的重要安全关联，需要重新考虑ML模型训练和评估中对编译器一致性的假设。

Abstract: A function inlining optimization is a widely used transformation in modern compilers, which replaces a call site with the callee's body in need. While this transformation improves performance, it significantly impacts static features such as machine instructions and control flow graphs, which are crucial to binary analysis. Yet, despite its broad impact, the security impact of function inlining remains underexplored to date. In this paper, we present the first comprehensive study of function inlining through the lens of machine learning-based binary analysis. To this end, we dissect the inlining decision pipeline within the LLVM's cost model and explore the combinations of the compiler options that aggressively promote the function inlining ratio beyond standard optimization levels, which we term extreme inlining. We focus on five ML-assisted binary analysis tasks for security, using 20 unique models to systematically evaluate their robustness under extreme inlining scenarios. Our extensive experiments reveal several significant findings: i) function inlining, though a benign transformation in intent, can (in)directly affect ML model behaviors, being potentially exploited by evading discriminative or generative ML models; ii) ML models relying on static features can be highly sensitive to inlining; iii) subtle compiler settings can be leveraged to deliberately craft evasive binary variants; and iv) inlining ratios vary substantially across applications and build configurations, undermining assumptions of consistency in training and evaluation of ML models.

</details>
