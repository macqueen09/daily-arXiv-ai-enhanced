<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Enforcing Temporal Constraints for LLM Agents](https://arxiv.org/abs/2512.23738)
*Adharsh Kamath,Sishen Zhang,Calvin Xu,Shubham Ugare,Gagandeep Singh,Sasa Misailovic*

Main category: cs.PL

TL;DR: Agent-C：一个为LLM智能体提供运行时安全保障的框架，确保其遵守时序安全策略，通过SMT求解和约束生成技术实现100%合规性。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的智能体被部署在安全关键应用中，但现有的护栏系统无法防止违反时序安全策略的行为，这些策略需要关于动作序列的推理而非单个动作。现有方法依赖不精确的自然语言指令或事后监控，无法提供形式化保证。

Method: Agent-C引入一个领域特定语言来表达时序属性（如认证前访问数据），将规范转换为一阶逻辑，并使用SMT求解在token生成期间检测不合规的智能体动作。当LLM尝试生成不合规的工具调用时，利用约束生成技术确保每个动作符合规范，并为不合规动作生成合规替代方案。

Result: 在零售客服和机票预订系统等真实应用中评估，Agent-C实现了完美的安全性（100%合规，0%伤害），同时相比最先进的护栏和无限制智能体提高了任务效用。在SoTA闭源模型上，将合规性从77.4%提升到100%（Claude Sonnet 4.5）和83.7%提升到100%（GPT-5），同时提高效用（71.8%到75.2%和66.1%到70.6%）。

Conclusion: Agent-C为可靠的智能体推理建立了新的SoTA前沿，通过形式化方法确保LLM智能体遵守时序安全策略，在保持安全性的同时提高任务效用。

Abstract: LLM-based agents are deployed in safety-critical applications, yet current guardrail systems fail to prevent violations of temporal safety policies, requirements that govern the ordering and sequencing of agent actions. For instance, agents may access sensitive data before authenticating users or process refunds to unauthorized payment methods, violations that require reasoning about sequences of action rather than an individual action. Existing guardrails rely on imprecise natural language instructions or post-hoc monitoring, and provide no formal guarantees that agents will satisfy temporal constraints. We present Agent-C, a novel framework that provides run-time guarantees ensuring LLM agents adhere to formal temporal safety properties. Agent-C introduces a domain-specific language for expressing temporal properties (e.g., authenticate before accessing data), translates specifications to first-order logic, and uses SMT solving to detect non-compliant agent actions during token generation. When the LLM attempts to generate a non-compliant tool call, Agent-C leverages constrained generation techniques to ensure that every action generated by the LLM complies with the specification, and to generate a compliant alternative to a non-compliant agent action. We evaluate Agent-C across two real-world applications: retail customer service and airline ticket reservation system, and multiple language models (open and closed-source). Our results demonstrate that Agent-C achieves perfect safety (100% conformance, 0% harm), while improving task utility compared to state-of-the-art guardrails and unrestricted agents. On SoTA closed-source models, Agent-C improves conformance (77.4% to 100% for Claude Sonnet 4.5 and 83.7% to 100% for GPT-5), while simultaneously increasing utility (71.8% to 75.2% and 66.1% to 70.6%, respectively), representing a new SoTA frontier for reliable agentic reasoning.

</details>


### [2] [Towards representation agnostic probabilistic programming](https://arxiv.org/abs/2512.23740)
*Ole Fenske,Maximilian Popko,Sebastian Bader,Thomas Kirste*

Main category: cs.PL

TL;DR: 提出因子抽象作为概率编程的通用接口，支持混合不同表示形式，解决现有工具耦合模型表示与特定推理算法的问题


<details>
  <summary>Details</summary>
Motivation: 当前概率编程语言和工具将模型表示与特定推理算法紧密耦合，阻碍了对新表示形式或混合离散-连续模型的实验探索

Method: 引入包含五个基本操作的因子抽象，作为操纵因子的通用接口，无论其底层表示形式如何

Result: 实现了表示无关的概率编程，用户可以在统一框架内自由混合不同表示形式，支持当前工具无法充分表达的复杂混合模型的实际推理

Conclusion: 因子抽象为概率编程提供了通用接口，解决了表示与算法耦合的问题，支持更灵活和强大的混合模型推理

Abstract: Current probabilistic programming languages and tools tightly couple model representations with specific inference algorithms, preventing experimentation with novel representations or mixed discrete-continuous models. We introduce a factor abstraction with five fundamental operations that serve as a universal interface for manipulating factors regardless of their underlying representation. This enables representation-agnostic probabilistic programming where users can freely mix different representations (e.g. discrete tables, Gaussians distributions, sample-based approaches) within a single unified framework, allowing practical inference in complex hybrid models that current toolkits cannot adequately express.

</details>


### [3] [VGC: A High-Performance Zone-Based Garbage Collector Architecture for Python with Partitioning and Parallel Execution](https://arxiv.org/abs/2512.23768)
*Abdulla M*

Main category: cs.PL

TL;DR: VGC提出了一种新型内存管理框架，采用主动/被动双层架构，通过编译时和运行时优化，在嵌入式设备到高性能并行系统中实现高效低开销内存管理。


<details>
  <summary>Details</summary>
Motivation: 传统垃圾收集器在多样化系统（从资源受限的嵌入式设备到高性能并行架构）中难以平衡性能与开销，需要一种更高效、可预测的内存管理方案。

Method: 采用双层架构：主动VGC在运行时使用并发标记清除策略管理动态对象；被动VGC在编译时通过预测性内存映射优化静态对象分配，对齐缓存边界减少碎片。

Result: 暂停时间减少30%（相比分代收集器），内存使用减少25%，内存访问模式可预测，现代并行应用的可扩展性得到改善。

Conclusion: VGC通过分离编译时和运行时优化职责，为内存密集型系统提供了稳健且适应性强的解决方案，适用于从低级到高级编程环境的各种场景。

Abstract: The Virtual Garbage Collector (VGC) introduces a novel memory management framework designed to optimize performance across diverse systems, ranging from resource constrained embedded devices to high performance parallel architectures. Unlike conventional garbage collectors, VGC employs a dual layer architecture consisting of Active VGC and Passive VGC to enable efficient, low overhead memory management. Active VGC dynamically manages runtime objects using a concurrent mark and sweep strategy tailored for parallel workloads, reducing pause times by up to 30 percent compared to generational collectors in multithreaded benchmarks. Passive VGC operates at compile time and optimizes static object allocation through predictive memory mapping, minimizing fragmentation by aligning objects to cache boundaries. This separation of responsibilities ensures predictable memory access patterns, reduces total memory usage by up to 25 percent, and improves scalability for modern parallel applications. By integrating compile time and runtime optimizations, VGC provides a robust and adaptable solution for memory intensive systems across both low level and high level programming environments.

</details>


### [4] [State Space Estimation for DPOR-based Model Checkers](https://arxiv.org/abs/2512.23996)
*A. R. Balasubramanian,Mohammad Hossein Khoshechin Jorshari,Rupak Majumdar,Umang Mathur,Minjian Zhang*

Main category: cs.PL

TL;DR: 提出首个可证明的多项式时间无偏估计器，用于计算并发程序的Mazurkiewicz迹等价类数量，解决基于枚举的模型检查中的资源分配问题。


<details>
  <summary>Details</summary>
Motivation: 在基于枚举的模型检查中，需要估计并发程序的Mazurkiewicz迹等价类数量，以预测模型检查的运行时间和评估搜索空间的覆盖程度。现有方法面临计算复杂度过高的问题。

Method: 将无状态最优DPOR算法转换为无偏估计器，将其探索过程视为有界深度和宽度的树，应用Knuth经典估计器。为控制方差，采用随机枚举方法，在每层维护少量部分路径的耦合演化。

Result: 在JMC模型检查器中实现该估计器，在共享内存基准测试中，即使状态空间有10^5-10^6个类，通过数百次试验即可获得稳定估计（通常在20%误差范围内）。

Conclusion: 该研究首次为计数迹问题提供了可证明的多项式时间无偏估计器，对于模型检查资源分配具有重要意义，能够有效估计模型检查成本。

Abstract: We study the estimation problem for concurrent programs: given a bounded program $P$, estimate the number of Mazurkiewicz trace-equivalence classes induced by its interleavings. This quantity informs two practical questions for enumeration-based model checking: how long a model checking run is likely to take, and what fraction of the search space has been covered so far. We first show the counting problem is #P-hard even for restricted programs and, unless $P=NP$, inapproximable within any subexponential factor, ruling out efficient exact or randomized approximation algorithms. We give a Monte Carlo approach to obtain a poly-time unbiased estimator: we convert a stateless optimal DPOR algorithm into an unbiased estimator by viewing its exploration as a bounded-depth, bounded-width tree whose leaves are the maximal Mazurkiewicz traces. A classical estimator by Knuth, when run on this tree, yields an unbiased estimate. To control the variance, we apply stochastic enumeration by maintaining a small population of partial paths per depth whose evolution is coupled. We have implemented our estimator in the JMC model checker and evaluated it on shared-memory benchmarks. With modest budgets, our estimator yields stable estimates, typically within a 20% band, within a few hundred trials, even when the state space has $10^5$--$10^6$ classes. We also show how the same machinery estimates model-checking cost by weighting all explored graphs, not only complete traces. Our algorithms provide the first provable poly-time unbiased estimators for counting traces, a problem of considerable importance when allocating model checking resources.

</details>
