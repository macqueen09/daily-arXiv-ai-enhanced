<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Backwards Data-Flow Analysis using Prophecy Variable in the BuildIt System](https://arxiv.org/abs/2601.02653)
*Ajay Brahmakshatriya,Saman Amarasinghe,Martin Rinard*

Main category: cs.PL

TL;DR: 该论文提出使用预言变量（prophecy variables）来预测程序未来执行信息，替代传统的反向程序分析，从而简化需要未来行为信息的程序转换和优化。


<details>
  <summary>Details</summary>
Motivation: 许多程序转换和优化需要了解程序未来行为信息。传统方法通过构建中间程序表示并使用反向程序分析来传播相关信息，但这种方法实现复杂且工程开销大。

Method: 在BuildIt系统中实现预言变量，这是一个轻量级领域特定语言实现系统。BuildIt使用分阶段编译，第一阶段通过标准C++程序执行生成优化的C、C++和CUDA第二阶段代码。结合预言变量和重复前向程序执行，无需反向分析即可实现需要未来执行信息的转换和优化。

Result: BuildIt能够消除解析器和中间表示等编程语言实现组件，显著减少领域特定语言实现的工程工作量。预言变量使BuildIt能够扩展这种方法，支持需要未来执行信息的优化，而无需实现反向分析。

Conclusion: 预言变量提供了一种有效的方法来获取程序未来执行信息，替代传统的反向程序分析，简化了需要这类信息的程序转换和优化的实现过程。

Abstract: Many program transformations and optimizations require information about the future behavior of the program. A standard way to obtain this information is to build an intermediate program representation, then use a backwards program analysis to propagate relevant information against the flow of control back to the transformation/optimization site. We instead propose to use prophecy variables, which predict information about the future execution of the program, to enable such transformations and optimizations. We implement prophecy variables in BuildIt, a lightweight domain specific language implementation system. BuildIt uses staged compilation to implement high performance domain specific languages embedded within a standard general purpose programming language (C++). The BuildIt first phase uses standard C++ program execution to generate optimized C, C++, and CUDA second phase code. This approach enables BuildIt to eliminate programming language implementation components such as parsers and intermediate representations, delivering a dramatic decrease in the engineering effort required to implement domain specific languages. The combination of prophecy variables and repeated forward program execution enables BuildIt to extend this approach to include transformations and optimizations that require information about the future execution of the program without backwards analyses and without the engineering overhead associated with implementing these analyses. We formalize the use of prophecy variables for this purpose, discuss the implementation of prophecy variables and repeated execution in BuildIt, and present experimental results for BuildIt computations that benefit from optimizations enabled by the information that prophecy variables provide.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [2] [Compressed code: the hidden effects of quantization and distillation on programming tokens](https://arxiv.org/abs/2601.02563)
*Viacheslav Siniaev,Iaroslav Chelombitko,Aleksey Komissarov*

Main category: cs.SE

TL;DR: 该论文系统分析了LLM在代码生成中的token级机制，特别是压缩模型中的表现，通过词汇分布和关键词覆盖模式研究编程语言编码方式，并评估不同优化技术对token表示和代码生成质量的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在代码生成方面表现出色，但其token级机制（尤其是在压缩模型中）仍未得到充分探索。需要理解编程语言在LLM分词器中的编码方式，以及不同优化技术如何影响token级表示和代码生成质量。

Method: 1. 分析编程语言token表示的词汇分布和关键词覆盖模式；2. 引入新颖的冷启动概率分析方法，无需显式提示即可洞察模型行为；3. 全面评估量化、蒸馏、模型缩放和任务特定微调等优化技术对token级表示和代码生成质量的影响；4. 使用概率分布分析和评估指标进行实验验证。

Result: 实验揭示了token级行为的关键洞察，提供了经验验证的指导原则，用于在各种优化约束下保持代码生成质量。研究发现不同优化技术对token表示和代码生成有显著影响。

Conclusion: 该研究不仅推进了对LLM代码生成的理论理解，还为生产环境中优化模型的实践实施提供了指导，有助于在保持代码生成质量的同时应用各种模型优化技术。

Abstract: Large Language Models (LLMs) have demonstrated exceptional code generation capabilities, yet their token-level mechanisms remain underexplored, particularly in compressed models. Through systematic analysis of programming language token representations, we characterize how programming languages are encoded in LLM tokenizers by analyzing their vocabulary distribution and keyword coverage patterns. We introduce a novel cold-start probability analysis method that provides insights into model behavior without requiring explicit prompts. Additionally, we present a comprehensive evaluation of how different model optimization techniques - including quantization, distillation, model scaling, and task-specific fine-tuning - affect token-level representations and code generation quality. Our experiments, supported by comprehensive probability distribution analysis and evaluation metrics, reveal critical insights into token-level behavior and provide empirically-validated guidelines for maintaining code generation quality under various optimization constraints. These findings advance both theoretical understanding of LLM code generation and practical implementation of optimized models in production environments.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [3] [Proceedings 16th International Workshop on Graph Computation Models](https://arxiv.org/abs/2601.03249)
*Leen Lambers,Oszkár Semeráth*

Main category: cs.LO

TL;DR: GCM 2025 是第十六届国际图计算模型研讨会的论文集，该研讨会作为STAF会议的一部分在德国科布伦茨举行，聚焦于图作为系统建模核心工具的研究与应用。


<details>
  <summary>Details</summary>
Motivation: 图作为直观的数学结构，在计算机科学、生物学、业务流程建模等多个领域是自然且无缝的系统建模方式。图计算模型将图作为一等公民，属于非常高级的模型。GCM研讨会旨在汇集对基于图和图变换的计算模型各方面感兴趣的研究人员。

Method: 通过国际研讨会形式，促进不同社区（包括资深和年轻研究人员）在理论基础、应用和实现方面的思想与经验交流，实现跨领域的交叉融合。

Result: 本卷收录了GCM 2025研讨会的后论文集，记录了在图计算模型领域的最新研究成果和讨论。

Conclusion: GCM研讨会系列持续推动图计算模型领域的发展，通过跨学科交流促进该领域在理论基础、应用实践和实现技术方面的进步。

Abstract: This volume contains the post-proceedings of the Sixteenth International Workshop on Graph Computation Models (GCM 2025). The workshops took place in Koblenz, Germany on June 10 as part of STAF (Software Technologies: Applications and Foundations).  
  Graphs are common mathematical structures that are visual and intuitive. They constitute a natural and seamless way for system modeling in science, engineering, and beyond, including computer science, biology, and business process modeling. Graph computation models constitute a class of very high-level models where graphs are first-class citizens. The aim of the International GCM Workshop series is to bring together researchers interested in all aspects of computation models based on graphs and graph transformation. It promotes the cross-fertilizing exchange of ideas and experiences among senior and young researchers from the different communities interested in the foundations, applications, and implementations of graph computation models and related areas.

</details>
