{"id": "2601.04492", "pdf": "https://arxiv.org/pdf/2601.04492", "abs": "https://arxiv.org/abs/2601.04492", "authors": ["Yuanzhuo Zhang", "Zhoulai Fu", "Binoy Ravindran"], "title": "Scalable Floating-Point Satisfiability via Staged Optimization", "categories": ["cs.PL", "cs.AI"], "comment": null, "summary": "This work introduces StageSAT, a new approach to solving floating-point satisfiability that bridges SMT solving with numerical optimization. StageSAT reframes a floating-point formula as a series of optimization problems in three stages of increasing precision. It begins with a fast, projection-aided descent objective to guide the search toward a feasible region, proceeding to bit-level accuracy with ULP$^2$ optimization and a final $n$-ULP lattice refinement.\n  By construction, the final stage uses a representing function that is zero if and only if a candidate satisfies all constraints. Thus, when optimization drives the objective to zero, the resulting assignment is a valid solution, providing a built-in guarantee of soundness.\n  To improve search, StageSAT introduces a partial monotone descent property on linear constraints via orthogonal projection, preventing the optimizer from stalling on flat or misleading landscapes. Critically, this solver requires no heavy bit-level reasoning or specialized abstractions; it treats complex arithmetic as a black-box, using runtime evaluations to navigate the input space.\n  We implement StageSAT and evaluate it on extensive benchmarks, including SMT-COMP'25 suites and difficult cases from prior work. StageSAT proved more scalable and accurate than state-of-the-art optimization-based alternatives. It solved strictly more formulas than any competing solver under the same time budget, finding most satisfiable instances without producing spurious models. This amounts to 99.4% recall on satisfiable cases with 0% false SAT, exceeding the reliability of prior optimization-based solvers. StageSAT also delivered significant speedups (often 5--10$\\times$) over traditional bit-precise SMT and numeric solvers. These results demonstrate that staged optimization significantly improves performance and correctness of floating-point satisfiability solving.", "AI": {"tldr": "StageSAT\uff1a\u4e00\u79cd\u65b0\u7684\u6d6e\u70b9\u53ef\u6ee1\u8db3\u6027\u6c42\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u4f18\u5316\u5c06SMT\u6c42\u89e3\u4e0e\u6570\u503c\u4f18\u5316\u7ed3\u5408\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u548c\u6b63\u786e\u6027", "motivation": "\u4f20\u7edf\u6d6e\u70b9SMT\u6c42\u89e3\u5668\u9700\u8981\u590d\u6742\u7684\u4f4d\u7ea7\u63a8\u7406\u548c\u4e13\u95e8\u62bd\u8c61\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u73b0\u6709\u57fa\u4e8e\u4f18\u5316\u7684\u65b9\u6cd5\u5728\u7cbe\u5ea6\u548c\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u8bc1\u6b63\u786e\u6027\u53c8\u80fd\u9ad8\u6548\u5904\u7406\u590d\u6742\u7b97\u672f\u7684\u65b9\u6cd5\u3002", "method": "1. \u5c06\u6d6e\u70b9\u516c\u5f0f\u91cd\u6784\u4e3a\u4e09\u4e2a\u7cbe\u5ea6\u9012\u589e\u7684\u4f18\u5316\u95ee\u9898\u9636\u6bb5\n2. \u7b2c\u4e00\u9636\u6bb5\uff1a\u5feb\u901f\u6295\u5f71\u8f85\u52a9\u4e0b\u964d\u76ee\u6807\u5f15\u5bfc\u641c\u7d22\u5230\u53ef\u884c\u533a\u57df\n3. \u7b2c\u4e8c\u9636\u6bb5\uff1a\u4f4d\u7ea7\u7cbe\u5ea6\u7684ULP\u00b2\u4f18\u5316\n4. \u7b2c\u4e09\u9636\u6bb5\uff1an-ULP\u683c\u70b9\u7ec6\u5316\uff0c\u4f7f\u7528\u8868\u793a\u51fd\u6570\u786e\u4fdd\u89e3\u7684\u6b63\u786e\u6027\n5. \u5f15\u5165\u7ebf\u6027\u7ea6\u675f\u7684\u90e8\u5206\u5355\u8c03\u4e0b\u964d\u7279\u6027\u9632\u6b62\u4f18\u5316\u5668\u505c\u6ede\n6. \u5c06\u590d\u6742\u7b97\u672f\u89c6\u4e3a\u9ed1\u76d2\uff0c\u4ec5\u4f7f\u7528\u8fd0\u884c\u65f6\u8bc4\u4f30", "result": "1. \u5728SMT-COMP'25\u6d4b\u8bd5\u96c6\u548c\u5148\u524d\u5de5\u4f5c\u7684\u56f0\u96be\u6848\u4f8b\u4e0a\u8868\u73b0\u4f18\u5f02\n2. \u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u4f18\u5316\u7684\u66ff\u4ee3\u65b9\u6848\u66f4\u5177\u53ef\u6269\u5c55\u6027\u548c\u51c6\u786e\u6027\n3. \u5728\u76f8\u540c\u65f6\u95f4\u9884\u7b97\u4e0b\u89e3\u51b3\u4e86\u66f4\u591a\u516c\u5f0f\n4. \u53ef\u6ee1\u8db3\u6848\u4f8b\u7684\u53ec\u56de\u7387\u8fbe\u523099.4%\uff0c\u5047SAT\u7387\u4e3a0%\n5. \u76f8\u6bd4\u4f20\u7edf\u4f4d\u7cbe\u786eSMT\u548c\u6570\u503c\u6c42\u89e3\u5668\u83b7\u5f975-10\u500d\u52a0\u901f", "conclusion": "\u5206\u9636\u6bb5\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6d6e\u70b9\u53ef\u6ee1\u8db3\u6027\u6c42\u89e3\u7684\u6027\u80fd\u548c\u6b63\u786e\u6027\uff0c\u4e3a\u6d6e\u70b9SMT\u6c42\u89e3\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\uff0c\u65e0\u9700\u590d\u6742\u7684\u4f4d\u7ea7\u63a8\u7406\u5373\u53ef\u4fdd\u8bc1\u89e3\u7684\u6b63\u786e\u6027\u3002"}}
{"id": "2601.04573", "pdf": "https://arxiv.org/pdf/2601.04573", "abs": "https://arxiv.org/abs/2601.04573", "authors": ["Kazutaka Matsuda", "Minh Nguyen", "Meng Wang"], "title": "Lenses for Partially-Specified States (Extended Version)", "categories": ["cs.PL"], "comment": "Extended version of our paper to appear in ESOP 2026", "summary": "A bidirectional transformation is a pair of transformations satisfying certain well-behavedness properties: one maps source data into view data, and the other translates changes on the view back to the source. However, when multiple views share a source, an update on one view may affect the others, making it hard to maintain correspondence while preserving the user's update, especially when multiple views are changed at once. Ensuring these properties within a compositional framework is even more challenging. In this paper, we propose partial-state lenses, which allow source and view states to be partially specified to precisely represent the user's update intentions. These intentions are partially ordered, providing clear semantics for merging intentions of updates coming from multiple views and a refined notion of update preservation compatible with this merging. We formalize partial-state lenses, together with partial-specifiedness-aware well-behavedness that supports compositional reasoning and ensures update preservation. In addition, we demonstrate the utility of the proposed system through examples.", "AI": {"tldr": "\u63d0\u51fa\u90e8\u5206\u72b6\u6001\u900f\u955c\uff0c\u901a\u8fc7\u90e8\u5206\u6307\u5b9a\u6e90\u72b6\u6001\u548c\u89c6\u56fe\u72b6\u6001\u6765\u7cbe\u786e\u8868\u793a\u7528\u6237\u66f4\u65b0\u610f\u56fe\uff0c\u652f\u6301\u591a\u89c6\u56fe\u66f4\u65b0\u5408\u5e76\uff0c\u5e76\u63d0\u4f9b\u7ec4\u5408\u63a8\u7406\u7684\u826f\u6784\u6027\u4fdd\u8bc1\u3002", "motivation": "\u53cc\u5411\u53d8\u6362\u4e2d\uff0c\u5f53\u591a\u4e2a\u89c6\u56fe\u5171\u4eab\u540c\u4e00\u6e90\u6570\u636e\u65f6\uff0c\u4e00\u4e2a\u89c6\u56fe\u7684\u66f4\u65b0\u4f1a\u5f71\u54cd\u5176\u4ed6\u89c6\u56fe\uff0c\u96be\u4ee5\u5728\u4fdd\u6301\u7528\u6237\u66f4\u65b0\u7684\u540c\u65f6\u7ef4\u6301\u5bf9\u5e94\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5728\u591a\u4e2a\u89c6\u56fe\u540c\u65f6\u66f4\u6539\u65f6\u3002\u5728\u7ec4\u5408\u6846\u67b6\u4e2d\u786e\u4fdd\u8fd9\u4e9b\u5c5e\u6027\u66f4\u5177\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u90e8\u5206\u72b6\u6001\u900f\u955c\uff0c\u5141\u8bb8\u90e8\u5206\u6307\u5b9a\u6e90\u72b6\u6001\u548c\u89c6\u56fe\u72b6\u6001\u4ee5\u7cbe\u786e\u8868\u793a\u7528\u6237\u66f4\u65b0\u610f\u56fe\u3002\u8fd9\u4e9b\u610f\u56fe\u91c7\u7528\u504f\u5e8f\u5173\u7cfb\uff0c\u4e3a\u5408\u5e76\u6765\u81ea\u591a\u4e2a\u89c6\u56fe\u7684\u66f4\u65b0\u610f\u56fe\u63d0\u4f9b\u6e05\u6670\u8bed\u4e49\uff0c\u5e76\u5b9a\u4e49\u4e0e\u8fd9\u79cd\u5408\u5e76\u517c\u5bb9\u7684\u66f4\u65b0\u4fdd\u6301\u6982\u5ff5\u3002", "result": "\u5f62\u5f0f\u5316\u4e86\u90e8\u5206\u72b6\u6001\u900f\u955c\u53ca\u5176\u652f\u6301\u7ec4\u5408\u63a8\u7406\u7684\u90e8\u5206\u6307\u5b9a\u611f\u77e5\u826f\u6784\u6027\uff0c\u786e\u4fdd\u66f4\u65b0\u4fdd\u6301\u3002\u901a\u8fc7\u793a\u4f8b\u5c55\u793a\u4e86\u6240\u63d0\u51fa\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u90e8\u5206\u72b6\u6001\u900f\u955c\u4e3a\u89e3\u51b3\u591a\u89c6\u56fe\u53cc\u5411\u53d8\u6362\u4e2d\u7684\u66f4\u65b0\u5408\u5e76\u548c\u4fdd\u6301\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u652f\u6301\u7ec4\u5408\u63a8\u7406\u5e76\u786e\u4fdd\u66f4\u65b0\u610f\u56fe\u7684\u7cbe\u786e\u8868\u793a\u548c\u4fdd\u6301\u3002"}}
{"id": "2601.05012", "pdf": "https://arxiv.org/pdf/2601.05012", "abs": "https://arxiv.org/abs/2601.05012", "authors": ["Luke A. D. Hutchison"], "title": "The Squirrel Parser: A Linear-Time PEG Packrat Parser Capable of Left Recursion and Optimal Error Recovery", "categories": ["cs.PL"], "comment": null, "summary": "We present the squirrel parser, a PEG packrat parser that directly handles all forms of left recursion with optimal error recovery, while maintaining linear time complexity in the length of the input even in the presence of an arbitrary number of errors. Traditional approaches to handling left recursion in a recursive descent parser require grammar rewriting or complex algorithmic extensions. We derive a minimal algorithm from first principles: cycle detection via per-position state tracking and $O(1)$-per-LR-cycle communication from descendant to ancestor recursion frames, and fixed-point search via iterative expansion. For error recovery, we derived a set of four axioms and twelve constraints that must be imposed upon an optimal error recovery design to ensure completeness, correctness, optimality of performance, and intuitiveness of behavior. We utilized a constraint satisfaction mechanism to search the space of all possibilities, arriving at a provably optimal and robust error recovery strategy that maintains perfect performance linearity.", "AI": {"tldr": "\u63d0\u51fa\u677e\u9f20\u89e3\u6790\u5668\uff0c\u4e00\u79cdPEG packrat\u89e3\u6790\u5668\uff0c\u80fd\u76f4\u63a5\u5904\u7406\u6240\u6709\u5f62\u5f0f\u7684\u5de6\u9012\u5f52\u5e76\u5177\u6709\u6700\u4f18\u9519\u8bef\u6062\u590d\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "motivation": "\u4f20\u7edf\u9012\u5f52\u4e0b\u964d\u89e3\u6790\u5668\u5904\u7406\u5de6\u9012\u5f52\u9700\u8981\u8bed\u6cd5\u91cd\u5199\u6216\u590d\u6742\u7b97\u6cd5\u6269\u5c55\uff0c\u7f3a\u4e4f\u65e2\u80fd\u5904\u7406\u5de6\u9012\u5f52\u53c8\u80fd\u4fdd\u6301\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u76f4\u63a5\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u7b2c\u4e00\u539f\u7406\u63a8\u5bfc\u6700\u5c0f\u7b97\u6cd5\uff1a\u901a\u8fc7\u6bcf\u4f4d\u7f6e\u72b6\u6001\u8ddf\u8e2a\u8fdb\u884c\u5faa\u73af\u68c0\u6d4b\uff0c\u540e\u4ee3\u5230\u7956\u5148\u9012\u5f52\u5e27\u7684O(1)\u901a\u4fe1\uff0c\u4ee5\u53ca\u901a\u8fc7\u8fed\u4ee3\u6269\u5c55\u8fdb\u884c\u5b9a\u70b9\u641c\u7d22\u3002\u9519\u8bef\u6062\u590d\u65b9\u9762\uff0c\u63a8\u5bfc\u4e864\u4e2a\u516c\u7406\u548c12\u4e2a\u7ea6\u675f\uff0c\u4f7f\u7528\u7ea6\u675f\u6ee1\u8db3\u673a\u5236\u641c\u7d22\u6240\u6709\u53ef\u80fd\u6027\u7a7a\u95f4\u3002", "result": "\u5f00\u53d1\u51fa\u80fd\u76f4\u63a5\u5904\u7406\u6240\u6709\u5f62\u5f0f\u5de6\u9012\u5f52\u7684\u89e3\u6790\u5668\uff0c\u5373\u4f7f\u5728\u4efb\u610f\u6570\u91cf\u9519\u8bef\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4fdd\u6301\u8f93\u5165\u957f\u5ea6\u7684\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u5e76\u5177\u6709\u53ef\u8bc1\u660e\u6700\u4f18\u4e14\u9c81\u68d2\u7684\u9519\u8bef\u6062\u590d\u7b56\u7565\u3002", "conclusion": "\u677e\u9f20\u89e3\u6790\u5668\u5728\u4fdd\u6301\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5de6\u9012\u5f52\u7684\u76f4\u63a5\u5904\u7406\u548c\u5bf9\u9519\u8bef\u6062\u590d\u7684\u6700\u4f18\u8bbe\u8ba1\uff0c\u4e3a\u89e3\u6790\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u8df5\u65b9\u6848\u3002"}}
{"id": "2601.04523", "pdf": "https://arxiv.org/pdf/2601.04523", "abs": "https://arxiv.org/abs/2601.04523", "authors": ["Ajay Singh", "Nikos Metaxakis", "Panagiota Fatourou"], "title": "Sharded Elimination and Combining for Highly-Efficient Concurrent Stacks", "categories": ["cs.DC", "cs.PL"], "comment": "extended version of paper in PPoPP 2026", "summary": "We present a new blocking linearizable stack implementation which utilizes sharding and fetch&increment to achieve significantly better performance than all existing concurrent stacks. The proposed implementation is based on a novel elimination mechanism and a new combining approach that are efficiently blended to gain high performance. Our implementation results in enhanced parallelism and low contention when accessing the shared stack. Experiments show that the proposed stack implementation outperforms all existing concurrent stacks by up to 2X in most workloads. It is particularly efficient in systems supporting a large number of threads and in high contention scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5206\u7247\u548cfetch&increment\u7684\u65b0\u578b\u963b\u585e\u7ebf\u6027\u5316\u6808\u5b9e\u73b0\uff0c\u6027\u80fd\u6bd4\u73b0\u6709\u5e76\u53d1\u6808\u63d0\u5347\u9ad8\u8fbe2\u500d", "motivation": "\u73b0\u6709\u5e76\u53d1\u6808\u5728\u9ad8\u5e76\u53d1\u573a\u666f\u4e0b\u6027\u80fd\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u591a\u7ebf\u7a0b\u7cfb\u7edf\u548c\u9ad8\u4e89\u7528\u60c5\u51b5\u4e0b\u9700\u8981\u66f4\u597d\u7684\u5e76\u884c\u6027\u548c\u66f4\u4f4e\u4e89\u7528", "method": "\u91c7\u7528\u5206\u7247\u6280\u672f\u7ed3\u5408fetch&increment\u64cd\u4f5c\uff0c\u7ed3\u5408\u65b0\u9896\u7684\u6d88\u9664\u673a\u5236\u548c\u7ec4\u5408\u65b9\u6cd5\uff0c\u6709\u6548\u6df7\u5408\u4ee5\u83b7\u5f97\u9ad8\u6027\u80fd", "result": "\u5b9e\u9a8c\u663e\u793a\u8be5\u5b9e\u73b0\u6bd4\u6240\u6709\u73b0\u6709\u5e76\u53d1\u6808\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe2\u500d\uff0c\u5728\u591a\u7ebf\u7a0b\u7cfb\u7edf\u548c\u9ad8\u4e89\u7528\u573a\u666f\u4e0b\u7279\u522b\u9ad8\u6548", "conclusion": "\u63d0\u51fa\u7684\u6808\u5b9e\u73b0\u901a\u8fc7\u521b\u65b0\u7684\u6d88\u9664\u673a\u5236\u548c\u7ec4\u5408\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5e76\u53d1\u6808\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u9ad8\u5e76\u53d1\u73af\u5883\u4e2d"}}
