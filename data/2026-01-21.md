<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 10]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [cs.IT](#cs.IT) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Context-Free Grammar Inference for Complex Programming Languages in Black Box Settings](https://arxiv.org/abs/2601.12385)
*Feifei Li,Xiao Chen,Xiaoyu Sun,Xi Xiao,Shaohua Wang,Yong Ding,Sheng Wen,Qing Li*

Main category: cs.PL

TL;DR: Crucio：一种通过分解森林和分布矩阵提取短示例进行语法推断的新方法，能够高效处理复杂编程语言，在48小时内成功推断C、C++、Java等语言的语法，性能优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 现有语法推断工具（如Arvada、Treevada、Kedavra）无法在48小时内处理复杂编程语言（C、C++、Java）的真实数据集。这些工具要么直接在完整输入上操作效率低下，要么分解方法不彻底，且严格的不过度泛化约束限制了复杂语法的构建。

Method: 提出Crucio方法，构建分解森林来提取短示例，通过分布矩阵同时进行词法和语法推断。这种方法避免了在完整输入上操作的低效性，同时克服了严格不过度泛化约束的限制。

Result: Crucio是唯一能在合理时间内成功推断复杂编程语言语法的方法（非终结符数量比先前基准多23倍）。在简单基准上，Crucio的召回率比Treevada和Kedavra分别提高1.37倍和1.19倍，F1分数提高1.21倍和1.13倍。

Conclusion: Crucio通过创新的分解森林和分布矩阵方法，解决了复杂编程语言语法推断的扩展性问题，显著优于现有工具，为实际应用提供了可行的解决方案。

Abstract: Grammar inference for complex programming languages remains a significant challenge, as existing approaches fail to scale to real world datasets within practical time constraints. In our experiments, none of the state-of-the-art tools, including Arvada, Treevada and Kedavra were able to infer grammars for complex languages such as C, C++, and Java within 48 hours. Arvada and Treevada perform grammar inference directly on full-length input examples, which proves inefficient for large files commonly found in such languages. While Kedavra introduces data decomposition to create shorter examples for grammar inference, its lexical analysis still relies on the original inputs. Additionally, its strict no-overgeneralization constraint limits the construction of complex grammars.
  To overcome these limitations, we propose Crucio, which builds a decomposition forest to extract short examples for lexical and grammar inference via a distributional matrix. Experimental results show that Crucio is the only method capable of successfully inferring grammars for complex programming languages (where the number of nonterminals is up to 23x greater than in prior benchmarks) within reasonable time limits. On the prior simple benchmark, Crucio achieves an average recall improvement of 1.37x and 1.19x over Treevada and Kedavra, respectively, and improves F1 scores by 1.21x and 1.13x.

</details>


### [2] [An Introduction to Razborov's Flag Algebra as a Proof System for Extremal Graph Theory](https://arxiv.org/abs/2601.12741)
*Gyeongwon Jeong,Seonghun Park,Hongseok Yang*

Main category: cs.PL

TL;DR: 本文是一篇面向计算机科学家的综述，以逻辑视角介绍Razborov的旗代数框架，将其表述为语法、语义和证明策略，并通过具体例子展示如何在旗代数中进行符号化数学论证。


<details>
  <summary>Details</summary>
Motivation: 旗代数作为极值图论中强大的框架，用于推导诱导子图密度的渐近不等式。本文旨在向逻辑、编程语言、自动验证和形式方法领域的计算机科学家介绍这一框架，采用更接近形式逻辑的风格进行阐述。

Method: 采用逻辑视角，将旗代数表述为语法、语义和证明策略。详细解释了一种流行的证明策略：先在标记变体中证明不等式，然后通过所谓的"向下算子"转移到原始无标记设置。强调这种转移机制依赖于作者称为"伴随对"的概念，类似于伽罗瓦连接和范畴伴随。

Result: 成功以逻辑视角向计算机科学家介绍了旗代数框架，展示了如何将数学论证符号化地在旗代数中执行。通过Mantel定理和Goodman的Ramsey多重性界等代表性例子，说明了框架的实际应用。

Conclusion: 旗代数为极值图论提供了强大的符号化论证框架，其逻辑视角和伴随对概念与计算机科学中的形式方法有密切联系，为计算机科学家理解和应用这一数学工具提供了桥梁。

Abstract: Razborov's flag algebra forms a powerful framework for deriving asymptotic inequalities between induced subgraph densities, underpinning many advances in extremal graph theory. This survey introduces flag algebra to computer scientists working in logic, programming languages, automated verification, and formal methods. We take a logical perspective on flag algebra and present it in terms of syntax, semantics, and proof strategies, in a style closer to formal logic. One popular proof strategy derives valid inequalities by first proving inequalities in a labelled variant of flag algebra and then transferring them to the original unlabelled setting using the so-called downward operator. We explain this strategy in detail and highlight that its transfer mechanism relies on the notion of what we call an adjoint pair, reminiscent of Galois connections and categorical adjunctions, which appear frequently in work on automated verification and programming languages. Along the way, we work through representative examples, including Mantel's theorem and Goodman's bound on Ramsey multiplicity, to illustrate how mathematical arguments can be carried out symbolically in the flag algebra framework.

</details>


### [3] [A Formally Verified Procedure for Width Inference in FIRRTL](https://arxiv.org/abs/2601.12813)
*Keyin Wang,Xiaomu Shi,Jiaxiang Liu,Zhilin Wu,Taolve Chen,Fu Song,David N. Jansen*

Main category: cs.PL

TL;DR: FIRRTL宽度推断问题研究：提出首个形式化验证的解决方案，比官方编译器能处理更多实例


<details>
  <summary>Details</summary>
Motivation: FIRRTL中许多组件的位宽未明确指定，需要在编译时推断。官方编译器firtool的InferWidths编译过程可能对简单程序也失败，需要更可靠、完整的解决方案。

Method: 证明如果FIRRTL程序约束可满足，存在唯一最小解。基于此提出完整的宽度推断过程，在Rocq交互式定理证明器中实现并证明功能正确性，从中提取OCaml实现。

Result: 实现了首个形式化验证的InferWidths过程，实验表明比官方firtool能解决更多实例，通常具有高效率。

Conclusion: 为FIRRTL宽度推断问题提供了理论基础和形式化验证的实现，解决了现有编译器中的不足，提高了可靠性和覆盖率。

Abstract: FIRRTL is an intermediate representation language for Register Transfer Level (RTL) hardware designs. In FIRRTL programs, the bit widths of many components are not specified explicitly and must be inferred during compilation. In mainstream FIRRTL compilers, such as the official compiler firtool, width inference is conducted by a compilation pass referred to as InferWidths, which may fail even for simple FIRRTL programs. In this paper, we thoroughly investigate the width inference problem for FIRRTL programs. We show that, if the constraints obtained from a FIRRTL program are satisfiable, there exists a unique least solution. Based on this result, we propose a complete procedure for solving the width inference problem. We implement it in the interactive theorem prover Rocq and prove its functional correctness. From the Rocq implementation, we extract an OCaml implementation, which is the first formally verified implementation of the InferWidths pass. Extensive experiments demonstrate that our approach can solve more instances than the official InferWidths pass in firtool, normally with high efficiency.

</details>


### [4] [Dependently-Typed AARA: A Non-Affine Approach for Resource Analysis of Higher-Order Programs](https://arxiv.org/abs/2601.12943)
*Han Xu,Di Wang*

Main category: cs.PL

TL;DR: λ_amor^na是一个非仿射的AARA风格依赖类型系统，用于高阶函数程序的资源推理，通过解耦资源与类型来解决传统仿射类型系统在高阶程序资源分析中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有仿射类型系统在分析高阶程序资源消耗时存在不足，特别是在处理部分应用时无法获得精确的资源行为。主要问题在于：(1) 类型与资源的紧密耦合；(2) 仿射类型机制与高阶类型机制之间的冲突。

Method: 提出λ_amor^na非仿射依赖类型系统，通过解耦资源与类型，使用依赖类型在类型层面表达潜在函数（与普通类型分离），采用非仿射类型机制来精确分析高阶函数的资源行为。

Result: 形式化了λ_amor^na的语法和语义，证明了其正确性，确保资源边界的正确性。通过多个具有挑战性的经典和高阶示例展示了系统的表达能力和组合性。

Conclusion: λ_amor^na通过解耦资源与类型、采用非仿射依赖类型机制，成功解决了传统仿射类型系统在高阶程序资源分析中的局限性，为高阶函数程序提供了更精确的资源推理能力。

Abstract: Static resource analysis determines the resource consumption (e.g., time complexity) of a program without executing it. Among the numerous existing approaches for resource analysis, affine type systems have been one dominant approach. However, these affine type systems fall short of deriving precise resource behavior of higher-order programs, particularly in cases that involve partial applications.
  This article presents λ_\ms{amor}^\ms{na}}, a non-affine AARA-style dependent type system for resource reasoning about higher-order functional programs. The key observation is that the main issue in previous approaches comes from (i) the close coupling of types and resources, and (ii) the conflict between affine and higher-order typing mechanisms. To derive precise resource behavior of higher-order functions, λ_\ms{amor}^\ms{na}} decouples resources from types and follows a non-affine typing mechanism. The non-affine type system of λ_\ms{amor}^\ms{na}} achieves this by using dependent types, which allows expressing type-level potential functions separate from ordinary types. This article formalizes λ_\ms{amor}^\ms{na}}'s syntax and semantics, and proves its soundness, which guarantees the correctness of resource bounds. Several challenging classic and higher-order examples are presented to demonstrate the expressiveness and compositionality of λ_\ms{amor}^\ms{na}}'s reasoning capability.

</details>


### [5] [Functional Logic Program Transformations](https://arxiv.org/abs/2601.13224)
*Michael Hanus,Steven Libby*

Main category: cs.PL

TL;DR: 使用函数逻辑编程实现程序转换，通过部分定义和非确定性操作简化语法树变换


<details>
  <summary>Details</summary>
Motivation: 编译器、分析器和验证器等工具需要对中间程序表示（如抽象语法树）进行变换，但实现这些变换很复杂，需要遍历完整语法树并在节点应用各种变换

Method: 提出将程序变换写为部分定义和非确定性操作，利用函数逻辑编程的特性，并与确定性变换方法进行比较

Result: 在函数逻辑语言Curry及其中间表示FlatCurry上评估了该方法，非确定性操作通常比确定性操作有额外开销

Conclusion: 函数逻辑编程的特性有助于以紧凑易懂的方式实现程序变换，尽管非确定性实现可能带来性能开销

Abstract: Many tools used to process programs, like compilers, analyzers, or verifiers, perform transformations on their intermediate program representation, like abstract syntax trees. Implementing such program transformations is a non-trivial task, since it is necessary to iterate over the complete syntax tree and apply various transformations at nodes in a tree. In this paper we show how the features of functional logic programming are useful to implement program transformations in a compact and comprehensible manner. For this purpose, we propose to write program transformations as partially defined and non-deterministic operations. Since the implementation of non-determinism usually causes some overhead compared to deterministically defined operations, we compare our approach to a deterministic transformation method. We evaluate these alternatives for the functional logic language Curry and its intermediate representation FlatCurry which is used in various analysis and verification tools and compilers.

</details>


### [6] [Reduction for Structured Concurrent Programs](https://arxiv.org/abs/2601.13341)
*Namratha Gangamreddypalli,Constantin Enea,Shaz Qadeer*

Main category: cs.PL

TL;DR: 提出一种新的结构化并发程序归约技术，统一了两种关键进展：将并行组合替换为顺序组合，以及扩展Lipton归约以支持包含（可能递归）过程调用的原子段。


<details>
  <summary>Details</summary>
Motivation: 基于Lipton移动子的交换性推理是验证并发程序的强大技术，但将其扩展到软件系统中常规使用的特性（如过程和并行组合）仍然是一个重大挑战。

Method: 引入一种新颖的归约技术，包含两个关键进展：1）将并行组合安全地替换为顺序组合的归约策略；2）将Lipton归约推广到支持包含（可能递归）过程调用的原子段。这两种基础策略可以任意组合。

Result: 在Civl中实现了该技术，并在多个具有挑战性的案例研究中证明了其有效性，包括快照对象、容错线性化寄存器、FLASH缓存一致性协议和非平凡的Two-Phase Commit变体。

Conclusion: 该工作通过统一两种基础归约策略，极大地扩展了基于归约的推理的范围和灵活性，能够处理包含过程和并行组合的复杂并发程序验证。

Abstract: Commutativity reasoning based on Lipton's movers is a powerful technique for verification of concurrent programs. The idea is to define a program transformation that preserves a subset of the initial set of interleavings, which is sound modulo reorderings of commutative actions. Scaling commutativity reasoning to routinely-used features in software systems, such as procedures and parallel composition, remains a significant challenge.
  In this work, we introduce a novel reduction technique for structured concurrent programs that unifies two key advances. First, we present a reduction strategy that soundly replaces parallel composition with sequential composition. Second, we generalize Lipton's reduction to support atomic sections containing (potentially recursive) procedure calls. Crucially, these two foundational strategies can be composed arbitrarily, greatly expanding the scope and flexibility of reduction-based reasoning. We implemented this technique in Civl and demonstrated its effectiveness on a number of challenging case studies, including a snapshot object, a fault-tolerant and linearizable register, the FLASH cache coherence protocol, and a non-trivial variant of Two-Phase Commit.

</details>


### [7] [Foundational VeriFast: Pragmatic Certification of Verification Tool Results through Hinted Mirroring](https://arxiv.org/abs/2601.13727)
*Bart Jacobs*

Main category: cs.PL

TL;DR: 将VeriFast验证工具扩展为在成功验证Rust程序后生成Rocq证明脚本，通过记录符号执行信息并在Rocq中重放，增强工具在安全关键领域的适用性。


<details>
  <summary>Details</summary>
Motivation: VeriFast作为领先的形式验证工具，其本身约3万行OCaml代码未经形式验证，可能存在导致错误报告程序正确性的bug。这限制了其在安全关键领域的应用。

Method: 采用"提示镜像"方法：记录VeriFast符号执行过程中的关键信息，使用这些信息在Rocq中重放执行过程，生成Rocq证明脚本来证明程序相对于Rocq编码的Rust公理语义的正确性。

Result: 成功扩展VeriFast，使其在验证Rust程序后能够生成Rocq证明脚本，显著增强了工具在安全关键领域的适用性。

Conclusion: 通过将VeriFast验证结果转换为Rocq证明，解决了工具本身未经验证的问题，提高了验证结果的可信度，特别适用于安全关键应用领域。

Abstract: VeriFast is a leading tool for the modular formal verification of correctness properties of single-threaded and multi-threaded C and Rust programs. It verifies a program by symbolically executing each function in isolation, exploiting user-annotated preconditions, postconditions, and loop invariants written in a form of separation logic, and using a separation logic-based symbolic representation of memory. However, the tool itself, written in roughly 30K lines of OCaml code, has not been formally verified. Therefore, bugs in the tool could cause it to falsely report the correctness of the input program. We here report on an early result extending VeriFast to emit, upon successful verification of a Rust program, a Rocq proof script that proves correctness of the program with respect to a Rocq-encoded axiomatic semantics of Rust. This significantly enhances VeriFast's applicability in safety-critical domains. We apply hinted mirroring: we record key information from VeriFast's symbolic execution run, and use it to direct a replay of the run in Rocq.

</details>


### [8] [Generating Functions Meet Occupation Measures: Invariant Synthesis for Probabilistic Loops (Extended Version)](https://arxiv.org/abs/2601.13991)
*Darion Haase,Kevin Batz,Adrian Gallus,Benjamin Lucien Kaminski,Joost-Pieter Katoen,Lutz Klinkenberg,Tobias Winkler*

Main category: cs.PL

TL;DR: 论文提出基于占用不变量的精确概率推理方法，用于带循环的程序，通过自动模板合成实现


<details>
  <summary>Details</summary>
Motivation: 概率编程中的核心计算任务是从先验分布推断后验分布，对于包含循环或无限递归的表达性语言尤其困难。现有文献主要关注统计近似，本文致力于解决数学上精确推理的问题。

Method: 引入占用测度概念，关联程序状态与其期望访问次数，基于此定义占用不变量。提出自动模板合成方法，将占用不变量编码为生成函数进行求解。

Result: 实现了基于占用不变量的自动推理方法，并在基准测试集上进行了评估验证。

Conclusion: 占用不变量为概率循环分析提供了新的有效方法，能够考虑初始分布并自动获得几乎必然终止性证明，是概率程序精确推理的重要进展。

Abstract: A fundamental computational task in probabilistic programming is to infer a program's output (posterior) distribution from a given initial (prior) distribution. This problem is challenging, especially for expressive languages that feature loops or unbounded recursion. While most of the existing literature focuses on statistical approximation, in this paper we address the problem of mathematically exact inference.
  To achieve this for programs with loops, we rely on a relatively underexplored type of probabilistic loop invariant, which is linked to a loop's so-called occupation measure. The occupation measure associates program states with their expected number of visits, given the initial distribution. Based on this, we derive the notion of an occupation invariant. Such invariants are essentially dual to probabilistic martingales, the predominant technique for formal probabilistic loop analysis in the literature. A key feature of occupation invariants is that they can take the initial distribution into account and often yield a proof of positive almost sure termination as a by-product.
  Finally, we present an automatic, template-based invariant synthesis approach for occupation invariants by encoding them as generating functions. The approach is implemented and evaluated on a set of benchmarks.

</details>


### [9] [Verifying Floating-Point Programs in Stainless](https://arxiv.org/abs/2601.14059)
*Andrea Gilot,Axel Bergström,Eva Darulova*

Main category: cs.PL

TL;DR: 将Stainless验证器扩展支持浮点数，为包含多态、递归和高阶函数的Scala子集提供首个自动化浮点数验证支持


<details>
  <summary>Details</summary>
Motivation: 现有的Stainless验证器缺乏对浮点数的支持，而浮点数在现实世界代码中广泛使用，需要自动化验证工具来确保浮点运算的正确性

Method: 采用KeY验证器的方法对数学函数进行公理化，但进一步支持Scala math API中的所有函数，并在Stainless自身中验证公理的正确性

Result: 在从GitHub真实代码采样的新基准测试集上验证了浮点支持，能够验证输出范围、特殊值缺失等规范，或在规范不成立时生成反例

Conclusion: 成功扩展了Stainless验证器的浮点数支持，为Scala程序提供了首个自动化浮点数验证能力，填补了该领域的空白

Abstract: We extend the Stainless deductive verifier with floating-point support, providing the first automated verification support for floating-point numbers for a subset of Scala that includes polymorphism, recursion and higher-order functions. We follow the recent approach in the KeY verifier to axiomatise reasoning about mathematical functions, but go further by supporting all functions from Scala's math API, and by verifying the correctness of the axioms against the actual implementation in Stainless itself. We validate Stainless' floating-point support on a new set of benchmarks sampled from real-world code from GitHub, showing that it can verify specifications about, e.g., ranges of output or absence of special values for most supported functions, or produce counter-examples when the specifications do not hold.

</details>


### [10] [Partial Reductions for Kleene Algebra with Linear Hypotheses](https://arxiv.org/abs/2601.14114)
*Liam Chung,Tobias Kappé*

Main category: cs.PL

TL;DR: 提出一种基于自动机的构造方法，可自动生成Kleene代数的归约函数，用于证明特定程序等价性，支持偏归约和偏完备性。


<details>
  <summary>Details</summary>
Motivation: 传统Kleene代数（KA）能证明一般程序等价性，但无法证明特定程序间的等价性。需要添加假设来编码程序特定知识，但手动构造归约函数工作量大，且由于正则性约束，并非所有表达式和假设组合都存在归约函数。

Method: 提出基于自动机的构造方法，可机械地推导出广泛类别假设的归约函数。这些归约可以是偏归约，在其定义域内具有偏完备性。

Result: 该方法能自动建立比现有工作覆盖更多等价性的可证明性，支持偏归约从而扩展了适用范围。

Conclusion: 提出的自动机构造方法能自动生成归约函数，解决了传统方法需要手动构造的问题，扩展了Kleene代数在程序等价性证明中的应用范围。

Abstract: Kleene algebra (KA) is an important tool for reasoning about general program equivalences, with a decidable and complete equational theory. However, KA cannot always prove equivalences between specific programs. For this purpose, one adds hypotheses to KA that encode program-specific knowledge. Traditionally, a map on regular expressions called a reduction then lets us lift decidability and completeness to these more expressive systems. Explicitly constructing such a reduction requires significant labour. Moreover, due to regularity constraints, a reduction may not exist for all combinations of expression and hypothesis.
  We describe an automaton-based construction to mechanically derive reductions for a wide class of hypotheses. These reductions can be partial, in which case they yield partial completeness: completeness for expressions in their domain. This allows us to automatically establish the provability of more equivalences than what is covered in existing work.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [11] [Verifying First-Order Temporal Properties of Infinite-State Systems via Timers and Rankings](https://arxiv.org/abs/2601.13325)
*Raz Lotan,Neta Elad,Oded Padon,Sharon Shoham*

Main category: cs.LO

TL;DR: 提出基于良基排序的一阶时序属性统一演绎验证框架，将任意时序属性验证归约为终止性验证，使用预言计时器变量和隐式排序技术，无需公平性假设，通过SMT求解器自动验证。


<details>
  <summary>Details</summary>
Motivation: 现有时序验证方法通常基于表结构归约，需要引入公平性假设，且验证过程复杂。本文旨在开发一个统一的演绎验证框架，能够处理任意一阶时序属性，避免公平性假设，并利用SMT求解器实现自动化验证。

Method: 1. 提出新颖归约方法：将任意时序属性验证转化为终止性验证，引入预言计时器变量预测时序公式成立前的步数；2. 扩展隐式排序技术：从有限域扩展到无限域，支持更一般的系统；3. 利用良基排序：为每个状态分配良基集合中的秩，证明每次转换秩都减小；4. 集成SMT求解器：自动验证秩的减小，即使秩无法用一阶逻辑表达。

Result: 1. 成功开发了统一的时序验证框架；2. 避免了传统方法中的公平性假设；3. 能够处理更一般的系统和时序属性；4. 在先前工作的多个时序验证任务上进行了评估，提供了简单直观的证明；5. 实现了自动化验证，利用计时器的减小简化终止性证明。

Conclusion: 本文提出了一个基于良基排序的一阶时序属性统一演绎验证框架，通过将时序验证归约为终止性验证，引入预言计时器变量和扩展隐式排序技术，实现了无需公平性假设的自动化验证。该方法在多个基准测试中表现出有效性，为时序验证提供了简单直观的解决方案。

Abstract: We present a unified deductive verification framework for first-order temporal properties based on well-founded rankings, where verification conditions are discharged using SMT solvers. To that end, we introduce a novel reduction from verification of arbitrary temporal properties to verification of termination. Our reduction augments the system with prophecy timer variables that predict the number of steps along a trace until the next time certain temporal formulas, including the negated property, hold. In contrast to standard tableaux-based reductions, which reduce the problem to fair termination, our reduction does not introduce fairness assumptions. To verify termination of the augmented system, we follow the traditional approach of assigning each state a rank from a well-founded set and showing that the rank decreases in every transition. We leverage the recently proposed formalism of implicit rankings to express and automatically verify the decrease of rank using SMT solvers, even when the rank is not expressible in first-order logic. We extend implicit rankings from finite to infinite domains, enabling verification of more general systems and making them applicable to the augmented systems generated by our reduction, which allows us to exploit the decrease of timers in termination proofs. We evaluate our technique on a range of temporal verification tasks from previous works, giving simple, intuitive proofs for them within our framework.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [12] [Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility](https://arxiv.org/abs/2601.13398)
*Nickil Maveli,Antonio Vergari,Shay B. Cohen*

Main category: cs.LG

TL;DR: 论文提出RoundTripCodeEval基准测试，评估LLMs在代码双向执行中的一致性，发现现有模型在保持编码-解码双向映射一致性方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 虽然LLMs在代码基准测试中表现良好，但在双向代码执行中暴露出推理一致性的局限性。现有基准测试无法充分评估模型在编码和解码操作之间保持一对一映射的能力。

Method: 提出RTCE基准测试，包含四个不同的代码执行推理任务，采用无需执行的精确匹配评估方法。系统评估了最先进的Code-LLMs，包括零样本提示、基于执行轨迹的监督微调和自反思机制。

Result: 所有评估方法都只带来有限的改进，无法完全解决双向一致性问题。这表明当前LLMs缺乏真正的双向一致性，不具备可信代码推理所需的内在连贯性。

Conclusion: RTCE揭示了现有I/O预测、执行推理或自然语言双向基准测试无法捕捉的新见解。LLMs在代码双向一致性方面存在根本性缺陷，需要新的方法来提升代码推理的可信度。

Abstract: LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [13] [Identification capacity and rate-query tradeoffs in classification systems](https://arxiv.org/abs/2601.14252)
*Tristan Simas*

Main category: cs.IT

TL;DR: 研究离散分类中的一次性识别问题，考虑三个资源：标签率L（每个实体存储的侧信息比特数）、识别成本W（每次识别所需的属性成员查询次数）和失真D（误分类概率），旨在刻画可实现的(L,W,D)三元组。


<details>
  <summary>Details</summary>
Motivation: 研究在有限观测条件下从实体属性中恢复其类别的识别问题，探索标签、查询成本和分类精度之间的权衡关系，为类型系统、数据库和生物分类学等应用提供理论基础。

Method: 采用信息论和组合数学方法，分析零误差可行性阈值，建立可达性和逆定理，利用拟阵理论描述最小充分查询族，通过图熵与零误差源编码建立联系。

Result: 1) 零误差可行性：若属性映射在类别上非单射，则无标签时零误差识别不可能；2) D=0时：需要L≥log₂k比特标签才能实现O(1)识别成本；3) L=0时：最坏情况下需要Ω(n)查询且可能D>0；4) 组合结构：最小充分查询族构成拟阵基。

Conclusion: 建立了离散分类中一次性识别的资源权衡理论框架，揭示了标签、查询成本和分类精度之间的基本限制关系，所有结果在Lean4中形式化验证（6000+行代码，无未证明声明）。

Abstract: We study a one-shot identification analogue of rate-distortion for discrete classification under three resources: tag rate L (bits of side information stored per entity), identification cost W (attribute-membership queries per identification, excluding global preprocessing and amortized caching), and distortion D (misclassification probability). The question is to characterize achievable triples (L,W,D) when a decoder must recover an entity's class from limited observations. Zero-error barrier. If two distinct classes induce the same attribute profile, then the observation pi(V) is identical for both and no decoder can identify the class from attribute queries alone. Thus, if the profile map pi is not injective on classes, zero-error identification without tags is impossible (a zero-error feasibility threshold). Achievability and converse at D=0. With k classes, nominal tags of L = ceil(log2 k) bits enable O(1) identification cost with D=0. Conversely, any scheme with D=0 must satisfy L >= log2 k bits (tight). Without tags (L=0), identification requires Omega(n) queries in the worst case and may incur D>0. Combinatorial structure. Minimal sufficient query families form the bases of a matroid; the induced distinguishing dimension is well-defined and links to zero-error source coding via graph entropy. We illustrate implications for type systems, databases, and biological taxonomy. All results are mechanized in Lean4 (6000+ lines, 0 sorry).

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [14] [CodeContests-O: Powering LLMs via Feedback-Driven Iterative Test Case Generation](https://arxiv.org/abs/2601.13682)
*Jianfeng Cai,Jinhua Zhu,Ruopei Sun,Kangwen Zhao,Dongyun Xue,Mingxiao Feng,Wengang Zhou,Houqiang Li*

Main category: cs.SE

TL;DR: 提出反馈驱动的迭代框架，用于构建高质量的编程测试用例，显著提升了测试集的质量和模型性能


<details>
  <summary>Details</summary>
Motivation: 推理模型需要大规模可验证数据，编程任务是理想来源。但现有竞争编程平台缺乏高质量测试用例，现有LLM生成方法依赖模型内在能力，缺乏外部反馈，导致测试用例多样性不足。

Method: 提出反馈驱动的迭代框架：1) 用LLM生成初始测试用例；2) 在正确和错误解决方案上执行测试；3) 利用失败结果作为反馈指导LLM优化测试用例，提高保真度和区分度。将此方法应用于CodeContests数据集构建优化版本CodeContests-O。

Result: CodeContests-O在1100万个解决方案上评估，平均真阳性率89.37%，真阴性率90.89%，分别比CodeContests和CodeContests+提升4.32%和9.37%。在CodeContests-O上微调Qwen2.5-7B模型，LiveCodeBench (Pass@1)提升9.52%。

Conclusion: 提出的反馈驱动迭代框架有效提升了测试用例质量，构建的CodeContests-O数据集显著优于现有基准。开源代码和数据集支持可复现性和未来研究。

Abstract: The rise of reasoning models necessitates large-scale verifiable data, for which programming tasks serve as an ideal source. However, while competitive programming platforms provide abundant problems and solutions, high-quality test cases for verification remain scarce. Existing approaches attempt to synthesize test cases using Large Language Models (LLMs), but rely solely on the model's intrinsic generation capabilities without external feedback, frequently resulting in insufficiently diverse cases. To address this limitation, we propose a $\textbf{Feedback-Driven Iterative Framework}$ for comprehensive test case construction. Specifically, our method leverages the LLM to generate initial test cases, executes them against known correct and incorrect solutions, and utilizes the failed results as feedback to guide the LLM in refining the test cases toward high fidelity and discriminability. We then apply this method to the CodeContests dataset to construct an optimized high-quality derivative, $\textbf{CodeContests-O}$. Evaluating against the entire pool of solutions ($1.1 \times 10^7$ in total), our dataset achieves an average True Positive Rate (TPR) of $89.37\%$ and True Negative Rate (TNR) of $90.89\%$, significantly outperforming the CodeContests and CodeContests+ by margins of $4.32\%$ and $9.37\%$, respectively. Furthermore, fine-tuning the Qwen2.5-7B model on CodeContests-O results in a $9.52\%$ improvement on LiveCodeBench (Pass@1). Experiments demonstrate the effectiveness of our framework and the quality of CodeContests-O. To support reproducibility and facilitate future research, we release the $\href{https://github.com/cai-jianfeng/CodeContests-O}{code}$ and $\href{https://huggingface.co/datasets/caijanfeng/CodeContests-O}{dataset}$.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [15] [SplittingSecrets: A Compiler-Based Defense for Preventing Data Memory-Dependent Prefetcher Side-Channels](https://arxiv.org/abs/2601.12270)
*Reshabh K Sharma,Dan Grossman,David Kohlbrenner*

Main category: cs.CR

TL;DR: SplittingSecrets是一个基于编译器的工具，通过防止秘密数据在内存中以地址形式存储，来防御数据内存依赖预取器(DMP)引起的侧信道攻击。


<details>
  <summary>Details</summary>
Motivation: 传统恒定时间编程防御对新型硬件优化——数据内存依赖预取器(DMP)无效。DMP使用内存内容和访问模式来确定预取目标，攻击者可利用DMP泄露静态数据，即使程序从未以不安全方式使用这些数据。

Method: SplittingSecrets通过编译器转换内存操作，确保秘密数据永远不会以地址形式存储在内存中，从而避免DMP激活。该方法不依赖DMP内部复杂机制，而是利用所有DMP都需要数据类似地址才能激活这一关键特性。

Result: 使用LLVM实现SplittingSecrets，支持AArch64架构的源代码级内存操作和编译器后端生成的操作。在Apple M系列CPU上评估了libsodium加密库常见原语的性能开销。

Conclusion: SplittingSecrets提供了一种软件层面的针对性加固方案，可在不完全禁用DMP的情况下保护特定秘密数据免受DMP诱导的侧信道攻击。

Abstract: Traditional side-channels take advantage of secrets being used as inputs to unsafe instructions, used for memory accesses, or used in control flow decisions. Constant-time programming, which restricts such code patterns, has been widely adopted as a defense against these vulnerabilities. However, new hardware optimizations in the form of Data Memory-dependent Prefetchers (DMP) present in Apple, Intel, and ARM CPUs have shown such defenses are not sufficient. These prefetchers, unlike classical prefetchers, use the content of memory as well as the trace of prior accesses to determine prefetch targets. An adversary abusing such a prefetcher has been shown to be able to mount attacks leaking data-at-rest; data that is never used by the program, even speculatively, in an unsafe manner.
  In response, this paper introduces SplittingSecrets, a compiler-based tool that can harden software libraries against side-channels arising from DMPs. SplittingSecrets's approach avoids reasoning about the complex internals of different DMPs and instead relies on one key aspect of all DMPs: activation requires data to resemble addresses. To prevent secret data from leaking, SplittingSecrets transforms memory operations to ensure that secrets are never stored in memory in a manner resembling an address, thereby avoiding DMP activation on those secrets. Rather than disable a DMP entirely, SplittingSecrets can provide targeted hardening for only specific secrets entirely in software.
  We have implemented SplittingSecrets using LLVM, supporting both source-level memory operations and those generated by the compiler backend for the AArch64 architecture, We have analyzed the performance overhead involved in safeguarding secrets from DMP-induced attacks using common primitives in libsodium, a popular cryptographic library when built for Apple M-series CPUs.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [16] [CPU-less parallel execution of lambda calculus in digital logic](https://arxiv.org/abs/2601.13040)
*Harry Fitchett,Charles Fox*

Main category: cs.DC

TL;DR: 该论文提出了一种将函数式语言直接编译为数字逻辑的CPU-less并行计算架构，使用λ演算作为源语言，通过树形表示和消息传递实现并行β规约。


<details>
  <summary>Details</summary>
Motivation: 随着晶体管密度持续增加而时钟速度不再提升，需要寻找新的并行架构。传统CPU并行编译器仍受冯·诺依曼瓶颈限制，因此探索完全放弃CPU概念，将函数式语言直接编译为数字逻辑以最大化并行性。

Method: 使用λ演算作为源语言，采用树形表示法，数据本地化存储在节点中，通过总线进行消息传递。节点类型和行为对应λ语法形式，并行执行β规约，使独立分支能同时进行变换。

Result: 实现了原型系统并进行了仿真，成功执行了λ表达式测试套件，证明了该方法的可行性，表明可以扩展到更大的函数式语言。

Conclusion: 该研究为CPU-less函数式计算提供了新的模型基础，展示了将函数式语言直接编译为数字逻辑以实现最大化并行的可行性，为扩展到更完整的函数式语言奠定了基础。

Abstract: While transistor density is still increasing, clock speeds are not, motivating the search for new parallel architectures. One approach is to completely abandon the concept of CPU -- and thus serial imperative programming -- and instead to specify and execute tasks in parallel, compiling from programming languages to data flow digital logic. It is well-known that pure functional languages are inherently parallel, due to the Church-Rosser theorem, and CPU-based parallel compilers exist for many functional languages. However, these still rely on conventional CPUs and their von Neumann bottlenecks. An alternative is to compile functional languages directly into digital logic to maximize available parallelism. It is difficult to work with complete modern functional languages due to their many features, so we demonstrate a proof-of-concept system using lambda calculus as the source language and compiling to digital logic. We show how functional hardware can be tailored to a simplistic functional language, forming the ground for a new model of CPU-less functional computation. At the algorithmic level, we use a tree-based representation, with data localized within nodes and communicated data passed between them. This is implemented by physical digital logic blocks corresponding to nodes, and buses enabling message passing. Node types and behaviors correspond to lambda grammar forms, and beta-reductions are performed in parallel allowing branches independent from one another to perform transformations simultaneously. As evidence for this approach, we present an implementation, along with simulation results, showcasing successful execution of lambda expressions. This suggests that the approach could be scaled to larger functional languages. Successful execution of a test suite of lambda expressions suggests that the approach could be scaled to larger functional languages.

</details>
