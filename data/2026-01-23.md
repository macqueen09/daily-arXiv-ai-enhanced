<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Remarks on Algebraic Reconstruction of Types and Effects](https://arxiv.org/abs/2601.15455)
*Patrycja Balik,Szymon Jędras,Piotr Polesiuk*

Main category: cs.PL

TL;DR: 该论文指出Jouvelot和Gifford 1991年开创性类型与效应重建算法中存在与高阶多态性相关的变量绑定细微错误，并重新审视了其类型系统和重建算法。


<details>
  <summary>Details</summary>
Motivation: Jouvelot和Gifford 1991年的论文"Algebraic Reconstruction of Types and Effects"被认为是类型与效应系统发展的里程碑，启发了后续大量静态分析研究。然而，与后续研究不同，原始算法考虑了具有高阶多态性的语言，这一特性难以正确实现。作者发现该算法在处理这一特性时存在变量绑定的细微错误。

Method: 重新审视Jouvelot和Gifford的类型系统和重建算法，识别并描述其中与高阶多态性相关的变量绑定问题。

Result: 发现了原始算法中与变量绑定相关的细微错误，这些错误源于对高阶多态性处理的复杂性。

Conclusion: 虽然Jouvelot和Gifford的算法是类型与效应系统的重要里程碑，但在处理高阶多态性时存在需要修正的细微错误，这些发现有助于完善该领域的理论基础。

Abstract: In their 1991 paper "Algebraic Reconstruction of Types and Effects," Pierre Jouvelot and David Gifford presented a type-and-effect reconstruction algorithm based on an algebraic structure of effects. Their work is considered a milestone in the development of type-and-effect systems, and has inspired numerous subsequent works in the area of static analysis. However, unlike the later research it spawned, the original algorithm considered a language with higher-rank polymorphism, a feature which is challenging to implement correctly. In this note, we identify subtle bugs related to variable binding in their approach to this feature. We revisit their type system and reconstruction algorithm, and describe the discovered issues.

</details>


### [2] [Prioritizing Configuration Relevance via Compiler-Based Refined Feature Ranking](https://arxiv.org/abs/2601.16008)
*Federico Bruzzone,Walter Cazzola,Luca Favini*

Main category: cs.PL

TL;DR: 提出首个基于编译器的Rust配置优先级排序方法，通过中间表示提取、图数据结构构建、中心性度量和代码影响分析来生成最相关配置，确保配置有效性。


<details>
  <summary>Details</summary>
Motivation: 现代编程语言（特别是Rust）支持高度可配置的软件系统，但配置组合爆炸给程序分析、优化和测试带来巨大挑战，使得穷举探索不可行。

Method: 1. 从Rust编译器提取定制中间表示；2. 构建两种互补的图数据结构；3. 使用中心性度量对特征排序；4. 考虑代码影响范围细化排序；5. 基于SAT求解器生成有效配置。

Result: 在开源Rust项目中，RustyEx原型能在有限资源内高效生成用户指定的配置集，同时确保构造的正确性，证明中心性引导的配置优先级排序是有效实用的。

Conclusion: 中心性引导的配置优先级排序实现了大型配置空间的有效探索，为配置感知分析和优化的未来研究铺平了道路。

Abstract: Modern programming languages, most notably Rust, offer advanced linguistic constructs for building highly configurable software systems as aggregation of features -- identified by a configuration. However, they pose substantial challenges for program analysis, optimization, and testing, as the combinatorial explosion of configurations often makes exhaustive exploration infeasible. In this manuscript, we present the first compiler-based method for prioritizing configurations. Our approach consists of four main steps: 1. extracting a tailored intermediate representation from the Rust compiler, 2. constructing two complementary graph-based data structures, 3. using centrality measures to rank features, and 4. refining the ranking by considering the extent of code they impact. A fixed number of most relevant configurations are generated based on the achieved feature ranking. The validity of the generated configurations is guaranteed by using a SAT solver that takes a representation of this graph in conjunctive normal form. We formalized this approach and implemented it in a prototype, RustyEx, by instrumenting the Rust compiler. An empirical evaluation on higher-ranked open source Rust projects shows that RustyEx efficiently generates user-specified sets of configurations within bounded resources, while ensuring soundness by construction. The results demonstrate that centrality-guided configuration prioritization enables effective and practical exploration of large configuration spaces, paving the way for future research in configuration-aware analysis and optimization.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [3] [KnowTeX: Visualizing Mathematical Dependencies](https://arxiv.org/abs/2601.15294)
*Elif Uskuplu,Lawrence S. Moss,Valeria de Paiva*

Main category: cs.HC

TL;DR: KnowTeX是一个从LaTeX源码提取数学陈述依赖关系并生成可视化依赖图的工具，为数学写作提供中间表示形式。


<details>
  <summary>Details</summary>
Motivation: 数学知识存在多种形式（从非正式教材到形式化证明库），但这些表示之间的转换很困难。非正式文本隐藏依赖关系，而形式化系统暴露过多细节且不易阅读。依赖图可以提供中间表示，使结果、定义和证明的结构可视化。

Method: 开发KnowTeX工具，扩展Lean Blueprints的思想，直接从LaTeX源码中提取依赖关系。通过简单的"uses"命令提取陈述之间的关系，并生成DOT和TikZ格式的可预览依赖图。

Result: KnowTeX能够应用于数学文本，生成的依赖图可以澄清核心结果、支持教育和形式化工作，并为对齐非正式和形式化数学表示提供资源。

Conclusion: 依赖图应该成为数学写作的标准功能，既有利于人类读者，也有利于自动化系统。KnowTeX为实现这一目标提供了实用工具。

Abstract: Mathematical knowledge exists in many forms, ranging from informal textbooks and lecture notes to large formal proof libraries, yet moving between these representations remains difficult. Informal texts hide dependencies, while formal systems expose every detail in ways that are not always human-readable. Dependency graphs offer a middle ground by making visible the structure of results, definitions, and proofs. We present KnowTeX, a standalone, user-friendly tool that extends the ideas of Lean's Blueprints, enabling the visualization of conceptual dependencies directly from LaTeX sources. Using a simple "uses" command, KnowTeX extracts relationships among statements and generates previewable graphs in DOT and TikZ formats. Applied to mathematical texts, such graphs clarify core results, support education and formalization, and provide a resource for aligning informal and formal mathematical representations. We argue that dependency graphs should become a standard feature of mathematical writing, benefiting both human readers and automated systems.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [ToolCaching: Towards Efficient Caching for LLM Tool-calling](https://arxiv.org/abs/2601.15335)
*Yi Zhai,Dian Shen,Junzhou Luo,Bin Yang*

Main category: cs.SE

TL;DR: ToolCaching：针对LLM工具调用系统的特征驱动自适应缓存框架，通过VAAC算法提高缓存命中率并降低延迟


<details>
  <summary>Details</summary>
Motivation: LLM工具调用系统中存在冗余或重复的工具调用请求问题，传统缓存策略因请求语义异构、动态工作负载和不同新鲜度要求而失效，需要专门解决方案

Method: 提出ToolCaching框架，集成语义和系统级特征评估请求可缓存性和缓存价值；核心VAAC算法结合基于bandit的准入和基于价值的多因素淘汰策略

Result: 在合成和公开工具调用工作负载上，ToolCaching相比标准策略实现高达11%的缓存命中率提升和34%的延迟降低

Conclusion: ToolCaching能有效加速LLM工具调用在实际应用中的性能，解决了传统缓存策略在LLM工具调用场景中的局限性

Abstract: Recent advances in Large Language Models (LLMs) have revolutionized web applications, enabling intelligent search, recommendation, and assistant services with natural language interfaces. Tool-calling extends LLMs with the ability to interact with external APIs, greatly enhancing their practical utility. While prior research has improved tool-calling performance by adopting traditional computer systems techniques, such as parallel and asynchronous execution, the challenge of redundant or repeated tool-calling requests remains largely unaddressed. Caching is a classic solution to this problem, but applying it to LLM tool-calling introduces new difficulties due to heterogeneous request semantics, dynamic workloads, and varying freshness requirements, which render conventional cache policies ineffective. To address these issues, we propose ToolCaching, an efficient feature-driven and adaptive caching framework for LLM tool-calling systems. ToolCaching systematically integrates semantic and system-level features to evaluate request cacheability and estimate caching value. At its core, the VAAC algorithm integrates bandit-based admission with value-driven, multi-factor eviction, jointly accounting for request frequency, recency, and caching value. Extensive experiments on synthetic and public tool-calling workloads demonstrate that ToolCaching with VAAC achieves up to 11% higher cache hit ratios and 34% lower latency compared to standard policies, effectively accelerating LLM tool-calling in practical applications.

</details>
