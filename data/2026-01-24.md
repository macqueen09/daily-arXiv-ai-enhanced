<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Remarks on Algebraic Reconstruction of Types and Effects](https://arxiv.org/abs/2601.15455)
*Patrycja Balik,Szymon Jędras,Piotr Polesiuk*

Main category: cs.PL

TL;DR: 该论文指出Jouvelot和Gifford 1991年开创性类型与效应系统论文中的算法存在与高阶多态性相关的变量绑定错误，并重新审视了其类型系统和重建算法。


<details>
  <summary>Details</summary>
Motivation: Jouvelot和Gifford 1991年的论文是类型与效应系统的里程碑工作，启发了大量后续研究。然而，与后来研究不同的是，原始算法考虑了具有高阶多态性的语言，这一特性难以正确实现。本文旨在识别该算法中与变量绑定相关的微妙错误。

Method: 重新审视Jouvelot和Gifford的类型系统和重建算法，分析其处理高阶多态性的方法，识别变量绑定相关的错误，并描述发现的问题。

Result: 发现了原始算法中与变量绑定相关的微妙错误，这些错误源于对高阶多态性的处理方式。论文详细描述了这些发现的问题。

Conclusion: 虽然Jouvelot和Gifford的原始工作是类型与效应系统的开创性贡献，但其算法在处理高阶多态性时存在变量绑定错误，这些错误需要被识别和纠正。

Abstract: In their 1991 paper "Algebraic Reconstruction of Types and Effects," Pierre Jouvelot and David Gifford presented a type-and-effect reconstruction algorithm based on an algebraic structure of effects. Their work is considered a milestone in the development of type-and-effect systems, and has inspired numerous subsequent works in the area of static analysis. However, unlike the later research it spawned, the original algorithm considered a language with higher-rank polymorphism, a feature which is challenging to implement correctly. In this note, we identify subtle bugs related to variable binding in their approach to this feature. We revisit their type system and reconstruction algorithm, and describe the discovered issues.

</details>


### [2] [Prioritizing Configuration Relevance via Compiler-Based Refined Feature Ranking](https://arxiv.org/abs/2601.16008)
*Federico Bruzzone,Walter Cazzola,Luca Favini*

Main category: cs.PL

TL;DR: 提出首个基于编译器的Rust配置优先级排序方法，通过中间表示提取、图结构构建、中心性度量和代码影响范围分析来生成最相关配置，解决配置组合爆炸问题。


<details>
  <summary>Details</summary>
Motivation: 现代编程语言（特别是Rust）提供了高级语言构造来构建高度可配置的软件系统，但配置的组合爆炸使得程序分析、优化和测试的穷尽探索变得不可行。

Method: 1) 从Rust编译器提取定制中间表示；2) 构建两个互补的图数据结构；3) 使用中心性度量对特征排序；4) 考虑代码影响范围细化排序。基于特征排序生成固定数量的最相关配置，使用SAT求解器保证配置有效性。

Result: 在RustyEx原型中实现，对高排名开源Rust项目的实证评估显示，该方法能在有限资源内高效生成用户指定的配置集，同时通过构造保证正确性。

Conclusion: 中心性引导的配置优先级排序能够实现大型配置空间的有效和实用探索，为配置感知分析和优化的未来研究铺平道路。

Abstract: Modern programming languages, most notably Rust, offer advanced linguistic constructs for building highly configurable software systems as aggregation of features -- identified by a configuration. However, they pose substantial challenges for program analysis, optimization, and testing, as the combinatorial explosion of configurations often makes exhaustive exploration infeasible. In this manuscript, we present the first compiler-based method for prioritizing configurations. Our approach consists of four main steps: 1. extracting a tailored intermediate representation from the Rust compiler, 2. constructing two complementary graph-based data structures, 3. using centrality measures to rank features, and 4. refining the ranking by considering the extent of code they impact. A fixed number of most relevant configurations are generated based on the achieved feature ranking. The validity of the generated configurations is guaranteed by using a SAT solver that takes a representation of this graph in conjunctive normal form. We formalized this approach and implemented it in a prototype, RustyEx, by instrumenting the Rust compiler. An empirical evaluation on higher-ranked open source Rust projects shows that RustyEx efficiently generates user-specified sets of configurations within bounded resources, while ensuring soundness by construction. The results demonstrate that centrality-guided configuration prioritization enables effective and practical exploration of large configuration spaces, paving the way for future research in configuration-aware analysis and optimization.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [3] [KnowTeX: Visualizing Mathematical Dependencies](https://arxiv.org/abs/2601.15294)
*Elif Uskuplu,Lawrence S. Moss,Valeria de Paiva*

Main category: cs.HC

TL;DR: KnowTeX：一个从LaTeX源码可视化数学概念依赖关系的工具，作为非正式文本与形式化系统之间的桥梁


<details>
  <summary>Details</summary>
Motivation: 数学知识存在于多种形式（从非正式教材到形式化证明库），但这些表示形式之间的转换很困难。非正式文本隐藏依赖关系，而形式化系统暴露所有细节但不够人性化。依赖图提供了一个中间方案，能够可视化结果、定义和证明的结构。

Method: 开发KnowTeX工具，扩展Lean的Blueprints思想，直接从LaTeX源码中提取概念依赖关系。使用简单的"uses"命令提取语句间的关系，并生成可预览的DOT和TikZ格式的依赖图。

Result: 应用于数学文本时，依赖图能够澄清核心结果、支持教育和形式化工作，并为对齐非正式和形式化数学表示提供资源。该工具是独立的、用户友好的。

Conclusion: 依赖图应该成为数学写作的标准功能，既有利于人类读者，也有利于自动化系统。KnowTeX为实现这一目标提供了实用工具。

Abstract: Mathematical knowledge exists in many forms, ranging from informal textbooks and lecture notes to large formal proof libraries, yet moving between these representations remains difficult. Informal texts hide dependencies, while formal systems expose every detail in ways that are not always human-readable. Dependency graphs offer a middle ground by making visible the structure of results, definitions, and proofs. We present KnowTeX, a standalone, user-friendly tool that extends the ideas of Lean's Blueprints, enabling the visualization of conceptual dependencies directly from LaTeX sources. Using a simple "uses" command, KnowTeX extracts relationships among statements and generates previewable graphs in DOT and TikZ formats. Applied to mathematical texts, such graphs clarify core results, support education and formalization, and provide a resource for aligning informal and formal mathematical representations. We argue that dependency graphs should become a standard feature of mathematical writing, benefiting both human readers and automated systems.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [ToolCaching: Towards Efficient Caching for LLM Tool-calling](https://arxiv.org/abs/2601.15335)
*Yi Zhai,Dian Shen,Junzhou Luo,Bin Yang*

Main category: cs.SE

TL;DR: ToolCaching：一个面向LLM工具调用的高效缓存框架，通过语义和系统特征评估请求可缓存性，使用VAAC算法进行准入和淘汰决策，显著提升缓存命中率并降低延迟。


<details>
  <summary>Details</summary>
Motivation: LLM工具调用系统面临冗余/重复请求问题，传统缓存策略因请求语义异构、工作负载动态、新鲜度要求多样而失效，需要专门针对LLM工具调用的缓存解决方案。

Method: 提出ToolCaching框架：1）整合语义和系统级特征评估请求可缓存性和缓存价值；2）核心VAAC算法结合基于多臂老虎机的准入机制和基于价值的多因素淘汰策略，综合考虑请求频率、最近性和缓存价值。

Result: 在合成和公开工具调用工作负载上的实验表明，ToolCaching相比标准策略实现高达11%的缓存命中率提升和34%的延迟降低，有效加速实际应用中的LLM工具调用。

Conclusion: ToolCaching通过特征驱动的自适应缓存机制成功解决了LLM工具调用中的冗余请求问题，为实际应用提供了高效的缓存解决方案，显著提升了系统性能。

Abstract: Recent advances in Large Language Models (LLMs) have revolutionized web applications, enabling intelligent search, recommendation, and assistant services with natural language interfaces. Tool-calling extends LLMs with the ability to interact with external APIs, greatly enhancing their practical utility. While prior research has improved tool-calling performance by adopting traditional computer systems techniques, such as parallel and asynchronous execution, the challenge of redundant or repeated tool-calling requests remains largely unaddressed. Caching is a classic solution to this problem, but applying it to LLM tool-calling introduces new difficulties due to heterogeneous request semantics, dynamic workloads, and varying freshness requirements, which render conventional cache policies ineffective. To address these issues, we propose ToolCaching, an efficient feature-driven and adaptive caching framework for LLM tool-calling systems. ToolCaching systematically integrates semantic and system-level features to evaluate request cacheability and estimate caching value. At its core, the VAAC algorithm integrates bandit-based admission with value-driven, multi-factor eviction, jointly accounting for request frequency, recency, and caching value. Extensive experiments on synthetic and public tool-calling workloads demonstrate that ToolCaching with VAAC achieves up to 11% higher cache hit ratios and 34% lower latency compared to standard policies, effectively accelerating LLM tool-calling in practical applications.

</details>
