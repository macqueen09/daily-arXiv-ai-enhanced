<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.DC](#cs.DC) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Refactoring and Equivalence in Rust: Expanding the REM Toolchain with a Novel Approach to Automated Equivalence Proofs](https://arxiv.org/abs/2601.19207)
*Matthew Britton,Sasha Pak,Alex Potanin*

Main category: cs.PL

TL;DR: REM2.0是基于rust-analyzer的Rust提取函数重构工具链，提供低延迟重构、自动修复借用检查问题，并可选择性地生成Coq等价证明。


<details>
  <summary>Details</summary>
Motivation: Rust的所有权、借用和高级类型特性使得自动化提取函数重构具有挑战性。现有工具要么依赖缓慢的编译器分析，要么只支持有限的语言片段，或者只能提供"仍然能编译"的有限保证。

Method: REM2.0基于rust-analyzer作为持久守护进程运行，提供低延迟重构。包含自动修复器调整生命周期和签名以解决借用检查问题，以及可选的验证管道连接CHARON和AENEAS为支持的Rust子集生成Coq等价证明。

Result: 在三个基准测试套件上评估：1) 原始REM工件上实现100%兼容性，延迟从~1000ms降至个位数毫秒；2) 40个GitHub高星仓库的提取案例中，能处理大多数涉及async/await、const fn、非局部控制流、泛型和高级trait边界的示例；3) 验证基准测试中，CHARON/AENEAS管道为当前子集内的案例构建端到端等价证明。

Conclusion: 基于rust-analyzer的设计能够为实际Rust程序提供快速、功能丰富的提取函数重构，而可选验证则提供机器检查的行为保持保证。

Abstract: Refactoring tools are central to modern development, with extract-function refactorings used heavily in day-to-day work. For Rust, however, ownership, borrowing, and advanced type features make automated extract-function refactoring challenging. Existing tools either rely on slow compiler-based analysis, support only restricted language fragments, or provide little assurance beyond "it still compiles." This paper presents REM2.0, a new extract-function and verification toolchain for Rust. REM2.0 works atop rust-analyzer as a persistent daemon, providing low-latency refactorings with a VSCode front-end. It adds a repairer that automatically adjusts lifetimes and signatures when extraction exposes borrow-checker issues, and an optional verification pipeline connecting to CHARON and AENEAS to generate Coq equivalence proofs for a supported Rust subset. The architecture is evaluated on three benchmark suites. On the original REM artefact, REM2.0 achieves 100% compatibility while reducing latency from ~1000ms to single-digit milliseconds in the daemon. On 40 feature-focused extractions from 20 highly starred GitHub repositories, REM2.0 handles most examples involving async/await, const fn, non-local control flow, generics, and higher-ranked trait bounds. On twenty verification benchmarks, the CHARON/AENEAS pipeline constructs end-to-end equivalence proofs for cases within its current subset. Overall, results show that a rust-analyzer-based design can provide fast, feature-rich extract-function refactoring for real Rust programs, while opt-in verification delivers machine-checked behaviour preservation.

</details>


### [2] [For Generalised Algebraic Theories, Two Sorts Are Enough](https://arxiv.org/abs/2601.19426)
*Samy Avrillon,Ambrus Kaposi,Ambroise Lafont,Niyousha Najmaei,Johann Rosain*

Main category: cs.PL

TL;DR: 将任意广义代数理论(GAT)简化为仅有两个排序的GAT，并在原模型与简化模型之间建立严格共反射对应关系


<details>
  <summary>Details</summary>
Motivation: 广义代数理论(GATs)允许排序相互索引，如范畴论和Martin-Löf类型论。但复杂的排序结构（如排序等式、排序与操作交错）在某些类型论元理论（如Cubical Agda）中难以实现。需要一种方法将任意GAT简化为更简单的形式，同时保持模型对应关系。

Method: 采用语义方法，不依赖GAT的语法描述，而是基于Uemura在具有选择可指数态射的有限完备范畴2-范畴中对（有限）GAT范畴的双初始特征刻画。通过严格共反射对应将任意GAT简化为仅有两个排序的GAT。

Result: 证明了任何GAT都可以简化为仅有两个排序的GAT，且原模型与简化模型之间存在严格共反射对应（section-retraction correspondence）。简化后的GAT消除了排序等式和排序与操作的交错结构，为在Cubical Agda等系统中实现具有复杂构造的商归纳-归纳类型(QIITs)提供了途径。

Conclusion: 该研究提供了一种通用的GAT简化方法，将任意多排序GAT简化为仅有两个排序的简化形式，同时保持模型对应关系。这不仅简化了GAT的结构，还为在类型论元理论中实现复杂构造提供了实用工具，扩展了互归纳类型归约方法的适用范围。

Abstract: Generalised algebraic theories (GATs) allow multiple sorts indexed over each other. For example, the theories of categories or Martin-L{ö}f type theories form GATs. Categories have two sorts, objects and morphisms, and the latter are double-indexed over the former. Martin-L{ö}f type theory has four sorts: contexts, substitutions, types and terms. For example, types are indexed over contexts, and terms are indexed over both contexts and types. In this paper we show that any GAT can be reduced to a GAT with only two sorts, and there is a section-retraction correspondence (formally, a strict coreflection) between models of the original and the reduced GAT. In particular, any model of the original GAT can be turned into a model of the reduced (two-sorted) GAT and back, and this roundtrip is the identity.
  The reduced GAT is simpler than the original GAT in the following aspects: it does not have sort equalities; it does not have interleaved sorts and operations; if the original GAT did not have interleaved sorts and operations, then the reduced GAT won't have operations interleaved between different sorts. In a type-theoretic metatheory, the initial algebra of a GAT is called a quotient inductive-inductive type (QIIT). Our reduction provides a way to implement QIITs with sort equalities or interleaved constructors which are not allowed by Cubical Agda. An instance of our reduction is the well-known method of reducing mutual inductive types to a single indexed family. Our approach is semantic in that it does not rely on a syntactic description of GATs, but instead, on Uemura's bi-initial characterisation of the category of (finite) GATs in the 2-category of finitely complete categories with a chosen exponentiable morphism.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [3] [LLMs versus the Halting Problem: Revisiting Program Termination Prediction](https://arxiv.org/abs/2601.18987)
*Oren Sultan,Jordi Armengol-Estape,Pascal Kesseli,Julien Vanegue,Dafna Shahaf,Yossi Adi,Peter O'Hearn*

Main category: cs.CL

TL;DR: LLMs在程序终止性预测任务上表现优异，GPT-5和Claude Sonnet-4.5接近SV-Comp 2025最佳工具水平，但无法提供有效证明且性能随程序长度增加而下降。


<details>
  <summary>Details</summary>
Motivation: 图灵停机问题的不可判定性使得传统验证工具只能近似处理终止性问题，且通常局限于特定语言和架构。随着大语言模型（LLMs）的快速发展，研究者希望探索LLMs是否能够可靠地预测程序终止性。

Method: 使用国际软件验证竞赛（SV-Comp）2025终止性类别的多样化C程序数据集，评估多个LLMs（包括GPT-5、Claude Sonnet-4.5和Code World Model）在程序终止性预测任务上的表现。

Result: LLMs在程序终止性预测方面表现突出：GPT-5和Claude Sonnet-4.5的性能仅次于排名第一的工具（使用测试时缩放），Code World Model则仅次于排名第二的工具。然而，LLMs通常无法提供有效的证明作为验证依据，且随着程序长度增加，其性能会下降。

Conclusion: LLMs在预测程序终止性方面展现出显著潜力，但存在无法提供有效证明和长度敏感性等局限性。这些发现为进一步研究LLMs在不可判定问题推理方面的潜力提供了动力。

Abstract: Determining whether a program terminates is a central problem in computer science. Turing's foundational result established the Halting Problem as undecidable, showing that no algorithm can universally determine termination for all programs and inputs. Consequently, automatic verification tools approximate termination, sometimes failing to prove or disprove; these tools rely on problem-specific architectures and abstractions, and are usually tied to particular programming languages. Recent success and progress in large language models (LLMs) raises the following question: can LLMs reliably predict program termination? In this work, we evaluate LLMs on a diverse set of C programs from the Termination category of the International Competition on Software Verification (SV-Comp) 2025. Our results suggest that LLMs perform remarkably well at predicting program termination, where GPT-5 and Claude Sonnet-4.5 would rank just behind the top-ranked tool (using test-time-scaling), and Code World Model (CWM) would place just behind the second-ranked tool. While LLMs are effective at predicting program termination, they often fail to provide a valid witness as a proof. Moreover, LLMs performance drops as program length increases. We hope these insights motivate further research into program termination and the broader potential of LLMs for reasoning about undecidable problems.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [The Opaque Pointer Design Pattern in Python: Towards a Pythonic PIMPL for Modularity, Encapsulation, and Stability](https://arxiv.org/abs/2601.19065)
*Antonios Saravanos,John Pazarzis,Stavros Zervoudakis,Dongnanzi Zheng*

Main category: cs.SE

TL;DR: Pythonic PIMPL模式：通过不透明委托将公共API与内部实现分离，解决Python库长期维护中内部实现依赖问题，支持延迟导入和后端切换


<details>
  <summary>Details</summary>
Motivation: Python库需要保持稳定的公共API，但用户容易依赖"可访问的内部对象"，这增加了重构风险并拖慢长期维护。需要一种模式来隔离内部实现变化

Method: 重新解释C++的PIMPL（指针到实现）模式为Pythonic的不透明委托模式：小型公共对象（或模块）将其行为委托给被视为内部的单独实现对象

Result: 该模式可隔离重型依赖、支持延迟导入、支持运行时选择替代后端而不改变公共API，已在标准库和科学Python生态系统中存在类似结构

Conclusion: Pythonic PIMPL模式为大型长期Python库提供了一种实用的封装技术，平衡了API稳定性和实现灵活性，提供了何时及如何应用该模式的实践指导

Abstract: Python libraries often need to maintain a stable public API even as internal implementations evolve, gain new backends, or depend on heavy optional libraries. In Python, where internal objects are easy to inspect and import, users can come to rely on "reachable internals" that were never intended to be public, making refactoring risky and slowing long-term maintenance. This paper revisits the pointer-to-implementation (PIMPL) idiom from C++ and reinterprets it as a Pythonic pattern of opaque delegation: a small public object (or module) that delegates its behavior to a separate implementation object treated as internal. We situate this pattern within a broader taxonomy of encapsulation techniques in Python, relate it to existing practices such as module-level indirection, facade objects, and backend dispatch, and identify PIMPL-like structures already used in the standard library and the scientific Python ecosystem. We then show how a Pythonic PIMPL can be used in existing codebases to isolate heavy dependencies, support lazy imports, and enable runtime selection of alternative backends without changing the public API. Finally, we discuss the benefits and trade-offs of the approach and offer practical guidance on when the pattern is appropriate and how to apply it in large, long-lived Python libraries.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [5] [Neural Theorem Proving for Verification Conditions: A Real-World Benchmark](https://arxiv.org/abs/2601.18944)
*Qiyuan Xu,Xiaokun Luan,Renxi Wang,Joshua Ong Jun Leang,Peixin Wang,Haonan Li,Wenda Li,Conrad Watt*

Main category: cs.AI

TL;DR: 提出首个面向程序验证中验证条件（VC）证明的神经定理证明基准NTP4VC，评估LLM在真实多语言VC证明任务上的表现，发现LLM有潜力但仍存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 程序验证中的验证条件（VC）自动证明是主要瓶颈，现有自动定理证明器无法处理困难VC，导致大量手动证明负担。虽然神经定理证明在数学竞赛中取得成功，但在程序验证领域的应用仍未被充分探索，缺乏专门针对VC证明的基准。

Method: 从Linux和Contiki-OS内核等真实项目中，利用工业级工具链（Why3和Frama-C）生成语义等价的测试用例，覆盖Isabelle、Lean和Rocq三种形式化语言，构建首个多语言VC证明基准NTP4VC。

Result: 评估了通用大语言模型和针对定理证明微调的模型在NTP4VC上的表现。结果显示LLM在VC证明方面显示出潜力，但在程序验证任务上仍面临重大挑战，存在显著差距。

Conclusion: NTP4VC填补了程序验证中VC自动证明基准的空白，揭示了LLM在该领域的潜力和局限性，为未来研究指明了重要机会和方向。

Abstract: Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [6] [Axe: A Simple Unified Layout Abstraction for Machine Learning Compilers](https://arxiv.org/abs/2601.19092)
*Bohan Hou,Hongyi Jin,Guanjie Wang,Jinqi Chen,Yaxing Cai,Lijie Yang,Zihao Ye,Yaoyao Ding,Ruihang Lai,Tianqi Chen*

Main category: cs.DC

TL;DR: Axe Layout是一个硬件感知的张量布局抽象，通过命名轴将逻辑张量坐标映射到多轴物理空间，统一了跨设备分布和设备内布局的平铺、分片、复制和偏移操作。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习工作负载需要跨设备网格、内存层次结构和异构加速器协调数据和计算的位置，现有方法缺乏统一的抽象来处理跨设备分布和设备内布局。

Method: 提出Axe Layout抽象，通过命名轴映射逻辑到物理空间；基于Axe设计多粒度、分布感知的领域特定语言（DSL）和编译器，在单个内核中组合线程本地控制和集体操作符。

Result: 实验表明，这种统一方法可以在最新的GPU设备、多设备环境和加速器后端上实现接近手动调优内核的性能。

Conclusion: Axe Layout提供了一个统一的硬件感知抽象，能够有效协调深度学习工作负载在异构加速器环境中的数据分布和计算布局，显著提升性能。

Abstract: Scaling modern deep learning workloads demands coordinated placement of data and compute across device meshes, memory hierarchies, and heterogeneous accelerators. We present Axe Layout, a hardware-aware abstraction that maps logical tensor coordinates to a multi-axis physical space via named axes. Axe unifies tiling, sharding, replication, and offsets across inter-device distribution and on-device layouts, enabling collective primitives to be expressed consistently from device meshes to threads. Building on Axe, we design a multi-granularity, distribution-aware DSL and compiler that composes thread-local control with collective operators in a single kernel. Experiments show that our unified approach can bring performance close to hand-tuned kernels on across latest GPU devices and multi-device environments and accelerator backends.

</details>
