<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 6]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Protean Compiler: An Agile Framework to Drive Fine-grain Phase Ordering](https://arxiv.org/abs/2602.06142)
*Amir H. Ashouri,Shayan Shirahmad Gale Bagi,Kavin Satheeskumar,Tejas Srikanth,Jonathan Zhao,Ibrahim Saidoun,Ziwen Wang,Bryan Chan,Tomasz S. Czajkowski*

Main category: cs.PL

TL;DR: Protean Compiler是一个集成到LLVM中的敏捷框架，通过在细粒度代码段上实现内置的phase-ordering能力，解决了编译器优化顺序的长期难题，平均获得4.1%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 编译器优化顺序问题自1970年代以来一直是个挑战，传统方法依赖于针对少量基准测试手动调优的算法，当基准套件变化时需要大量重新调优工作。虽然过去20年机器学习被用于改进优化选择和排序，但这些方法未能无缝集成到编译器中，也无法在细粒度代码段上应用。

Method: 提出Protean Compiler框架，将其集成到LLVM中，提供内置的细粒度phase-ordering能力。框架包含超过140个手工制作的静态特征收集方法，支持与第三方ML框架和大型语言模型轻松集成，实现两步优化过程。

Result: 在Cbench基准测试中，相对于LLVM的O3优化级别，平均获得4.1%的速度提升，某些应用最高达到15.7%的提升，仅增加几秒钟的构建时间。与第三方ML集成后，在Susan和Jpeg应用上分别获得10.1%和8.5%的速度提升。

Conclusion: Protean Compiler成功解决了编译器phase-ordering的长期挑战，通过无缝集成到LLVM中，提供了一个增强的完整编译器解决方案，计划在近期开源发布。

Abstract: The phase ordering problem has been a long-standing challenge since the late 1970s, yet it remains an open problem due to having a vast optimization space and an unbounded nature, making it an open-ended problem without a finite solution, one can limit the scope by reducing the number and the length of optimizations. Traditionally, such locally optimized decisions are made by hand-coded algorithms tuned for a small number of benchmarks, often requiring significant effort to be retuned when the benchmark suite changes. In the past 20 years, Machine Learning has been employed to construct performance models to improve the selection and ordering of compiler optimizations, however, the approaches are not baked into the compiler seamlessly and never materialized to be leveraged at a fine-grained scope of code segments. This paper presents Protean Compiler: An agile framework to enable LLVM with built-in phase-ordering capabilities at a fine-grained scope. The framework also comprises a complete library of more than 140 handcrafted static feature collection methods at varying scopes, and the experimental results showcase speedup gains of up to 4.1% on average and up to 15.7% on select Cbench applications wrt LLVM's O3 by just incurring a few extra seconds of build time on Cbench. Additionally, Protean compiler allows for an easy integration with third-party ML frameworks and other Large Language Models, and this two-step optimization shows a gain of 10.1% and 8.5% speedup wrt O3 on Cbench's Susan and Jpeg applications. Protean compiler is seamlessly integrated into LLVM and can be used as a new, enhanced, full-fledged compiler. We plan to release the project to the open-source community in the near future.

</details>


### [2] [Uniqueness is Separation](https://arxiv.org/abs/2602.06386)
*Liam O'Connor,Pilar Selene Linares Arevalo,Christine Rizkallah*

Main category: cs.PL

TL;DR: 将值独立性表达为分离逻辑中的断言，以在形式验证中结合唯一性类型系统的推理优势与可变语义的实际需求。


<details>
  <summary>Details</summary>
Motivation: 值独立性对于大规模软件系统推理非常有益，但在实际软件中，唯一性类型系统的限制过于严格，通常需要"逃生舱口"来放宽限制，但这会失去值独立性的推理优势。为了形式验证这种混合保证的系统，需要在可变语义中表达值独立性。

Method: 提出将值独立性表达为分离逻辑中的断言，使得在可变语义中也能获得值独立性的推理优势，同时允许使用突变来提高效率。

Result: 通过将值独立性表达为分离逻辑断言，可以在形式验证中结合唯一性类型系统的代数推理优势与可变语义的实际需求，为混合保证系统提供统一的验证框架。

Conclusion: 需要在分离逻辑中表达值独立性断言，以在形式验证中充分利用唯一性类型系统的推理优势，同时适应实际软件中对突变的需求。

Abstract: Value independence is enormously beneficial for reasoning about software systems at scale. These benefits carry over into the world of formal verification. Reasoning about programs algebraically is a simple affair in a proof assistant, whereas programs with unconstrained mutation necessitate much more complex techniques, such as Separation Logic, where invariants about memory safety, aliasing, and state changes must be established by manual proof. Uniqueness type systems allow programs to be compiled to code that uses mutation for efficiency, while retaining a semantics that enjoys value independence for reasoning. The restrictions of these type systems, however, are often too onerous for realistic software. Thus, most uniqueness type systems include some "escape hatch" where the benefits of value independence for reasoning are lost, but the restrictions of uniqueness types are lifted. To formally verify a system with such mixed guarantees, the value independence guarantees from uniqueness types must be expressed in terms of imperative, mutable semantics. In other words, we ought to express value independence as an assertion in Separation Logic.

</details>


### [3] [Auditing Rust Crates Effectively](https://arxiv.org/abs/2602.06466)
*Lydia Zoghbi,David Thien,Ranjit Jhala,Deian Stefan,Caleb Stanford*

Main category: cs.PL

TL;DR: Cargo Scan是首个交互式Rust程序分析工具，通过副作用分析帮助开发者审计第三方Rust代码依赖，可将审计工作量减少到代码量的0.2%。


<details>
  <summary>Details</summary>
Motivation: Rust系统依赖大量第三方crate，这些依赖与其他语言一样危险，但当前审计需要手动检查每一行代码。Rust的类型和模块系统为自动化分析提供了独特机会。

Method: Cargo Scan将潜在危险代码建模为"效果"，执行针对Rust定制的副作用分析，跨crate和模块边界跟踪效果。使用调用图跟踪上下文依赖信息，并将审计结果收集到可组合重用的审计文件中。

Result: 在69.2%的情况下，开发者可以本地检查标记的效果；审计hyper及其所有依赖时，可将潜在危险代码审计负担减少到中位数0.2%的代码行数；在crates.io前10K个crate中，约3.5K个可自动分类为安全，需要手动检查的crate中，大部分潜在危险副作用集中在约3%的crate中。

Conclusion: Cargo Scan通过利用Rust的类型系统进行副作用分析，显著降低了第三方Rust代码的审计负担，使开发者能够专注于真正潜在危险的代码部分。

Abstract: We introduce Cargo Scan, the first interactive program analysis tool designed to help developers audit third-party Rust code. Real systems written in Rust rely on thousands of transitive dependencies. These dependencies are as dangerous in Rust as they are in other languages (e.g., C or JavaScript) -- and auditing these dependencies today means manually inspecting every line of code. Unlike for most industrial languages, though, we can take advantage of Rust's type and module system to minimize the amount of code that developers need to inspect to the code that is potentially dangerous. Cargo Scan models such potentially dangerous code as effects and performs a side-effects analysis, tailored to Rust, to identify effects and track them across crate and module boundaries. In most cases (69.2%) developers can inspect flagged effects and decide whether the code is potentially dangerous locally. In some cases, however, the safety of an effect depends on the calling context -- how a function is called, potentially by a crate the developer imports later. Hence, Cargo Scan tracks context-dependent information using a call-graph, and collects audit results into composable and reusable audit files. In this paper, we describe our experience auditing Rust crates with Cargo Scan. In particular, we audit the popular client and server HTTP crate, hyper, and all of its dependencies; our experience shows that Cargo Scan can reduce the auditing burden of potentially dangerous code to a median of 0.2% of lines of code when compared to auditing whole crates. Looking at the Rust ecosystem more broadly, we find that Cargo Scan can automatically classify ~3.5K of the top 10K crates on crates.io as safe; of the crates that do require manual inspection, we find that most of the potentially dangerous side-effects are concentrated in roughly 3% of these crates.

</details>


### [4] [Same Engine, Multiple Gears: Parallelizing Fixpoint Iteration at Different Granularities (Extended Version)](https://arxiv.org/abs/2602.06680)
*Ali Rasim Kocal,Michael Schwarz,Simmo Saan,Helmut Seidl*

Main category: cs.PL

TL;DR: 提出了一种参数化任务粒度的并行不动点引擎，支持两种并行化哲学：即时方法和独立方法，并在Goblint静态分析框架中实现和评估。


<details>
  <summary>Details</summary>
Motivation: 并行化不动点迭代可以显著减少静态分析时间。现有方法通常预先固定任务粒度（如程序线程或过程级别），导致引擎性能受限。需要一种能灵活调整任务粒度的并行化方法。

Method: 基于支持混合流敏感性的TD自上而下求解器，实现两种并行化哲学：1）即时方法：所有任务访问单个线程安全哈希表；2）独立方法：每个任务有自己的状态，通过发布/订阅数据结构交换数据。两种方法都使用任务池调度固定数量的工作线程。

Result: 在Goblint静态分析框架中实现了两种并行化方法，并对大型真实世界程序进行了评估，展示了并行化对分析时间的显著改进。

Conclusion: 提出了一种参数化任务粒度的并行不动点引擎设计，支持不同的并行化策略，为静态分析提供了更灵活的并行化解决方案，能够根据分析需求调整并行粒度。

Abstract: Fixpoint iteration constitutes the algorithmic core of static analyzers. Parallelizing the fixpoint engine can significantly reduce analysis times. Previous approaches typically fix the granularity of tasks upfront, e.g., at the level of program threads or procedures - yielding an engine permanently stuck in one gear. Instead, we propose to parallelize a generic fixpoint engine in a way that is parametric in the task granularity - meaning that our engine can be run in different gears. We build on the top-down solver TD, extended with support for mixed-flow sensitivity, and realize two competing philosophies for parallelization, both building on a task pool that schedules tasks to a fixed number of workers. The nature of tasks differs between the philosophies. In the immediate approach, all tasks access a single thread-safe hash table maintaining solver state, while in the independent approach, each task has its own state and exchanges data with other tasks via a publish/subscribe data structure. We have equipped the fixpoint engine of the static analysis framework Goblint with implementations following both philosophies and report on our results for large real-world programs.

</details>


### [5] [Practical Refinement Session Type Inference (Extended Version)](https://arxiv.org/abs/2602.06715)
*Toby Ueno,Ankush Das*

Main category: cs.PL

TL;DR: 提出一种带算术精化的会话类型系统类型推断算法，减轻程序员标注负担，通过Z3求解约束，在Rast语言上实现并评估


<details>
  <summary>Details</summary>
Motivation: 带算术精化的会话类型能更细粒度描述通信协议，但增加了程序员标注负担，需要自动类型推断来减轻这一负担

Method: 1) 建立会话类型子类型理论，包括基于类型模拟的语义定义和证明正确的算法；2) 设计形式化推断算法，生成类型和算术约束，用Z3求解；3) 在Rast语言上实现，包含3个关键优化

Result: 算法在6个挑战性基准测试中有效，包括一元/二元自然数和线性λ演算；优化显著提升了Z3求解算术约束的性能，使其在合理时间内完成

Conclusion: 提出的类型推断算法成功减轻了带算术精化的会话类型的标注负担，通过子类型理论和Z3约束求解实现了实用可行的推断系统

Abstract: Session types express and enforce safe communication in concurrent message-passing systems by statically capturing the interaction protocols between processes in the type. Recent works extend session types with arithmetic refinements, which enable additional fine-grained description of communication, but impose additional annotation burden on the programmer. To alleviate this burden, we propose a type inference algorithm for a session type system with arithmetic refinements. We develop a theory of subtyping for session types, including an algorithm which we prove sound with respect to a semantic definition based on type simulation. We also provide a formal inference algorithm that generates type and arithmetic constraints, which are then solved using the Z3 SMT solver. The algorithm has been implemented on top of the Rast language, and includes 3 key optimizations that make inference feasible and practical. We evaluate the efficacy of our inference engine by evaluating it on 6 challenging benchmarks, ranging from unary and binary natural numbers to linear $λ$-calculus. We show the performance benefits provided by our optimizations in coercing Z3 into solving the arithmetic constraints in reasonable time.

</details>


### [6] [Implementing Grassroots Logic Programs with Multiagent Transition Systems and AI](https://arxiv.org/abs/2602.06934)
*Ehud Shapiro*

Main category: cs.PL

TL;DR: GLP是一种具有读者/写者变量分区的并发逻辑编程语言，用于草根平台分布式系统。本文描述了为AI在Dart中实现GLP而开发的数学框架，包括单代理确定性语义dGLP和多代理语义madGLP。


<details>
  <summary>Details</summary>
Motivation: 为AI在Dart中实现GLP语言提供形式化规范，使AI能够基于这些规范开发工作站和智能手机上的GLP实现，特别是针对草根平台（智能手机点对点通信的分布式系统）。

Method: 开发了两种实现就绪的操作语义：1) dGLP - 单代理GLP的确定性操作语义，已证明相对于并发GLP操作语义的正确性；2) madGLP - 多代理GLP的操作语义，在代理级别是确定性的（系统级别因异步通信而非确定性）。

Result: dGLP已成功用作AI开发工作站GLP实现的形式化规范；madGLP正在被AI用作开发智能手机maGLP实现的形式化规范。两种语义都经过数学证明正确。

Conclusion: 通过开发dGLP和madGLP这两种实现就绪的操作语义，为AI在Dart中实现GLP提供了可靠的形式化基础，支持了草根平台在智能手机点对点通信环境中的实际部署。

Abstract: Grassroots Logic Programs (GLP) is a concurrent logic programming language with variables partitioned into paired \emph{readers} and \emph{writers}, conjuring both linear logic and futures/promises: an assignment is produced at most once via the sole occurrence of a writer (promise) and consumed at most once via the sole occurrence of its paired reader (future), and may contain additional readers and/or writers, enabling the concise expression of rich multidirectional communication modalities.
  GLP was designed as a language for grassroots platforms -- distributed systems with multiple instances that can operate independently of each other and of any global resource, and can coalesce into ever larger instances -- with its target architecture being smartphones communicating peer-to-peer. The operational semantics of Concurrent (single-agent) GLP and of multiagent GLP (maGLP) were defined via transition systems/multiagent transition systems, respectively.
  Here, we describe the mathematics developed to facilitate the workstation- and smartphone-based implementations of GLP by AI in Dart. We developed dGLP -- implementation-ready deterministic operational semantics for single-agent GLP -- and proved it correct with respect to the Concurrent GLP operational semantics; dGLP was used by AI as a formal spec, from which it developed a workstation-based implementation of GLP. We developed madGLP -- an implementation-ready multiagent operational semantics for maGLP -- and proved it correct with respect to the maGLP operational semantics; madGLP is deterministic at the agent level (not at the system level due to communication asynchrony), and is being used by AI as a formal spec from which it develops a smartphone-based implementation of maGLP.

</details>
