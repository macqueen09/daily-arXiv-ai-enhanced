<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.CL](#cs.CL) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Static Analysis Under Non-Deterministic Program Assumptions](https://arxiv.org/abs/2602.07324)
*Abdullah H. Rasheed*

Main category: cs.PL

TL;DR: 提出一种接受用户提供程序假设的静态分析方法，通过局部假设抵消分析不精确性，生成假设集合到分析结果的函数，支持在假设搜索空间中进行优化


<details>
  <summary>Details</summary>
Motivation: 传统静态分析在精确性、完备性和自动化之间权衡，不精确性限制了其应用范围。需要一种方法能够通过用户提供的程序假设来抵消分析的不精确性，从而扩展静态分析的应用场景。

Method: 提出并规范了一种接受用户提供程序假设的静态分析方法，这些假设是程序位置的局部假设。分析器非确定性地接受这些假设，生成从接受的假设集合到相应分析结果的函数。

Result: 该方法能够生成假设集合到分析结果的函数，这个函数可以在假设搜索空间中进行优化，否则在没有这种指定分析的情况下是不可行的。展示了这种函数在两种方式中的实用性。

Conclusion: 通过接受用户提供的局部程序假设，静态分析可以抵消不精确性，扩展应用范围。生成的假设-结果函数支持在假设搜索空间中进行优化，为静态分析开辟了新的应用可能性。

Abstract: Static analyses overwhelmingly trade precision for soundness and automation. For this reason, their use-cases are restricted to situations where imprecision isn't prohibitive. In this paper, we propose and specify a static analysis that accepts user-supplied program assumptions that are local to program locations. Such assumptions can be used to counteract imprecision in static analyses, enabling their use in a much wider variety of applications. These assumptions are taken by the analyzer non-deterministically, resulting in a function from sets of accepted assumptions to the resulting analysis under those assumptions. We also demonstrate the utility of such a function in two ways, both of which showcase how it can enable optimization over a search space of assumptions that is otherwise infeasible without the specified analysis.

</details>


### [2] [RustCompCert: A Verified and Verifying Compiler for a Sequential Subset of Rust](https://arxiv.org/abs/2602.07455)
*Jinhua Wu,Yuting Wang,Liukun Yu,Linglong Meng*

Main category: cs.PL

TL;DR: 开发基于CompCert的端到端验证Rust编译器，提供语义保持和内存安全保证


<details>
  <summary>Details</summary>
Motivation: 现有的Rust编译器缺乏形式化验证，无法保证编译过程的正确性。需要构建一个经过验证的编译器，确保Rust程序的语义在编译过程中得到保持，同时利用借用检查简化程序验证

Method: 基于CompCert验证编译器框架，构建端到端的Rust编译器。通过形式化验证确保从Rust源代码到汇编代码的语义保持，并验证借用检查过程的内存安全性

Result: 开发中的验证编译器提供两个关键保证：1) 语义保持性 - 源代码行为包含目标代码行为，源级验证的属性可保持到目标级；2) 内存安全性 - 验证编译过程中的借用检查，简化Rust程序验证

Conclusion: 基于CompCert构建验证的Rust编译器是可行的，能够提供形式化保证，简化Rust程序的验证工作，为安全关键系统开发提供可靠基础

Abstract: We present our ongoing work on developing an end-to-end verified Rust compiler based on CompCert. It provides two guarantees: one is semantics preservation from Rust to assembly, i.e., the behaviors of source code includes the behaviors of target code, with which the properties verified at the source can be preserved down to the target; the other is memory safety ensured by the verifying compilation -- the borrow checking pass, which can simplify the verification of Rust programs, e.g., by allowing the verification tools focus on the functional correctness.

</details>


### [3] [Series-Parallel-Loop Decompositions of Control-flow Graphs](https://arxiv.org/abs/2602.07627)
*Xuran Cai,Amir Goharshady,S Hitarth,Chun Kit Lam*

Main category: cs.PL

TL;DR: 本文提出了一种新的基于语法的分解框架，能够精确描述结构化程序生成的控制流图（CFG），并利用该框架改进了寄存器分配和生命周期最优投机性部分冗余消除两个编译器优化问题的算法。


<details>
  <summary>Details</summary>
Motivation: 传统方法使用树宽和路径宽等图参数来建模CFG的稀疏性，但这些参数只能近似CFG的结构约束。虽然每个结构化CFG的树宽最多为7，但许多树宽≤7的图并不能作为CFG出现。现有参数化技术针对的图类比实践中遇到的CFG要广泛得多，因此需要更精确的CFG表征方法。

Method: 引入一种新的基于语法的分解框架，能够精确描述结构化程序生成的控制流图。该分解框架直观、反映程序的语法结构，并且完全兼容基于树宽的动态规划方法。利用该框架设计了改进的算法，用于寄存器分配和生命周期最优投机性部分冗余消除两个编译器优化问题。

Result: 通过广泛的实验评估表明，与之前最先进的方法相比，新方法在性能上有显著提升，突显了使用专门为CFG定制的分解方法的优势。

Conclusion: 提出的基于语法的分解框架能够精确表征结构化程序的CFG，相比传统树宽方法更贴合实际程序结构。基于该框架的算法在编译器优化问题上表现出显著性能改进，证明了针对CFG特定结构定制分解方法的价值。

Abstract: Control-flow graphs (CFGs) of structured programs are well known to exhibit strong sparsity properties. Traditionally, this sparsity has been modeled using graph parameters such as treewidth and pathwidth, enabling the development of faster parameterized algorithms for tasks in compiler optimization, model checking, and program analysis. However, these parameters only approximate the structural constraints of CFGs: although every structured CFG has treewidth at most~7, many graphs with treewidth at most~7 cannot arise as CFGs. As a result, existing parameterized techniques are optimized for a substantially broader class of graphs than those encountered in practice.
  In this work, we introduce a new grammar-based decomposition framework that characterizes \emph{exactly} the class of control-flow graphs generated by structured programs. Our decomposition is intuitive, mirrors the syntactic structure of programs, and remains fully compatible with the dynamic-programming paradigm of treewidth-based methods. Using this framework, we design improved algorithms for two classical compiler optimization problems: \emph{Register Allocation} and \emph{Lifetime-Optimal Speculative Partial Redundancy Elimination (LOSPRE)}. Extensive experimental evaluation demonstrates significant performance improvements over previous state-of-the-art approaches, highlighting the benefits of using decompositions tailored specifically to CFGs.

</details>


### [4] [Gillian Debugging: Swinging Through the (Compositional Symbolic Execution) Trees, Extended Version](https://arxiv.org/abs/2602.07742)
*Nat Karmios,Sacha-Élie Ayoun,Philippa Gardner*

Main category: cs.PL

TL;DR: 为符号执行工具开发了一个可视化调试界面，集成到VS Code和Gillian平台，通过用户研究验证其有效性


<details>
  <summary>Details</summary>
Motivation: 当前组合符号执行(CSE)工具的输出难以调试，即使是专业用户也面临困难，需要更好的调试工具来提升可用性

Method: 开发了一个与Visual Studio Code和Gillian多语言CSE平台集成的调试界面，重点关注可视化、交互性和符号执行树的直观表示，并确保工具无关性以便未来移植

Result: 通过用户研究进行实证评估，结果显示该调试器能有效帮助早期研究人员理解CSE原理，并在Gillian中验证基本数据结构算法

Conclusion: 成功开发了一个可视化、交互式的符号执行调试界面，解决了CSE工具调试困难的问题，并通过用户研究验证了其有效性

Abstract: In recent years, compositional symbolic execution (CSE) tools have been growing in prominence and are becoming more and more applicable to real-world codebases. Still to this day, however, debugging the output of these tools remains difficult, even for specialist users. To address this, we introduce a debugging interface for symbolic execution tools, integrated with Visual Studio Code and the Gillian multi-language CSE platform, with strong focus on visualisation, interactivity, and intuitive representation of symbolic execution trees. We take care in making this interface tool-agnostic, easing its transfer to other symbolic analysis tools in future. We empirically evaluate our work with a user study, the results of which show the debugger's usefulness in helping early researchers understand the principles of CSE and verify fundamental data structure algorithms in Gillian.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [5] [Bridging the Knowledge Void: Inference-time Acquisition of Unfamiliar Programming Languages for Coding Tasks](https://arxiv.org/abs/2602.06976)
*Chen Shen,Wei Cheng,Jingyue Yang,Huan Zhang,Yuhan Wu,Wei Hu*

Main category: cs.CL

TL;DR: ILA-agent框架让大语言模型通过推理时与官方文档和执行环境的交互来学习新编程语言，显著优于检索增强基线


<details>
  <summary>Details</summary>
Motivation: 大语言模型在遇到未训练过的编程语言时性能会急剧下降，传统的数据密集型微调方法成本高昂。本文研究推理时语言获取(ILA)范式，让模型通过有限外部资源动态交互来掌握新语言

Method: 提出ILA-agent框架，将人类基本行为建模为一套工具，使LLM能够通过结构化交互逐步探索、应用和验证语言知识。构建Cangjie-bench多任务基准，并在Cangjie语言上实例化ILA-agent进行评估

Result: 使用不同LLM的实验表明，ILA-agent在代码生成、翻译和程序修复任务上显著优于检索增强基线。轨迹分析揭示了涌现的行为模式，同时突显了持续存在的性能差距

Conclusion: ILA-agent为LLM学习新编程语言提供了一种有效的推理时获取框架，通过结构化交互减少了对大量训练数据的依赖，展示了在低资源设置下的潜力

Abstract: The proficiency of Large Language Models (LLMs) in coding tasks is often a reflection of their extensive pre-training corpora, which typically collapses when confronted with previously unfamiliar programming languages. Departing from data-intensive finetuning, we investigate the paradigm of Inference-time Language Acquisition (ILA), where an LLM masters an unfamiliar language through dynamic interaction with limited external resources. In this paper, we propose ILA-agent, a general ILA framework that equips LLMs with a set of behavioral primitives. By modeling essential human-like behaviors as a suite of tools, ILA-agent enables LLMs to incrementally explore, apply, and verify language knowledge through structured interactions with the official documentation and execution environment. To provide a rigorous evaluation in a low-resource setting, we construct Cangjie-bench, a multi-task benchmark based on the novel statically-typed language Cangjie. We instantiate ILA-agent for Cangjie and evaluate its performance across code generation, translation, and program repair tasks. Results using diverse LLMs demonstrate that ILA-agent significantly outperforms retrieval-augmented baselines. Further analysis of agent trajectories characterizes the emergent behavior patterns while highlighting persisting performance gaps.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [6] [$\partial$CBDs: Differentiable Causal Block Diagrams](https://arxiv.org/abs/2602.07581)
*Thomas Beckers,Ján Drgoňa,Truong X. Nghiem*

Main category: eess.SY

TL;DR: 论文提出了一种可微分因果框图（∂CBDs）的统一形式化方法，将可组合性、可学习性和可验证性整合到网络物理系统建模中。


<details>
  <summary>Details</summary>
Motivation: 现有网络物理系统建模方法存在局限性：因果框图（CBDs）支持模块化系统互连但缺乏可微分性；可微分编程（DP）支持端到端梯度优化但缺乏正确性保证；基于契约的验证框架与数据驱动模型精炼脱节。需要一种能同时满足可组合性、可学习性和可验证性的统一框架。

Method: 提出可微分因果框图（∂CBDs），保留CBDs的组合结构和执行语义，集成假设-保证契约进行模块化正确性推理，引入基于残差的契约作为可微分的轨迹级证书，兼容自动微分，支持梯度优化和学习。

Result: ∂CBDs提供了一个可扩展、可验证、可训练的建模流程，在保持因果性和模块化的同时，支持数据驱动、物理约束和约束感知的网络物理系统优化。

Conclusion: ∂CBDs统一了可组合性、可学习性和可验证性三个视角，为网络物理系统提供了一个同时满足模块化设计、梯度优化和形式化验证需求的综合建模框架。

Abstract: Modern cyber-physical systems (CPS) integrate physics, computation, and learning, demanding modeling frameworks that are simultaneously composable, learnable, and verifiable. Yet existing approaches treat these goals in isolation: causal block diagrams (CBDs) support modular system interconnections but lack differentiability for learning; differentiable programming (DP) enables end-to-end gradient-based optimization but provides limited correctness guarantees; while contract-based verification frameworks remain largely disconnected from data-driven model refinement. To address these limitations, we introduce differentiable causal block diagrams ($\partial$CBDs), a unifying formalism that integrates these three perspectives. Our approach (i) retains the compositional structure and execution semantics of CBDs, (ii) incorporates assume--guarantee (A--G) contracts for modular correctness reasoning, and (iii) introduces residual-based contracts as differentiable, trajectory-level certificates compatible with automatic differentiation (AD), enabling gradient-based optimization and learning. Together, these elements enable a scalable, verifiable, and trainable modeling pipeline that preserves causality and modularity while supporting data-, physics-, and constraint-informed optimization for CPS.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [7] [Debugging code world models](https://arxiv.org/abs/2602.07672)
*Babak Rahmani*

Main category: cs.SE

TL;DR: 代码世界模型通过预测程序执行状态来模拟程序运行，但存在两个主要失败模式：长执行历史导致的token预算耗尽，以及字符串值状态处理中的子词分词限制问题。


<details>
  <summary>Details</summary>
Motivation: 代码世界模型通过执行基础的世界建模提供内部验证，但错误来源和模型限制尚未被充分理解，需要从局部语义执行和长时状态跟踪两个角度进行研究。

Method: 从两个互补视角研究CWMs：局部语义执行和长时状态跟踪。使用真实代码基准测试识别失败模式，并通过受控的排列跟踪基准测试来隔离动作执行下的状态传播。

Result: 发现两个主要失败模式：1）密集运行时状态产生token密集型执行轨迹，导致长执行历史的程序token预算耗尽；2）失败主要集中在字符串值状态，归因于子词分词限制而非程序结构。长时状态跟踪中，性能下降主要由错误动作生成驱动，当使用真实命令时，Transformer能准确传播状态。

Conclusion: 研究为代码世界模型提供了更高效的监督和状态表示方向，这些方向应更好地与程序执行和数据类型对齐，特别是需要解决token预算和字符串处理问题。

Abstract: Code World Models (CWMs) are language models trained to simulate program execution by predicting explicit runtime state after every executed command. This execution-based world modeling enables internal verification within the model, offering an alternative to natural language chain-of-thought reasoning. However, the sources of errors and the nature of CWMs' limitations remain poorly understood. We study CWMs from two complementary perspectives: local semantic execution and long-horizon state tracking. On real-code benchmarks, we identify two dominant failure regimes. First, dense runtime state reveals produce token-intensive execution traces, leading to token-budget exhaustion on programs with long execution histories. Second, failures disproportionately concentrate in string-valued state, which we attribute to limitations of subword tokenization rather than program structure. To study long-horizon behavior, we use a controlled permutation-tracking benchmark that isolates state propagation under action execution. We show that long-horizon degradation is driven primarily by incorrect action generation: when actions are replaced with ground-truth commands, a Transformer-based CWM propagates state accurately over long horizons, despite known limitations of Transformers in long-horizon state tracking. These findings suggest directions for more efficient supervision and state representations in CWMs that are better aligned with program execution and data types.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [8] [Impredicativity in Linear Dependent Type Theory](https://arxiv.org/abs/2602.08846)
*Sam Speight,Niels van der Weide*

Main category: cs.LO

TL;DR: 从线性组合代数构建线性依赖类型理论的实现模型，提出扩展类型系统的新特性，包括具有两种解码操作的宇宙、注入性规则，并支持编码线性归纳类型。


<details>
  <summary>Details</summary>
Motivation: 构建线性依赖类型理论的实现模型，为线性类型系统提供理论基础，并探索如何增强类型系统的表达能力以支持更复杂的类型构造。

Method: 从线性组合代数构造实现模型，扩展类型系统：添加具有两种解码操作（笛卡尔类型和线性类型）的宇宙，引入模态注入性规则，支持编码线性归纳类型。

Result: 成功构建了线性依赖类型理论的实现模型，扩展的类型系统能够编码线性归纳类型，并以线性列表类型为例验证了相关唯一性原理。模型在Rocq证明助手中完全形式化。

Conclusion: 通过实现模型为线性依赖类型理论提供了坚实基础，提出的扩展增强了类型系统的表达能力，特别是支持线性归纳类型，为线性类型理论的进一步发展开辟了道路。

Abstract: We construct a realizability model of linear dependent type theory from a linear combinatory algebra. Our model motivates a number of additions to the type theory. In particular, we add a universe with two decoding operations: one takes codes to cartesian types and the other takes codes to linear types. The universe is impredicative in the sense that it is closed under both large cartesian dependent products and large linear dependent products. We also add a rule for injectivity of the modality turning linear terms into cartesian terms. With all of the additions, we are able to encode (linear) inductive types. As a case study, we consider the type of lists over a linear type, and demonstrate that our encoding has the relevant uniqueness principle. The construction of the realizability model is fully formalized in the proof assistant Rocq.

</details>
