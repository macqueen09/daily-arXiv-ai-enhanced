<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.CL](#cs.CL) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Programming Backpropagation with Reverse Handlers for Arrows](https://arxiv.org/abs/2602.18090)
*Takahiro Sanada,Keisuke Hoshino,Kenshin Hirai,Shin-ya Katsumata*

Main category: cs.PL

TL;DR: 提出一种新的编程语言，通过代数效应和处理器的范畴语义来设计和实现神经网络，支持符号化构建网络并灵活分配实现（如反向传播）。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络设计通常与具体实现紧密耦合，缺乏抽象性和灵活性。作者希望创建一个能符号化描述神经网络、并能通过处理器机制灵活分配不同实现（如反向传播计算）的高层语言框架。

Method: 1. 设计新的编程语言，基于代数效应和箭头处理器框架；2. 引入"反向处理器"机制专门处理反向传播；3. 建立类型系统、操作语义、范畴语义；4. 在反向微分限制范畴上构建强前单子的新代数；5. 使用弦图作为神经网络的正式图形语法和语义。

Result: 1. 开发了完整的语言框架，支持神经网络的符号化构建；2. 证明了语言的可靠性和充分性定理；3. 实现了通过处理器机制灵活分配网络实现的能力；4. 建立了神经网络的形式化图形表示。

Conclusion: 该语言设计使神经网络描述变得抽象和高层，同时实现可以灵活分配。通过范畴语义和反向处理器机制，为神经网络编程提供了坚实的理论基础和实用的实现框架。

Abstract: We introduce a new programming language and its categorical semantics in order to design and implement neural networks within the framework of algebraic effects and handlers for arrows. Our language enables us to construct neural networks symbolically, in the same manner as algebraic effects, and to assign implementations -- such as backpropagation computations -- to them via handlers. The advantage of this language design is that network descriptions become abstract and high-level, while implementations can be flexibly assigned to networks. We establish a rigorous foundation for our language by developing a type system, an operational semantics, a categorical semantics, and soundness and adequacy theorems. The technical core is the introduction of \emph{reverse handlers}, a novel handler mechanism for arrows for implementing backpropagation, together with new algebras of strong promonads on reverse differential restriction categories (RDRCs), whose string diagrams provide a formal graphical syntax and semantics for neural networks.

</details>


### [2] [Grammar Repair with Examples and Tree Automata: Extended Version](https://arxiv.org/abs/2602.18166)
*Yunjeong Lee,Gokul Rajiv,Ilya Sergey*

Main category: cs.PL

TL;DR: Greta：基于树自动机学习的上下文无关文法消歧工具，通过示例引导自动修复语法歧义


<details>
  <summary>Details</summary>
Motivation: 上下文无关文法（CFG）是描述编程语言语法的标准形式，但在定义语法时，消除所有可能的歧义（如作用域规则、运算符优先级和结合性）是一个主要挑战。现有解析器生成工具通常采用临时方法解决歧义，可能导致解析器行为与语言设计者意图不符。

Method: 1. 将初始CFG和定义优先级/结合性限制的示例都解释为树自动机（TAs）
2. 开发新的TA学习算法，基于原始文法和用户偏好的歧义解决方式构建单一自动机
3. 设计高效的TA交集算法，利用可达性分析和优化技术显著减小结果自动机规模
4. 最终生成符合解析器生成器要求的惯用CFG

Result: 1. 证明了算法的正确性
2. 实现了名为Greta的工具
3. 通过一系列案例研究证明了方法的有效性

Conclusion: Greta提供了一种用户友好的方法，能够基于示例引导自动修复语法歧义，确保生成的解析器行为符合语言设计者意图，相比传统临时方法更加可靠和系统化。

Abstract: Context-free grammars (CFGs) are the de-facto formalism for declaratively describing concrete syntax for programming languages and generating parsers. One of the major challenges in defining a desired syntax is ruling out all possible ambiguities in the CFG productions that determine scoping rules as well as operator precedence and associativity. Practical tools for parser generation typically apply ad-hoc approaches for resolving such ambiguities, which might result in a parser's behavior that contradicts the intents of the language designer. In this work, we present a user-friendly approach to soundly repair grammars with ambiguities, which is inspired by the programming by example line of research in automated program synthesis. At the heart of our approach is the interpretation of both the initial CFG and additional examples that define the desired restrictions in precedence and associativity, as tree automata (TAs). The technical novelties of our approach are (1) a new TA learning algorithm that constructs an automaton based on the original grammar and examples that encode the user's preferred ways of resolving ambiguities all in a single TA, and (2) an efficient algorithm for TA intersection that utilises reachability analysis and optimizations that significantly reduce the size of the resulting automaton, which results in idiomatic CFGs amenable to parser generators. We have proven the soundness of the algorithms, and implemented our approach in a tool called Greta, demonstrating its effectiveness on a series of case studies.

</details>


### [3] [Towards a Higher-Order Bialgebraic Denotational Semantics](https://arxiv.org/abs/2602.18295)
*Sergey Goncharov,Marco Peressotti,Stelios Tsampas,Henning Urbat,Stefano Volpe*

Main category: cs.PL

TL;DR: 本文提出了高阶抽象GSOS框架中的充分指称语义理论，将Turi和Plotkin的双代数方法扩展到高阶语言，通过局部终结余代数构建语义域，统一了现有指称语义方法。


<details>
  <summary>Details</summary>
Motivation: Turi和Plotkin的双代数抽象GSOS框架为编程语言的操作和指称语义提供了优雅的范畴方法，但高阶语言中一直缺乏符合其原始愿景的双代数指称语义理解。需要发展高阶抽象GSOS中的充分指称语义理论。

Method: 提出高阶抽象GSOS中的指称语义理论，使用行为双函子的局部终结余代数作为参数化语义域，完全解耦语言语法与语义域构造。该方法能捕获现有指称语义描述，如通过通用步索引构建的语义域。

Result: 该方法适用于广泛的高阶语言，包括简单类型和无类型语言，以及具有计算效应（如概率或非确定性分支）的语言。为高阶语言提供了统一的指称语义框架。

Conclusion: 成功将Turi和Plotkin的双代数指称语义愿景扩展到高阶设置，建立了高阶抽象GSOS中的充分指称语义理论，为高阶语言提供了参数化、解耦的语义建模方法。

Abstract: The bialgebraic abstract GSOS framework by Turi and Plotkin provides an elegant categorical approach to modelling the operational and denotational semantics of programming and process languages. In abstract GSOS, bisimilarity is always a congruence, and it coincides with denotational equivalence. This saves the language designer from intricate, ad-hoc reasoning to establish these properties. The bialgebraic perspective on operational semantics in the style of abstract GSOS has recently been extended to higher-order languages, preserving compositionality of bisimilarity. However, a categorical understanding of bialgebraic denotational semantics according to Turi and Plotkin's original vision has so far been missing in the higher-order setting. In the present paper, we develop a theory of adequate denotational semantics in higher-order abstract GSOS. The denotational models are parametric in an appropriately chosen semantic domain in the form of a locally final coalgebra for a behaviour bifunctor, whose construction is fully decoupled from the syntax of the language. Our approach captures existing accounts of denotational semantics such as semantic domains built via general step-indexing, previously introduced on a per-language basis, and is shown to be applicable to a wide range of different higher-order languages, e.g. simply typed and untyped languages, or languages with computational effects such as probabilistic or non-deterministic branching.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [4] [VeriSoftBench: Repository-Scale Formal Verification Benchmarks for Lean](https://arxiv.org/abs/2602.18307)
*Yutong Xin,Qiaochu Chen,Greg Durrett,Işil Dillig*

Main category: cs.SE

TL;DR: VeriSoftBench：一个包含500个Lean 4证明义务的基准测试，专注于软件验证而非数学证明，评估LLM在真实代码库环境中的定理证明能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM定理证明基准主要基于数学领域的Mathlib，而软件验证中的证明通常涉及定义丰富的项目特定代码库，需要评估LLM在真实软件验证环境中的表现。

Method: 创建VeriSoftBench基准，包含500个来自开源形式化方法项目的Lean 4证明义务，保留真实的仓库上下文和跨文件依赖关系，评估前沿LLM和专业证明器。

Result: 1) 针对Mathlib风格数学调优的证明器在此仓库中心化环境中表现不佳；2) 成功与传递性仓库依赖强相关，依赖闭包大的任务更难解决；3) 提供依赖闭包内的精选上下文比暴露完整仓库效果更好，但仍有很大改进空间。

Conclusion: 软件验证中的定理证明与数学证明有显著差异，需要专门针对仓库中心化环境的基准和评估方法，VeriSoftBench为此提供了基础。

Abstract: Large language models have achieved striking results in interactive theorem proving, particularly in Lean. However, most benchmarks for LLM-based proof automation are drawn from mathematics in the Mathlib ecosystem, whereas proofs in software verification are developed inside definition-rich codebases with substantial project-specific libraries. We introduce VeriSoftBench, a benchmark of 500 Lean 4 proof obligations drawn from open-source formal-methods developments and packaged to preserve realistic repository context and cross-file dependencies. Our evaluation of frontier LLMs and specialized provers yields three observations. First, provers tuned for Mathlib-style mathematics transfer poorly to this repository-centric setting. Second, success is strongly correlated with transitive repository dependence: tasks whose proofs draw on large, multi-hop dependency closures are less likely to be solved. Third, providing curated context restricted to a proof's dependency closure improves performance relative to exposing the full repository, but nevertheless leaves substantial room for improvement. Our benchmark and evaluation suite are released at https://github.com/utopia-group/VeriSoftBench.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [5] [Analyzing LLM Instruction Optimization for Tabular Fact Verification](https://arxiv.org/abs/2602.17937)
*Xiaotang Du,Giwon Hong,Wai-Chung Kwan,Rohit Saxena,Ivan Titov,Pasquale Minervini,Emily Allaway*

Main category: cs.CL

TL;DR: 本文首次系统比较了基于DSPy优化框架的指令优化方法在表格事实验证任务中的表现，发现指令优化能持续提升验证准确率，不同优化器对不同提示技术效果各异。


<details>
  <summary>Details</summary>
Motivation: 指令优化为提升大语言模型推理性能提供了一种轻量级、模型无关的方法。本文旨在系统比较不同指令优化技术在表格事实验证任务中的效果，填补该领域的研究空白。

Method: 使用DSPy优化框架，评估四种现成的提示技术（直接预测、思维链、带SQL工具的ReAct、带Python执行的CodeAct），并研究三种优化器（COPRO、MiPROv2、SIMBA）在四个基准测试和三个模型家族上的表现。

Result: 指令优化持续提升验证准确率：MiPROv2在思维链上获得最稳定的增益，SIMBA为ReAct智能体带来最大收益（尤其在更大模型规模时）。行为分析显示SIMBA通过启发式方法鼓励更直接的推理路径，提升思维链中的数值比较能力，并帮助ReAct智能体避免不必要的工具调用。

Conclusion: 对于表格事实检查，思维链在小模型上特别有效；虽然基于大模型的ReAct智能体可以达到竞争性性能，但需要仔细的指令优化。不同提示技术需要匹配不同的优化策略才能获得最佳效果。

Abstract: Instruction optimization provides a lightweight, model-agnostic approach to enhancing the reasoning performance of large language models (LLMs). This paper presents the first systematic comparison of instruction optimization, based on the DSPy optimization framework, for tabular fact verification. We evaluate four out-of-the-box prompting techniques that cover both text-only prompting and code use: direct prediction, Chain-of-Thought (CoT), ReAct with SQL tools, and CodeAct with Python execution. We study three optimizers from the DSPy framework -- COPRO, MiPROv2, and SIMBA -- across four benchmarks and three model families. We find that instruction optimization consistently improves verification accuracy, with MiPROv2 yielding the most stable gains for CoT, and SIMBA providing the largest benefits for ReAct agents, particularly at larger model scales. Behavioral analyses reveal that SIMBA encourages more direct reasoning paths by applying heuristics, thereby improving numerical comparison abilities in CoT reasoning and helping avoid unnecessary tool calls in ReAct agents. Across different prompting techniques, CoT remains effective for tabular fact checking, especially with smaller models. Although ReAct agents built with larger models can achieve competitive performance, they require careful instruction optimization.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [AnCoder: Anchored Code Generation via Discrete Diffusion Models](https://arxiv.org/abs/2602.17688)
*Anton Xue,Litu Rout,Constantine Caramanis,Sanjay Shakkottai*

Main category: cs.LG

TL;DR: AnchorTree框架通过抽象语法树引导扩散过程，优先解决语法和语义关键标记，提升代码生成质量


<details>
  <summary>Details</summary>
Motivation: 现有扩散语言模型在代码生成时未能尊重编程语言的刚性结构，常产生无法执行的破碎程序

Method: 引入AnchorTree框架，使用抽象语法树作为结构化先验，优先解析关键字和标识符等关键标记，建立结构支架指导后续生成

Result: 通过AnCoder模型系列验证，结构锚定的扩散方法能以参数高效的方式实现高质量代码生成

Conclusion: 结构化锚定的扩散语言模型为代码生成提供了有前景的替代方案，能更好地尊重编程语言结构

Abstract: Diffusion language models offer a compelling alternative to autoregressive code generation, enabling global planning and iterative refinement of complex program logic. However, existing approaches fail to respect the rigid structure of programming languages and, as a result, often produce broken programs that fail to execute. To address this, we introduce AnchorTree, a framework that explicitly anchors the diffusion process using structured, hierarchical priors native to code. Specifically, AnchorTree uses the abstract syntax tree to prioritize resolving syntactically and semantically salient tokens, such as keywords (e.g., if, while) and identifiers (e.g., variable names), thereby establishing a structural scaffold that guides the remaining generation. We validate this framework via AnCoder, a family of models showing that structurally anchored diffusion offers a parameter-efficient path to high-quality code generation.

</details>
