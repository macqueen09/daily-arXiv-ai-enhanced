<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.CL](#cs.CL) [Total: 1]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Type-Based Enforcement of Non-Interference for Choreographic Programming](https://arxiv.org/abs/2602.21630)
*Marco Bertoni,Saverio Giallorenzo,Marco Peressotti*

Main category: cs.PL

TL;DR: 开发了一个策略参数化的类型系统，用于防止高安全数据向低安全观察者的信息泄露，支持递归过程并通过约束生成重建过程上下文，证明了终止不敏感的非干扰性。


<details>
  <summary>Details</summary>
Motivation: 编排（choreographies）从全局视角描述分布式协议，支持正确性构造的本地行为合成。然而，需要防止高安全数据向低安全观察者的信息泄露，包括显式和隐式流，同时支持递归过程。

Method: 开发了一个策略参数化的类型系统，通过程序计数器机制处理显式和隐式流。系统支持递归过程，通过约束生成重建过程上下文。基于标准小步语义进行形式化验证。

Result: 证明了终止不敏感的非干扰性（termination-insensitive non-interference），确保高安全数据不会通过信息流泄露给低安全观察者。

Conclusion: 提出的策略参数化类型系统能够有效防止编排中的信息泄露，支持递归过程并通过形式化验证保证了安全性。

Abstract: Choreographies describe distributed protocols from a global viewpoint, enabling correct-by-construction synthesis of local behaviours. We develop a policy-parametric type system that prevents information leaks from high-security data to low-security observers, handling both explicit and implicit flows through a program-counter discipline. The system supports recursive procedures via a procedure context that we reconstruct through constraint generation. We prove termination-insensitive non-interference with respect to a standard small-step semantics.

</details>


### [2] [RustyDL: A Program Logic for Rust](https://arxiv.org/abs/2602.22075)
*Daniel Drodt,Reiner Hähnle*

Main category: cs.PL

TL;DR: RustyDL是一个用于Rust程序的源级程序逻辑，支持人机交互式验证，可直接在源代码层面进行推理，无需转换为中间语言。


<details>
  <summary>Details</summary>
Motivation: 现有Rust验证工具都基于转换为中间语言，缺乏直接在源代码层面进行推理的程序逻辑，这对于需要证明复杂功能属性的人机交互式验证至关重要。

Method: 设计RustyDL程序逻辑和演算，解决Rust特定挑战，在KeY验证工具中实现Rust实例原型。

Result: 开发了RustyDL程序逻辑原型，可直接在Rust源代码层面进行推理，支持人机交互式验证复杂功能属性。

Conclusion: RustyDL为Rust程序提供了源级程序逻辑基础，支持人机交互式验证，是验证复杂Rust程序功能属性的重要工具。

Abstract: Rust is a modern programming language that guarantees memory safety and the absence of data races with a strong type system. We present RustyDL, a program logic for Rust, as a foundation for an auto-interactive, deductive verification tool for Rust. RustyDL reasons about Rust programs directly on the source code level, in contrast to other tools that are all based on translation to an intermediate language. A source-level program logic for Rust is crucial for a human-in-the-loop (HIL) style of verification that permits proving highly complex functional properties. We discuss specific Rust challenges in designing a program logic and calculus for HIL-style verification and propose a solution in each case. We provide a proof-of-concept of our ideas in the form of a prototype of a Rust instance of the deductive verification tool KeY.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [AgenticTyper: Automated Typing of Legacy Software Projects Using Agentic AI](https://arxiv.org/abs/2602.21251)
*Clemens Pohle*

Main category: cs.SE

TL;DR: AgenticTyper是一个基于LLM的代理系统，通过迭代错误纠正和转译比较来为JavaScript代码库自动添加TypeScript类型，显著减少人工工作量。


<details>
  <summary>Details</summary>
Motivation: 传统JavaScript系统缺乏类型安全性，维护风险高。虽然TypeScript可以提供帮助，但手动添加类型成本高昂。现有的自动化类型研究主要关注类型推断，很少解决类型检查设置、定义生成、错误识别或仓库级别的行为正确性问题。

Method: 基于大型语言模型的代理系统，通过迭代错误纠正和转译比较来保持行为正确性。系统能够处理类型检查设置、定义生成和错误识别。

Result: 在两个专有代码库（81K行代码）上评估，AgenticTyper在20分钟内解决了所有633个初始类型错误，将人工工作量从一整天减少到几乎为零。

Conclusion: AgenticTyper有效地解决了JavaScript代码库自动化TypeScript类型添加的多个关键问题，显著提高了效率和准确性，减少了维护风险。

Abstract: Legacy JavaScript systems lack type safety, making maintenance risky. While TypeScript can help, manually adding types is expensive. Previous automated typing research focuses on type inference but rarely addresses type checking setup, definition generation, bug identification, or behavioral correctness at repository scale. We present AgenticTyper, a Large Language Model (LLM)-based agentic system that addresses these gaps through iterative error correction and behavior preservation via transpilation comparison. Evaluation on two proprietary repositories (81K LOC) shows that AgenticTyper resolves all 633 initial type errors in 20 minutes, reducing manual effort from one working day.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [4] [Structured Prompt Language: Declarative Context Management for LLMs](https://arxiv.org/abs/2602.21257)
*Wen G. Gong*

Main category: cs.CL

TL;DR: SPL是一种声明式SQL风格的语言，将LLM视为生成式知识库，提供显式token预算管理、自动查询优化、RAG集成和弹性代理管道，显著减少提示模板代码并实现跨云/本地环境的无缝运行。


<details>
  <summary>Details</summary>
Motivation: 当前LLM应用开发面临提示工程复杂、token管理困难、成本控制不透明、云/本地环境切换不便等问题。需要一种声明式语言来简化LLM编程，提供类似SQL的透明度和优化能力。

Method: 设计了SPL声明式语言，包含WITH BUDGET/LIMIT token管理、自动查询优化器、EXPLAIN透明度机制。扩展了SPL-flow代理管道，采用三层回退策略。开发了五个扩展：Text2SPL、MoM路由、Logical Chunking、SPL-flow和BENCHMARK。

Result: SPL平均减少65%的提示模板代码，在预执行阶段揭示68倍的成本差异，同一.spl脚本可在OpenRouter上以$0.002运行或在本地Ollama实例上零边际成本运行。提供了EBNF语法和两个Python包。

Conclusion: SPL为LLM应用开发提供了声明式、透明、可优化的框架，显著简化了提示工程，实现了成本透明和跨环境无缝部署，代表了LLM编程范式的重要进步。

Abstract: We present SPL (Structured Prompt Language), a declarative SQL-inspired language that treats large language models as generative knowledge bases and their context windows as constrained resources. SPL provides explicit WITH BUDGET/LIMIT token management, an automatic query optimizer, EXPLAIN transparency analogous to SQL's EXPLAIN ANALYZE, and native integration of retrieval-augmented generation (RAG) and persistent memory in a single declarative framework. SPL-flow extends SPL into resilient agentic pipelines with a three-tier provider fallback strategy (Ollama -> OpenRouter -> self-healing retry) fully transparent to the .spl script. Five extensions demonstrate the paradigm's breadth: (1) Text2SPL (multilingual NL->SPL translation); (2) Mixture-of-Models (MoM) routing that dispatches each PROMPT to a domain-specialist model at runtime; (3) Logical Chunking, an intelligent strategy for documents exceeding a single context window--expressed naturally through SPL's existing CTE syntax with no new constructs, decomposing a large query into a Map-Reduce pipeline that reduces attention cost from O(N^2) to O(N^2/k) and runs identically on cloud (parallel) or local hardware (sequential); (4) SPL-flow, a declarative agentic orchestration layer with resilient three-tier provider fallback; and (5) BENCHMARK for parallel multi-model comparison with automatic winner persistence. We provide a formal EBNF grammar, two pip-installable Python packages (spl-llm, spl-flow), and comparison against Prompty, DSPy, and LMQL. SPL reduces prompt boilerplate by 65% on average, surfaces a 68x cost spread across model tiers as a pre-execution signal, and runs the identical .spl script at $0.002 on OpenRouter or at zero marginal cost on a local Ollama instance--without modification.

</details>
